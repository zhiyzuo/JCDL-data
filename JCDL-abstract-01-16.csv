abstract,citedby-count,dc:publisher,eid,prism:aggregationType,prism:coverDate,prism:doi,prism:endingPage,prism:isbn,prism:issn,prism:pageRange,prism:publicationName,prism:startingPage,prism:url,prism:volume,scopus-id,source-id,srctype,title
"With the number and types of documents in digital library systems increasing, tools for automatically organizing and presenting the content have to be found. While many approaches focus on topic-based organization and structuring, hardly any system incorporates automatic structural analysis and representation. Yet, genre information (unconsciously) forms one of the most distinguishing features in conventional libraries and in information searches. In this paper we present an approach to automatically analyze the structure of documents and to integrate this information into an automatically created content-based organization. In the resulting visualization, documents on similar topics, yet representing different genres, are depicted as books in differing colors. This representation supports users intuitively in locating relevant information presented in a relevant form. Copyright 2001 ACM.",9,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901253569,Conference Proceeding,2001-01-01,10.1145/379437.379439,10,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,1-10,Proceedings of the ACM International Conference on Digital Libraries,1,http://api.elsevier.com/content/abstract/scopus_id/84901253569,,84901253569,62702,p,Integrating automatic genre analysis into digital libraries
"Text categorization is typically formulated as a concept learning problem where each instance is a single isolated document. In this paper we are interested in a more general formulation where documents are organized as page sequences, as naturally occurring in digital libraries of scanned books and magazines. We describe a method for classifying pages of sequential OCR text documents into one of several assigned categories and suggest that taking into account contextual information provided by the whole page sequence can significantly improve classification accuracy. The proposed architecture relies on hidden Markov models whose emissions are bag-of-words according to a multinomial word event model, as in the generative portion of the Naive Bayes classifier. Our results on a collection of scanned journals from the Making of America project confirm the importance of using whole page sequences. Empirical evaluation indicates that the error rate (as obtained by running a plain Naive Bayes classifier on isolated page) can be roughly reduced by half if contextual information is incorporated. Copyright 2001 ACM.",2,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901254140,Conference Proceeding,2001-01-01,10.1145/379437.379440,20,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,11-20,Proceedings of the ACM International Conference on Digital Libraries,11,http://api.elsevier.com/content/abstract/scopus_id/84901254140,,84901254140,62702,p,Text categorization for multi-page documents: A hybrid Naive Bayes HMM approach
"This paper describes a system for the automated assignment of authorized names. A collaboration between a computer scientist and a librarian, the system provides for enhanced end-user searching of digital libraries without increasing drastically the cost and effort of creating a digital library. It is a part of the workflow management system of the Levy Sheet Music Project. Copyright 2001 ACM.",12,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901279132,Conference Proceeding,2001-01-01,10.1145/379437.379441,22,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,21-22,Proceedings of the ACM International Conference on Digital Libraries,21,http://api.elsevier.com/content/abstract/scopus_id/84901279132,,84901279132,62702,p,Automated name authority control
"We propose a novel approach for automatic generation of topically-related events from multi-lingual news sources. Named entity terms are extracted automatically from the news content. Together with the content terms, they constitute the basis of representing the story. We employ transformation-based linguistic tagging approach for named entity extraction. Two methods of gross translation on Chinese story representation into English have been implemented. The first approach uses only a bilingual dictionary. The second method makes use of a parallel corpus as an additional resource. Unsupervised learning is employed to discover the events. Copyright 2001 ACM.",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901274621,Conference Proceeding,2001-01-01,10.1145/379437.379442,24,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,23-24,Proceedings of the ACM International Conference on Digital Libraries,23,http://api.elsevier.com/content/abstract/scopus_id/84901274621,,84901274621,62702,p,Automatic event generation from multi-lingual news stories
"A service is described to help enable digital libraries for education, such as the NSDL, to serve as collaboration spaces for the creation, modification and use of active learning experiences. The goal is to redefine the line between those activities that fall within the domain of computer programming and those that fall within the domain of content authoring. The current location of this line, as defined by web technologies, is such that far too much of the design and development process is in the domain of software creation. This paper explores the definition and use of ""linked active content"", which builds on the hypertext paradigm by extending it to support active content. This concept has community development advantages, since it provides an authoring paradigm that supports contributions from a more diverse audience, including especially those who have substantial classroom and pedagogical expertise but lack programming expertise. It also promotes the extraction of content from software so that collections may be better organized and more easily repurposed to meet the needs of a diverse audience of educators and students. Copyright 2001 ACM.",2,Association for Computing Machinery acmhelpacm.org,2-s2.0-0041390750,Conference Proceeding,2001-01-01,10.1145/379437.379443,32,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,25-32,Proceedings of the ACM International Conference on Digital Libraries,25,http://api.elsevier.com/content/abstract/scopus_id/0041390750,,0041390750,62702,p,Linked active content: A service for digital libraries for education
"We believe that an important category of SMET digital library content will be highly interactive, explorable microworlds for teaching science, mathematics, and engineering concepts. Such environments have proved extraordinarily time-consuming and difficult to produce, however, threatening the goals of widespread creation and use. One proposed solution for accelerating production has been the creation of repositories of reusable software components or learning objects. Programmers would use such components to rapidly assemble larger-scale environments. Although many agree on the value of this approach, few repositories of such components have been successfully created. We suggest some reasons for the lack of expected results and propose two strategies for developing such repositories. We report on a case study that provides a proof of concept of these strategies. Copyright 2001 ACM.",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901257016,Conference Proceeding,2001-01-01,10.1145/379437.379444,40,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,33-40,Proceedings of the ACM International Conference on Digital Libraries,33,http://api.elsevier.com/content/abstract/scopus_id/84901257016,,84901257016,62702,p,A component repository for learning objects: A progress report
"In this paper we report the findings from a field study of legal research in a first-tier law school and on the resulting redesign of XLibris, a next-generation e-book. We first characterize a work setting in which we expected an e-book to be a useful interface for reading and otherwise using a mix of physical and digital library materials, and explore what kinds of reading-related functionality would bring value to this setting. We do this by describing important aspects of legal research in a heterogeneous information environment, including mobility, reading, annotation, link following and writing practices, and their general implications for design. We then discuss how our work with a user community and an evolving e-book prototype allowed us to examine tandem issues of usability and utility, and to redesign an existing e-book user interface to suit the needs of law students. The study caused us to move away from the notion of a stand-alone reading device and toward the concept of a document laptop, a platform that would provide wireless access to information resources, as well as support a fuller spectrum of reading-related activities. Copyright 2001 ACM.",3,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901252462,Conference Proceeding,2001-01-01,10.1145/379437.379445,48,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,41-48,Proceedings of the ACM International Conference on Digital Libraries,41,http://api.elsevier.com/content/abstract/scopus_id/84901252462,,84901252462,62702,p,Designing e-books for legal research
"Interoperability is a fundamental challenge for networked information discovery and retrieval. Often treated monolithically in the literature, interoperability is multifaceted and can be analyzed into different types and levels. This paper discusses an approach to map the interoperability landscape for networked information retrieval as part of an interoperability assessment research project. Copyright 2001 ACM.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901255939,Conference Proceeding,2001-01-01,10.1145/379437.379447,51,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,50-51,Proceedings of the ACM International Conference on Digital Libraries,50,http://api.elsevier.com/content/abstract/scopus_id/84901255939,,84901255939,62702,p,Mapping the interoperability landscape for networked information retrieval
"This short paper describes the construction and application of Cross-Domain Information Servers using features of the standard Z39.50 information retrieval protocol[11]. We use the Z39.50 Explain Database to determine the databases and indexes of a given server, then use the SCAN facility to extract the contents of the indexes. This information is used to build ""collection documents"" that can be retrieved using probabilistic retrieval algorithms. Copyright 2001 ACM.",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901280219,Conference Proceeding,2001-01-01,10.1145/379437.379448,53,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,52-53,Proceedings of the ACM International Conference on Digital Libraries,52,http://api.elsevier.com/content/abstract/scopus_id/84901280219,,84901280219,62702,p,Distributed resource discovery: Using Z39.50 to build Cross-Domain Information Servers
"The Open Archives Initiative (OAI) develops and promotes interoperability solutions that aim to facilitate the efficient dissemination of content. The roots of the OAI lie in the E-Print community. Over the last year its focus has been extended to include all content providers. This paper describes the recent history of the OAI - its origins in promoting E-Prints, the broadening of its focus, the details of its technical standard for metadata harvesting, the applications of this standard, and future plans. Copyright 2001 ACM.",24,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901277116,Conference Proceeding,2001-01-01,10.1145/379437.379449,62,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,54-62,Proceedings of the ACM International Conference on Digital Libraries,54,http://api.elsevier.com/content/abstract/scopus_id/84901277116,,84901277116,62702,p,The Open Archives Initiative: Building a low-barrier interoperability framework
"The Open Archives Initiative (OAI) is an organization dedicated to solving problems of digital library interoperability by defining simple protocols, most recently for the exchange of metadata. The success of such an activity requires vigilance in specification of the protocol as well as standardization of implementation. The lack of standardized implementation is a substantial barrier to interoperability in many existing client/server protocols. To avoid this pitfall we developed the Repository Explorer, a tool that supports manual and automated protocol testing. This tool has a significant impact on simplifying development of interoperability interfaces and increasing the level of confidence of early adopters of the technology, thus exemplifying the positive impact of exhaustive testing and quality assurance on interoperability ventures. Copyright 2001 ACM.",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901282004,Conference Proceeding,2001-01-01,10.1145/379437.379450,64,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,63-64,Proceedings of the ACM International Conference on Digital Libraries,63,http://api.elsevier.com/content/abstract/scopus_id/84901282004,,84901282004,62702,p,Enforcing interoperability with the Open Archives Initiative Repository Explorer
"The usefulness of the many on-line journals and scientific digital libraries that exist today is limited by the lack of a service that can federate them through a unified interface. The Open Archive Initiative (OAI) is one major effort to address technical interoperability among distributed archives. The objective of OAI is to develop a framework to facilitate the discovery of content in distributed archives. In this paper, we describe our experience and lessons learned in building Arc, the first federated searching service based on the OAI protocol. Arc harvests metadata from several OAI compliant archives, normalizes them, and stores them in a search service based on a relational database (MySQL or Oracle). At present we have over 165K metadata records from 16 data providers from various domains. Copyright 2001 ACM.",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901270823,Conference Proceeding,2001-01-01,10.1145/379437.379451,66,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,65-66,Proceedings of the ACM International Conference on Digital Libraries,65,http://api.elsevier.com/content/abstract/scopus_id/84901270823,,84901270823,62702,p,Arc - An OAI service provider for cross-archive searching
"Increasingly, digital libraries are being defined that collect pointers to World-Wide Web based resources rather than hold the resources themselves. Maintaining these collections is challenging due to distributed document ownership and high fluidity. Typically a collection's maintainer has to assess the relevance of changes with little system aid. In this paper, we describe the Walden's Paths Path Manager, which assists a maintainer in discovering when relevant changes occur to linked resources. The approach and system design was informed by a study of how humans perceive changes of Web pages. The study indicated that structural changes are key in determining the overall change and that presentation changes are considered irrelevant. Copyright 2001 ACM.",5,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901276495,Conference Proceeding,2001-01-01,10.1145/379437.379973,76,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,67-76,Proceedings of the ACM International Conference on Digital Libraries,67,http://api.elsevier.com/content/abstract/scopus_id/84901276495,,84901276495,62702,p,Managing change on the Web
"We describe the preliminary results from a pilot study, which assessed the perceived reputation - authority and trustworthiness - of the output from five WWW indexing/ranking tools. The tools are based on three techniques: external link structures, internal content, or human selection/indexing. Twenty-two participants reviewed the output from each tool and assessed the reputation of the retrieved sites. Copyright 2001 ACM.",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901250325,Conference Proceeding,2001-01-01,10.1145/379437.379453,78,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,77-78,Proceedings of the ACM International Conference on Digital Libraries,77,http://api.elsevier.com/content/abstract/scopus_id/84901250325,,84901250325,62702,p,Measuring the reputation of web sites: A preliminary exploration
"Searching for useful information on the World Wide Web has become increasingly difficult. While Internet search engines have been helping people to search on the web, low recall rate and outdated indexes have become more and more problematic as the web grows. In addition, search tools usually present to the user only a list of search results, failing to provide further personalized analysis which could help users identify useful information and comprehend these results. To alleviate these problems, we propose a client-based architecture that incorporates noun phrasing and self-organizing map techniques. Two systems, namely CI Spider and Meta Spider, have been built based on this architecture. User evaluation studies have been conducted and the findings suggest that the proposed architecture can effectively facilitate web search and analysis. Copyright 2001 ACM.",5,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901250116,Conference Proceeding,2001-01-01,10.1145/379437.379454,87,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,79-87,Proceedings of the ACM International Conference on Digital Libraries,79,http://api.elsevier.com/content/abstract/scopus_id/84901250116,,84901250116,62702,p,Personalized spiders for web search and analysis
"In this paper, we describe Salticus, a web crawler that learns from users' web browsing activity. Salticus enables users to build a personal digital library by collecting documents and generalizing over the user's choices. Copyright 2001 ACM.",2,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901268877,Conference Proceeding,2001-01-01,10.1145/379437.379455,89,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,88-89,Proceedings of the ACM International Conference on Digital Libraries,88,http://api.elsevier.com/content/abstract/scopus_id/84901268877,,84901268877,62702,p,Salticus: Guided crawling for personal digital libraries
"Naturally, digital library systems focus principally on the reader: the consumer of the material that constitutes the library. In contrast, this paper describes an interface that makes it easy for people to build their own library collections. Collections may be built and served locally from the user's own web server, or (given appropriate permissions) remotely on a shared digital library host. End users can easily build new collections styled after existing ones from material on the Web or from their local files - or both, and collections can be updated and new ones brought on-line at any time. The interface, which is intended for non-professional end users, is modeled after widely used commercial software installation packages. Lest one quail at the prospect of end users building their own collections on a shared system, we also describe an interface for the administrative user who is responsible for maintaining a digital library installation. Copyright 2001 ACM.",5,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901280381,Conference Proceeding,2001-01-01,10.1145/379437.379458,103,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,94-103,Proceedings of the ACM International Conference on Digital Libraries,94,http://api.elsevier.com/content/abstract/scopus_id/84901280381,,84901280381,62702,p,Power to the people: End-user building of digital library collections
"The DL offers the possibility of collaborative scholarship, but the appropriate tools must be integrated within the DL to serve this purpose. We propose aWeb-based tool to guide controlled data annotations that link items in the DL to a domain-specific ontology and which provide an effective means to query a data collection in an abstract and uniform fashion. Copyright 2001 ACM.",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901257543,Conference Proceeding,2001-01-01,10.1145/379437.379460,105,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,104-105,Proceedings of the ACM International Conference on Digital Libraries,104,http://api.elsevier.com/content/abstract/scopus_id/84901257543,,84901257543,62702,p,Web-based scholarship: Annotating the digital library
"Silver is an authoring tool that aims to allow novice users to edit digital video. The goal is to make editing of digital video as easy as text editing. Silver provides multiple coordinated views, including project, source, outline, subject, storyboard, textual transcript and timeline views. Selections and edits in any view are synchronized with all other views. A variety of recognition algorithms are applied to the video and audio content and then are used to aid in the editing tasks. The Informedia Digital Library supplies the recognition algorithms and metadata used to support intelligent editing, and Informedia also provides search and a repository. The metadata includes shot boundaries and a time-synchronized transcript, which are used to support intelligent selection and intelligent cut/copy/paste. Copyright 2001 ACM.",3,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901276776,Conference Proceeding,2001-01-01,10.1145/379437.379461,115,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,106-115,Proceedings of the ACM International Conference on Digital Libraries,106,http://api.elsevier.com/content/abstract/scopus_id/84901276776,,84901276776,62702,p,A multi-view intelligent editor for digital video libraries
"This paper introduces VideoGraph, a new tool for video mining and visualizing the structure of the plot of a video sequence. The main idea is to ""stitch"" together similar scenes which are apart in time. We give a fast algorithm to do stitching and we show case studies, where our approach (a) gives good features for classification (91% accuracy), and (b) results in VideoGraphs which reveal the logical structure of the plot of the video clips. Copyright 2001 ACM.",1,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901259223,Conference Proceeding,2001-01-01,10.1145/379437.379462,117,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,116-117,Proceedings of the ACM International Conference on Digital Libraries,116,http://api.elsevier.com/content/abstract/scopus_id/84901259223,,84901259223,62702,p,VideoGraph: A new tool for video mining and classification
"This note summarizes the system development activities of the Alexandria Digital Earth Prototype (ADEPT) Project.5 ADEPT and the Alexandria Digital Library (ADL) are, respectively, the research and operational components of the Alexandria Digital Library Project. The goal of ADEPT is to build a distributed digital library (DL) of personalized collections of geospatially referenced information. This DL is characterized by: (1) services for building, searching, and using personalized collections; (2) collections of georeferenced multimedia information, including dynamic simulation models of spatially distributed processes; and (3) user interfaces employing the concept of a "" Digital Earth"". Important near-term objectives for ADEPT are to build prototype collections that support undergraduate learning in physical, human, and cultural geography and related disciplines, and then to evaluate whether using such resources helps students learn to reason scientifically. Collections and services developed by ADEPT researchers will migrate to ADL as they mature. Copyright 2001 ACM.",3,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901290278,Conference Proceeding,2001-01-01,10.1145/379437.379463,119,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,118-119,Proceedings of the ACM International Conference on Digital Libraries,118,http://api.elsevier.com/content/abstract/scopus_id/84901290278,,84901290278,62702,p,The Alexandria Digital Earth Prototype system
"This paper reviews considerations associated with implementing the Alexandria Digital Earth Prototype (ADEPT) in undergraduate geography education by means of Iscapes (or Information landscapes). In particular, we are interested in how Iscapes might be used to promote scientific thinking by undergraduate students. Based upon an ongoing educational needs assessment, we present a set of conceptual principles that might selectively be implemented in the design of educational digital library environments. Copyright 2001 ACM.",3,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901267812,Conference Proceeding,2001-01-01,10.1145/379437.379465,121,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,120-121,Proceedings of the ACM International Conference on Digital Libraries,120,http://api.elsevier.com/content/abstract/scopus_id/84901267812,,84901267812,62702,p,Iscapes: Digital libraries environments for the promotion of scientific thinking by undergraduates in geography
"This paper describes a new project funded in the UK by the Joint Information Systems Committee, to develop a virtual learning environment which combines a new awareness of internet sources such as bibliographic databases and full-text electronic journals with a sophisticated access management component which permits single sign-on authentication. Copyright 2001 ACM.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901278123,Conference Proceeding,2001-01-01,10.1145/379437.379466,123,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,122-123,Proceedings of the ACM International Conference on Digital Libraries,122,http://api.elsevier.com/content/abstract/scopus_id/84901278123,,84901278123,62702,p,Project ANGEL: An open virtual learning environment with sophisticated access management
"In this paper, we describe the NBDL (National Biology Digital Library) project, one of the six CIS (Core Integration System) projects of the NSF NSDL (National SMETE Digital Library) Program. Copyright 2001 ACM.",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901281476,Conference Proceeding,2001-01-01,10.1145/379437.379467,125,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,124-125,Proceedings of the ACM International Conference on Digital Libraries,124,http://api.elsevier.com/content/abstract/scopus_id/84901281476,,84901281476,62702,p,NBDL: A CIS framework for NSDL
"The potential of automatically generated indexes for information access has been recognized for several decades (e.g., Bush 1945 [2], Edmundson and Wyllys 1961 [4]), but the quantity of text and the ambiguity of natural language processing have made progress at this task more difficult than was originally foreseen. Recently, a body of work on development of interactive systems to support phrase browsing has begun to emerge (e.g., Anick and Vaithyanathan 1997 [1], Gutwin et al. [10], Nevill-Manning et al. 1997 [17], Godby and Reighart 1998 [9]). In this paper, we consider two issues related to the use of automatically identified phrases as index terms in a dynamic text browser (DTB), a user-centered system for navigating and browsing index terms: 1) What criteria are useful for assessing the usefulness of automatically identified index terms? and 2) Is the quality of the terms identified by automatic indexing such that they provide useful access to document content? The terms that we focus on have been identified by LinkIT, a software tool for identifying significant topics in text [7]. Over 90% of the terms identified by LinkIT are coherent and therefore merit inclusion in the dynamic text browser. Terms identified by LinkIT are input to Intell-Index, a prototype DTB that supports interactive navigation of index terms. The distinction between phrasal heads (the most important words in a coherent term) and modifiers serves as the basis for a hierarchical organization of terms. This linguistically motivated structure helps users to efficiently browsing and disambiguate terms. We conclude that the approach to information access discussed in this paper is very promising, and also that there is much room for further research. In the meantime, this research is a contribution to the establishment of a solid foundation for assessing the usability of terms in phrase browsing applications. Copyright 2001 ACM.",5,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901269347,Conference Proceeding,2001-01-01,10.1145/379437.379468,134,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,126-134,Proceedings of the ACM International Conference on Digital Libraries,126,http://api.elsevier.com/content/abstract/scopus_id/84901269347,,84901269347,62702,p,Automatic identification and organization of index terms for interactive browsing
"The Internet has considerably empowered libraries and changed common perception of what they entail. Public libraries, in particular, are using technological advancements to expand their range of services and enhance their civic roles. Providing community information (CI) in innovative, digital forms via community networks is one way in which public libraries are facilitating everyday information needs. These networks have been lauded for their potential to strengthen physical communities through increasing information flow about local services and events, and through facilitating civic interaction. However, little is known about how the public uses such digital services and what barriers they encounter. This paper presents findings about how digital CI systems benefit physical communities based on extensive case studies in three states. At each site, rich data were collected using online surveys, field observation, in-depth interviews and focus groups with Internet users, human service providers and library staff. Both the online survey and the follow-up interviews with respondents were based on sense-making theory. In our paper we discuss our findings regarding: (1) how the public is using digital CI systems for daily problem solving, and (2) the types of barriers they encounter. Suggestions for improving digital CI systems are provided. Copyright 2001 ACM.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901264185,Conference Proceeding,2001-01-01,10.1145/379437.379470,143,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,136-143,Proceedings of the ACM International Conference on Digital Libraries,136,http://api.elsevier.com/content/abstract/scopus_id/84901264185,,84901264185,62702,p,Public use of digital community information systems: Findings from a recent study with implications for system design
The UK's development of a Distributed National Electronic Resource (DNER) is being subjected to intensive formative evaluation by a multi-disciplinary team. In this paper the Project Director reports on initial actions designed to characterise the DNER from multi-stakeholder perspectives. Copyright 2001 ACM.,0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901270235,Conference Proceeding,2001-01-01,10.1145/379437.379471,145,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,144-145,Proceedings of the ACM International Conference on Digital Libraries,144,http://api.elsevier.com/content/abstract/scopus_id/84901270235,,84901270235,62702,p,Evaluating the distributed national electronic resource
"Digital libraries, particularly those with a community-based governance structure, are best designed in a collaborative setting. In this paper, we compare our experience using two design methods: a Task-centered method that draws upon a group's strength for eliciting and formulating tasks, and a Use Case method that tends to require a focus on defining an explicit process for tasks. We discuss how these methods did and did not work well in a collaborative setting. Copyright 2001 ACM.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901279083,Conference Proceeding,2001-01-01,10.1145/379437.379472,147,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,146-147,Proceedings of the ACM International Conference on Digital Libraries,146,http://api.elsevier.com/content/abstract/scopus_id/84901279083,,84901279083,62702,p,Collaborative design with use case scenarios
"This paper describes an evaluation of the Kea automatic keyphrase extraction algorithm. Tools that automatically identify keyphrases are desirable because document keyphrases have numerous applications in digital library systems, but are costly and time consuming to manually assign. Keyphrase extraction algorithms are usually evaluated by comparison to author-specified keywords, but this methodology has several well-known shortcomings. The results presented in this paper are based on subjective evaluations of the quality and appropriateness of keyphrases by human assessors, and make a number of contributions. First, they validate previous evaluations of Kea that rely on author keywords. Second, they show Kea's performance is comparable to that of similar systems that have been evaluated by human assessors. Finally, they justify the use of author keyphrases as a performance metric by showing that authors generally choose good keywords. Copyright 2001 ACM.",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901280141,Conference Proceeding,2001-01-01,10.1145/379437.379473,156,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,148-156,Proceedings of the ACM International Conference on Digital Libraries,148,http://api.elsevier.com/content/abstract/scopus_id/84901280141,,84901280141,62702,p,"Human evaluation of Kea, an automatic keyphrasing system"
"In this paper, I describe the design of a collection review policy for the Digital Library for Earth System Education (DLESE). A distinctive feature of DLESE as a digital library is the 'DLESE community,' composed of voluntary members who contribute metadata and resource reviews to DLESE. As the DLESE community is open, the question of how to evaluate community contributions is a crucial part of the review policy design process. In this paper, technological frames theory is used to analyse this design process by looking at how the designers work with two differing definitions of the 'peer reviewer,' (a) peer reviewer as arbiter or editor, and (b) peer reviewer as colleague. Content analysis of DLESE documents shows that these frames can in turn be related to two definitions that DLESE offers of itself: DLESE as a library, and DLESE as a digital artifact. The implications of the presence of divergent technological frames for the design process are summarised, and some suggestions for future research are outlined. Copyright 2001 ACM.",5,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901286489,Conference Proceeding,2001-01-01,10.1145/379437.379474,164,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,157-164,Proceedings of the ACM International Conference on Digital Libraries,157,http://api.elsevier.com/content/abstract/scopus_id/84901286489,,84901286489,62702,p,Community design of DLESE's collections review policy: A technological frames analysis
"There is a global trend towards extending legal deposit to include digital publications in order to maintain comprehensive national archives. However, including digital publications in legal deposit regulation is not enough to ensure the long-term preservation of these publications. Concepts, principles and practices accepted and understood in the print environment, may have new meanings or no longer be appropriate in a networked environment. Mechanisms for identifying, selecting and depositing digital material either do not exist, or are inappropriate, for some kinds of digital publication. Work on developing digital preservation strategies is at an early stage. National and other deposit libraries are at the forefront of research and develop in this area, often working in partnership with other libraries, publishers and technology vendors. Most work is of a technical nature. There is some work on developing policies and strategies for managing digital resources. However, not all management issues or users needs are being addressed. Copyright 2001 ACM.",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901276669,Conference Proceeding,2001-01-01,10.1145/379437.379475,173,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,165-173,Proceedings of the ACM International Conference on Digital Libraries,165,http://api.elsevier.com/content/abstract/scopus_id/84901276669,,84901276669,62702,p,Legal deposit of digital publications: A review of research and development activity
"The CAPM Project features the development and evaluation of an automated, robotic on-demand scanning system for materials at remote locations. To date, we have developed a book retrieval robot and a valuation analysis framework for evaluating CAPM. We intend to augment CAPM by exploring approaches for automated page turning and improved valuation. These extensions will results in a more fully automated CAPM system and a valuation framework that will not only be useful for assessing CAPM specifically, but also for library services and functions generally. Copyright 2001 ACM.",4,Association for Computing Machineryacmhelpacm.org,2-s2.0-1642295308,Conference Proceeding,2001-01-01,10.1145/379437.379476,175,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,174-175,Proceedings of the ACM International Conference on Digital Libraries,174,http://api.elsevier.com/content/abstract/scopus_id/1642295308,,1642295308,62702,p,Comprehensive access to printed materials (CAPM)
"Technology does not develop independently of its social context. Rather, there is a range of social, cultural and economic factors (in addition to technical factors) that define the parameters for the development and use of technologies. This paper presents a case study of the social shaping of one aspect of digital libraries, the development of national union catalogs (NUC), in four countries of Central and Eastern Europe (CEE). It examines the specific choices and values that are embedded in the design of a NUC, and how these might be transferred to other cultural contexts. Copyright 2001 ACM.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901251114,Conference Proceeding,2001-01-01,10.1145/379437.379477,177,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,176-177,Proceedings of the ACM International Conference on Digital Libraries,176,http://api.elsevier.com/content/abstract/scopus_id/84901251114,,84901251114,62702,p,Technology and values: Lessons from Central and Eastern Europe
"The aim of the work reported here was to better understand the usability issues raised when digital libraries are used in a natural setting. The method used was a protocol analysis of users working on a task of their own choosing to retrieve documents from publicly available digital libraries. Various classes of usability difficulties were found. Here, we focus on use in context - that is, usability concerns that arise from the fact that libraries are accessed in particular ways, under technically and organisationally imposed constraints, and that use of any particular resource is discretionary. The concepts from an Interaction Framework, which provides support for reasoning about patterns of interaction between users and systems, are applied to understand interaction issues. Copyright 2001 ACM.",9,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901288755,Conference Proceeding,2001-01-01,10.1145/379437.379479,188,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,179-188,Proceedings of the ACM International Conference on Digital Libraries,179,http://api.elsevier.com/content/abstract/scopus_id/84901288755,,84901288755,62702,p,Use of multiple digital libraries: A case study
"In this paper we describe the results of an ethnographic study of the information behaviourss of university technical support workers and their information needs. The study looked at how the group identified, located and used information from a variety of sources to solve problems arising in the course of their work. The results of the investigation are discussed in the context of the feasibility of developing a potential information base that could be used by all members of the group. Whilst a number of their requirements would easily be fulfilled by the use of a digital library, other requirements would not. The paper illustrates the limitations of a digital library with respect to the information behaviourss of this group of subjects and focuses on why a digital library would not appear to be the ideal support tool for their work. Copyright 2001 ACM.",1,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901288189,Conference Proceeding,2001-01-01,10.1145/379437.379480,198,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,189-198,Proceedings of the ACM International Conference on Digital Libraries,189,http://api.elsevier.com/content/abstract/scopus_id/84901288189,,84901288189,62702,p,An ethnographic study of technical support workers: Why we didn't build a tech support digital library
"In developing recommendation services for a new digital library called iLumina (www.ilumina-project.org), we are faced with several challenges related to the nature of the data we have available. The availability and consistency of data associated with iLumina is likely to be highly variable. Any recommendation strategy we develop must be able to cope with this fact, while also being robust enough to adapt to additional types of data available over time as the digital library develops. In this paper we describe the challenges we are faced with in developing a system that can provide our users with good, consistent recommendations under changing and uncertain conditions. Copyright 2001 ACM.",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901255977,Conference Proceeding,2001-01-01,10.1145/379437.379483,200,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,199-200,Proceedings of the ACM International Conference on Digital Libraries,199,http://api.elsevier.com/content/abstract/scopus_id/84901255977,,84901255977,62702,p,Developing recommendation services for a digital library with uncertain and changing data
"In this paper we present DEFINDER, a rule-based system that mines consumer-oriented full text articles in order to extract definitions and the terms they define. This research is part of Digital Library Project at Columbia University, entitled PERSIVAL (PErsonalized Retrieval and Summarization of Image, Video and Language resources) [5]. One goal of the project is to present information to patients in language they can understand. A key component of this stage is to provide accurate and readable lay definitions for technical terms, which may be present in articles of intermediate complexity. The focus of this short paper is on quantitative and qualitative evaluation of the DEFINDER system [3]. Our basis for comparison was definitions from Unified Medical Language System (UMLS), On-line Medical Dictionary (OMD) and Glossary of Popular and Technical Medical Terms (GPTMT). Quantitative evaluations show that DEFINDER obtained 87% precision and 75% recall and reveal the incompleteness of existing resources and the ability of DEFINDER to address gaps. Qualitative evaluation shows that the definitions extracted by our system are ranked higher in terms of user-based criteria of usability and readability than definitions from on-line specialized dictionaries. Thus the output of DEFINDER can be used to enhance existing specialized dictionaries, and also as a key feature in summarizing technical articles for non-specialist users. Copyright 2001 ACM.",2,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901249399,Conference Proceeding,2001-01-01,10.1145/379437.379488,202,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,201-202,Proceedings of the ACM International Conference on Digital Libraries,201,http://api.elsevier.com/content/abstract/scopus_id/84901249399,,84901249399,62702,p,Evaluation of DEFINDER: A system to mine definitions from consumer-oriented medical text
"In this paper, we present an overview of the Virtual Data Center (VDC) software, an open-source digital library system for the management and dissemination of distributed collections of quantitative data. (see 〈http://TheData.org〉). The VDC functionality provides everything necessary to maintain and disseminate an individual collection of research studies, including facilities for the storage, archiving, cataloging, translation, and on-line analysis of a particular collection. Moreover, the system provides extensive support for distributed and federated collections including: location-independent naming of objects, distributed authentication and access control, federated metadata harvesting, remote repository caching, and distributed 'virtual' collections of remote objects. Copyright 2001 ACM.",2,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901272501,Conference Proceeding,2001-01-01,10.1145/379437.379491,204,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,203-204,Proceedings of the ACM International Conference on Digital Libraries,203,http://api.elsevier.com/content/abstract/scopus_id/84901272501,,84901272501,62702,p,Overview of the Virtual Data Center project and software
"In addition to preserving and retrieving digital information, digital libraries need to allow data scholars to create post-publication references to objects within files and across collections of files. Such references can serve as new metadata in their own right and should also provide methods for efficiently extracting the subset of the original data that belongs to the object. This paper discusses some ideas about the requirements for such references within the context of long-term, active archival, where neither the data format nor the institutional basis can be guaranteed to remain constant.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901262814,Conference Proceeding,2001-01-01,10.1145/379437.379494,206,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,205-206,Proceedings of the ACM International Conference on Digital Libraries,205,http://api.elsevier.com/content/abstract/scopus_id/84901262814,,84901262814,62702,p,Digital libraries and data scholarship
"In this paper we describe how we combined SDLIP and STARTS, two complementary protocols for searching over distributed document collections. The resulting protocol, which we call SDARTS, is simple yet expressible enough to enable building sophisticated metasearch engines. SDARTS can be viewed as an instantiation of SDLIP with metasearch-specific elements from STARTS. We also report on our experience building three SDARTS-compliant wrappers: for locally available plain-text document collections, for locally available XML document collections, and for external webaccessible collections. These wrappers were developed to be easily customizable for new collections. Our work was developed as part of Columbia University's Digital Libraries Initiative-Phase 2 (DLI2) project, which involves the departments of Computer Science, Medical Informatics, and Electrical Engineering, the Columbia University libraries, and a large number of industrial partners. The main goal of the project is to provide personalized access to a distributed patient-care digital library. Copyright 2001 ACM.",8,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901246527,Conference Proceeding,2001-01-01,10.1145/379437.379496,214,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,207-214,Proceedings of the ACM International Conference on Digital Libraries,207,http://api.elsevier.com/content/abstract/scopus_id/84901246527,,84901246527,62702,p,SDLIP + STARTS = SDARTS a protocol and toolkit for metasearching
"We consider the processing of digital library queries, consisting of a text component and a structured component in distributed environments. The text component can be processed using techniques given in previous papers such as [7, 8, 11]. In this paper, we concentrate on the processing of the structured component of a distributed query. Histograms are constructed and algorithms are given to provide estimates of the desirabilities of the databases with respect to the given query. Databases are selected in descending order of desirability. An algorithm is also given to select tuples from the selected databases. Experimental results are given to show that the techniques provided here are effective and eficient. Copyright 2001 ACM.",5,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901283922,Conference Proceeding,2001-01-01,10.1145/379437.379504,222,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,215-222,Proceedings of the ACM International Conference on Digital Libraries,215,http://api.elsevier.com/content/abstract/scopus_id/84901283922,,84901283922,62702,p,Database selection for processing k nearest neighbors queries in distributed environments
"In February 2001 the Panel on Digital Libraries of the President's Information Technology Advisory Committee issued a report entitled ""Digital Libraries: Universal Access to Human Knowledge."" This JCDL panel, which consists of two members of the PITAC Panel on Digital Libraries and representatives of key Federal science and digital library agencies who had briefed the Panel, will discuss the report's findings and recommendations and how the report is and can be helpful in improving the development and use of digital libraries. Copyright is held by the author/owner(s).",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-78650633562,Conference Proceeding,2001-01-01,10.1145/379437.379509,225,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,223-225,Proceedings of the ACM International Conference on Digital Libraries,223,http://api.elsevier.com/content/abstract/scopus_id/78650633562,,78650633562,62702,p,The President's Information Technology Advisory Committee's February 2001 digital library report and its impact
"We have applied speech recognition and text-mining technologies to a set of recorded outbound marketing calls and analyzed the results. Since speaker-independent speech recognition technology results in a significantly lower recognition rate than that found when the recognizer is trained for a particular speaker, we applied a number of post-processing algorithms to the output of the recognizer to render it suitable for the Textract text mining system. We indexed the call transcripts using a search engine and used Textract and associated Java technologies to place the relevant terms for each document in a relational database. Following a search query, we generated a thumbnail display of the results of each call with the salient terms highlighted. We illustrate these results and discuss their utility. We took the results of these experiments and continued this analysis on a set of talks and presentations. We describe a distinct document genre based on the note-taking concept of document content, and propose a significant new method for measuring speech recognition accuracy. This procedure is generally relevant to the problem of capturing meetings and talks and providing a searchable index of these presentations on the web. Copyright 2001 ACM.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901280945,Conference Proceeding,2001-01-01,10.1145/379437.379655,234,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,226-234,Proceedings of the ACM International Conference on Digital Libraries,226,http://api.elsevier.com/content/abstract/scopus_id/84901280945,,84901280945,62702,p,Building searchable collections of enterprise speech data
The National Gallery of the Spoken Word (NGSW) project is creating a carefully organized on-line repository ofspoken-word collections spanning the 20th century. Unprecedented technical challenges are inherent in the development of an archive ofsuch extensive scale and diversity. This paper describesresearch onthe development of text-free search-engine technology usedto locate requested content in the audio records. A companionpaperin these proceedings addresses watermarking technologiesfor copyright protection. Copyright 2001 ACM.,3,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901265818,Conference Proceeding,2001-01-01,10.1145/379437.379658,236,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,235-236,Proceedings of the ACM International Conference on Digital Libraries,235,http://api.elsevier.com/content/abstract/scopus_id/84901265818,,84901265818,62702,p,Transcript-free search of audio archives for the National Gallery of the Spoken Word
"This is one of two companion papers describing technical challenges faced in the development of the National Gallery of the Spoken Word (NGSW). The present paper describes watermarking technologies for intellectual property protection. Following an introduction to data watermarking, the paper focuses on a new algorithm called transform encryption coding (TEC) and its application to watermarking the NGSW archives. TEC has a number of flexible features that make it amenable to the NGSW development. Copyright 2001 ACM.",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901267719,Conference Proceeding,2001-01-01,10.1145/379437.379660,238,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,237-238,Proceedings of the ACM International Conference on Digital Libraries,237,http://api.elsevier.com/content/abstract/scopus_id/84901267719,,84901267719,62702,p,Audio watermarking techniques for the National Gallery of the Spoken Word
"Almost all work on music information retrieval to date has concentrated on music in the audio and event (normally MIDI) domains. However, music in the form of notation, especially Conventional Music Notation (CMN), is of much interest to musically-trained persons, both amateurs and professionals, and searching CMN has great value for digital music libraries. One obvious reason little has been done on music retrieval in CMN form is the overwhelming complexity of CMN, which requires a very substantial investment in programming before one can even begin studying music IR. This paper reports on work adding music-retrieval capabilities to Nightingale®, an existing professional-level music-notation editor. Copyright 2001 ACM.",2,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901273389,Conference Proceeding,2001-01-01,10.1145/379437.379662,246,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,239-246,Proceedings of the ACM International Conference on Digital Libraries,239,http://api.elsevier.com/content/abstract/scopus_id/84901273389,,84901273389,62702,p,Music-notation searching and digital libraries
"In this paper, we carry out a study on classification of musical instruments using a small set of features selected from a broad range of extracted ones by sequential forward feature selection method. Firstly, we extract 58 features for each record in the music database of 351 sound files. Then, the sequential forward selection method is adopted to choose the best feature set to achieve high classification accuracy. Three different classification techniques have been tested out and an accuracy of up to 93% can be achieved by using 19 features. Copyright 2001 ACM.",3,Association for Computing Machinery acmhelpacm.org,2-s2.0-51449105608,Conference Proceeding,2001-01-01,10.1145/379437.379663,248,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,247-248,Proceedings of the ACM International Conference on Digital Libraries,247,http://api.elsevier.com/content/abstract/scopus_id/51449105608,,51449105608,62702,p,Feature selection for automatic classification of musical instrument sounds
"Most online music library catalogues can only be searched by textual metadata. Whilst highly effective - since the rules for maintaining consistency have been refined over many years - this does not allow searching by musical content. Many music librarians are familiar with users humming their enquiries. Most systems providing a ""query by humming"" interface tend to run independently of music library catalogue systems and not offer similar textual metadata searching. This paper discusses the ongoing investigative work on integrating these two types of system conducted as part of the NSF/JISC funded OMRAS project (http://www.omras.org). Copyright 2001 ACM.",2,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901282365,Conference Proceeding,2001-01-01,10.1145/379437.379667,250,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,249-250,Proceedings of the ACM International Conference on Digital Libraries,249,http://api.elsevier.com/content/abstract/scopus_id/84901282365,,84901282365,62702,p,Adding content-based searching to a traditional music library catalogue server
"Three different search effectiveness measures were used to classify 50 question narratives as easy or hard. Each measure was then encoded onto a spatial representation of interquestion similarity. Discriminant analysis based on the resulting map was able to predict question difficulty with approximately 80% accuracy, robust across multiple measures. Implications for the design of digital document collections are discussed. Copyright 2001 ACM.",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901285631,Conference Proceeding,2001-01-01,10.1145/379437.379669,252,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,251-252,Proceedings of the ACM International Conference on Digital Libraries,251,http://api.elsevier.com/content/abstract/scopus_id/84901285631,,84901285631,62702,p,Locating question difficulty through explorations in question space
This paper present an interactive search engine (Website Term Browser) which makes use of phrasal information to process queries and suggest relevant topics in a fully multilingual setting. Copyright 2001 ACM.,1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901261586,Conference Proceeding,2001-01-01,10.1145/379437.379670,254,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,253-254,Proceedings of the ACM International Conference on Digital Libraries,253,http://api.elsevier.com/content/abstract/scopus_id/84901261586,,84901261586,62702,p,Browsing by phrases: Terminological information in interactive multilingual text retrieval
"In this paper, we describe AQSim, an ongoing effort to design and implement a system to manage terabytes of scientific simulation data. The goal of this project is to reduce data storage requirements and access times while permitting ad-hoc queries using statistical and mathematical models of the data. In order to facilitate data exchange between models based on different representations, we are evaluating using the ASCI common data model that is comprised of several layers of increasing semantic complexity. To support queries over the spatial-temporal mesh structured data we are in the process of defining and implementing a grammar for MeshSQL. Copyright 2001 ACM.",2,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901279405,Conference Proceeding,2001-01-01,10.1145/379437.379673,256,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,255-256,Proceedings of the ACM International Conference on Digital Libraries,255,http://api.elsevier.com/content/abstract/scopus_id/84901279405,,84901279405,62702,p,Approximate ad-hoc query engine for simulation data
"We present a system which extracts the genus word and phrase from free-form definition text, entitled LEXING, for Lexical Information from Glossaries. The extractions will be used to build automatically a lexical knowledge base from on-line domain specific glossary sources. We combine statistical and semantic processes to extract these terms, and demonstrate that this combination allows us to predict the genus even in difficult situations such as empty head definitions or verb definitions. We also discuss the use of 'linking prepositions' for use in skipping past empty head genus phrases. This system is part of a project to extract ontological information for energy glossary information. Copyright 2001 ACM.",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901280406,Conference Proceeding,2001-01-01,10.1145/379437.379675,258,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,257-258,Proceedings of the ACM International Conference on Digital Libraries,257,http://api.elsevier.com/content/abstract/scopus_id/84901280406,,84901280406,62702,p,Extracting taxonomic relationships from on-line definitional sources using LEXING
"BoW is an on-line bibliographical repository based on a hierarchical concept index to which entries are linked. Searching in the repository should therefore return matching topics from the hierarchy, rather than just a list of entries. Likewise, when new entries are inserted, a search for relevant topics to which they should be linked is required. We develop a vector-based algorithm that creates keyword vectors for the set of competing topics at each node in the hierarchy, and show how its performance improves when domainspecific features are added (such as special handling of topic titles and author names). The results of a 7-fold cross validation on a corpus of some 3,500 entries with a 5-level index are hit ratios in the range of 89-95%, and most of the misclassifications are indeed ambiguous to begin with. Copyright 2001 ACM.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901288805,Conference Proceeding,2001-01-01,10.1145/379437.379677,267,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,259-267,Proceedings of the ACM International Conference on Digital Libraries,259,http://api.elsevier.com/content/abstract/scopus_id/84901288805,,84901288805,62702,p,Hierarchical indexing and document matching in BoW
"Statistical clustering is critical in designing scalable image retrieval systems. In this paper, we present a scalable algorithm for indexing and retrieving images based on region segmentation. The method uses statistical clustering on region features and IRM (Integrated Region Matching), a measure developed to evaluate overall similarity between images that incorporates properties of all the regions in the images by a region-matching scheme. Compared with retrieval based on individual regions, our overall similarity approach (a) reduces the influence of inaccurate segmentation, (b) helps to clarify the semantics of a particular region, and (c) enables a simple querying interface for region-based im- age retrieval systems. The algorithm has been implemented as a part of our experimental SIMPLI city image retrieval system and tested on large-scale image databases of both general-purpose images and pathology slides. Experiments have demonstrated that this technique maintains the accuracy and robustness of the original system while reducing the matching time significantly. Copyright 2001 ACM.",3,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901285456,Conference Proceeding,2001-01-01,10.1145/379437.379679,277,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,268-277,Proceedings of the ACM International Conference on Digital Libraries,268,http://api.elsevier.com/content/abstract/scopus_id/84901285456,,84901285456,62702,p,Scalable integrated region-based image retrieval using IRM and statistical clustering
"""To catalyze and support continual improvements in the quality of science, mathematics, engineering, and technology (SMET) education, the National Science Foundation (NSF) has established the National Science, Mathematics, Engineering, and Technology Education Digital Library (NSDL) program. The resulting digital library, a network of learning environments and resources for SMET education, will ultimately meet the needs of students and teachers at all levels-K-12, undergraduate, graduate, and lifelong learning-in both individual and collaborative settings, as well as formal and informal modes."" -National Science Foundation, 2001 The national in the NSDL program is quickly becoming a reality with the broad reach of the currently funded projects. This panel session will provide bring together the leaders developing the National SMETE Digital Library to provide a brief background and broad overview of the NSDL program. Panelists will discuss the overall vision and broad steps underway to develop the National SMETE Digital Library. Building the National SMETE Digital Library presents many challenges: • Developing a shared vision for the form and function of the NSDL; • Meeting the needs of diverse learners and of the many disciplines encompassed by the NSDL; • Acquiring input from the community of users to ensure that the NSDL is both used and useable; • Evaluating progress and impacts; • Integrating technologies that already exist, and the development of new technologies; and • Providing mechanisms for sharing and cooperation of knowledge and resources among NSDL collaborators. Copyright is held by the author/owner(s).",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901264039,Conference Proceeding,2001-01-01,10.1145/379437.379680,281,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,278-281,Proceedings of the ACM International Conference on Digital Libraries,278,http://api.elsevier.com/content/abstract/scopus_id/84901264039,,84901264039,62702,p,Panel: The National SMETE Digital Library program
"In this paper, we focus on a user driven approach to improve video indexing. It consists in cumulating the large amount of small, individual efforts done by the users who access information, and to provide a community management mechanism to let users share the elicited knowledge. This technique is currently being developed in the ""OPALES"" environment and tuned up at the ""Institut National de l'Audiovisuel"" (INA), a National Video Library in Paris, to increase the value of its patrimonial video archive collections. It relies on a portal providing private workspaces to end users, so that a large part of their work can be shared between them. The effort for interpreting documents is directly done by the expert users who work for their own job on the archives. OPALES provides an original notion of ""point of view"" to enable the elicitation and the sharing of knowledge between communities of users, without leading to messy structures. The overall result consists in linking exportable private metadata to archive documents and managing the sharing of the elicited knowledge between users communities.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901272428,Conference Proceeding,2001-01-01,10.1145/379437.379683,289,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,282-289,Proceedings of the ACM International Conference on Digital Libraries,282,http://api.elsevier.com/content/abstract/scopus_id/84901272428,,84901272428,62702,p,Cumulating and sharing end users knowledge to improve video indexing in a video digital library
"Surrogates, summaries, and visualizations have been developed and evaluated for accessing a digital video library containing thousands of documents and terabytes of data. These interfaces, formerly implemented within a monolithic stand-alone application, are being migrated to XML and XSLT for delivery through web browsers. The merits of these interfaces are presented, along with a discussion of the benefits in using W3C recommendations such as XML and XSLT for delivering tailored access to video over the web. Copyright 2001 ACM.",2,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901267003,Conference Proceeding,2001-01-01,10.1145/379437.379686,299,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,290-299,Proceedings of the ACM International Conference on Digital Libraries,290,http://api.elsevier.com/content/abstract/scopus_id/84901267003,,84901267003,62702,p,XSLT for tailored access to a digital video library
"This paper is focused on a central aspect in the design of our planned digital library for human movement, i.e. on the aspect of representation and recognition of human activity from video data. The method of representation is important since it has a major impact on the design of all the other building blocks of our system such as the user interface/query block or the activity recognition/storage block. In this paper we evaluate a representation method for human movement that is based on sequences of angular poses and angular velocities of the human skeletal joints, for storage and retrieval of human actions in video databases. The choice of a representation method plays an important role in the database structure, search methods, storage efficiency etc.. For this representation, we develop a novel approach for complex human activity recognition by employing multidimensional indexing combined with temporal or sequential correlation. This scheme is then evaluated with respect to its efficiency in storage and retrieval. For the indexing we use postures of humans in videos that are decomposed into a set of multidimensional tuples which represent the poses/velocities of human body parts such as arms, legs and torso. Three novel methods for human activity recognition are theoretically and experimentally compared. The methods require only a few sparsely sampled human postures. We also achieve speed invariant recognition of activities by eliminating the time factor and replacing it with sequence information. The indexing approach also provides robust recognition and an efficient storage/retrieval of all the activities in a small set of hash tables. Copyright 2001 ACM.",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901264922,Conference Proceeding,2001-01-01,10.1145/379437.379692,309,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,300-309,Proceedings of the ACM International Conference on Digital Libraries,300,http://api.elsevier.com/content/abstract/scopus_id/84901264922,,84901264922,62702,p,Design of a digital library for human movement
"The Open Video project is a collection of public domain digital video available for research and other purposes. The Open Video collection currently consists of approximately 350 video segments, ranging in duration from 10 seconds to 1 hour. Rapid growth for the collection is planned through agreements with other video repository projects and provision for user contribution of video. To handle the increased accession, we are experimenting with ""buckets,"" aggregative intelligent publishing constructs for use in digital libraries. Copyright 2001 ACM.",1,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901288518,Conference Proceeding,2001-01-01,10.1145/379437.379694,311,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,310-311,Proceedings of the ACM International Conference on Digital Libraries,310,http://api.elsevier.com/content/abstract/scopus_id/84901288518,,84901288518,62702,p,A bucket architecture for the Open Video project
"Físchlár is a system for recording, indexing, browsing and playback of broadcast TV programmes which has been operational on our University campus for almost 18 months. In this paper we give a brief overview of how the system operates, how TV programmes are organised for browse/playback and a short report on the system usage by over 900 users in our University. Copyright 2001 ACM.",2,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901285639,Conference Proceeding,2001-01-01,10.1145/379437.379696,313,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,312-313,Proceedings of the ACM International Conference on Digital Libraries,312,http://api.elsevier.com/content/abstract/scopus_id/84901285639,,84901285639,62702,p,The Físchlár digital video system: A digital library of broadcast TV programmes
"This implementation paper introduces principles for the information architecture of an educational digital library, principles that address the distinction between designing digital libraries for education and designing digital libraries for information retrieval in general. Design is a key element of any successful product. Good designers and their designs put technology into the hands of the user, making the product's focus comprehensible and tangible through design. As straightforward as this may appear, the design of learning technologies is often masked by the enabling technology. In fact, they often lack an explicitly stated instructional design methodology. While the technologies are important hurdles to overcome, we advocate learning systems that empower education-driven experiences rather than technology-driven experiences. This work describes a concept for a digital library for science, mathematics, engineering and technology education (SMETE), a library with an information architecture designed to meet learners' and educators' needs. Utilizing a constructivist model of learning, the authors present practical approaches to implementing the information architecture and its technology underpinnings. The authors propose the specifications for the information architecture and a visual design of a digital library for communicating learning to the audience. The design methodology indicates that a scenario-driven design technique sensitive to the contextual nature of learning offers a useful framework for tailoring technologies that help empower, not hinder, the educational sector. Copyright 2001 ACM.",8,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901268889,Conference Proceeding,2001-01-01,10.1145/379437.379699,321,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,314-321,Proceedings of the ACM International Conference on Digital Libraries,314,http://api.elsevier.com/content/abstract/scopus_id/84901268889,,84901268889,62702,p,Design principles for the information architecture of a SMET education digital library
"We describe a model of self-administering data. In this model, a declarative description of how a data object should behave is attached to the object, either by a user or by a data input device. A widespread infrastructure of self-administering data handlers is presumed to exist; these handlers are responsible for carrying out the specifications attached to the data. Typically, the specifications express how and to whom the data should be transferred, how it should be incorporated when it is received, what rights recipients of the data will have with respect to it, and the kind of relation that should exist between distributed copies of the object. Functions such as distributed version control can be implemented on top of the basic handler functions. We suggest that this model can provide superior support for common cooperative functions. Because the model is declarative, users need only express their intentions once in creating a self-administering description, and need not be concerned with manually performing subsequent repetitious operations. Because the model is peer-to-peer, users are less dependent on additional, perhaps costly resources, at least when these are not critical. An initial implementation of the model has been created. We are experimenting with the model both as a tool to aid in digital library functions, and as a possible replacement for some server oriented functions. Copyright 2001 ACM.",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901275836,Conference Proceeding,2001-01-01,10.1145/379437.379703,330,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,322-330,Proceedings of the ACM International Conference on Digital Libraries,322,http://api.elsevier.com/content/abstract/scopus_id/84901275836,,84901275836,62702,p,Toward a model of self-administering data
"In healthcare settings, patients need access to online information that can help them understand their medical situation. Physicians need information that is clinically relevant to an individual patient. In this paper, we present our progress on developing a system, PERSIVAL, that is designed to provide personalized access to a distributed patient care digital library. Using the secure, online patient records at New York Presbyterian Hospital as a user model, PERSIVAL's components tailor search, presentation and summarization of online multimedia information to both patients and healthcare providers. Copyright 2001 ACM.",22,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901283790,Conference Proceeding,2001-01-01,10.1145/379437.379722,340,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,331-340,Proceedings of the ACM International Conference on Digital Libraries,331,http://api.elsevier.com/content/abstract/scopus_id/84901283790,,84901283790,62702,p,"PERSIVAL, a system for personalized search and summarization over multimedia healthcare information"
"The chief form of accessing the content of a digital library (DL) is its search interface. While a DL needs an interface that integrates a range of options from search to browse to serendipity, in this work we focus on analytical search. We propose using Bates' search tactics as a basis for the re-design of search interfaces. We believe this approach will help to identify the types of tools that need to be supported by a DL interface. Copyright 2001 ACM.",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901254660,Conference Proceeding,2001-01-01,10.1145/379437.379723,342,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,341-342,Proceedings of the ACM International Conference on Digital Libraries,341,http://api.elsevier.com/content/abstract/scopus_id/84901254660,,84901254660,62702,p,An approach to search for the digital library
"TilePic is a method for storing tiled data of arbitrary type in a hierarchical, indexed format for fast retrieval. It is useful for storing moderately large, static, spatial datasets in a manner that is suitable for panning and zooming over the data, especially in distributed applications. Because different data types may be stored in the same object, TilePic can support semantic zooming as well. It has proven suitable for a wide variety of applications involving the networked access and presentation of images, geographic data, and text. The TilePic format and its supporting tools are unencumbered, and available to all. Copyright 2001 ACM.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901250326,Conference Proceeding,2001-01-01,10.1145/379437.379724,344,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,343-344,Proceedings of the ACM International Conference on Digital Libraries,343,http://api.elsevier.com/content/abstract/scopus_id/84901250326,,84901250326,62702,p,TilePic: A file format for tiled hierarchical data
"The preservation of digital data for the long term presents a variety of challenges from technical to social and organizational. The technical challenge is to ensure that the information, generated today, can survive long term changes in storage media, devices and data formats. This paper presents a novel approach to the problem. It distinguishes between archiving of data files and archiving of programs (so that their behavior may be reenacted in the future). For the archiving of a data file, the proposal consists of specifying the processing that needs to be performed on the data (as physically stored) in order to return the information to a future client (according to a logical view of the data). The process specification and the logical view definition are archived with the data. For the archiving of a program behavior, the proposal consists of saving the original executable object code together with the specification of the processing that needs to be performed for each machine instruction of the original computer (emulation). In both cases, the processing specification is based on a Universal Virtual Computer that is general, yet basic enough as to remain relevant in the future. Copyright 2001 ACM.",4,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901254752,Conference Proceeding,2001-01-01,10.1145/379437.379726,352,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,346-352,Proceedings of the ACM International Conference on Digital Libraries,346,http://api.elsevier.com/content/abstract/scopus_id/84901254752,,84901254752,62702,p,Long term preservation of digital information
"Digital archives can best survive failures if they have made several copies of their collections at remote sites. In this paper, we discuss how autonomous sites can cooperate to provide preservation by trading data. We examine the decisions that an archive must make when forming trading networks, such as the amount of storage space to provide and the best number of partner sites. We also deal with the fact that some sites may be more reliable than others. Experimental results from a data trading simulator illustrate which policies are most reliable. Our techniques focus on preserving the ""bits"" of digital collections; other services that focus on other archiving concerns (such as preserving meaningful metadata) can be built on top of the system we describe here. Copyright 2001 ACM.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901287285,Conference Proceeding,2001-01-01,10.1145/379437.379727,362,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,353-362,Proceedings of the ACM International Conference on Digital Libraries,353,http://api.elsevier.com/content/abstract/scopus_id/84901287285,,84901287285,62702,p,Creating trading networks of digital archives
"Designing an archival repository is a complex task because there are many alternative configurations, each with different reliability levels and costs. In this paper we study the costs involved in an Archival Repository and we introduce a design framework for evaluating alternatives and choosing the best configuration in terms of reliability and cost. We also present a new version of our simulation tool, ArchSim/C that aids in the decision process. The design framework and the usage of ArchSim/C are illustrated with a case study of a hypothetical (yet realistic) archival repository shared between two universities. Copyright 2001 ACM.",2,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901285614,Conference Proceeding,2001-01-01,10.1145/379437.379729,372,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,363-372,Proceedings of the ACM International Conference on Digital Libraries,363,http://api.elsevier.com/content/abstract/scopus_id/84901285614,,84901285614,62702,p,Cost-driven design for Archival Repositories
"The high publication rate of scholarly material makes searching and browsing an inconvenient way to keep oneself up-to-date. Instead of being the active part in information access, researchers want to be notified whenever a new paper in one's research area is published. While more and more publishing houses or portal sites offer notification services this approach has several disadvantages. We introduce the Hermes alerting service, a service that integrates a variety of different information providers making their heterogeneity transparent for the users. Hermes offers sophisticated filtering capabilities preventing the user from drowning in a flood of irrelevant information. From the user's point of view it integrates the providers into a single source. Its simple provider interface makes it easy for publishers to join the service and thus reaching the potential readers directly. This paper presents the architecture of the Hermes service and discusses the issues of heterogeneity of information sources. Furthermore, we discuss the benefits and disadvantages of message-oriented middleware for implementing such a service for digital libraries. Copyright 2001 ACM.",28,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901281544,Conference Proceeding,2001-01-01,10.1145/379437.379730,380,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,373-380,Proceedings of the ACM International Conference on Digital Libraries,373,http://api.elsevier.com/content/abstract/scopus_id/84901281544,,84901281544,62702,p,Hermes - A notification service for digital libraries
"The current system for scholarly information dissemination may be amenable to significant improvement. In particular, going from the current system of journal publication to one of self-distributed documents offers significant cost and timeliness advantages. A major concern with such alternatives is how to provide the value currently afforded by the peer review system. Here we propose a mechanism that could plausibly supply such value. In the peer review system, papers are judged meritorious if good reviewers give them good reviews. In its place, we propose a collaborative filtering algorithm which automatically rates reviewers, and incorporates the quality of the reviewer into the metric of merit for the paper. Such a system seems to provide all the benefits of the current peer review system, while at the same time being much more flexible. We have implemented a number of parameterized variations of this algorithm, and tested them on data available from a quite different application. Our initial experiments suggest that the algorithm is in fact ranking reviewers reasonably. Copyright 2001 ACM.",13,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901247224,Conference Proceeding,2001-01-01,10.1145/379437.379731,387,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,381-387,Proceedings of the ACM International Conference on Digital Libraries,381,http://api.elsevier.com/content/abstract/scopus_id/84901247224,,84901247224,62702,p,An algorithm for automated rating of reviewers
"HeinOnline is a new online archive of law journals. Development of HeinOnline began in late 1997 through the cooperation of Cornell Information Technologies, William S. Hein & Co., Inc. of Buffalo, NY, and the Cornell Law Library. Built upon the familar Dienst and new Open Archive Initiative protocols, HeinOnline extends the reliable and well-established management practices of open access archives like NCSTRL and CoRR to a subscription-based collection. The decisions made in creating HeinOnline, Dienst architectural extensions, and issues which have arisen during operation of HeinOnline are described. Copyright 2001 ACM.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901258259,Conference Proceeding,2001-01-01,10.1145/379437.379836,394,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,388-394,Proceedings of the ACM International Conference on Digital Libraries,388,http://api.elsevier.com/content/abstract/scopus_id/84901258259,,84901258259,62702,p,HeinOnline: An online archive of law journals
"The needs of society have long been addressed through government research support for new technologies - the Internet representing one example. Today, under the rubric of 'digital government,' federal agencies as well as state and local units of governments at all levels have begun to leverage the fruits of these research investments to better serve the needs of their constituencies. Government agencies apply these technologies in a variety of settings including emergency response, health and safety regulation, financial management, data gathering, and hosts of information dissemination needs. In addition, governments are investigating ways to use technology to encourage citizen participation. There is a growing digital government community of practice that strongly parallels the evolving digital library community. These parallel developments are not surprising because libraries and governments share service missions for their overlapping constituencies. Governments at all levels create enormous volumes of information for use by citizens and have long depended on libraries to organize, disseminate, and preserve this public information. There is an inextricable link between democratic government and libraries stemming from the 19th century creation of public libraries as democracy's offer to citizens to learn, to grow, and to participate. The idea of sharing knowledge to enable good citizenship engenders many cross-currents inherent in socialpolitical policy, and today this idea is given new incarnation in the global Internet environment. Digital library projects in national and local libraries were in many ways the precursors of digital government initiatives and it is particularly instructive to examine a selection of digital government projects through the lens of digital libraries. This panel presents overviews of several digital government projects and initiatives that combine the technical and conceptual threads composing these mutually reinforcing developments. Copyright is held by the author/owner(s).",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901256998,Conference Proceeding,2001-01-01,10.1145/379437.379733,397,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,395-397,Proceedings of the ACM International Conference on Digital Libraries,395,http://api.elsevier.com/content/abstract/scopus_id/84901256998,,84901256998,62702,p,Digital libraries supporting digital government
"As more information resources become accessible using computers, our digital interfaces to those resources need to be appropriate for all people. However when it comes to digital libraries, the interfaces have typically been designed for older children or adults. Therefore, we have begun to develop a digital library interface developmentally appropriate for young children (ages 5-10 years old). Our prototype system we now call ""SearchKids"" offers a graphical interface for querying, browsing and reviewing search results. This paper describes our motivation for the research, the design partnership we established between children and adults, our design process, the technology outcomes of our current work, and the lessons we have learned. Copyright 2001 ACM.",7,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901284759,Conference Proceeding,2001-01-01,10.1145/379437.379735,405,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,398-405,Proceedings of the ACM International Conference on Digital Libraries,398,http://api.elsevier.com/content/abstract/scopus_id/84901284759,,84901284759,62702,p,Designing a digital library for young children: An intergenerational partnership
"The majority of current digital libraries (DLs) are not designed for children. For DLs to be popular with children, they need to be fun, easy-to-use and empower them, whether as readers or authors. This paper describes a new children's DL emphasizing its design and evaluation, working with the children (11-14 year olds) as design partners and testers. A truly participatory process was used, and observational study was used as a means of refinement to the initial design of the DL prototype. In contrast with current DLs, the children's DL provides both a static as well as a dynamic environment to encourage active engagement of children in using it. Design, implementation and security issues are also raised. Copyright 2001 ACM.",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901266192,Conference Proceeding,2001-01-01,10.1145/379437.379738,415,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,406-415,Proceedings of the ACM International Conference on Digital Libraries,406,http://api.elsevier.com/content/abstract/scopus_id/84901266192,,84901266192,62702,p,Dynamic digital libraries for children
"The need for information systems to support the dissemination and reuse of educational resources has sparked a number of largescale digital library efforts. This article describes usability findings from one such project - the Digital Library for Earth System Education (DLESE) - focusing on its role in the process of educational resource reuse. Drawing upon a reuse model developed in the domain of software engineering, the reuse cycle is broken down into five stages: formulation of a reuse intention, location, comprehension, modification, and sharing. Using this model to analyze user studies in the DLESE project, several implications for library system design and library outreach activities are highlighted. One finding is that resource reuse occurs at different stages in the educational design process, and each stage imposes different and possibly conflicting requirements on digital library design. Another finding is that reuse is a distributed process across several artifacts, both within and outside of the library itself. In order for reuse to be successful, a usability line cannot be drawn at the library boundary, but instead must encompass both the library system and the educational resources themselves. Copyright 2001 ACM.",4,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901289260,Conference Proceeding,2001-01-01,10.1145/379437.379742,425,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,416-425,Proceedings of the ACM International Conference on Digital Libraries,416,http://api.elsevier.com/content/abstract/scopus_id/84901289260,,84901289260,62702,p,Looking at digital library usability from a reuse perspective
"This paper describes the creation of a new humanities digital library collection: 11,000,000 words and 10,000 images representing books, images and maps on pre-twentieth century London and its environs. The London collection contained far more dense and precise information than the materials from the Greco-Roman world on which we had previously concentrated. The London collection thus allowed us to explore new problems of data structure, manipulation, and visualization. This paper contrasts our model for how humanities digital libraries are best used with the assumptions that underlie many academic digital libraries on the one hand and more literary hypertexts on the other. Since encoding guidelines such as those from the TEI provide collection designers with far more options than any one project can realize, this paper describes what structures we used to organize the collection and why. We particularly emphasize the importance of mining historical ""authority lists"" (encyclopedias, gazetteers, etc.) and then generating automatic ""span-to-span"" links within the collection. Copyright 2001 ACM.",1,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901274288,Conference Proceeding,2001-01-01,10.1145/379437.379756,434,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,426-434,Proceedings of the ACM International Conference on Digital Libraries,426,http://api.elsevier.com/content/abstract/scopus_id/84901274288,,84901274288,62702,p,Building a hypertextual digital library in the humanities: A case study on London
"Corpus editions can only be useful to scholars when users know what to expect of the texts. We argue for text quality indicators, both general and domain-specific. Copyright 2001 ACM.",1,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901257595,Conference Proceeding,2001-01-01,10.1145/379437.379757,436,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,435-436,Proceedings of the ACM International Conference on Digital Libraries,435,http://api.elsevier.com/content/abstract/scopus_id/84901257595,,84901257595,62702,p,Document quality indicators and corpus editions
"This paper presents research focused on developing new techniques and algorithms for the digital acquisition, restoration, and study of damaged manuscripts. We present results from an acquisition effort in partnership with the British Library, funded through the NSF DLI-2 program, designed to capture 3-D models of old and damaged manuscripts. We show how these 3-D facsimiles can be analyzed and manipulated in ways that are tedious or even impossible if confined to the physical manuscript. In particular, we present results from a restoration framework we have developed for ""flattening"" the 3-D representation of badly warped manuscripts. We expect these research directions to give scholars more sophisticated methods to preserve, restore, and better understand the physical objects they study. Copyright 2001 ACM.",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901268736,Conference Proceeding,2001-01-01,10.1145/379437.379759,443,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,437-443,Proceedings of the ACM International Conference on Digital Libraries,437,http://api.elsevier.com/content/abstract/scopus_id/84901268736,,84901268736,62702,p,"The digital atheneum: New approaches for preserving, restoring and analyzing damaged manuscripts"
"The Cervantes Project is creating an Electronic Variorum Edition of Cervantes' well-known Don Quixote. This paper gives an overview of the computer-based tools that we are using in this endeavor, and summarizes the current status of the project. The Electronic Variorum Edition will join the other content elements maintained by the project, which focuses on electronic resources in support of the study of Cervantes, his works, and his times. Copyright 2001 ACM.",1,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901282309,Conference Proceeding,2001-01-01,10.1145/379437.379763,445,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,444-445,Proceedings of the ACM International Conference on Digital Libraries,444,http://api.elsevier.com/content/abstract/scopus_id/84901282309,,84901282309,62702,p,Towards an Electronic Variorum Edition of Don Quixote
Digital music libraries provide enhanced access and functionality that facilitates scholarly research and education. This panel will present a report on the progress of several major research and development projects in digital music libraries. Copyright is held by the author/owner(s).,0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901253953,Conference Proceeding,2001-01-01,10.1145/379437.379765,448,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,446-448,Proceedings of the ACM International Conference on Digital Libraries,446,http://api.elsevier.com/content/abstract/scopus_id/84901253953,,84901253953,62702,p,Digital music libraries - Research and development
"An online exhibition of a digital museum often consists of a variety of multimedia objects such as webpages, animation, and video clips. Ideally, there should be different exhibitions on the same topic for users with different needs. The difficulty is that it is time-consuming to produce illustrative and intriguing online exhibitions. In this paper, we present a content management system for producing exhibitions. This framework is a novel approach for organizing digital collections and for quickly selecting, integrating, and composing objects from the collection to produce exhibitions of different presentation styles, one for each user group. A prototype based on our framework has been implemented and successfully used in the production of a Lanyu digital museum. Using our method, the Lanyu Digital Museum online exhibition has several features: (1) It provides an easy way to compose artifacts extracted from the digital collection into exhibitions. (2) It provides an easy way to create different presentations of the same exhibition content that are catered to users with different needs. (3) It provides easy-touse film-editing capability to re-arrange an exhibition and to produce new exhibitions from existing ones. Copyright is held by the author/owner(s).",3,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901265565,Conference Proceeding,2001-01-01,10.1145/379437.379768,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,450,http://api.elsevier.com/content/abstract/scopus_id/84901265565,,84901265565,62702,p,Content management for digital museum exhibitions
"As digital libraries grow in size, querying their contents will become as frustrating as querying the web is now. One remedy is to hierarchically cluster the results that are returned by searching a digital library. We demonstrate the clustering of search results from Carnegie Mellon's Informedia database, a large video library that supports indexing and retrieval with automatically generated descriptors. Copyright is held by the author/owner(s).",4,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901289746,Conference Proceeding,2001-01-01,10.1145/379437.379770,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,451,http://api.elsevier.com/content/abstract/scopus_id/84901289746,,84901289746,62702,p,Demonstration of hierarchical document clustering of digital library retrieval results
"The Indiana University Digital Music Library project plans to create a digital library testbed system containing music in a variety of formats, designed to support research and education in the field of music and to serve as a platform for digital library research. Prototypes of user interfaces to the system will be demonstrated. Copyright is held by the author/owner(s).",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901287348,Conference Proceeding,2001-01-01,10.1145/379437.379774,453,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,452-453,Proceedings of the ACM International Conference on Digital Libraries,452,http://api.elsevier.com/content/abstract/scopus_id/84901287348,,84901287348,62702,p,Indiana University Digital Music Library project
"Much current research on digital libraries focuses on named entity extraction and transformation into structured information. Examples include entities like events, people, and places, and attributes like birth date or latitude. This video demonstration illustrates the potential for finding relationships among entities extracted from 50,000 news segments from CMU's Informedia Digital Video Library. A visual query language is used to specify relationships among entities. Data populate the query structure, which becomes an interface for exploration that gives continuous feedback in the form of visualizations of summary statistics. The target user is a data analyst familiar with the domain from which the entities come, but not a computer scientist. Copyright is held by the author/owner.",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901256966,Conference Proceeding,2001-01-01,10.1145/379437.379777,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,453,http://api.elsevier.com/content/abstract/scopus_id/84901256966,,84901256966,62702,p,Interactive visualization of video metadata
"In this demonstration, we present several integrated components of PER SIVAL PErsonalized Retrieval and Summarization of Image, Video And anguage), a system designed to provide personalized access to a distributed digital library of medical literature and consumer health information. The global system architecture of PERSIVAL is best described as a two-stage processing pipeline. The first stage is a retrieval system that matches user queries with relevant multimedia data in the library. The second stage is a visualization system that processes the multimedia data matched by the first stage for display. Our demonstration focuses on the second stage of PERSIVAL's processing pipeline. Given a set of relevant documents for certain predefined queries, our integrated demonstration seeks to give a tailored response for either physicians or patients, featuring textual summaries, as well as relevant medical definitions. To visualize the summaries and definitions, we employ automated constraint-based layout of the user interface that allows for rich interaction between summaries and definitions. PERSIVAL's natural language processing and user interface modules make up the visualization portion of the system and illustrate state-of-the-art digital library technology. Following are the modules presented in our demonstration.Copyright 2001 ACM.",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901264129,Conference Proceeding,2001-01-01,10.1145/379437.379784,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,455,http://api.elsevier.com/content/abstract/scopus_id/84901264129,,84901264129,62702,p,PERSIVAL: Personalized summarization over multimedia health-care information
"The primary goal of the Stanford Encyclopedia of Philosophy project $< $http://plato.stanford.edu/$>$ is to produce an authoritative and comprehensive reference work devoted to the academic discipline of philosophy that will be kept up to date ally so as to remain useful to those in academia and the general public. To accomplish this goal we have designed and implemented web-based software by which academic philosophers can collaboratively write and maintain such a 'dynamic reference work'. Our implementation has features that are not found in any other online reference work in any discipline, and that enable the profession of philosophy to maintain such a reference work without the cost or level of staff support required for traditional reference work publishing. Copyright 2001 ACM.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901274290,Conference Proceeding,2001-01-01,10.1145/379437.379789,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,457,http://api.elsevier.com/content/abstract/scopus_id/84901274290,,84901274290,62702,p,Stanford encyclopedia of philosophy: A dynamic reference work
"Most online music library catalogues can only be searched by textual metadata. Whilst highly effective - since the rules for maintaining consistency have been refined over many years - this does not allow searching by musical content. Many music librarians are familiar with users humming their enquiries. Most systems providing a ""query by humming"" interface tend to run independently of music library catalogue systems and not offer similar textual metadata searching. This demonstration shows how we can integrate these two types of system based on work conducted as part of the NSF/JISC funded OMRAS project (http://www.omras.org). Copyright is held by the author/owner(s).",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901278423,Conference Proceeding,2001-01-01,10.1145/379437.379791,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,458,http://api.elsevier.com/content/abstract/scopus_id/84901278423,,84901278423,62702,p,A system for adding content-based searching to a traditional music library catalogue server
"In this poster, we describe visualization and educational efforts underway to build an Atmospheric Visualization Collection for the NSDL. Copyright 2001 ACM.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901286099,Conference Proceeding,2001-01-01,10.1145/379437.379793,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,463,http://api.elsevier.com/content/abstract/scopus_id/84901286099,,84901286099,62702,p,An atmospheric visualization collection for the NSDL
"In 2000, a vision of a Physical Sciences Information Infrastructure - an integrated network for the physical sciences - was captured and endorsed. Work continues in 2001 as partnerships are formed and strategies are formulated to move the vision forward. Copyright is held by the author/owner.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901284124,Conference Proceeding,2001-01-01,10.1145/379437.379797,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,465,http://api.elsevier.com/content/abstract/scopus_id/84901284124,,84901284124,62702,p,"Building the Physical Sciences Information Infrastructure, a phased approach"
"We propose and examine new methods for automatic data loading system and flexible user interface system with many features such as 3D visualization. We implement the earth environmental digital library and operate it on the Web. Though our system is focusing the limited users like earth environmental researchers, more than 8000 hits per month describe the practical usefulness of it. Copyright is held by the author/owner(s).",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901258666,Conference Proceeding,2001-01-01,10.1145/379437.379799,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,466,http://api.elsevier.com/content/abstract/scopus_id/84901258666,,84901258666,62702,p,Development of an earth environmental digital library system for soil and land-atmospheric data
"Digitizing a large collection of books is an expensive and time-consuming task-but there may be volunteers all over the world who are willing to do a small portion of the task. This poster describes a system for making digital facsimile editions-e-books consisting of page images and OCR'ed but uncorrected text. The user can choose to view low or high resolution page images or text for each page or search the text. Authenticated users with little or no training can correct the text on-line, and the corrections are incorporated in the document. Source code is available for the described implementation, which is a part of the Christian Classics Ethereal Library (http://www.ccel.org). Copyright is held by the author/owner.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901272771,Conference Proceeding,2001-01-01,10.1145/379437.379802,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,467,http://api.elsevier.com/content/abstract/scopus_id/84901272771,,84901272771,62702,p,Digital facsimile editions and on-line editing
"DSpace is a joint development effort by HP and MIT to establish an electronic system that will enable MIT faculty and researchers to capture, preserve, manage, and disseminate their intellectual output, and that will enable the Institute to maintain its intellectual heritage. The effort further aims to facilitate sharing of intellectual content and metadata among institutions by minimizing barriers to adoption and federation. This brief paper describes the motivation behind the project, its goals, objectives, progress, and references to detailed definition & design materials.Copyright is held by the author/owner(s).",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901273860,Conference Proceeding,2001-01-01,10.1145/379437.379803,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,468,http://api.elsevier.com/content/abstract/scopus_id/84901273860,,84901273860,62702,p,DSpace at MIT: Meeting the challenges
"We consider the application of a system for learning the semantics of image collections to digital libraries. We discuss our approach to browsing and search, and investigate the integration both in more detail. Copyright is held by the author/owner(s).",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901275153,Conference Proceeding,2001-01-01,10.1145/379437.379804,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,469,http://api.elsevier.com/content/abstract/scopus_id/84901275153,,84901275153,62702,p,Exploiting image semantics for picture libraries
"In this paper, we describe how we use a mediator-based architecture for integrating digital libraries. We discuss how we tackle the obstacles of firewalls in the expansion of our system by using XML and Java Servlet, which are used to achieve CORBA general communications and callback features across the firewalls. Copyright is held by the author/owner(s).",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901252252,Conference Proceeding,2001-01-01,10.1145/379437.379807,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,472,http://api.elsevier.com/content/abstract/scopus_id/84901252252,,84901252252,62702,p,"Integrating digital libraries by CORBA, XML and Servlet"
"In this poster, we report methodology and initial results from a study of an academic library's migration to an all-electronic journal collection Copyright is held by the author/owner(s).",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901259104,Conference Proceeding,2001-01-01,10.1145/379437.379809,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,474,http://api.elsevier.com/content/abstract/scopus_id/84901259104,,84901259104,62702,p,Print to electronic: Measuring the operational and economic implications of an electronic journal collection
"This paper, discusses a general approach to predicting data access rates and user access patterns for planning distribution capacities and for monitoring data usage. The approach uses a steady-state Markov model to describe user activities and innovation-diffusion to describe the rate at which a naïve population adopts accessing data from a digital library.",0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901284154,Conference Proceeding,2001-01-01,10.1145/379437.379811,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,476,http://api.elsevier.com/content/abstract/scopus_id/84901284154,,84901284154,62702,p,Using Markov models and innovation-diffusion as a tool for predicting digital library access and distribution rates
The purpose of this poster is to describe our approach to provide facsimiles of manuscripts and old books as one of our DL services publicly available by Internet. Copyright is held by the author/owner.,0,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901248196,Conference Proceeding,2001-01-01,10.1145/379437.379812,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,477,http://api.elsevier.com/content/abstract/scopus_id/84901248196,,84901248196,62702,p,A versatile facsimile and transcription service for manuscripts and rare old books at the Miguel de Cervantes Digital Library
"The design of easy-to-use and informative visual interfaces to digital libraries is an integral part to the advances of digital libraries. A wide range of approaches have been developed from a diverse spectrum of perspectives that focus on users and tasks to be supported, data to be modeled, and the efficiency of algorithms. Information visualization aims to exploit the human visual information processing system, especially with non-spatial data (such as documents and images typically found in digital libraries). Generally, information visualization examines semantic relationships intrinsic to an abstract information space and how they can be spatially navigated and memorized using similar cognitive processes to those that would apply during interactions with the 'real world'. This workshop promotes the convergence of information visualization and digital libraries. It brings together researchers and practitioners in the areas of information visualization, digital libraries, human-computer interaction, library and information science, and computer science to identify the most important issues in the past and the present, and what should be done in the future. Copyright is held by the author/owner(s).",1,Association for Computing Machinery acmhelpacm.org,2-s2.0-84901262253,Conference Proceeding,2001-01-01,10.1145/379437.379816,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,482,http://api.elsevier.com/content/abstract/scopus_id/84901262253,,84901262253,62702,p,"Workshop 1: Visual interfaces to digital libraries - Its past, present, and future"
"Mapping between/among classification schemes is beneficial within an organization that has a number of implicit schemes, between organizations seeking to exchange information, and in a digital library context where collections are organized by different classifications. This cross scheme mapping could be done manually, but if many schemes are to be mapped, it may be desirable to provide automated tools and techniques to support the process. This workshop will present research and projects that identify the state-of-the-practice and outline the research agenda. In addition to the educational part of the program, the afternoon will be devoted to ongoing NKOS activities related to a vocabulary mark-up language, mechanisms for search and retrieval of online knowledge organization sources, and a typology for describing knowledge organization sources that supports the development of knowledge organization services on the Web. The program is available from the NKOS Web site at http://nkos.slis.kent.edu. Copyright is held by the author/owner(s).",0,Association for Computing Machineryacmhelpacm.org,2-s2.0-84901277987,Conference Proceeding,2001-01-01,10.1145/379437.379819,,"[{'$': '1581133456'}, {'$': '9781581133455'}]",,,Proceedings of the ACM International Conference on Digital Libraries,484,http://api.elsevier.com/content/abstract/scopus_id/84901277987,,84901277987,62702,p,Workshop 3: Classification crosswalks: Bringing communities together
"Exploring services for digital libraries (DLs) include two major paradigms, browsing and searching, as well as other services such as clustering and visualization. In this paper, we formalize and generalize DL exploring services within a DL theory. We develop theorems to indicate that browsing and searching can be converted or mapped to each other under certain conditions. The theorems guide the design and implementation of exploring services for an integrated archaeological DL, ETANA-DL. Its integrated browsing and searching can support users in moving seamlessly between these operations, minimizing context switching, and keeping users focused. It also integrates browsing and searching into a single visual interface for DL exploration. A user study to evaluate ETANA-DL's exploring services helped validate our hypotheses. Copyright 2006 ACM.",21,,2-s2.0-34247277123,Conference Proceeding,2006-12-01,10.1145/1141753.1141755,10,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,1-10,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,1,http://api.elsevier.com/content/abstract/scopus_id/34247277123,2006,34247277123,145752,p,"Exploring digital libraries: Integrating browsing, searching, and visualization"
"People need to find, work with, and put together information. Diverse activities, such as scholarly research, comparison shopping, and entertainment involve collecting and connecting information resources. We need to represent collections in ways that promote understanding of individual information resources and also their relationships. Representing individual resources with images as well as text makes good use of human cognitive facilities. Composition, an alternative to lists, means putting representations of elements in a collection together using design principles to form a connected whole. We develop combinFormation, a mixed-initiative system for representing collections as compositions of image and text surrogates. The system provides a set of direct manipulation facilities for forming, editing, organizing, and distributing collections as compositions. Additionally, to assist users in sifting through the vast expanse of potentially relevant information resources, the system also includes a generative agent that can proactively engage in processes of collecting information resources and forming image and text surrogates. A generative temporal visual composition agent develops the collection and its visual representation over time, enabling users to see more possibilities. To keep the user in control, we develop interactive techniques that enable the user to direct the agent. For evaluation, we conducted a field study in an undergraduate general education course offered in the architecture department. Alternating groups of students used combinFormation as an aid in preparing one of two major assignments involving information discovery to support processes of invention. The students that used combinFormation were found to perform better. Copyright 2006 ACM.",20,,2-s2.0-34247190694,Conference Proceeding,2006-12-01,10.1145/1141753.1141756,20,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,11-20,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,11,http://api.elsevier.com/content/abstract/scopus_id/34247190694,2006,34247190694,145752,p,CombinFormation: A mixed-initiative system for representing collections as compositions of image and text surrogates
"Much focus in digital libraries research has been devoted to new online services rather than services for the visitors in the physical library. This paper describes InfoGallery, which is a web-based infrastructure for enriching the physical library space with informative art ""exhibitions"" of digital library material and other relevant information, such as RSS news streams, event announcements etc. InfoGallery presents information in an aesthetically attractive manner on a variety of surfaces in the library, including cylindrical displays and floors. The infrastructure consists of a server structure, an editor application and a variety of display clients. The paper discusses the design of the infrastructure and its utilization of RSS, podcasts and manually edited news. Applications in the library domain are described and the experiences are discussed. Copyright 2006 ACM.",15,,2-s2.0-34247235662,Conference Proceeding,2006-12-01,10.1145/1141753.1141757,30,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,21-30,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,21,http://api.elsevier.com/content/abstract/scopus_id/34247235662,2006,34247235662,145752,p,InfoGallery: Informative art services for physical library spaces
"This paper evaluates automatic extraction of ten named entity classes from a 19th century newspaper, the Civil War years of the Richmond Times Dispatch, digitized with IMLS support by the University of Richmond. This paper analyzes success with ten categories of entities prominent in these newspapers and the particular problems that these classes of named entities raise. Personal and place names are familiar but some more important categories (such as ship names and military units) illustrate some of the challenges that named entity identification confronts as it evolves into a fundamental tool not only for automatic metadata generation but also for searching and browsing as well. We conclude by suggesting the kinds of knowledge sources that digital libraries need to assemble as part of their machine readable reference collections to support named entity identification as a core service. Copyright 2006 ACM.",16,,2-s2.0-34247183701,Conference Proceeding,2006-12-01,10.1145/1141753.1141759,40,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,31-40,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,31,http://api.elsevier.com/content/abstract/scopus_id/34247183701,2006,34247183701,145752,p,The challenge of Virginia banks: An evaluation of named entity analysis in a 19th-century newspaper collection
"Identifying record replicas in Digital Libraries and other types of digital repositories is fundamental to improve the quality of their content and services as well as to yield eventual sharing efforts. Several deduplication strategies are available, but most of them rely on manually chosen settings to combine evidence used to identify records as being replicas. In this paper, we present the results of experiments we have carried out with a novel Machine Learning approach we have proposed for the deduplication problem. This approach, based on Genetic Programming (GP), is able to automatically generate similarity functions to identify record replicas in a given repository. The generated similarity functions properly combine and weight the best evidence available among the record fields in order to tell when two distinct records represent the same real-world entity. The results of the experiments show that our approach outperforms the baseline method by Fellegi and Sunter by more than 12% when identifying replicas in a, data set containing researcher's personal data, and by more than 7%, in a data set with article citation data. Copyright 2006 ACM.",23,,2-s2.0-34247190122,Conference Proceeding,2006-12-01,10.1145/1141753.1141760,50,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,41-50,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,41,http://api.elsevier.com/content/abstract/scopus_id/34247190122,2006,34247190122,145752,p,Learning to deduplicate
"We study how to resolve entities that contain a group of related elements in them (e.g., an author entity with a list of citations or an intermediate result by GROUP BY SQL query). Such entities, named as grouped-entities, frequently occur in many applications. By exploiting contextual information mined from the group of elements per entity in addition to syntactic similarity, we show that our approach, Quasi-Cllque, improves precision and recall unto 91% when used together with a variety of existing entity resolution solutions, but never worsens them. Copyright 2006 ACM.",15,,2-s2.0-34247276592,Conference Proceeding,2006-12-01,10.1145/1141753.1141761,52,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,51-52,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,51,http://api.elsevier.com/content/abstract/scopus_id/34247276592,2006,34247276592,145752,p,An effective approach to entity resolution problem using Quasi-Clique and its application to digital libraries
"The desire for definitive data and the semantic web drive for inference over heterogeneous data sources requires co-reference resolution to be performed on those data. In particular, name disambiguation is required to allow accurate publication lists, citation counts and impact measures to be determined. This paper describes a graph-based approach to author disambiguation on large-scale citation networks. Using self-citation, co-authorship and document source analyses, AKTiveAuthor clusters papers, achieving precision of 0.997 and recall of 0.818 over a test group of eight surname clusters. Copyright 2006 ACM.",22,,2-s2.0-34247253021,Conference Proceeding,2006-12-01,10.1145/1141753.1141762,54,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,53-54,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,53,http://api.elsevier.com/content/abstract/scopus_id/34247253021,2006,34247253021,145752,p,"Also by the same Author: AKTiveAuthor, a citation graph approach to name disambiguation"
"In this paper we introduce POLAR, a probabilistic object-oriented logical framework for annotation-based information retrieval. In POLAR, the knowledge about digital objects, annotations and their relationships in a digital library repository can be modelled considering certain characteristics of annotations and annotated objects. Insights about these characteristics are gained by an analysis of the annotation models behind existing systems and a discussion of an object-oriented, logical view on relevant objects in a digital library. Retrieval methods applied in a digital library should take annotations into account to satisfy users' information needs. POLAR thus supports a wide range of flexible and powerful annotation-based fact and content queries by making use of knowledge and relevance augmentation. An evaluation of our approach on email discussions shows performance improvements when annotation characteristics are considered. Copyright 2006 ACM.",19,,2-s2.0-34247241084,Conference Proceeding,2006-12-01,10.1145/1141753.1141764,64,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,55-64,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,55,http://api.elsevier.com/content/abstract/scopus_id/34247241084,2006,34247241084,145752,p,"Probabilistic, object-oriented logics for annotation-based retrieval in digital libraries"
"Measurements of the impact and history of research literature provide a useful complement to scientific digital library collections. Bibliometric indicators have been extensively studied, mostly in the context of journals. However, journal-based metrics poorly capture topical distinctions in fast-moving fields, and are increasingly problematic with the rise of open-access publishing. Recent developments in latent topic models have produced promising results for automatic sub-field discovery. The fine-grained, faceted topics produced by such models provide a clearer view of the topical divisions of a body of research literature and the interactions between those divisions. We demonstrate the usefulness of topic models in measuring impact by applying a new phrase-based topic discovery model to a collection of 300,000 Computer Science publications, collected by the Rexa automatic citation indexing system. Copyright 2006 ACM.",42,,2-s2.0-34247210745,Conference Proceeding,2006-12-01,10.1145/1141753.1141765,74,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,65-74,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,65,http://api.elsevier.com/content/abstract/scopus_id/34247210745,2006,34247210745,145752,p,Bibliometric impact measures leveraging topic analysis
"It is well known that links are an important source of information when dealing with Web collections. However, the question remains on whether the same techniques that are used on the Web can be applied to collections of documents containing citations between scientific papers. In this work we present a comparative study of digital library citations and Web links, in the context of automatic text classification. We show that there are in fact differences between citations and links in this context. For the comparison, we run a series of experiments using a digital library of computer science papers and a Web directory. In our reference collections, measures based on co-citation tend to perform better for pages in the Web directory, with gains up to 37% over text based classifiers, while measures based on bibliographic coupling perform better in a digital library. We also propose a simple and effective way of combining a traditional text based classifier with a citation-link based classifier. This combination is based on the notion of classifier reliability and presented gains of up to 14% in micro-averaged F1 in the Web collection. However, no significant gain was obtained in the digital library. Finally, a user study was performed to further investigate the causes for these results. We discovered that misclassifications by the citation-link based classifiers are in fact difficult cases, hard to classify even for humans. Copyright 2006 ACM.",30,,2-s2.0-34247196659,Conference Proceeding,2006-12-01,10.1145/1141753.1141766,84,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,75-84,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,75,http://api.elsevier.com/content/abstract/scopus_id/34247196659,2006,34247196659,145752,p,A comparative study of citations and links in document classification
"The panel will discuss various aspects related to an invitational meeting held at the Mellon Foundation On April 20th and 21st 2006 aimed at identifying concrete steps that can be taken to reach new levels of interoperability across scholarly repositories. The focus of the meeting was specifically on repository interfaces that support locating, identifying, harvesting, retrieving and submitting complex digital objects.",1,,2-s2.0-34247251392,Conference Proceeding,2006-12-01,10.1145/1141753.1141768,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,85,http://api.elsevier.com/content/abstract/scopus_id/34247251392,2006,34247251392,145752,p,Augmenting interoperability across scholarly repositories
"This paper addresses the issues associated with building software images to support a collection of archived documents using machine emulators. Emulation has been proposed as a strategy for preservation of digital documents that require their original software for access. The creation of software images is a critical component in archiving documents via emulation. The software images include the operating system, application software, and supporting software artifacts such as fonts and Codecs (Compression-Decompression algorithm). A practical emulation environment to support a digital document requires both an emulator and a software image. This paper considers the issues associated with creating such software images to support Microsoft Office documents. In particular, we discuss a set of software tools and strategies that we developed to automatically analyze the dependencies of Microsoft Office documents on software resources and supporting files. As a proof of concept, the tools and strategies have been applied to establish dependencies of Office documents from a document library containing approximately 200,000 documents and to automatically collect missing resources such as fonts. The software tools are a first step toward an interactive system that aids in the construction of robust emulation environments for preserving digital artifacts. However, they may also be used in other contexts, for example, to support screening of documents for archiving and migration to new platforms to ensure correct visualization. Copyright 2006 ACM.",7,,2-s2.0-34247251391,Conference Proceeding,2006-12-01,10.1145/1141753.1141770,94,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,86-94,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,86,http://api.elsevier.com/content/abstract/scopus_id/34247251391,2006,34247251391,145752,p,Quantifying software requirements for supporting archived office documents using emulation
"This paper describes the building of a research library for studying the Web, especially research on how the structure and content of the Web change over time. The library is particularly aimed at supporting social scientists for whom the Web is both a fascinating social phenomenon and a mirror on society. The library is built on the collections of the Internet Archive, which has been preserving a crawl of the Web every two months since 1996. The technical challenges in organizing this data for research fall into two categories: high-performance computing to transfer and manage the very large amounts of data, and human-computer interfaces that empower research by non-computer specialists.",15,,2-s2.0-34247233186,Conference Proceeding,2006-12-01,10.1145/1141753.1141771,102,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,95-102,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,95,http://api.elsevier.com/content/abstract/scopus_id/34247233186,2006,34247233186,145752,p,Building a research library for the history of the Web
"This paper describes the processing of digitised works at the National Library of Portugal, as done in the scope of the National Digital Library initiate (BND). This comprises the normalization of the names of the images, the creation of technical metadata, image processing, OCR, indexing, and the creation of derived copies for preservation and copies for access in PNG, JPG, GIF, and PDF. The structural descriptions of all the objects are done in METS. Copyright 2006 ACM.",0,,2-s2.0-34247185324,Conference Proceeding,2006-12-01,10.1145/1141753.1141772,104,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,103-104,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,103,http://api.elsevier.com/content/abstract/scopus_id/34247185324,2006,34247185324,145752,p,The processing of digitized works
"Digital library interoperability for both documents and metadata is a critical and complex issue. Although many relevant standards have been developed, and continue to evolve, in practice things are not quite so easy as they seem. We have built a software environment called the Exchange Center that helps digital librarians manage the process of sourcing documents and metadata from various repositories, adding local content where necessary, and exporting the resulting collection into formats that are suitable for digital library repositories. This paper describes the software, which is built on Greenstone but does not require its use as the final digital library server. Copyright 2006 ACM.",6,,2-s2.0-34247269143,Conference Proceeding,2006-12-01,10.1145/1141753.1141773,106,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,105-106,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,105,http://api.elsevier.com/content/abstract/scopus_id/34247269143,2006,34247269143,145752,p,Document level interoperability for collection creators
"The NDIIPP ECHO DEPository project [1] digital repository evaluation will use an augmented version of the draft Audit Checklist for Certification of Trusted Digital Repositories (Audit Checklist) [2] to provide a framework for examining how well currently popular repository software applications support the notion of a ""trusted digital repository."" The evaluation will also demonstrate the application of a scoring software evaluation methodology similar to one developed by the Center for Data Insight (GDI) at Northern Arizona University [3], used for evaluation data mining software. This scoring methodology in conjunction with the Audit Checklist can be used as a tool by librarians, archivists, and other data custodians to make informed decisions as they develop digital preservation management services. Copyright 2006 ACM.",1,,2-s2.0-34247229175,Conference Proceeding,2006-12-01,10.1145/1141753.1141774,108,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,107-108,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,107,http://api.elsevier.com/content/abstract/scopus_id/34247229175,2006,34247229175,145752,p,Repository software evaluation using the audit checklist for certification of trusted digital repositories
"A number of projects are creating searchable digital libraries of printed books. These include the Million Book Project, the Google Book project and similar efforts from Yahoo and Microsoft. Content-based on line book retrieval usually requires first converting printed text into machine readable (e.g. ASCII) text using an optical character recognition (OCR) engine and then doing full text search on the results. Many of these books are old and there are a variety of processing steps that are required to create an end to end system. Changing any step (including the scanning process) can affect OCR. performance and hence a good automatic statistical evaluation of OCR performance on book length material is needed. Evaluating OCR performance on the entire book is non-trivial. The only easily obtainable ground truth (the Gutenberg e-texts) must be automatically aligned with the OCR. output over the entire length of a book. This may be viewed as equivalent to the problem of aligning two large (easily a million long) sequences. The problem is further complicated by OCR. errors as well as the possibility of large chunks of missing material in one of the sequences. We propose a Hidden Markov Model (HMM) based hierarchical alignment algorithm to align OCR output and the ground truth for books. We believe this is the first work to automatically align a whole book without using any book structure information. The alignment process works by breaking up the problem of aligning two long sequences into the problem of aligning many smaller subsequences. This can be rapidly and effectively done. Experimental results show that our hierarchical alignment approach works very well even if OCR. output has a high recognition error rate. Finally, we evaluate the performance of a commercial OCR. engine over a large dataset of books based on the alignment results. Copyright 2006 ACM.",30,,2-s2.0-34247235660,Conference Proceeding,2006-12-01,10.1145/1141753.1141776,118,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,109-118,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,109,http://api.elsevier.com/content/abstract/scopus_id/34247235660,2006,34247235660,145752,p,"A hierarchical, HMM-based automatic evaluation of OCR accuracy for a digital library of books"
"We describe an HTML web page segmentation algorithm, which is applied to segment online medical journal articles (regular HTML and PDF-Converted-HTML files). The web page content is modeled by a zone tree structure based primarily on the geometric layout of the web page. For a given journal article, a zone tree is generated by combining DOM tree analysis and recursive X-Y cut algorithm. Combining with other visual cues, such as background color, font size, font color and so on, the page is segmented into homogeneous regions. Evaluation is conducted with 104 articles from 11 journals. Out of 9726 ground-truth zones, 9376 zones are correctly segmented, for an accuracy of 96.40%. Segmenting the entire web page into zones can significantly expedite and increase the accuracy of the subsequent information retrieval steps. Copyright 2006 ACM.",15,,2-s2.0-34247256782,Conference Proceeding,2006-12-01,10.1145/1141753.1141777,128,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,119-128,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,119,http://api.elsevier.com/content/abstract/scopus_id/34247256782,2006,34247256782,145752,p,Combining DOM tree and geometric layout analysis for online medical journal article segmentation
"Figures are very important non-textual information contained in scientific documents. Current digital libraries do not provide users tools to retrieve documents based on the information available within the figures. We propose an architecture for retrieving documents by integrating figures and other information. The initial step in enabling integrated document search is to categorize figures into a set of pre-defined types. We propose several categories of figures based on their functionalities in scholarly articles. We have developed a machine-learning-based approach for automatic categorization of figures. Both global features, such as texture, and part features, such as lines, are utilized in the architecture for discriminating among figure categories. The proposed approach has been evaluated on a testbed document set collected from the CiteSeer scientific literature digital library. Experimental evaluation has demonstrated that our algorithms can produce acceptable results for real-world use. Our tools will be integrated into a scientific-document digital library. Copyright 2006 ACM.",21,,2-s2.0-34247258424,Conference Proceeding,2006-12-01,10.1145/1141753.1141778,138,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,129-138,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,129,http://api.elsevier.com/content/abstract/scopus_id/34247258424,2006,34247258424,145752,p,Automatic categorization of figures in scientific documents
In this paper we discuss the implementation of user-defined views over multihierarchical document-centric XML documents. Copyright 2006 ACM.,0,,2-s2.0-34247209122,Conference Proceeding,2006-12-01,10.1145/1141753.1141779,140,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,139-140,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,139,http://api.elsevier.com/content/abstract/scopus_id/34247209122,2006,34247209122,145752,p,XML views for electronic editions
"This paper describes a system to support humanities scholars in their interpretation of literary work. It presents a user interface and web architecture that integrates text mining, a graphical user interface and visualization, while attempting to remain easy to use by non specialists. Users can interactively read and rate documents found in a digital libraries collection, prepare training sets, review results of classification algorithms and explore possible indicators and explanations. Initial evaluation steps suggest that there is a rationale for ""provocational"" text mining in literary interpretation. Copyright 2006 ACM.",22,,2-s2.0-34247207093,Conference Proceeding,2006-12-01,10.1145/1141753.1141781,150,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,141-150,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,141,http://api.elsevier.com/content/abstract/scopus_id/34247207093,2006,34247207093,145752,p,Exploring erotics in Emily Dickinson's correspondence with text mining and visual interfaces
"Metadata is ordinarily used to describe documents, but it can also constitute a form of infrastructure for access to networked resources and for traversal of those resources. One problematic area for access to digital library resources has been the search for time periods or events. If there is a capability to search for time, it is usually a date search - a standardized and precise form but unfortunately rarely used in common chronological expressions. For example, a user interested in the ""Vietnam war"", ""Clinton Administration"" or the ""Elizabethan Period"" must either know the corresponding dates, or rely on simple keyword matching for those period names. We consider the ability to interpret user statements of periods or eras as ranges of dates and to associate them with particular locations an important feature of an information system. This paper describes the Time Period Directory, a metadata infrastructure for named time periods linking them with their geographic location as well as a canonical time period range. Copyright 2006 ACM.",21,,2-s2.0-34247271371,Conference Proceeding,2006-12-01,10.1145/1141753.1141782,160,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,151-160,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,151,http://api.elsevier.com/content/abstract/scopus_id/34247271371,2006,34247271371,145752,p,Time period directories: A metadata infrastructure for placing events in temporal and geographic context
"ETANA-DL is an archaeology digital library built based on the principles of Open Digital Libraries. A key challenge addressed in ETANA-DL is integration of new archaeological sites. To enable archaeologists to build OAI data providers for easy integration, we developed an interactive software tool for database-to-XML generation, schema mapping, and global archive generation. This tool greatly enhances our ability to build new Open Archives. We tested the tool with data from the Umm el-Jimal site. Copyright 2006 ACM.",2,,2-s2.0-34247238802,Conference Proceeding,2006-12-01,10.1145/1141753.1141783,162,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,161-162,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,161,http://api.elsevier.com/content/abstract/scopus_id/34247238802,2006,34247238802,145752,p,ETANA-ADD: An interactive tool for integrating archaeological DL collections
"In this paper, we describe the Travelers in the Middle East Archive (TIMEA), a digital archive focused on Western explorations in the Middle East between the 18th and early 20th centuries [7]. TIMEA brings together TEI-encoded texts and digital images stored in DSpace, research and teaching materials in Connexions, and GIS maps made available online through ArcIMS. By using the functionality of three distinct systems, TIMEA enables users to more fully understand the materials, place them in context, and conduct queries. We outline the rationale for this architecture, the challenges it presents, and our approach to providing an integrated user experience. Copyright 2006 ACM.",2,,2-s2.0-34247255448,Conference Proceeding,2006-12-01,10.1145/1141753.1141784,164,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,163-164,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,163,http://api.elsevier.com/content/abstract/scopus_id/34247255448,2006,34247255448,145752,p,Enabling exploration: Travelers in the middle east archive
"In this paper, we review and examine the current status of digital library education and compare the range of provision with that found in earlier studies [1, 2, 3]. It is found that the number of institutions offering programmes or courses in digital library education is still increasing. About 43% of these programmes or courses are stand-alone rather than integrated with wider material. The curriculum design and focused teaching areas appear more systematic and comprehensive than in earlier studies. Over half the institutions examined in this study have posted their detailed course information on-line. Most courses offered are now based on a combination of theory and practice, and are available at different levels. There are increasing opportunities for funding for developing new initiatives in digital library education. However, since digital library education is still at an early stage, an optimized model of best practice in digital library education has not yet emerged. Copyright 2006 ACM.",16,,2-s2.0-33845959472,Conference Proceeding,2006-12-01,10.1145/1141753.1141786,174,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,165-174,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,165,http://api.elsevier.com/content/abstract/scopus_id/33845959472,2006,33845959472,145752,p,Digital library education: The current status
"The Virginia Tech Department of Computer Science (VT CS) and the University of North Carolina at Chapel Hill School of Information and Library Science (UNC SILS) have launched a curriculum development project in the area of digital libraries. Educational resources will be developed based on the ACM/IEEE-CS Computing Curriculum 2001. Lesson plans and modules will be developed in a variety of areas (that cover the topics of papers and conference sessions in the field), evaluated by experts in those areas, and then pilot tested in CS and LIS courses. An analysis of papers on digital library-related topics from several corpora was performed, to identify the areas in which more and less work has already been performed on these topics; this analysis will guide the initial stages of this curriculum development. Copyright 2006 ACM.",25,,2-s2.0-33751198826,Conference Proceeding,2006-12-01,10.1145/1141753.1141787,184,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,175-184,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,175,http://api.elsevier.com/content/abstract/scopus_id/33751198826,2006,33751198826,145752,p,Curriculum development for digital libraries
"The implications of using digital library software in educational contexts, for both students and software developers, are discussed using two case studies of students building digital libraries. Copyright 2006 ACM.",4,,2-s2.0-34247211690,Conference Proceeding,2006-12-01,10.1145/1141753.1141788,186,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,185-186,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,185,http://api.elsevier.com/content/abstract/scopus_id/34247211690,2006,34247211690,145752,p,Learning by building digital libraries
"Without well-educated digital librarians, digital libraries cannot reach their full potential. In order to offer relevant courses and programs to train digital librarians, educators need feedback from practitioners. Current digital library professionals in academic libraries in the United States were surveyed to determine their activities, skills and training gaps. The findings have implications for the design of digital library education in order to meet workplace needs. Copyright 2006 ACM.",6,,2-s2.0-34247282732,Conference Proceeding,2006-12-01,10.1145/1141753.1141789,188,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,187-188,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,187,http://api.elsevier.com/content/abstract/scopus_id/34247282732,2006,34247282732,145752,p,What do digital librarians do?
"This paper discusses the specification, organization, and utility of time references identified in digital library materials, emphasizing how to treat date references that cannot be resolved to a single day. The HistoryMakers oral history archive is used to illustrate the concept of windowing such time in digital library interfaces. Copyright 2006 ACM.",2,,2-s2.0-34247224867,Conference Proceeding,2006-12-01,10.1145/1141753.1141793,191,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,190-191,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,190,http://api.elsevier.com/content/abstract/scopus_id/34247224867,2006,34247224867,145752,p,Windowing time in digital libraries
"In this paper we describe a novel technique to support information seeking in oral history archives using concept maps. We conducted a pilot study with teachers engaged in work tasks using a prototype concept mapping tool. Results suggest that concept maps can help searchers, especially when tasks are complex. Copyright 2006 ACM.",3,,2-s2.0-34247238279,Conference Proceeding,2006-12-01,10.1145/1141753.1141794,193,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,192-193,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,192,http://api.elsevier.com/content/abstract/scopus_id/34247238279,2006,34247238279,145752,p,Concept maps to support oral history search and use
"This paper discusses the application of speech alignment, image processing, and language understanding technologies to build efficient interfaces into large digital oral history archives, as exemplified by a thousand hour HistoryMakers corpus. Browsing, querying, and navigation features are discussed. Copyright 2006 ACM.",13,,2-s2.0-34247187431,Conference Proceeding,2006-12-01,10.1145/1141753.1141795,195,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,194-195,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,194,http://api.elsevier.com/content/abstract/scopus_id/34247187431,2006,34247187431,145752,p,Facilitating access to large digital oral history archives through informedia technologies
We continue our work on the automatic mining of user-created music reviews towards the goal of connecting user opinions to music objects in Music Digital Libraries (MDL). We demonstrate an experimental system which automatically discovered the key descriptive patterns that differentiated positive from negative reviews which helps us to better understand our successful Phase I results. Comparison to an earlier study indicates an important consistency across projects that warrants further investigation. Copyright 2006 ACM.,6,,2-s2.0-34247211689,Conference Proceeding,2006-12-01,10.1145/1141753.1141796,197,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,196-197,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,196,http://api.elsevier.com/content/abstract/scopus_id/34247211689,2006,34247211689,145752,p,Review mining for music digital libraries: Phase II
There is at present a dearth of information on the everyday image information behavior of ordinary people. Analysis of a set of 64 image-related searches provides insight into potentially useful facilities for an image digital library. Copyright 2006 ACM.,29,,2-s2.0-34247203139,Conference Proceeding,2006-12-01,10.1145/1141753.1141797,199,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,198-199,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,198,http://api.elsevier.com/content/abstract/scopus_id/34247203139,2006,34247203139,145752,p,Looking for a picture: An analysis of everyday image information searching
We are exploring the use of image interfaces for testing video-acquired research skills. We studied user performance on three testing image layouts that differ in their use of the available display real estate and in the flexibility of managing the time available to them. Our results confirm that image layout affects user performance on particular tasks and that experts use different strategies from novices. These alternative layouts will be useful for viewing and understanding digital image collections. Copyright 2006 ACM.,0,,2-s2.0-34247182580,Conference Proceeding,2006-12-01,10.1145/1141753.1141798,201,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,200-201,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,200,http://api.elsevier.com/content/abstract/scopus_id/34247182580,2006,34247182580,145752,p,Image-based evaluation of video-acquired research skills
"In pseudo-relevance feedback, the two key factors affecting the retrieval performance most are the source from which expansion terms are generated and the method of ranking those expansion terms. In this paper, we present a novel unsupervised query expansion technique that utilizes keyphrases and POS phrase categorization. The keyphrases are extracted from the retrieved documents and weighted with an algorithm based on information gain and co-occurrence of phrases. The selected keyphrases are translated into Disjunctive Normal Form (DNF) based on the POS phrase categorization technique for better query refomulation. Furthermore, we study whether ontologies such as WordNet and MeSH improve the retrieval performance in conjunction with the keyphrases. We test our techniques on TREC 5, 6, and 7 as well as a MEDLINE collection. The experimental results show that the use of keyphrases with POS phrase categorization produces the best average precision. Copyright 2006 ACM.",12,,2-s2.0-34247260471,Conference Proceeding,2006-12-01,10.1145/1141753.1141800,209,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,202-209,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,202,http://api.elsevier.com/content/abstract/scopus_id/34247260471,2006,34247260471,145752,p,Keyphrase extraction-based query expansion in digital libraries
"When search results against digital libraries and web resources have limited metadata, augmenting them with meaningful and stable category information can enable better overviews and support user exploration. This paper proposes six ""fast-feature"" techniques that use only features available in the search result list, such as title, snippet, and URL, to categorize results into meaningful categories. They use credible knowledge resources, including a US government organizational hierarchy, a thematic hierarchy from the Open Directory Project (ODP) web directory, and personal browse histories, to add valuable metadata to search results. In three tests the percent of results categorized for five representative queries was high enough to suggest practical benefits: general web search (76-90%), government web search (39-100%), and the Bureau of Labor Statistics website (48-94%). An additional test submitted 250 TREC queries to a search engine and successfully categorized 66% of the top 100 using the ODP and 61% of the top 350. Fast-feature techniques have been implemented in a prototype search engine. We propose research directions to improve categorization rates and make suggestions about how web site designers could re-organize their sites to support fast categorization of search results. Copyright 2006 ACM.",32,,2-s2.0-33847793862,Conference Proceeding,2006-12-01,10.1145/1141753.1141801,219,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,210-219,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,210,http://api.elsevier.com/content/abstract/scopus_id/33847793862,2006,33847793862,145752,p,Categorizing web search results into meaningful and stable categories using fast-feature techniques
"Document clustering has been used for better document retrieval, document browsing, and text mining in digital library. In this paper, we perform a comprehensive comparison study of various document clustering approaches such as three hierarchical methods (single-link, complete-link, and complete link), Bisecting K-means, K-means, and Suffix Tree Clustering in terms of the efficiency, the effectiveness, and the scalability. In addition, we apply a domain ontology to document clustering to investigate if the ontology such as MeSH improves clustering qualify for MEDLINE articles. Because an ontology is a formal, explicit specification of a shared conceptualization for a domain of interest, the use of ontologies is a natural way to solve traditional information retrieval problems such as synonym/hypernym/hyponym problems. We conducted fairly extensive experiments based on different evaluation metrics such as misclassification index, F-measure, cluster purity, and Entropy on very large article sets from MEDLINE, the largest biomedical digital library in biomedicine. Copyright 2006 ACM.",28,,2-s2.0-34247201591,Conference Proceeding,2006-12-01,10.1145/1141753.1141802,229,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,220-229,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,220,http://api.elsevier.com/content/abstract/scopus_id/34247201591,2006,34247201591,145752,p,A comprehensive comparison study of document clustering for a biomedical digital library MEDLINE
"Over three years ago, the Core Integration team of the National Science Digital Library (NSDL) implemented a digital library based on metadata aggregation using Dublin Core and OAI-PMH. The initial expectation was that such low-barrier technologies would be relatively easy to automate and administer. While this architectural choice permitted rapid deployment of a production NSDL, our three years of experience have contradicted our original expectations of easy automation and low people cost. We have learned that alleged ""low-barrier"" standards are often harder to deploy than expected. In this paper we report on this experience and comment on the general cost, the functionality, and the ultimate effectiveness of this architecture. Copyright 2006 ACM.",48,,2-s2.0-33748971415,Conference Proceeding,2006-12-01,10.1145/1141753.1141804,239,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,230-239,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,230,http://api.elsevier.com/content/abstract/scopus_id/33748971415,2006,33748971415,145752,p,"Metadata aggregation and ""automated digital libraries"": A retrospective on the NSDL experience"
"This article reports on analyses of usage and design activities by users of the Instructional Architect (IA), an end-user authoring tool designed to support easy access to and use of NSDL and online resources in creating instructional materials. This analysis provides a unique window for understanding how users use resources from multiple digital libraries, and the related issues of resource granularity and context dependence. Analyses suggest that active use and design with online resources is relegated to 'early adopters'. These users designed significantly more instructional projects with more content and more online resources than less-active users. Users in general appeared to value digital library resources, and at a smaller granularity than cataloged. Copyright 2006 ACM.",2,,2-s2.0-34247204264,Conference Proceeding,2006-12-01,10.1145/1141753.1141805,241,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,240-241,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,240,http://api.elsevier.com/content/abstract/scopus_id/34247204264,2006,34247204264,145752,p,Using resources across educational digital libraries
"The Walden's Paths project is developing tools for leveraging student learning with the incredible amount of educational material on the Web. Specialized templates based on established educational frameworks, learning theories, or activities aid path authors in creating pedagogically sound paths by guiding them in collecting and structuring the information included in the path. We describe a template based on the Inquiry-Based Learning educational framework and an implementation that provides support in applying the template to the path authoring process. Copyright 2006 ACM.",2,,2-s2.0-34247282731,Conference Proceeding,2006-12-01,10.1145/1141753.1141806,243,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,242-243,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,242,http://api.elsevier.com/content/abstract/scopus_id/34247282731,2006,34247282731,145752,p,Template-based authoring of educational artifacts
"Biological studies rely heavily on large collections of species observations. All of these collections cannot be compiled by biology professionals alone. Skilled amateurs can assist by contributing observations they make in the field. The challenge with such contributions is their potentially questionable quality. We present our PDA-based application EcoPod, which replaces traditional paper field guides with a mobile computing platform. EcoPod aims both to increase the efficiency of the identification process and its reliability. The application solicits as little information from the user as possible. At the same time it places no restrictions on the sequencing of the identification process. This approach is to make our solution attractive to both skilled amateurs and professionals. The tool creates a record of the identification process, thereby providing an audit trail for quality assurance. EcoPod's user interface driver computes information gain over identification metadata to maximize screen utilization. The tool ingests SDD, an international standard for XML datasets that describe organisms. Copyright 2006 ACM.",10,,2-s2.0-34247277647,Conference Proceeding,2006-12-01,10.1145/1141753.1141807,253,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,244-253,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,244,http://api.elsevier.com/content/abstract/scopus_id/34247277647,2006,34247277647,145752,p,EcoPod: A mobile tool for community based biodiversity collection building
"Knowledge about how users use digital libraries and their contents is inextricably tied to a library's ability to sustain itself, grow its services and meet the needs of its users. This paper reports on the preliminary results of a study of how science, technology, engineering and mathematics (STEM) instructors perceive and use digital libraries. Preliminary findings indicate that: they do not differentiate between digital libraries and other kinds of content that comes from the web, they seek content to supplement traditional teaching methods and their reliance on Google and personal networks impedes their ability to recall the primary sources of useful content. Copyright 2006 ACM.",4,,2-s2.0-34247223160,Conference Proceeding,2006-12-01,10.1145/1141753.1141808,255,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,254-255,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,254,http://api.elsevier.com/content/abstract/scopus_id/34247223160,2006,34247223160,145752,p,Factors motivating use of digital libraries
This paper describes from a developer's point of view the integration of a content management system (Plone) and a metadata repository (CWIS) in order to create an interactive online digital library for publishing and evaluation of computational science materials. It explains how CSERD's project requirements were addressed by setting up a framework for collaboration between the two systems mentioned above. Copyright 2006 ACM.,0,,2-s2.0-34247257308,Conference Proceeding,2006-12-01,10.1145/1141753.1141810,257,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,256-257,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,256,http://api.elsevier.com/content/abstract/scopus_id/34247257308,2006,34247257308,145752,p,Scaffolding the infrastructure of the computational science digital library
"We describe Voai and Xoai, two software environments that facilitate the automatic construction of OAI servers for collections managed via relational and XML databases, respectively. We have used Voai and Xoai to generate OAI servers for diverse collections. We use freely available tools and do not impose programming requirements upon the users. By making this software publicly available, we aim to facilitate the process of joining the OAI community and becoming data providers. Copyright 2006 ACM.",0,,2-s2.0-34247271968,Conference Proceeding,2006-12-01,10.1145/1141753.1141811,259,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,258-259,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,258,http://api.elsevier.com/content/abstract/scopus_id/34247271968,2006,34247271968,145752,p,Dynamic generation of OAI servers
"FRBR (Functional Requirements for Bibliographic Records) is a promising framework for supporting rich indexation, and therefore rich interaction, in digital libraries. However, it is poorly reported in the digital library research literature and practical examples of its use are seldom discussed. In this paper, we introduce an implemented architecture for FRBR, support that can supplement existing digital library systems. We also demonstrate the benefits gained by the user when FRBR, data is used to enrich the user's interaction with the digital library. Copyright 2006 ACM.",14,,2-s2.0-34247237246,Conference Proceeding,2006-12-01,10.1145/1141753.1141812,269,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,260-269,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,260,http://api.elsevier.com/content/abstract/scopus_id/34247237246,2006,34247237246,145752,p,FRBR: Enriching and integrating digital libraries
"Describes the MARC Content Designation Utilization Project, which is examining a very large set of metadata records as artifacts of the library cataloging enterprise. This is the first large-scale examination of descriptive metadata utilization. Presents an overview of study activities and suggests the study's significance to the broader use of metadata in digital libraries. Copyright 2006 ACM.",5,,2-s2.0-34247185860,Conference Proceeding,2006-12-01,10.1145/1141753.1141813,271,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,270-271,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,270,http://api.elsevier.com/content/abstract/scopus_id/34247185860,2006,34247185860,145752,p,Learning from artifacts: Metadata utilization analysis
"Although often disparaged or dismissed in the library community, the MARC standard, notably the MARCXML standard, provides surprising flexibility and robustness for mapping disparate metadata to a vendor-neutral format for storage, exchange, and downstream use. Copyright 2006 ACM.",1,,2-s2.0-34247180682,Conference Proceeding,2006-12-01,10.1145/1141753.1141814,273,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,272-273,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,272,http://api.elsevier.com/content/abstract/scopus_id/34247180682,2006,34247180682,145752,p,"Looking back, looking forward: A metadata standard for LANL's aDORe repository"
"When professional indexers independently assign terms to a given document, the term sets generally differ between indexers. Studies of inter-indexer consistency measure the percentage of matching index terms, but none of them consider the semantic relationships that exist amongst these terms. We propose to represent multiple-indexers data in a vector space and use the cosine metric as a new consistency measure that can be extended by semantic relations between index terms. We believe that this new measure is more accurate and realistic than existing ones and therefore more suitable for evaluation of automatically extracted index terms. Copyright 2006 ACM.",15,,2-s2.0-34247262631,Conference Proceeding,2006-12-01,10.1145/1141753.1141816,275,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,274-275,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,274,http://api.elsevier.com/content/abstract/scopus_id/34247262631,2006,34247262631,145752,p,Measuring inter-indexer consistency using a thesaurus
"Citation matching, or the automatic grouping of bibliographic references that refer to the same document, is a data management problem faced by automatic digital libraries for scientific literature such as CiteSeer and Google Scholar. Although several solutions have been offered for citation matching in large bibliographic databases, these solutions typically require expensive batch clustering operations that must be run offline. Large digital libraries containing citation information can reduce maintenance costs and provide new services through efficient online processing of citation data, resolving document citation relationships as new records become available. Additionally, information found in citations can be used to supplement document metadata, requiring the generation of a canonical citation record from merging variant citation subfields into a unified ""best guess"" from which to draw information. Citation information must be merged with other information sources in order to provide a complete document record. This paper outlines a system and algorithms for online citation matching and canonical metadata generation. A Bayesian framework is employed to build the ideal citation record for a document that carries the added advantages of fusing information from disparate sources and increasing system resilience to erroneous data. Copyright 2006 ACM.",9,,2-s2.0-34247205876,Conference Proceeding,2006-12-01,10.1145/1141753.1141817,285,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,276-285,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,276,http://api.elsevier.com/content/abstract/scopus_id/34247205876,2006,34247205876,145752,p,Learning metadata from the evidence in an on-line citation matching scheme
"Currently in document retrieval there are many algorithms each with different strengths and weakness. There is some difficulty, however, in evaluating the impact of the test query set on retrieval results. The traditional evaluation process, the Cranfield evaluation paradigm, which uses a corpus and a set of user queries, focuses on making the queries as realistic as possible. Unfortunately such query sets lack the fine grained control necessary to test algorithm properties. We present an approach called Controlled Query Generation (CQG) that creates query sets from documents in the corpus in a way that regulates the theoretic information quality of each query. This allows us to generate reproducible and well defined sets of queries of varying length and term specificity. Imposing this level of control over the query sets used for testing retrieval algorithms enables the rigorous simulation of different query environments to identify specific algorithm properties before introducing user queries. In this work, we demonstrate the usefulness of CQG by generating three different query environments to investigate characteristics of two blind relevance feedback approaches. Copyright 2006 ACM.",18,,2-s2.0-34247194212,Conference Proceeding,2006-12-01,10.1145/1141753.1141818,295,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,286-295,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,286,http://api.elsevier.com/content/abstract/scopus_id/34247194212,2006,34247194212,145752,p,Using controlled query generation to evaluate blind relevance feedback algorithms
We propose a new method that enhances automatic keyphrase extraction by using semantic information on terms and phrases gleaned from a domain-specific thesaurus. We evaluate the results against keyphrase sets assigned by a state-of-the-art keyphrase extraction system and those assigned by six professional indexers. Copyright 2006 ACM.,116,,2-s2.0-34247270229,Conference Proceeding,2006-12-01,10.1145/1141753.1141819,297,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,296-297,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,296,http://api.elsevier.com/content/abstract/scopus_id/34247270229,2006,34247270229,145752,p,Thesaurus based automatic keyphrase indexing
"Although recording of usage data is common in scholarly information services, its exploitation for the creation of value-added services remains limited due to concerns regarding, among others, user privacy, data validity, and the lack of accepted standards for the representation, sharing and aggregation of usage data. This paper presents a technical, standards-based architecture for sharing usage information, which we have designed and implemented. In this architecture, OpenURL-compliant linking servers aggregate usage information of a specific user community as it navigates the distributed information environment that it has access to. This usage information is made OAI-PMH harvestable so that usage information exposed by many linking servers can be aggregated to facilitate the creation of value-added services with a reach beyond that of a single community or a single information service. This paper also discusses issues that were encountered when implementing the proposed approach, and it presents preliminary results obtained from analyzing a usage data set containing about 3,500,000 requests aggregated by a federation of linking servers at the California State University system over a 20 month period. Copyright 2006 ACM.",21,,2-s2.0-34247215600,Conference Proceeding,2006-12-01,10.1145/1141753.1141821,307,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,298-307,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,298,http://api.elsevier.com/content/abstract/scopus_id/34247215600,2006,34247215600,145752,p,An architecture for the aggregation and analysis of scholarly usage data
"Evaluation of digital libraries assesses their effectiveness, quality and overall impact. In this paper we present a novel, multi-level logging framework that will provide complete coverage of the different aspects of DL usage for user-system interactions. Based on this framework, we can analyse for various DL stakeholders the logging data according to their specific interests. In addition, analysis tools and a freely accessible log data repository will yield synergies and sustainability in DL evaluation and encourage a community for DL evaluation by providing for discussion on a common ground. Copyright 2006 ACM.",2,,2-s2.0-34247266040,Conference Proceeding,2006-12-01,10.1145/1141753.1141822,309,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,308-309,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,308,http://api.elsevier.com/content/abstract/scopus_id/34247266040,2006,34247266040,145752,p,An experimental framework for comparative digital library evaluation: The logging scheme
"We describe the analysis of zero result searches in DLESE, the Digital Library for Earth System Education, with the intent to use the information to discover gaps in the collection. Close examination of null result searches reveals insights into the kinds of information sought by users but which is missing from the collection. Although it is not possible to consistently isolate collection gaps as a cause for null result searches, it is possible to define a set of null result searches that are very likely to have been caused by collections gaps. This information can be used to improve a collection in specific subject areas. We recommend using this method, along with other inputs, for a digital library with a specific collection scope but a broad and mostly unknown user base, and we recognize the need for automating this analysis. Copyright 2006 ACM.",2,,2-s2.0-34247258998,Conference Proceeding,2006-12-01,10.1145/1141753.1141823,311,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,310-311,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,310,http://api.elsevier.com/content/abstract/scopus_id/34247258998,2006,34247258998,145752,p,Insights into collections gaps through examination of null result searches in DLESE
"The development of public libraries may have inadvertently brought the age of marginalia to a close but now that digital copies no longer require us to refrain from writing in a shared text, it is possible to create sociable books, texts that sustain communities of readers. How might people respond to opportunities to share their readings through marginalia and how might the process of reading for pleasure be altered by situating it in a more social space? The current study examining sociable reading among a small group of middle-school girls demonstrates the potential of reading sociably and affirms the value of developing digital library books to support social exchanges among readers. Copyright 2006 ACM.",0,,2-s2.0-34247277119,Conference Proceeding,2006-12-01,10.1145/1141753.1141824,313,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,312-313,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,312,http://api.elsevier.com/content/abstract/scopus_id/34247277119,2006,34247277119,145752,p,The social life of books in the humane library
"In scholarly digital libraries, author disambiguation is an important task that attributes a scholarly work with specific authors. This is critical when individuals share the same name. We present an approach to this task that analyzes the results of automatically-crafted web searches. A key observation is that pages from rare web sites are stronger source of evidence than pages from common web sites, which we model as Inverse Host Frequency (IHF). Our system is able to achieve an average accuracy of 0.836. Copyright 2006 ACM.",62,,2-s2.0-34247201022,Conference Proceeding,2006-12-01,10.1145/1141753.1141826,315,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,314-315,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,314,http://api.elsevier.com/content/abstract/scopus_id/34247201022,2006,34247201022,145752,p,Search engine driven author disambiguation
"In this paper we present a method of parsing unstructured textual records briefly describing a person and their direct relatives, which we use in the construction of a browsing tool for genealogical data. The records have been created by researchers who are currently digitising a collection of historical archives stored at the Abbaye de Saint-Maurice, Switzerland. The string 'Beatrix, daughter of Johannes Trona, of Saillon' is a typical example of a record. We wish to annotate every term (word and symbol) in our records with a label which describes whether the term is a name (e.g. 'Beatrix'), a place (e.g. 'Saillon'), or a relationship (e.g. 'daughter'). Using this information, we are able to derive both a canonical form for each name (e.g. 'Beatrix Trona'), and the relationships between people. We build upon work developed for the cleaning and standardization of names for record linkage corpora, adding several enhancements to deal with our more difficult data, which contains common name structures of French, Italian and Latin, over hundreds of years. We present an approach to this problem that works interactively with a user to annotate the data set accurately, greatly reducing the human effort required. We do this by learning a Hidden Markov Model representing a record structure, and finding structural patterns in new records. Finally, we present a brief overview of a tool we are developing to help genealogical researchers browse and search the data. Copyright 2006 ACM.",5,,2-s2.0-34247193599,Conference Proceeding,2006-12-01,10.1145/1141753.1141827,325,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,316-325,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,316,http://api.elsevier.com/content/abstract/scopus_id/34247193599,2006,34247193599,145752,p,Tagging of name records for genealogical data browsing
"ADL Gazetteer is a digitalized worldwide gazetteer developed in the Alexandria Digital Library (ADL) Project, which contains millions of geographic names (placenames). The placenames are indexed with type terms from the ADL Feature Type Thesaurus (FTT), a hierarchical category scheme. The paper proposes a two-step method to enrich the category scheme automatically; to discover frequent generic terms by detecting phase boundaries with a mutual information-based method, and to correlate the generic terms with the relevant type terms by hierarchical clustering. The correlation pair established can then be used to supplement the FTT with the generic terms found. The extensive experiments conducted on millions of ADLG placenames demonstrated the effectiveness of the proposed methods. Besides the thesaurus enrichment, the potential applications of this research include: to suggest likely type terms when categorizing new placenames, and to help users choose likely search terms. Copyright 2006 ACM.",2,,2-s2.0-34247189087,Conference Proceeding,2006-12-01,10.1145/1141753.1141828,333,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,326-333,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,326,http://api.elsevier.com/content/abstract/scopus_id/34247189087,2006,34247189087,145752,p,Automatic feature thesaurus enrichment - Extracting generic terms from digital gazetteer
This research in progress investigates how technological protection measures are used on collections of licensed digital scholarly resources. It describes the range and variation in access and rights restrictions embedded in the technological protection measures; and it analyzes whether observed access and use restrictions were described in acceptable use statements or resource licenses.,0,,2-s2.0-34247185318,Conference Proceeding,2006-12-01,10.1145/1141753.1141830,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,334,http://api.elsevier.com/content/abstract/scopus_id/34247185318,2006,34247185318,145752,p,An assessment of access and use rights for licensed scholarly digital resources
"Electronic performance support tools are used in many workplaces, but digital libraries have not evaluated their potential usefulness. In a pilot project, the Florida State University Libraries developed inexpensive performance support tools for three types of in-house digital publishing. This strategy improved productivity and quality control.",0,,2-s2.0-34247217470,Conference Proceeding,2006-12-01,10.1145/1141753.1141832,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,336,http://api.elsevier.com/content/abstract/scopus_id/34247217470,2006,34247217470,145752,p,A performance support systems approach to digital publishing in libraries
"Our research compares the impact of paper vs. electronic presentation of text on the book selection process. Our focus is on the stage of book selection in which users study the content of a book to decide whether it will be useful for their intended purpose. Effectiveness is operationalized as accurate determination of whether a non-fiction book contains enough discussion of a particular topic to be useful for a research paper. 24 undergraduates participated in a balanced study in which they were given a topic-book pair and asked to decide whether the book was useful for the topic. We explore the differences in performance, with specific reference to the role of the search function, table-of-contents and index.",2,,2-s2.0-34247216676,Conference Proceeding,2006-12-01,10.1145/1141753.1141833,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,337,http://api.elsevier.com/content/abstract/scopus_id/34247216676,2006,34247216676,145752,p,Selecting books: A performance-based study
"To examine how users make sense of a federated search system we collected data from professional and novice searchers, using a survey instrument that contained simulated searches. A main task of participants was to provide a narrative and a drawing of their understanding of how MetaLib works. The poster presents the methodology and findings, identifies design issues related to federated search systems, and discusses strategies for increasing information literacy in federated search.",0,,2-s2.0-34247211687,Conference Proceeding,2006-12-01,10.1145/1141753.1141834,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,338,http://api.elsevier.com/content/abstract/scopus_id/34247211687,2006,34247211687,145752,p,User perceptions of a federated search system
"Tables are used to present, list, summarize, and structure important data in documents. In scholarly articles, they are often used to present the relationships among data and highlight a collection of results obtained from experiments and scientific analysis. In digital libraries, extracting this data automatically and understanding the structure and content of tables are very important to many applications. Automatic identification extraction, and search for the contents of tables can be made more precise with the help of metadata. In this paper, we propose a set of medium-independent table metadata to facilitate the table indexing, searching, and exchanging. To extract the contents of tables and their metadata, an automatic table metadata extraction algorithm is designed and tested on PDF documents.",21,,2-s2.0-34247230999,Conference Proceeding,2006-12-01,10.1145/1141753.1141835,340,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,339-340,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,339,http://api.elsevier.com/content/abstract/scopus_id/34247230999,2006,34247230999,145752,p,Automatic extraction of table metadata from digital documents
"We developed a simple web-based prototype to familiarize students with digital library tools. To assist the students with the indexing task, the prototype provided basic functionalities, including metadata input form, photo search interface. The students generally expressed a positive feedback toward the use of digital library tools in their image indexing project.",0,,2-s2.0-34247279770,Conference Proceeding,2006-12-01,10.1145/1141753.1141836,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,341,http://api.elsevier.com/content/abstract/scopus_id/34247279770,2006,34247279770,145752,p,A tool for teaching principles of image metadata generation
"NSDL Core Integration is conducting a program-wide evaluation of all NSDL program activities. The evaluation will inventory and describe NSDL achievements to date, and identify directions for future development. The scale and complexity of the NSDL program - 200 projects over 5 years - poses significant challenges for the evaluation. The poster outlines the theoretical and practical approaches being used to guide and coordinate evaluation activities.",1,,2-s2.0-34247212808,Conference Proceeding,2006-12-01,10.1145/1141753.1141837,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,342,http://api.elsevier.com/content/abstract/scopus_id/34247212808,2006,34247212808,145752,p,Evaluating the national science digital library
"A new Video-based Muti-linguistic Collaborative Distance Learning (VMC-DE) was proposed to support knowledge translation by integrating information, translation, interactive learning, knowledge and context into an interactive learning environment. Two types of user interfaces are under development.",0,,2-s2.0-34247234042,Conference Proceeding,2006-12-01,10.1145/1141753.1141838,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,343,http://api.elsevier.com/content/abstract/scopus_id/34247234042,2006,34247234042,145752,p,Multi-linguistic collaborative distance learning: From information translation to knowledge translation
This paper introduces a new metadata data dictionary design to assist in the consistent creation of digital libraries of analog sound recording and to promote their interoperability.,3,,2-s2.0-34247236703,Conference Proceeding,2006-12-01,10.1145/1141753.1141839,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,344,http://api.elsevier.com/content/abstract/scopus_id/34247236703,2006,34247236703,145752,p,Metadata data dictionary for analog sound recordings
"We asked 18 teachers about their use of video and digital video in the classroom. In general teachers desired digital collections organized by curriculum objectives because curriculum objectives allowed them to quickly narrow search results based on particular units and objectives. To understand the implications for creating metadata, an example video was tagged according to 3 different state curricular standards. The time intensive task required both in-depth knowledge of the video and of the standards. This finding has implications for third party metadata generation.",0,,2-s2.0-34247269140,Conference Proceeding,2006-12-01,10.1145/1141753.1141840,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,345,http://api.elsevier.com/content/abstract/scopus_id/34247269140,2006,34247269140,145752,p,Feasibility of developing curriculum standards metadata
A new method for federated searching of music archives using a grid-based dynamic feature extraction system is proposed.,3,,2-s2.0-34247193598,Conference Proceeding,2006-12-01,10.1145/1141753.1141841,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,346,http://api.elsevier.com/content/abstract/scopus_id/34247193598,2006,34247193598,145752,p,On-demand Metadata Extraction Network (OMEN)
"The NSDL Materials Digital Library Pathway (MatDL) is working with materials scientists to capture, in Dublin Core XML format, optimal description of nanoscale computer simulation output as research codes are executed. The long term goal of the work is to enable users, such as research groups and students, to efficiently and effectively manage their results for internal use, for exchange with outside collaborators, for use in educational settings, and for submissions to digital libraries.",0,,2-s2.0-34247224326,Conference Proceeding,2006-12-01,10.1145/1141753.1141843,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,348,http://api.elsevier.com/content/abstract/scopus_id/34247224326,2006,34247224326,145752,p,"Scientific research groups, digital libraries, & education: Metadata from nanoscale simulation code"
"The team developing the new version of the Computational Science Education Reference Desk (CSERD) has recognized the need for, and implemented, a more flexible and interactive system for finding resources using a combination of browsing and searching.",1,,2-s2.0-34247189086,Conference Proceeding,2006-12-01,10.1145/1141753.1141844,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,349,http://api.elsevier.com/content/abstract/scopus_id/34247189086,2006,34247189086,145752,p,Interface design for browsing faceted metadata
"The poster traces ongoing efforts to develop and refine a metadata schema for the Computational Science Education Reference Desk (CSERD). Design and development is informed by evolving metadata standards for educational resources, usability studies, audience analysis, and interoperability guidelines for National Science Digital Library (NSDL), NSDL Metadata Registry, and digital libraries, such as Merlot. The poster will illustrate and define each of these as ""facets"" of metadata structures.",0,,2-s2.0-34247225531,Conference Proceeding,2006-12-01,10.1145/1141753.1141845,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,350,http://api.elsevier.com/content/abstract/scopus_id/34247225531,2006,34247225531,145752,p,Developing a metadata schema for CSERD: A computational science digital library
"This study identifies (1) the steps involved in framing a multi disciplinary digital library to the 5S Model, a formal model for digital libraries. (2) the major benefits the 5S Model delivers toward simplifying a digital library's resource info structure; including the creation of simplified resource classification trees and development of a user interface which interacts with such trees to enable the best in browse ability. This poster presents a graphical mapping of how individual naming functions of the spatial temporal organization (Fnodes) are mapped to the user interface. More so, the poser will display the importance of the examples of how the spaces element is used to create ""HTML HELPERS"" which eventually result in the ultimate in ease of usability on the user end. The blending of these components to suffice for all disciplines of a digital library are the fundamental ingredients to creating an established online repository.",0,,2-s2.0-34247215598,Conference Proceeding,2006-12-01,10.1145/1141753.1141846,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,351,http://api.elsevier.com/content/abstract/scopus_id/34247215598,2006,34247215598,145752,p,Creating a multi disciplinary digital library in the 58 framework
"This poster will present an analysis of the bid behavior of the 2005 JCDL program committee [2]. For each paper, poster, and tutorial submitted for review to the 2005 JCDL, each program committee member was asked to state their expertise with regards to the subject domain of the submission. Therefore, for each submission, each referee selected one of the four categories: 1. expert in the domain of the submission and wants to review 2. expert in the domain of the submission 3. non-expert in the domain of the submission 4. conflict of interest between referee and the submission When ignoring conflict of interest situations, the hypothesis of this study is that referee bidding is based solely on the subject domain of the submission and the area of expertise of the referee. In order to validate or falsify this hypothesis, submission similarity is determined according to a TFIDF [1] and cosine similarity calculation of the terms in their abstracts and then compared against the similarity of submissions as determined by referee bidding. The correlation between these two calculations is positive, though not strong. Therefore, it is concluded that other aspects besides submission subject domain are influencing referee bidding. Next, if referees are bidding with respect to submission subject domain, then referees of similar domain expertise should be bidding in a similar manner. An analysis of the relative expertise of program committee members is computed using a relative-rank algorithm within a co-authorship network. The correlation between referee similarity as determined by their bidding behavior and referee similarity as determined by the relative-rank algorithm is positive, but not strong. Therefore, the hypothesis is again falsified because submission subject domain is not the only factor influencing referee bidding. This poster will present the various statistical techniques used throughout this study with sufficient diagrams to ensure that the audience understands the methods and conclusions drawn from the study.",0,,2-s2.0-34247203134,Conference Proceeding,2006-12-01,10.1145/1141753.1141847,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,352,http://api.elsevier.com/content/abstract/scopus_id/34247203134,2006,34247203134,145752,p,An analysis of the bid behavior of the 2005 JCDL program committee
"New practices are emerging in all stages of biological research, from data collection through dissemination of results. Through a series of cooperative projects with biologists working in data-intensive and informatics-based domains, we have documented requirements for digital libraries, tool development, and data management techniques to support contemporary scientific practice. This research is now serving as the foundation for a new biological informatics master's program to train scientific information specialists to manage and integrate scientific information and tools to support scientific problem solving and communication.",0,,2-s2.0-34247268592,Conference Proceeding,2006-12-01,10.1145/1141753.1141848,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,353,http://api.elsevier.com/content/abstract/scopus_id/34247268592,2006,34247268592,145752,p,Supporting biological information work: Research and education for digital resources and long-lived data
"The National Science Digital Library (NSDL) dramatically broadens the information about STEM resources that it can accept and make available to its users with the introduction of the NSDL Data Repository (NDR) architecture. [1] On Ramp is a platform for managing workflow, and creating, editing, distributing and storing content from multiple users and groups in a variety of formats to transform information into knowledge by enabling the NSDL community to engage in a rich exchange of information. [2] Flexible content that is small, modular, and adaptable is favored to promote this type of distributed reusable and multilayered information in an educational digital library such as NSDL. In this poster we trace the process used to determine a metaphor for the NSDL On Ramp (ONR) content and communications system [3] by exhibiting iterative designs for a user interface derived from ONR User Survey results.",1,,2-s2.0-34247238278,Conference Proceeding,2006-12-01,10.1145/1141753.1141849,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,354,http://api.elsevier.com/content/abstract/scopus_id/34247238278,2006,34247238278,145752,p,Finding a metaphor for collecting and disseminating distributed NSDL content and communications
"We describe a curated harvesting approach to creating and maintaining a subject portal, comprising selected records harvested from remote services via information retrieval standards such as SRU, Z39.50 and OAI-PMH. The result was a web-based data curation interface where administrative users can configure access to remote resources, queries to be performed at them, and review records for inclusion in end user searches.",5,,2-s2.0-34247229172,Conference Proceeding,2006-12-01,10.1145/1141753.1141850,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,355,http://api.elsevier.com/content/abstract/scopus_id/34247229172,2006,34247229172,145752,p,A curated harvesting approach to establishing a multi-protocol online subject portal
"Despite great increases in the role of computation in Science, Technology, Engineering and Mathematics (STEM), there has been no comprehensive curriculum for computational science in K-12 education [5]. The June 2005 President's Information Technology Advisory Committee (PITAC) report stated that ""only a small fraction of the potential of computational science is being realized"", and ""the diverse technical skills and technologies ... constitute a critical U.S. infrastructure that we under appreciate and undervalue at our peril [4]."" Despite a growing focus on STEM education, a substantial shortage exists of Americans qualified to work in STEM professions, including scientific research [1]. Progress in training computational scientists is lagging demand in the U.S. today. As this decade is seeing growth in the number of graduate, undergraduate, and teacher training programs in computational science [7], it is vital that the curriculum and materials to infuse computation into K-12 schools are made available. Previous studies have shown how interactive learning objects can be incorporated into teaching, allowing teachers to make classrooms more engaging and student active, provided faculty using the resources have adequate training, a willingness to modify their teaching styles, and access to or time to create quality interactive assignments [6]. The Computational Science Education Reference Desk (CSERD), a Pathway project of the National Science Digital Library, collects learning objects for teaching about and teaching with computation, reviewing items in its catalog on the basis of verification, validation, and accreditation to help provide faculty with information regarding the quality of the learning objects [3]. This study attempts to determine the effectiveness of a set of interactive learning materials from the CSERD collection in teaching concepts in a freshman Algebra I class. Materials from the CSERD resource Project Interactivate [2] will be used in a series of 4 lessons through February and March 2006 at a parochial school in Northeastern New Jersey. Students will take a pre- and post-test on topics covered in this period. Students and teachers will be surveyed to determine their attitudes towards the use of computation in learning and towards mathematics in general. Additionally, students will submit a daily feedback statement after each augmented lesson.",0,,2-s2.0-34247195036,Conference Proceeding,2006-12-01,10.1145/1141753.1141851,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,356,http://api.elsevier.com/content/abstract/scopus_id/34247195036,2006,34247195036,145752,p,Incorporating computational science activities in High School Algebra
"This poster describes an on-going process to adapt a public access peer-based verification, validation and accreditation system for a digital library that is designed to serve the science, technology, engineering and mathematics (STEM) education community.",2,,2-s2.0-34247263827,Conference Proceeding,2006-12-01,10.1145/1141753.1141852,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,357,http://api.elsevier.com/content/abstract/scopus_id/34247263827,2006,34247263827,145752,p,"Adapting peer verification, validation and accreditation processes for digital libraries"
An initial evaluation of the English Wikipedia indicates that it may provide accurate data for disambiguating and finding relations among named entities.,18,,2-s2.0-34247204813,Conference Proceeding,2006-12-01,10.1145/1141753.1141853,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,358,http://api.elsevier.com/content/abstract/scopus_id/34247204813,2006,34247204813,145752,p,Quantifying the accuracy of relational statements in Wikipedia: A methodology
This poster will present the findings of an NHPRC electronic records research grant conducted by Tufts University and Yale University.,1,,2-s2.0-34247202622,Conference Proceeding,2006-12-01,10.1145/1141753.1141854,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,359,http://api.elsevier.com/content/abstract/scopus_id/34247202622,2006,34247202622,145752,p,The ingest and maintenance of electronic records: Moving from theory to practice
"This poster describes a model for acquiring, packaging and ingesting web objects for archiving in multiple repositories. This ongoing work is part of the ECHO DEPository Project [1], a 3-year NDIIPP-partner digital preservation project at the University of Illinois at Urbana-Champaign with partners OCLC, a consortium of content provider partners, and the Library of Congress.",2,,2-s2.0-34247267168,Conference Proceeding,2006-12-01,10.1145/1141753.1141855,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,360,http://api.elsevier.com/content/abstract/scopus_id/34247267168,2006,34247267168,145752,p,"Technical architecture overview: Tools for acquisition, packaging and ingest of web objects into multiple repositories"
Browsing is a widespread user behavior in the digital library (DL) environment; there are an array of existing techniques that afford browsing and are readily applicable to digital libraries. We outline the designs of two such methods based on well-known techniques: treemaps and ScentTrails.,3,,2-s2.0-34247212807,Conference Proceeding,2006-12-01,10.1145/1141753.1141856,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,361,http://api.elsevier.com/content/abstract/scopus_id/34247212807,2006,34247212807,145752,p,Browsing affordance designs for the human-centered computing education digital library
"Most academic research libraries provide subject guides or data-driven subject portals on their websites to help users find information resources by topical research area. Unfortunately, these guides and portals are underutilized because users fail to discover them in their information search process. We describe an approach in development at NCSU to increase the discovery of library subject portals, and topically organized library resources in general. This approach exploits the rich topical content in available institutional data stores to generate subject recommendations related to the user's search query.",1,,2-s2.0-33845623920,Conference Proceeding,2006-12-01,10.1145/1141753.1141857,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,362,http://api.elsevier.com/content/abstract/scopus_id/33845623920,2006,33845623920,145752,p,Indexing institutional data to promote library resource discovery
"There has been a recent dramatic shift from analog to digital creation, management and use of video, creating unprecedented opportunities to develop rich, interactive collections, but without proper care, much of this digital video could be inaccessible or incomprehensible in the future. Several projects have explored technical challenges and potential strategies for ensuring long-term access to digital video collections. A number of initiatives have also generated sets of proposed metadata for digital video. Most of the above activities have focused on ensuring that videos can be discovered, accessed and rendered over time. Another active steam of research has examined how users can best navigate, understand, view, interact with and annotate collections of digital video. This research has generated valuable lessons, tools and observations to support current users. However, it has generally not investigated how the components of a digital video collection might support or fail to support future users of videos. The Preserving Video Objects and Context (VidArch) project - NSF Grant # US 0455970, involving the authors, Gary Marchionini and Gary Geisler - lies at the intersection between the two streams of research described above. We are developing a preservation framework for digital video context. Among other issues, we are considering: Are there interface elements from current collections (e.g. surrogates, navigation aids, behaviors) that should be retained over time, in order to support long-term use and understanding of the videos? How might curators of digital video collections decide which contextual elements are important and then devise strategies for preserving them? According to the glossary of the Society of American Archivists, context is the ""organizational, functional, and operational circumstances surrounding materials' creation, receipt, storage, or use, and its relationship to other materials."" Documents derive value and meaning from relationships with other documents within the same collection. Rather than treating each item as a discrete entity, archival theory and practice suggests that digital videos should be managed, preserved and presented to users in a way that reflects the social and documentary context in which they were originally embedded. Access Systems for text-based collections often rely on surrogates, such as indices, catalogs, and abstracts. In addition to facilitating information navigation, discovery and retrieval, surrogates also provide valuable contextual information about the documents. In archival descriptive practices, attention to context is expressed through the creation of finding aids, which include not only inventories of the contents of collections, but also background information about the actors and activities that generated the materials, and the ways they were organized by their original creators or recipients. Recent research has produced and investigated an analogous set of surrogates for digital video collections. These include textual descriptions, title, captions, and annotations, but they also include surrogates that are themselves still or moving images: video segments, keyframes, slide shows, and fast forwards. VidArch is focused on two collections within the Open Video repository: the complete set of videos that National Aeronautic and Space Administration (NASA) produces and broadcasts to advance learning and appreciation for science; and a set of videos of juried presentations to various annual Association for Computing Machinery (ACM) conferences. The two collections reflect several forms of documentation that may be valuable to preserve in order to convey the context of the videos: text-based surrogates, image-based surrogates (story boards and fast forwards), links to related videos, use history data, and supporting documents (e.g. lesson plans). We have generated archival finding aids to the two collections in order to reflect contextual information that is not readily available within Open Video. Such documentary elements should not simply be treated as part of the current interface to the collection but should also be considered as potential targets of long-term preservation in their own right. This poster presents an information model for digital video context and places the information model within the context of recent guidance on metadata for digital video, metadata for digital preservation, and the Reference Model for an Open Archival Information System (OAIS).",1,,2-s2.0-34247184180,Conference Proceeding,2006-12-01,10.1145/1141753.1141858,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,363,http://api.elsevier.com/content/abstract/scopus_id/34247184180,2006,34247184180,145752,p,Keeping the context: An investigation in preserving collections of digital video
"Cloudalicious is an online visualization tool that has been designed to give insight into how tag clouds, or folksonomies, develop over time. A folksonomy is an organic system of text labels attributed to an object by the users of that object. The most common object so far to be the subject of this tagging has been the online bookmark. Stabilization of a URL's tag cloud over time is the clearest result of this type of visualization. Any diagonal movement on the graphs, indicative of a change in the tags being used to describe a URL, should garner further discussion.",24,,2-s2.0-34247203133,Conference Proceeding,2006-12-01,10.1145/1141753.1141859,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,364,http://api.elsevier.com/content/abstract/scopus_id/34247203133,2006,34247203133,145752,p,Cloudalicious: Folksonomy over time
"As we advance with the implementation of novel technologies, apparati and protocols that combine existing technologies with emergent ones are becoming more relevant to ensure smoother transitions and overcome challenges that new technologies (alone) can not address. The author essentially suggests a new type of information exchange which focuses on the olfactory/gustatory perceptual realm of smell and taste. In principle, a printing module transforms signals received from the processing unit into olfactory documents that can, in turn, be stored and preserved as scented texts on thin layers of a gustative medium.",2,,2-s2.0-34247237244,Conference Proceeding,2006-12-01,10.1145/1141753.1141860,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,365,http://api.elsevier.com/content/abstract/scopus_id/34247237244,2006,34247237244,145752,p,Apparatus and methods for production of printed aromatic and gustative information
"This poster and accompanying demonstration introduces the Teaching Box Builder application that, as being implemented, supports the development of pedagogically rich inquiry-based earth science lessons using digital library resources.",1,,2-s2.0-34247227556,Conference Proceeding,2006-12-01,10.1145/1141753.1141861,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,366,http://api.elsevier.com/content/abstract/scopus_id/34247227556,2006,34247227556,145752,p,Teaching box builder: Customizing pedagogical contexts for use of digital library resources in classrooms
"In this poster, the authors describe a system, claimID1, that enables individuals to create representation of their online identity. Realizing that online identity, especially personal identity as represented in search, is difficult to collect and verify, the authors propose a, system that enables individuals to collect and self-classify the information that is about them online.",2,,2-s2.0-34247250799,Conference Proceeding,2006-12-01,10.1145/1141753.1141862,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,367,http://api.elsevier.com/content/abstract/scopus_id/34247250799,2006,34247250799,145752,p,ClaimID: A system for personal identity management
"As part of the NSF-funded Pathways project, we have created an interoperable data model to facilitate object re-use and a broad spectrum of cross-repository services. The resulting Pathways Core data model is designed to be lightweight to implement, and to be widely applicable as a shared profile or as an overlay on data models currently used in repository systems and applications. We consider the data models underlying the Fedora, Dspace and aDORe repository systems, and a number of XML-based formats used for the representation of compound objects, including MPEG-21 DIDL, METS, and IMS/CP. At the heart of the Pathways Core data model (Fig. 1) are the entity and datastream elements, entity elements model the abstract aspects of digital objects and align with works and expressions in FRBR [1], An entity can model anything from a digital object to a collection of digital objects (other entities), to a node created merely to express abstract properties. Core properties of entities are hasIdentifier, has ProviderInfo, hasLineage, and hasProvider-Persistence. If a repository attaches providerInfo to an entity, it provides a handle to access the entity from the repository, supporting its use and re-use. Persistence of this handle may be indicated with providerPersistence. The hasLineage property is used to indicate the entity (or entities) from which the entity to which the hasLineage is attached was derived. Other properties, such as hasSemantic, that convey the intellectual genre of the entity (i.e. journal article), can be added, datastream elements model the concrete aspects of a digital object; these align with items in FRBR, and can be thought of as aspects at the level of bitstreams. An entity may have any number of datastreams. Two properties of datastream have been defined as part of the Pathways Core: hasLocation conveys a URI that can be resolved to yield a bitstream; and hasFormat conveys the digital format of the bitstream. If a datastream has multiple hasLocation properties, resolution of the conveyed URIs yields bit-equivalent bitstreams.The Pathways Core data model can be serialized in a variety of ways, and, an RDF serialization as well as a profile of MPEG-21 DIDL have been created as reference implementations. We have also conducted the following experiment to illustrate the power of the Pathways Core. A number of heterogeneous repositories implemented an OpenURL-based obtain interface from which, given the providerInfo of an entity, an RDF serialization of the entity compliant with the Pathways Core could be retrieved. Using this interface, an overlay journal can collect serializations of some entities (scholarly papers) from the different collaborating repositories, and assemble those into a new issue of the journal. The overlay journal then itself implemented the same obtain interface, and as a result, an RDF serialization of the entire journal, an issue, and an article could be extracted. This interface could then, for example, be used by a preservation repository to collect content from the overlay journal for ingest and mirroring. This experiment illustrates how cross-repository services and workflows can be facilitated through support of an interoperable data model (the Pathways Core) and an interoperable service interface (the OpenURL-based obtain interface).",2,,2-s2.0-34247186898,Conference Proceeding,2006-12-01,10.1145/1141753.1141863,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,368,http://api.elsevier.com/content/abstract/scopus_id/34247186898,2006,34247186898,145752,p,Pathways core: A data model for cross-repository services
"The Association of Research Libraries (ARL) is developing the DigiQUAL™ protocol to assess the service quality provided by digital libraries (DLs). In 2005, statements about DL service quality were put through a two-step validation process with DL developers and then with users in an online survey.",0,,2-s2.0-34247224863,Conference Proceeding,2006-12-01,10.1145/1141753.1141864,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,369,http://api.elsevier.com/content/abstract/scopus_id/34247224863,2006,34247224863,145752,p,Pilot testing the DigiQUAL™ protocol: Lessons learned
"The purpose of this demonstration is to show how LexiURL may be used with a search engine to download links to and colinks with a digital library site for ""Web intelligence"" purposes.",1,,2-s2.0-34247187427,Conference Proceeding,2006-12-01,10.1145/1141753.1141867,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,371,http://api.elsevier.com/content/abstract/scopus_id/34247187427,2006,34247187427,145752,p,LexiURL Web link analysis for digital libraries
"Networks have remained a challenge for information retrieval and visualization because of the rich set of tasks that users want to accomplish. This paper demonstrates a tool, NetLens, to explore a Content-Actor paired network data model. The NetLens interface was designed to allow users to pose a series of elementary queries and iteratively refine visual overviews and sorted lists. This enables the support of complex queries that are traditionally hard to specify in node-link visualizations. NetLens is general and scalable in that it applies to any dataset that can be represented with our abstract Content-Actor data model.",0,,2-s2.0-34247228073,Conference Proceeding,2006-12-01,10.1145/1141753.1141868,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,372,http://api.elsevier.com/content/abstract/scopus_id/34247228073,2006,34247228073,145752,p,Exploring content-actor paired network data using iterative query refinement with NetLens
"A new interactive shot level video navigation system is developed to support three types of content-based browsing functions: Neighbor clustering, Visual similarity, and Visual Neighbor Similarity (VNS) browsing.",2,,2-s2.0-34247244137,Conference Proceeding,2006-12-01,10.1145/1141753.1141869,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,373,http://api.elsevier.com/content/abstract/scopus_id/34247244137,2006,34247244137,145752,p,A content-based video browsing system based on visual neighbor similarity
"Numerous digital libraries (DLs), electronic archives (EAs) and portal services have been developed. These services allow online structured access to digitised information, facilitating remote access for educators and students. Often, DL users and information are remotely located - so too are their users. The authors can envision numerous circumstances where two remotely located parties may wish to opportunistically examine an online resource - e-learning environments for example. We are particularly interested in assisting users whose collaboration resolves around discussion of a common visual resource (documents and collections of documents in the case under discussion). By providing a single tool for information seeking and multi-user collaboration, we believe that the amount of preparation required for an online session is reduced, while the flexibility allowed to parties to conduct ad-hoc examinations of a resource is increased. This paper proposes a framework to address this functionality deficit by describing a document foraging tool that provides facilities for both visual exploration of a document set and Voice-over-IP (VoIP) based collaborative features.",0,,2-s2.0-34247202605,Conference Proceeding,2006-12-01,10.1145/1141753.1141871,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,375,http://api.elsevier.com/content/abstract/scopus_id/34247202605,2006,34247202605,145752,p,Real-time collaboration through visual search and voice-over-IP
"MyLifeBits is both an application and a framework to manage a personal lifetime of memories. We will demonstrate the use of a small digital library that manages data from two Microsoft SenseCams, used by: 1) students in the Virginia-Maryland Regional College of Veterinary Medicine, and 2) students supported by our Assistive Technologies office.",2,,2-s2.0-34247227547,Conference Proceeding,2006-12-01,10.1145/1141753.1141872,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,376,http://api.elsevier.com/content/abstract/scopus_id/34247227547,2006,34247227547,145752,p,Demonstrating the use of a SenseCam in two domains
"In a variety of applications such as learning, we need to integrate multimedia information into convenient packages (like presentations). The challenges involved in this process are: Selecting or working with information elements at sub-document level while retaining the original context; describing the integration or packaging of such elements; and making use of minimal storage during this activity. Current multimedia authoring software, like RealProducer (http://www.realnetworks.com/products/producer/), tend to repeatedly copy information, or to limit granularity of information referenced. Although editors for the Synchronized Multimedia Integration Language (http://www.w3.org/ AudioVideo/), such as GRiNS (http://www.oratrix.com/Products/G2E), address some of the aforementioned challenges, they are difficult to use and require considerable training effort before a user can work with them. We developed the Superimposed Multimedia Presentation Editor and Player (SIMPEL), a tool to address these challenges. SIMPEL allows a user to reference information of many types, at varying granularity, without replicating the referenced information. It also allows the user to compose synchronized multimedia presentations. For example, for a specific topic a user can select an audio clip, some images, and some text. He can then ""play"" (render in specific panes of a window) this information-set in some order. Figure 1 shows a snapshot of a SIMPEL presentation. Pane A contains an audio clip. Panes B, C, and D show selected information within web pages. SIMPEL is in a genre of applications called superimposed applications (SAs), which allow users to superimpose new interpretations over existing or base information [1]. SAs employ ""marks"", references to selected regions within base information. SIMPEL uses the Superimposed Pluggable Architecture for Contexts and Excerpts (SPARCE), middleware that provides mark management and other services for SAs [2]. SIMPEL has been implemented for Windows in Visual Basic.NET and uses XML for storing presentation data. Future work on SIMPEL will include support for pre-fetching media files (for better performance) and packaging and sharing of SIMPEL presentations. We also plan to index marks and make them searchable, thus facilitating further reuse. A more detailed report on SIMPEL is available at http://pubs.dlib.vt.edu:9090/48/.",2,,2-s2.0-34247191223,Conference Proceeding,2006-12-01,10.1145/1141753.1141873,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,377,http://api.elsevier.com/content/abstract/scopus_id/34247191223,2006,34247191223,145752,p,SIMPEL: A superimposed multimedia presentation editor and player
"Documents have, in general, a multihierarchical structure (such as physical organization in the form of pages and lines, content organization in the form of paragraphs and sentences, etc.). Searching multihierarchical XML encoding presents a number of unique challenges for both computer scientists and document experts. We present an extension of the XQuery language suitable for searching multihierarchical XML.",2,,2-s2.0-34247193579,Conference Proceeding,2006-12-01,10.1145/1141753.1141874,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,378,http://api.elsevier.com/content/abstract/scopus_id/34247193579,2006,34247193579,145752,p,Extended XQuery for digital libraries
"With the growing importance of mapping land, regions, and their related features, Geographic Information Systems (GIS) has become an ever important standard in fields where such detailed study of land features is required. Our archaeology digital library, ETANA-DL (http://etana.dlib.vt.edu), contains thousands of records from eight member excavations. Here, we draw on the Space aspect of the 5S meta-model [1] for digital libraries and demonstrate a methodology used to integrate archaeological GIS data with the wealth of information within ETANA-DL. ETANA-GIS connects the digital library's textual records with a spatial representation of their original locations, enhancing users' understanding of the finds. Using a dataset of the University of Toronto's Tell Madaba excavation project [2], we developed an interactive, Web-based representation of the original ArcGIS document (accessible from ETANA-DL homepage). For dynamic generation of maps from geospatial data, we use the MapServer [3] project, a mature, project which boasts a rich toolset of features for cartographic-related image generation. MapServer can directly utilize ArcGIS layer resources but some translation and additional authoring must occur for proper image generation. Then, using PHP, the MapScript MapServer API, and navigation tools, the map was ported to an interactive, Web-accessible format. Based on a study of alternatives, the technology we chose for our technique seemed to be the best suited for digital library integration and is also completely open source. To explore the presentation of the map, a user employs the navigation tools displayed in the corner of the main view (see Figure 1). In addition, full control of displayed layers, a smaller map showing overall view and context, as well as a dynamic scale bar are available for use. To integrate the Web-based version of the Tell Madaba GIS map with the existing digital library, the layers depicting archaeological divisions are clickable and labeled for easy identification. Any area queried results in a pop-up box with ETANA-DL's records and artifacts for that area. While this integration connects the digital library with the spatial representation of the region, the unique quality of various GIS maps causes certain difficulties. The lack of standard in denoting spatial divisions in GIS is one hindrance to producing a more automated technique. Future work will include more automation, usability evaluation, and integration of additional excavations. We hope integration of the digital library and GIS greatly aids users' understanding of the spatial organization of the included data.",5,,2-s2.0-34247215577,Conference Proceeding,2006-12-01,10.1145/1141753.1141875,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,379,http://api.elsevier.com/content/abstract/scopus_id/34247215577,2006,34247215577,145752,p,ETANA-GIS: GIS for archaeological digital libraries
This demonstration shows a set of tools for managing and performing quality control processes to monitor and enforce quality over UNIMARC descriptive metadata records. These tools share a common infrastructure consisting mainly on information coded in XML and tools to process it. This system is currently being used on the National Library of Portugal in production services for the quality control and maintenance of the national union catalogue.,0,,2-s2.0-34247239847,Conference Proceeding,2006-12-01,10.1145/1141753.1141876,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,380,http://api.elsevier.com/content/abstract/scopus_id/34247239847,2006,34247239847,145752,p,MANGAS infrastructure
This demonstration illustrates the use of two search services offered by the Digital Library for Earth System Education (DLESE) and shows how they have been used to create customized discovery interfaces for library resources in science Web sites.,1,,2-s2.0-34247272455,Conference Proceeding,2006-12-01,10.1145/1141753.1141877,,"[{'$': '1595933549'}, {'$': '9781595933546'}]",15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,381,http://api.elsevier.com/content/abstract/scopus_id/34247272455,2006,34247272455,145752,p,How science web sites are leveraging DLESE search web services to extend value to their users
"The availability of map interfaces and location-aware devices makes a growing amount of unstructured, geo-referenced information available on the Web. This type of information can be valuable not only for browsing, finding and making sense of individual items, but also in aggregate form to help understand data trends and features. In particular, over twenty million geo-referenced photos are now available on Flickr, a photo-sharing website - the first major collection of its kind. These photos are often associated with user-entered unstructured text labels (i.e., tags). We show how we analyze the tags associated with the geo-referenced Flickr images to generate aggregate knowledge in the form of ""representative tags"" for arbitrary areas in the world. We use these tags to create a visualization tool, World Explorer, tha tcan help expose the content of the data, using a map interface to display the derived tags and the original photo items. We perform a qualitative evaluation of World Explorer that outlines the visualization's benefits in browsing this type of content. We provide insights regarding the aggregate versus individual-item requirements in browsing digital geo-referenced material. Copyright 2007 ACM.",170,,2-s2.0-36348963718,Conference Proceeding,2007-11-29,10.1145/1255175.1255177,10,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,1-10,Proceedings of the ACM International Conference on Digital Libraries,1,http://api.elsevier.com/content/abstract/scopus_id/36348963718,,36348963718,62702,p,World explorer: Visualizing aggregate data from unstructured text in geo-referenced collections
"Digital libraries (DLs) for online discourse contain large amounts of valuable information that is difficult to navigate and analyze. Visualization systems developed to facilitate improved CMC archive analysis and navigation primarily focus on interaction information, with little emphasis on textual content. In this paper we present a system that provides DL exploration services such as visualization, categorization, and analysis for CMC text. The system incorporates an extended feature set comprised of stylistic, topical, and sentiment related features to enable richer content representation. The system also includes the Ink Blot technique which utilizes decision tree models and text overlay to visualize CMC messages. Ink Blots can be used for text categorization and analysis across forums, authors, threads, messages, and over time. The proposed system's analysis capabilities were evaluated with a series of examples and a qualitative user study. Empirical categorization experiments comparing the Ink Blot technique against a benchmark support vector machine classifier were also conducted. The results demonstrated the efficacy of the Ink Blot technique for text categorization and also highlighted the effectiveness of the extended feature set for improved text categorization. Copyright 2007 ACM.",16,,2-s2.0-36349003655,Conference Proceeding,2007-11-29,10.1145/1255175.1255178,18,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,11-18,Proceedings of the ACM International Conference on Digital Libraries,11,http://api.elsevier.com/content/abstract/scopus_id/36349003655,,36349003655,62702,p,Categorization and analysis of text in computer mediated communication archives using visualization
"Identifying the significance of specific concepts in the diffusion of scientific knowledge is a challenging issue concerning many theoretical and practical areas. We introduce an innovative visual analytic approach to integrate microscopic and macroscopic perspectives of a rapidly growing scientific knowledge domain. Specifically, our approach focuses on statistically unexpected phrases extracted from unstructured text of titles and abstracts at the microscopic level in association with the magnitude and timeliness of their citation impact at the macroscopic level. The H-index, originally defined to measure individual scientists. productivity in terms of their citation profiles, is extended in two ways: 1) to papers and terms as a means of dividing these items into two groups so as to replace the less optimal threshold-based divisions, and 2) to take into account the timeliness of the impact of knowledge diffusion in terms of the timing of citations and publications so that attention is particularly drawn towards potentially significant and timely papers. The selected terms are connected to higher-level performance indicators, such as measures derived from the H-index, in the form of decision trees. A top-down traversal of such decision trees provides an intuitive walkthrough of concepts and phrases that may underline potentially significant but currently still latent scientific discoveries. Timeliness measures can also help to identify institutions that are at the forefront of a research field. We illustrate how widely accessible tools such as Google Earth can be utilized to disseminate such insights. The practical significance for digital libraries and fostering scientific discoveries is demonstrated through the astronomical literature related to the Sloan Digital Sky Survey (SDSS). Copyright 2007 ACM.",8,,2-s2.0-36349029240,Conference Proceeding,2007-11-29,10.1145/1255175.1255179,28,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,19-28,Proceedings of the ACM International Conference on Digital Libraries,19,http://api.elsevier.com/content/abstract/scopus_id/36349029240,,36349029240,62702,p,Delineating the citation impact of scientific discoveries
"An increasing number of institutions throughout the world face legal obligations or business needs to collect and preserve digital objects over several decades. A range of tools exists today to support the variety of preservation strategies such as migration or emulation. Yet, different preservation requirements across institutions and settings make the decision on which solution to implement very diffcult. This paper presents the PLANETS Preservation Planning approach. It provides an approved way to make informed and accountable decisions on which solution to implement in order to optimally preserve digital objects for a given purpose. It is based on Utility Analysis to evaluate the performance of various solutions against well-defined requirements and goals. The viability of this approach is shown in a range of case studies for different settings. We present its application to two scenarios of web archives, two collections of electronic publications, and a collection of multimedia art. This work focuses on the different requirements and goals in the various preservation settings. Copyright 2007 ACM.",35,,2-s2.0-36448943964,Conference Proceeding,2007-11-30,10.1145/1255175.1255181,38,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,29-38,Proceedings of the ACM International Conference on Digital Libraries,29,http://api.elsevier.com/content/abstract/scopus_id/36448943964,,36448943964,62702,p,How to choose a digital preservation strategy: Evaluating a preservation planning procedure
"When a website is suddenly lost without a backup, it maybe reconstituted by probing web archives and search engine caches for missing content. In this paper we describe an experiment where we crawled and reconstructed 300 randomly selected websites on a weekly basis for 14 weeks. The reconstructions were performed using our web-repository crawler named Warrick which recovers missing resources from the Web Infrastructure (WI), the collective preservation effort of web archives and search engine caches. We examine several characteristics of the websites over time including birth rate, decay and age of resources. We evaluate the reconstructions when compared to the crawled sites and develop a statistical model for predicting reconstruction success from the WI. On average, we were able to recover 61% of each website's resources. We found that Google's PageRank, number of hops and resource age were the three most significant factors in determining if a resource would be recovered from the WI. Copyright 2007 ACM.",10,,2-s2.0-36348992623,Conference Proceeding,2007-11-29,10.1145/1255175.1255182,48,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,39-48,Proceedings of the ACM International Conference on Digital Libraries,39,http://api.elsevier.com/content/abstract/scopus_id/36348992623,,36348992623,62702,p,Factors affecting Website reconstruction from the Web infrastructure
"The DigCCurr (Digital Curation Curriculum) project is developing a graduate level curricular framework, course modules, and experiential components to prepare students for digital curation in various environments. This paper summarizes a draft and guiding principles behind a matrix of digital curation knowledge and competencies, which are serving as the basis for our curriculum design efforts. Copyright 2007 ACM.",7,,2-s2.0-36349003654,Conference Proceeding,2007-11-29,10.1145/1255175.1255183,50,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,49-50,Proceedings of the ACM International Conference on Digital Libraries,49,http://api.elsevier.com/content/abstract/scopus_id/36349003654,,36349003654,62702,p,Defining what digital curators do and what they need to know: The DigCCurr project
"HTTP and MIME, while sufficient for contemporary webpage access, do not provide enough forensic information to enable the long-term preservation of the resources they describe and transport. But what if the originating web server automatically provided preservation metadata encapsulated with the resource at time of dissemination? Perhaps the ingestion process could be streamlined, with additional forensic metadata available to future information archeologists. We have adapted an Apache web server implementation of OAI-PMH which can utilize third-party metadata analysis tools to provide a metadata-rich description of each resource. The resource and its forensic metadata are packaged together as a complex object, expressed in plain ASCII and XML. The result is a CRATE: a self-contained preservation-ready version of the resource, created at time of dissemination. Copyright 2007 ACM.",1,,2-s2.0-36348960789,Conference Proceeding,2007-11-29,10.1145/1255175.1255184,52,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,51-52,Proceedings of the ACM International Conference on Digital Libraries,51,http://api.elsevier.com/content/abstract/scopus_id/36348960789,,36348960789,62702,p,Generating best-effort preservation metadata for Web resources at time of dissemination
"Words in natural language documents exhibit a small world network structure. Thus the physics community provides us with an extensive supply of algorithms for extracting community structure. We present a novel method for semantically clustering a large collection of documents using small world communities. This method combines modified physics algorithms with traditional information retrieval techniques. A term network is generated from the document collection, the terms are clustered into small world communities, the semantic term clusters are used to generate overlapping document clusters. The algorithm combines the speed of single link with the quality of complete link. Clustering takes place in nearly real-time and the results are judged to be coherent by expert users. Our algorithm occupies a middle ground between speed and quality of document clustering. Copyright 2007 ACM.",8,,2-s2.0-36348957963,Conference Proceeding,2007-11-29,10.1145/1255175.1255186,62,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,53-62,Proceedings of the ACM International Conference on Digital Libraries,53,http://api.elsevier.com/content/abstract/scopus_id/36348957963,,36348957963,62702,p,Document clustering using small world communities
"News portals gather and organize news articles published daily on the Internet. Typically, news articles are clustered into 'events' and each cluster is displayed with a short description of its contents. A particularly interesting choice for describing the contents of a cluster is a machine-generated multi-document summary of the articles in the cluster. Such summaries are informative and help news readers to identify and explore only clusters of interest. Naturally, multi-document clusters and summaries are also valuable to help users navigate the results of keyword-search queries. Unfortunately, current document summarizers are still slow; as a result, search strategies that define document clusters and their multi-document summaries online, in a query-specific manner, are prohibitively expensive. In contrast, search strategies that only return offline, query-independent document clusters are efficient, but might return clusters whose (query-independent) summaries are of little relevance to the queries. In this paper, we present an efficient Hybrid search strategy to address the limitations of fully online and fully offline summarization-aware search approaches. Extensive experiments involving user relevance judgments and real news articles show that the quality of our Hybrid results is high, and that these results are computed in substantially less time than with the fully online strategy. We have implemented our strategy and made it available on the Newsblaster news summarization system, which crawls and summarizes news articles from a variety of web sources on a daily basis. Copyright 2007 ACM.",5,,2-s2.0-36349017837,Conference Proceeding,2007-11-29,10.1145/1255175.1255187,72,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,63-72,Proceedings of the ACM International Conference on Digital Libraries,63,http://api.elsevier.com/content/abstract/scopus_id/36349017837,,36349017837,62702,p,Efficient summarization-aware search for online news articles
"This paper explores the integration of text mining and data mining techniques, digital library systems, and computational and data grid technologies with the objective of developing an online classification service exemplar. We discuss the current research issues relating to the use of data mining algorithms and toolkits for textual data; the necessary changes within the Cheshire3 Information Framework to accommodate analysis workflows; the outcomes of a demonstrator based on the National Library of Medicine's Medline dataset; and the provision of comparable metrics for evaluation purposes. The prototype has resulted in extremely accurate online classification services and offers a novel method of supporting text mining and data mining within a highly scaled computational environment, integrated seamlessly into the digital library architecture. Copyright 2007 ACM.",7,,2-s2.0-36348965457,Conference Proceeding,2007-11-29,10.1145/1255175.1255188,79,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,73-79,Proceedings of the ACM International Conference on Digital Libraries,73,http://api.elsevier.com/content/abstract/scopus_id/36348965457,,36348965457,62702,p,Integrating data and text mining processes for digital library applications
"The panel will discuss various aspects of the ongoing Object Re-Use and Exchange (ORE) effort of the Open Archives Initiative (OAI). OAI-ORE is funded by the Andrew W. Mellon Foundation and is a result of the ""Augmenting Interoperability across Scholarly Repositories"" meeting that took place in April 2006 at the Mellon Foundation. A panel at JCDL 2006 reported on this meeting. The goal of OAI-ORE is to develop, identify, and profile extensible standards and protocols that allow repositories, agents, and services to interoperate in the context of use and reuse of compound digital objects beyond the boundaries of the holding repositories. Copyright 2007 ACM.",5,,2-s2.0-36349032905,Conference Proceeding,2007-11-29,10.1145/1255175.1255190,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,80,http://api.elsevier.com/content/abstract/scopus_id/36349032905,,36349032905,62702,p,"The OAI-ORE effort: Progress, challenges, synergies"
"Research findings are often transmitted both as written documents and narrated slide presentations. As these two forms of media contain both unique and replicated information, it is useful to combine and align these two views to create a single synchronized medium. We introduce SlideSeer, a digital library that discovers, aligns and presents such presentation and document pairs. We discuss the three major system components of the SlideSeer DL: 1) the resource discovery, 2) the fine-grained alignment and 3) the user interface. For resource discovery, we have bootstrapped our collection building process using metadata from DBLP and CiteSeer. For alignment, we modify maximum similarity alignment to favor monotonic alignments and incorporate a classifier to handle slides which should not be aligned. For the user interface, we allow the user to seamlessly switch between four carefully motivated views of the resulting synchronized media pairs. Copyright 2007 ACM.",21,,2-s2.0-36348955093,Conference Proceeding,2007-11-29,10.1145/1255175.1255192,90,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,81-90,Proceedings of the ACM International Conference on Digital Libraries,81,http://api.elsevier.com/content/abstract/scopus_id/36348955093,,36348955093,62702,p,SlideSeer: A digital library of aligned document and presentation pairs
"Tables are ubiquitous in digital libraries. In scientific documents, tables are widely used to present experimental results or statistical data in a condensed fashion. However, current search engines do not support table search. The difficulty of automatic extracting tables from un-tagged documents, the lack of a universal table metadata specification, and the limitation of the existing ranking schemes make table search problem challenging. In this paper, we describe TableSeer, a search engine for tables. TableSeer crawls digital libraries, detects tables from documents, extracts tables metadata, indexes and ranks tables, and provides a user-friendly search interface. We propose an extensive set of medium-independent metadata for tables that scientists and other users can adopt for representing table information. In addition, we devise a novel page box-cutting method to improve the performance of the table detection. Given a query, TableSeer ranks the matched tables using an innovative ranking algorithm - TableRank. TableRank rates each query, table pair with a tailored vector space model and a specific term weighting scheme. Overall, TableSeer eliminates the burden of manually extract table data from digital libraries and enables users to automatically examine tables. We demonstrate the value of TableSeer with empirical studies on scientific documents. Copyright 2007 ACM.",74,,2-s2.0-36348992621,Conference Proceeding,2007-11-29,10.1145/1255175.1255193,100,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,91-100,Proceedings of the ACM International Conference on Digital Libraries,91,http://api.elsevier.com/content/abstract/scopus_id/36348992621,,36348992621,62702,p,TableSeer: Automatic table metadata extraction and searching in digital libraries
"The coverage of citations in citation databases of today is disjoint and incomplete, which can result in conflicting quality assessment outcomes across different data sources. Fusion approach to quality assessment that employs a range of citation-based methods to analyze data from multiple sources is one way to address this limitation. The paper discusses a citation analysis pilot study that measured the impact of scholarly publications based on the data mined from Web of Science, Scopus, and Google Scholar. Copyright 2007 ACM.",4,,2-s2.0-36348969563,Conference Proceeding,2007-11-29,10.1145/1255175.1255194,102,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,101-102,Proceedings of the ACM International Conference on Digital Libraries,101,http://api.elsevier.com/content/abstract/scopus_id/36348969563,,36348969563,62702,p,CiteSearch: Next-generation citation analysis
The effectiveness of two modes of subject representation - table of contents (TOC) and subject headings - in subject searching in an online public access catalog (OPAC) system was investigated. The retrieval difference between TOC and the Library of Congress subject headings (LCSH) was statistically significant; the effect of subject domain was not statistically significant; users had better success matching their keywords to TOC than to LCSH; but their keywords often failed to retrieve items similar to the target items. These findings underscore the need to bridge user keywords to both TOC and LCSH. Copyright 2007 ACM.,3,,2-s2.0-36349037240,Conference Proceeding,2007-11-29,10.1145/1255175.1255195,104,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,103-104,Proceedings of the ACM International Conference on Digital Libraries,103,http://api.elsevier.com/content/abstract/scopus_id/36349037240,,36349037240,62702,p,Retrieval effectiveness of table of contents and subject headings
"When browsing a digital library of research papers, it is natural to ask which authors are most influential in a particular topic. We present a probabilistic model that ranks authors based on their influence in particular areas of scientific research. This model combines several sources of information: citation information between documents as represented by PageRank scores, authorship data gathered through automatic information extraction, and the words in paper abstracts. We compare the performance of a topic model versus a smoothed language model by assessing the number of major award winners in the resulting ranked list of researchers. Copyright 2007 ACM.",15,,2-s2.0-36348992066,Conference Proceeding,2007-11-29,10.1145/1255175.1255196,106,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,105-106,Proceedings of the ACM International Conference on Digital Libraries,105,http://api.elsevier.com/content/abstract/scopus_id/36348992066,,36348992066,62702,p,Mining a digital library for influential authors
"Social bookmarking is an emerging type of a Web service that helps users share, classify, and discover interesting resources. In this paper, we explore the concept of an enhanced search, in which data from social bookmarking systems is exploited for enhancing search in the Web. We propose combining the widely used link-based ranking metric with the one derived using social bookmarking data. First, this increases the precision of a standard link-based search by incorporating popularity estimates from aggregated data of bookmarking users. Second, it provides an opportunity for extending the search capabilities of existing search engines. Individual contributions of bookmarking users as well as the general statistics of their activities are used here for a new kind of a complex search where contextual, temporal or sentiment-related information is used. We investigate the usefulness of social bookmarking systems for the purpose of enhancing Web search through a series of experiments done on datasets obtained from social bookmarking systems. Next, we show the prototype system that implements the proposed approach and we present some preliminary results. Copyright 2007 ACM.",143,,2-s2.0-36349023867,Conference Proceeding,2007-11-29,10.1145/1255175.1255198,116,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,107-116,Proceedings of the ACM International Conference on Digital Libraries,107,http://api.elsevier.com/content/abstract/scopus_id/36349023867,,36349023867,62702,p,Can social bookmarking enhance search in the Web?
"This paper describes a formative evaluation of an integrated multilingual, multimedia information system, a series of user studies designed to guide system development. The system includes automatic speech recognition for English, Chinese, and Arabic, automatic translation from Chinese and Arabic into English, and query-based and profile-based search options. The study design emphasizes repeated evaluation with the same (increasingly experienced) participants, exploration of alternative task designs, rich qualitative and quantitative data collection, and rapid analysis to provide the timely feedback needed to support iterative and responsive development. Results indicate that users presented with materials in a language that they do not know can generate remarkably useful work products, but that integration of transcription, translation, search and profile management poses challenges that would be less evident were each technology to be evaluated in isolation. Copyright 2007 ACM.",5,,2-s2.0-36349019841,Conference Proceeding,2007-11-29,10.1145/1255175.1255199,126,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,117-126,Proceedings of the ACM International Conference on Digital Libraries,117,http://api.elsevier.com/content/abstract/scopus_id/36349019841,,36349019841,62702,p,"Task-based interaction with an integrated multilingual, multimedia information system: A formative evaluation"
"This paper describes a framework to annotate images using personal and social network contexts. The problem is important as the correct context reduces the number of image annotation choices.. Social network context is useful as real-world activities of members of the social network are often correlated within a specific context. The correlation can serve as a powerful resource to effectively increase the ground truth available for annotation. There are three main contributions of this paper: (a) development of an event context framework and definition of quantitative measures for contextual correlations based on concept similarity in each facet of event context; (b) recommendation algorithms based on spreading activations that exploit personal context as well as social network context; (c) experiments on real-world, everyday images that verified both the existence of inter-user semantic disagreement and the improvement in annotation when incorporating both the user and social network context. We have conducted two user studies, and our quantitative and qualitative results indicate that context (both personal and social) facilitates effective image annotation. Copyright 2007 ACM.",22,,2-s2.0-36348970669,Conference Proceeding,2007-11-29,10.1145/1255175.1255200,134,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,127-134,Proceedings of the ACM International Conference on Digital Libraries,127,http://api.elsevier.com/content/abstract/scopus_id/36348970669,,36348970669,62702,p,Modeling personal and social network context for event annotation in images
"Web-based distributed collections often include links to documents that are expected to change frequently, such as blogs. The study reported here demonstrates that blog changes follow specific patterns. The results also illustrate the substantial role of standardized templates in blog pages. These results extend our earlier models that assess the significance of Web page change from a human perspective. These improved models will enable software systems to assist human collection managers in identifying unexpected changes and aberrant events. Copyright 2007 ACM.",4,,2-s2.0-36348947532,Conference Proceeding,2007-11-29,10.1145/1255175.1255201,136,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,135-136,Proceedings of the ACM International Conference on Digital Libraries,135,http://api.elsevier.com/content/abstract/scopus_id/36348947532,,36348947532,62702,p,Longitudinal study of changes in blogs
"Due to the popularity of web applications and their heavy usage, it is important to obtain a good understanding of their workloads in order to improve performance of search services. Existing works have typically focused on generic web workloads without putting emphasis on specific domains. In this paper, we analyze the usage logs of CiteSeer, a scientific literature digital library and search engine, to characterize workloads for both robots and users. Essential ingredients that contribute to workloads are proposed. Among them we find the access intervals show high variance, and thus cannot be predicted well with time-series models. On the other hand, client visiting path and semantics can be well captured with probabilistic models and Zipf-law. Based on the findings, we propose SearchGen, a synthetic workload generator to output traces for scientific literature digital libraries and search engines. A comparison between synthetic workloads and actual logged traces suggests that the synthetic workload fits well. Copyright 2007 ACM.",6,,2-s2.0-36349033571,Conference Proceeding,2007-11-29,10.1145/1255175.1255203,146,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,137-146,Proceedings of the ACM International Conference on Digital Libraries,137,http://api.elsevier.com/content/abstract/scopus_id/36349033571,,36349033571,62702,p,SearchGen: A synthetic workload generator for scientific literature digital libraries and search engines
"The Greenstone Digital Library Software has helped spread the practical impact of digital library technology throughout the world, with particular emphasis on developing countries. As Greenstone enters its second decade, this article takes a retrospective look at its development, the challenges that have been faced, and the lessons that have been learned in developing and deploying a comprehensive open-source system for the construction of digital libraries internationally. Not surprisingly, the most difficult challenges have been political, educational, and sociological, echoing that old programmers' blessing ""may all your problems be technical ones."". Copyright 2007 ACM.",15,,2-s2.0-36348978817,Conference Proceeding,2007-11-29,10.1145/1255175.1255204,156,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,147-156,Proceedings of the ACM International Conference on Digital Libraries,147,http://api.elsevier.com/content/abstract/scopus_id/36348978817,,36348978817,62702,p,A retrospective look at Greenstone: Lessons from the first decade
"The archival community has developed content and data structure standards to facilitate access to the diverse and unique sets of archival records, personal papers, and manuscript collections that are held by archival repositories and special collections libraries. However, these standards are difficult for archivists to use and are often implemented in ways that negatively affect materials-handling workflows, depriving archival users of the best possible access to the totality of materials available within an individual repository. The authors propose that archival descriptive problems can be addressed by implementing a web/database application that is tailored specifically to archival needs and can be implemented with little technical knowledge. This paper describes the system architecture of one such tool, the Archon software package, which was developed at the University of Illinois at Urbana-Champaign. Archon automates many technical tasks, such as producing a searchable website, an EAD instance or a MARC record. Although the system utilizes sophisticated algorithms and optimizations, it is easily extensible because most development takes place in an easy-to-use, object-oriented environment. Copyright 2007 ACM.",12,,2-s2.0-36348964317,Conference Proceeding,2007-11-29,10.1145/1255175.1255205,166,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,157-166,Proceedings of the ACM International Conference on Digital Libraries,157,http://api.elsevier.com/content/abstract/scopus_id/36348964317,,36348964317,62702,p,A unified platform for archival description and access
"This paper presents a case study of 12 children who used the International Children's Digital Library (ICDL) over four years and live in one of four countries: Germany, Honduras, New Zealand, and the United States. By conducting interviews, along with collecting drawings and book reviews, this study describes these children's interests in books, libraries, technology and the world around them. Findings from this study include: these young people increased the variety of books they read online; still valued their physical libraries as spaces for social interaction and reading; showed increased reading motivation; and showed interest in exploring different cultures. Copyright 2007 ACM.",16,,2-s2.0-36349014339,Conference Proceeding,2007-11-29,10.1145/1255175.1255207,176,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,167-176,Proceedings of the ACM International Conference on Digital Libraries,167,http://api.elsevier.com/content/abstract/scopus_id/36349014339,,36349014339,62702,p,Children's interests and concerns when using the international children's digital library: A four-country case study
"In an effort to identify the ""state of the art"" in digital library education in computer science (CS) programs, we analyzed CS courses on digital libraries and digital library-related topics. Fifteen courses that mention digital libraries in the title or short description were identified; of these, five are concerned with digital libraries as the primary topic of the course. The readings from these five courses were analyzed further, in terms of their authors and the journals in which they were published. Copyright 2007 ACM.",8,,2-s2.0-36349011958,Conference Proceeding,2007-11-29,10.1145/1255175.1255208,178,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,177-178,Proceedings of the ACM International Conference on Digital Libraries,177,http://api.elsevier.com/content/abstract/scopus_id/36349011958,,36349011958,62702,p,Digital library education in computer science programs
"This paper defines a model of teacher practice (""teaching as design""), and describes a professional development curriculum in which K-12 teachers design learning activities using resources and tools from education digital libraries. It then presents preliminary findings from an application of this model in which teachers' artifacts are analyzed to learn how online learning resources are used in situ. Initial results suggest that learning resources of a smaller granularity are more likely to be adapted or improvised upon in teacher-designed learning activities, which further supports teachers' becoming contributors of online resources and active participants in an education cyberinfrastructure. Copyright 2007 ACM.",1,,2-s2.0-36348932243,Conference Proceeding,2007-11-29,10.1145/1255175.1255209,180,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,179-180,Proceedings of the ACM International Conference on Digital Libraries,179,http://api.elsevier.com/content/abstract/scopus_id/36348932243,,36348932243,62702,p,A study of how online learning resource are used
"Aligning digital library resources with national and state educational standards to help K-12 teachers search for relevant curriculum is an important issue in the digital library community. Aligning standards from different states promises to help teachers in one state find appropriate materials created and cataloged elsewhere. Although such alignments provide a powerful means for crosswalking standards and curriculum across states, alignment matrices are intrinsically sparse. Hence, we hypothesize that such sparseness may cause significant numbers of false negatives when used for searching curriculum. Our preliminary results confirm the false negative hypothesis, demonstrate the usefulness of term-based techniques in addressing the false negative problem, and explore ways to combine term occurrence data with standards correlations. Copyright 2007 ACM.",2,,2-s2.0-36349017271,Conference Proceeding,2007-11-29,10.1145/1255175.1255210,182,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,181-182,Proceedings of the ACM International Conference on Digital Libraries,181,http://api.elsevier.com/content/abstract/scopus_id/36349017271,,36349017271,62702,p,Standards or semantics for curriculum search?
We report findings of a study that investigates the information behavior of online small groups engaged in math problem solving and discuss the implications for designing digital libraries that can support learning of younger students and their broader information practices. Copyright 2007 ACM.,4,,2-s2.0-36349000695,Conference Proceeding,2007-11-29,10.1145/1255175.1255211,184,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,183-184,Proceedings of the ACM International Conference on Digital Libraries,183,http://api.elsevier.com/content/abstract/scopus_id/36349000695,,36349000695,62702,p,Information behavior of small groups: Implications for design of digital libraries
"Traditionally, record linkage algorithms have played an important role in maintaining digital libraries - i.e., identifying matching citations or authors for consolidation in updating or integrating digital libraries. As such, a variety of record linkage algorithms have been developed and deployed successfully. Often, however, existing solutions have a set of parameters whose values are set by human experts off-lineand are fixed during the execution. Since finding the ideal values of such parameters is not straightforward, or no such single ideal value even exists, the applicability of existing solutions to new scenarios or domains is greatly hampered. To remedy this problem, we argue that one can achieve significant improvement by adaptively and dynamically changing such parameters of record linkage algorithms. To validate our hypothesis, we take a classical record linkage algorithm, the sorted neighborhood method (SNM), and demonstrate how we can achieve improved accuracy and performance by adaptively changing its fixed sliding window size. Our claim is analytically and empirically validated using both real and synthetic data sets of digital libraries and other domains. Copyright 2007 ACM.",54,,2-s2.0-36348961379,Conference Proceeding,2007-11-29,10.1145/1255175.1255213,194,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,185-194,Proceedings of the ACM International Conference on Digital Libraries,185,http://api.elsevier.com/content/abstract/scopus_id/36348961379,,36348961379,62702,p,Adaptive sorted neighborhood methods for efficient record linkage
"A large set of Web documents (the TREC GOV2 collection) comes from many separate Internet hosts, such as www.nih.gov and travel.state.gov. There is considerable variability in the number of Web pages (i.e., documents) from each host. In this paper, we present and evaluate a method for setting a maximum number of ""hits"" that may be presented for each web host. Federated search environments are increasingly common components of digital libraries and in these environments, the benefit of such a maximum is that it can reduce the number of possibly relevant documents presented by each subcollection, without hurting early precision measures such as P@20. Derivation of a maximum number, which is proportional to the subcollection size but not sensitive to different search topics, is made possible by an analysis of patterns of relevance judgment across approximately 17,000 web hosts in GOV2. Copyright 2007 ACM.",2,,2-s2.0-36348939952,Conference Proceeding,2007-11-29,10.1145/1255175.1255214,203,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,195-203,Proceedings of the ACM International Conference on Digital Libraries,195,http://api.elsevier.com/content/abstract/scopus_id/36348939952,,36348939952,62702,p,Distributed Web search efficiency by truncating results
"Entity resolution is a very common Information Quality (IQ) problem with many different applications. In digital libraries, it is related to problems of citation matching and author name disambiguation; in Natural Language Processing, it is related to coreference matching and object identity; in Web application, it is related to Web page disambiguation. The problem of Entity Resolution arises because objects/entities in real world datasets are often referred to by descriptions, which might not be unique identifiers of these entities, leading to ambiguity. The goal is to group all the entity descriptions that refer to the same real world entities. In this paper we present a graphical approach for entity resolution. It complements the traditional methodology with the analysis of the entity-relationship graph constructed for the dataset being analyzed. The paper demonstrates that a technique that measures the degree of interconnectedness between various pairs of nodes in the graph can significantly improve the quality of entity resolution. Furthermore, the paper presents an algorithm for making that technique self-adaptive to the underlying data, thus minimizing the required participation from the domain-analyst and potentially further improving the disambiguation quality. Copyright 2007 ACM.",40,,2-s2.0-36348962508,Conference Proceeding,2007-11-29,10.1145/1255175.1255215,213,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,204-213,Proceedings of the ACM International Conference on Digital Libraries,204,http://api.elsevier.com/content/abstract/scopus_id/36348962508,,36348962508,62702,p,Adaptive graphical approach to entity resolution
"In 2006 the American Council of Learned Societies (ACLS) released Our Cultural Commonwealth, the final report of the Commission on Cyberinfrastructure for the Humanities and Social Sciences. The report, based on a study funded by the Mellon Foundation, explored how research environments might be created for the humanities and social sciences to complement those being developed to support scientific research. The report includes key recommendations addressed to universities, funding agencies, scholarly societies, academic libraries, publishers, Congress, state legislatures, and others. Implementation of the recommendations could potentially transform scholarship and exponentially increase access to resources and new scholarship in the humanities and social sciences. But the report has not been universally embraced. How will humanities scholarship be advanced by new technologies and research practices, and how will the academic community recognize new forms of scholarship? How will funding agencies respond to the challenges and issues raised? What does cyberinfrastructure mean for different domains within the humanities? These questions will be addressed by panelists and discussed by participants. Copyright 2007 ACM.",1,,2-s2.0-36348978799,Conference Proceeding,2007-11-29,10.1145/1255175.1255217,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,214,http://api.elsevier.com/content/abstract/scopus_id/36348978799,,36348978799,62702,p,Cyberinfrastructure for the humanities and social sciences: Advancing the humanities research agenda
"In this paper we propose a knowledge-base approach to help extracting the correct components of citations in any given format. Differently from related approaches that rely on manually built knowledge-bases (KBs) for recognizing the components of a citation, in our case, such a KB is automatically constructed from an existing set of sample metadata records from a given area (e.g., computer science or health sciences). Our approach does not rely on patterns encoding specific delimitators of a particular citation style. It is also unsupervised, in the sense that it does not rely on a learning method that requires a training phase. These features assign to our technique a high degree of automation and flexibility. To demonstrate the effectiveness and applicability of our proposed approach we have run experiments in which we applied it to extract information from citations in papers of two different domains. Results of these experiments indicate precision and recall levels above 94% and perfect extraction for the large majority of citations tested. Copyright 2007 ACM.",41,,2-s2.0-36348953944,Conference Proceeding,2007-11-29,10.1145/1255175.1255219,224,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,215-224,Proceedings of the ACM International Conference on Digital Libraries,215,http://api.elsevier.com/content/abstract/scopus_id/36348953944,,36348953944,62702,p,FLUX-CIM: Flexible unsupervised extraction of citation metadata
"Bibliometrics are important measures for venue quality in digital libraries. Impacts of venues are usually the major consideration for subscription decision-making, and for ranking and recommending high-quality venues and documents. For digital libraries in the Computer Science literature domain, conferences play a major role as an important publication and dissemination outlet. However, with a recent profusion of conferences and rapidly expanding fields, it is increasingly challenging for researchers and librarians to assess the quality of conferences. We propose a set of novel heuristics to automatically discover prestigious (and low-quality) conferences by mining the characteristics of Program Committee members. We examine the proposed cues both in isolation and combination under a classification scheme. Evaluation on a collection of 2,979 conferences and 16,147 PC members shows that our heuristics, when combined, correctly classify about 92% of the conferences, with a low false positive rate of 0.035 and a recall of more than 73% for identifying reputable conferences. Furthermore, we demonstrate empirically that our heuristics can also effectively detect a set of low-quality conferences, with a false positive rate of merely 0.002. We also report our experience of detecting two previously unknown low-quality conferences. Finally, we apply the proposed techniques to the entire quality spectrum by ranking conferences in the collection. Copyright 2007 ACM.",26,,2-s2.0-36349003629,Conference Proceeding,2007-11-29,10.1145/1255175.1255220,234,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,225-234,Proceedings of the ACM International Conference on Digital Libraries,225,http://api.elsevier.com/content/abstract/scopus_id/36349003629,,36349003629,62702,p,Measuring conference quality by mining program committee characteristics
"Ranking of publication venues is often closely related with important issues such as evaluating the contributions of individual scholars/research groups, or subscription decision making. The development of large-scale digital libraries and the availability of various meta data provide the possibility of building new measures more efficiently and accurately. In this work, we propose two novel measures for ranking the impacts of academic venues an easy-to-implement seed-based measure that does not use citation analysis, and a realistic browsing-based measure that takes an article reader's behavior into account. Both measures are computationally efficient yet mimic the results of the widely accepted Impact Factor. In particular, our proposal exploits the fact that: (1)in most disciplines, there are ""top"" venues that most people agree on; and (2) articles that appeared in good venues are more likely to be viewed by readers. Our proposed measures are extensively evaluated on a test case of the Database research community using two real bibliography data sets - ACM and DBLP. Finally, ranks of venues by our proposed measures are compared against the Impact Factor using the Spearman's rank correlation coefficient, and their positive rank order relationship is proved with a statistical significance test. Copyright 2007 ACM.",29,,2-s2.0-36349028666,Conference Proceeding,2007-11-29,10.1145/1255175.1255221,244,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,235-244,Proceedings of the ACM International Conference on Digital Libraries,235,http://api.elsevier.com/content/abstract/scopus_id/36349028666,,36349028666,62702,p,Toward alternative measures for ranking venues: A case of database research community
"Digital libraries (DLs) must cater not only to the varied needs of its target users but also to their differing abilities, and to the adaptive technologies used by persons whose computing capabilities are restricted due to disabilities. This paper proposes a model for DL design that includes optimization of the usability of the search process and ensures accessibility of the content for users of DLs with disabilities. Copyright 2007 ACM.",0,,2-s2.0-36348968360,Conference Proceeding,2007-11-29,10.1145/1255175.1255223,246,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,245-246,Proceedings of the ACM International Conference on Digital Libraries,245,http://api.elsevier.com/content/abstract/scopus_id/36348968360,,36348968360,62702,p,A model for inclusive design of digital libraries
"This paper studies the challenge of representing aggregate works such as encyclopedias, collected poems and journals in heterogenous digital library collections. Reflecting on the materials used by humanities academics, we demonstrate the varied range of aggregate types and the problems of faithfully representing this in the DL interface. Aggregates are complex and pervasive, challenge common assumptions and confuse boundaries within organisational structures. Existing DL systems can only provide imperfect representation of aggregates, and alterations to document encoding are insufficient to create a faithful reproduction of the physical library. The challenge is amplified through concrete examples, and solutions are demonstrated in a well-known DL system and related to standard DL architecture. Copyright 2007 ACM.",5,,2-s2.0-36348972966,Conference Proceeding,2007-11-29,10.1145/1255175.1255224,256,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,247-256,Proceedings of the ACM International Conference on Digital Libraries,247,http://api.elsevier.com/content/abstract/scopus_id/36348972966,,36348972966,62702,p,Representing aggregate works in the digital library
"This paper considers information access styles for a community digital library in an Indian village. We present our impressions of the community gathered during a field-study and show how these have influenced the interaction design. The prototype aims to overcome low-textual literacy and lack of computing experience by combining touch-based interaction, engaging visual presentations and drawing on villagers' familiarity with radio listening. Copyright 2007 ACM.",8,,2-s2.0-36348935653,Conference Proceeding,2007-11-29,10.1145/1255175.1255225,258,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,257-258,Proceedings of the ACM International Conference on Digital Libraries,257,http://api.elsevier.com/content/abstract/scopus_id/36348935653,,36348935653,62702,p,StoryBank: An indian village community digital library
"Increasingly individuals are turning to online sources for their daily news. Traditional newspapers have developed significant web presences to compete with newer services such as news aggregators and emerging genres such as blogs and other forms of citizen journalism. This paper reports the results of a field study to investigate the use of a new RSS-driven, template-based presentation mechanism that delivers a daily newspaper to subscribers' laptops and desktops; the Times News Reader hybridizes elements of print newspapers with aspects of online news. We explore how this application compares with print and web-based news reading and evaluate functionality developed to draw in readers from both audiences. Finally we examine three general technological implications drawn from current use: how the news reader may adapt to different styles of reading; how the news reader's functionality may be extended to highlight the timeliness of the content and to personalize the application; and how long-term use of the news reader can result in a personal news archive. Copyright 2007 ACM.",12,,2-s2.0-36349005371,Conference Proceeding,2007-11-29,10.1145/1255175.1255226,268,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,259-268,Proceedings of the ACM International Conference on Digital Libraries,259,http://api.elsevier.com/content/abstract/scopus_id/36349005371,,36349005371,62702,p,The gray lady gets a new dress: A field study of the times news reader
"New technologies for scientific research are producing a deluge of data that is overwhelming traditional tools for data capture, analysis, storage, and access. We report on a study of scientific practices associated with dynamic deployments of embedded sensor networks to identify requirements for data digital libraries. As part of continuing research on scientific data management, we interviewed 22 participants in 5 environmental science projects to identify data types and uses, stages in their data life cycle, and requirements for digital library architecture. We found that scientists need continuous access to their data from the time that field experiments are designed through final analysis and publication, thus reflecting a broader notion of ""digital library."" Six categories of requirements are discussed: the ability to obtain and maintain data in the field, verify data in the field, document data context for subsequent interpretation, integrate data from multiple sources, analyze data, and preserve data. Three digital library efforts currently underway within the Center for Embedded Networked Sensing are addressing these requirements, with the goal of a tightly coupled interoperable framework that, in turn, will be a component of cyberinfrastructure for science. Copyright 2007 ACM.",42,,2-s2.0-36348946387,Conference Proceeding,2007-11-29,10.1145/1255175.1255228,277,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,269-277,Proceedings of the ACM International Conference on Digital Libraries,269,http://api.elsevier.com/content/abstract/scopus_id/36348946387,,36348946387,62702,p,Drowning in data: Digital library architecture to support scientific use of embedded sensor networks
"The large-scale analysis of scholarly artifact usage is constrained primarily by current practices in usage data archiving, privacy issues concerned with the dissemination of usage data, and the lack of a practical ontology for modeling the usage domain. As a remedy to the third constraint, this article presents a scholarly ontology that was engineered to represent those classes for which large-scale bibliographic and usage data exists, supports usage research, and whose instantiation is scalable to the order of 50 million articles along with their associated artifacts (e.g. authors and journals) and an accompanying 1 billion usage events. The real world instantiation of the presented abstract ontology is a semantic network model of the scholarly community which lends the scholarly process to statistical analysis and computational support. We present the ontology, discuss its instantiation, and provide some example inference rules for calculating various scholarly artifact metrics. Copyright 2007 ACM.",14,,2-s2.0-36348949765,Conference Proceeding,2007-11-29,10.1145/1255175.1255229,287,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,278-287,Proceedings of the ACM International Conference on Digital Libraries,278,http://api.elsevier.com/content/abstract/scopus_id/36348949765,,36348949765,62702,p,A practical ontology for the large-scale modeling of scholarly artifacts and their usage
"The successful deployment of digital technologies by humanities scholars presents computer scientists with a number of unique scientific and technological challenges. The task seems particularly daunting because issues in the humanities are presented in abstract language demanding the kind of subtle interpretation often thought to be beyond the scope of artificial intelligence, and humanities scholars themselves often disagree about the structure of their disciplines. The future of humanities computing depends on having tools for automatically discovering complex semantic relationships among different parts of a corpus. Digital library tools for the humanities will need to be capable of dynamically tracking the introduction of new ideas and interpretations and applying them to older texts in ways that support the needs of scholars and students. This paper describes the design of new algorithms and the adjustment of existing algorithms to support the automated and semi-automated management of domain-rich metadata for an established digital humanities project, the Stanford Encyclopedia of Philosophy. Our approach starts with a ""hand-built"" formal ontology that is modified and extended by a combination of automated and semi-automated methods, thus becoming a ""dynamic ontology"". We assess the suitability of current information retrieval and information extraction methods for the task of automatically maintaining the ontology. We describe a novel measure of term-relatedness that appears to be particularly helpful for predicting hierarchical relationships in the ontology. We believe that our project makes a further contribution to information science by being the first to harness the collaboration inherent in a expert-maintained dynamic reference work to the task of maintaining and verifying a formal ontology. We place special emphasis on the task of bringing domain expertise to bear on all phases of the development and deployment of the system, from the initial design of the software and ontology to its dynamic use in a fully operational digital reference work. Copyright 2007 ACM.",21,,2-s2.0-36348967223,Conference Proceeding,2007-11-29,10.1145/1255175.1255230,297,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,288-297,Proceedings of the ACM International Conference on Digital Libraries,288,http://api.elsevier.com/content/abstract/scopus_id/36348967223,,36348967223,62702,p,A dynamic ontology for a dynamic reference work
"This paper examines procedures for the creation and delivery of digital music that are being undertaken by contributors to the National Library of Australia's federated music gateway MusicAustralia. The case study discusses access to and preservation of digital material as key drivers of the digitization movement, and compares projects being undertaken worldwide. Also analyzed are the underlying digitization principles and standards, and metadata schemas for the description and exchange of digital objects which facilitate record exchange and improve audience reach. The paper provides an overview of some individual contributing institutions, however particular focus is placed on the State Library of Queensland's (SLQ) approach to preparing its unique Queensland music collection for digital resource discovery in MusicAustralia. A detailed analysis of SLQ's strategy is presented, including its risk management approach to copyright implications,and consideration of infrastructure issues affecting the creation, preservation and online delivery of its digital music objects. Whilst SLQ's current digital music collection is relatively small, it has become core business of SLQ's Arts and Humanities branch, and the collection will expand with the continued incorporation of music material unique to Queensland into the collection. SLQ has developed a sound foundation for digitization based on widely endorsed principles and standards which should allow this to effectively occur. Copyright 2007 ACM.",0,,2-s2.0-36348970112,Conference Proceeding,2007-11-29,10.1145/1255175.1255232,302,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,298-302,Proceedings of the ACM International Conference on Digital Libraries,298,http://api.elsevier.com/content/abstract/scopus_id/36348970112,,36348970112,62702,p,Preparing resource discovery for digitized music: An analysis of an australian application
"Optical music recognition (OMR) systems are promising tools for the creation of searchable digital music libraries. Using an adaptive OMR system for early music prints based on hidden Markov models, we leverage an edit distance evaluation metric to improve recognition accuracy. Baseline results are computed with new labeled training and test sets drawn from a diverse group of prints. We present two experiments based on this evaluation technique. The first resulted in a significant improvement to the feature extraction function for these images. The second is a goal-directed comparison of several popular adaptive binarization algorithms, which are often evaluated only subjectively. Accuracy increased by as much as 55% for some pages, and the experiments suggest several avenues for further research. Copyright 2007 ACM.",12,,2-s2.0-36348953254,Conference Proceeding,2007-11-29,10.1145/1255175.1255233,304,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,303-304,Proceedings of the ACM International Conference on Digital Libraries,303,http://api.elsevier.com/content/abstract/scopus_id/36348953254,,36348953254,62702,p,Goal-directed evaluation for the improvement of optical music recognition on early music prints
"This paper describes the findings of an ethnographic study that examined the annotation behaviors of musicians working with musical scores for the purpose of performance. Annotation was found to be an important part of the rehearsal process, and specific annotation functionalities are recommended for future digital library development. Copyright 2007 ACM.",1,,2-s2.0-36348974635,Conference Proceeding,2007-11-29,10.1145/1255175.1255234,306,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,305-306,Proceedings of the ACM International Conference on Digital Libraries,305,http://api.elsevier.com/content/abstract/scopus_id/36348974635,,36348974635,62702,p,Annotation functionality for digital libraries supporting collaborative performance: An example of musical scores
"This paper presents an analysis of 7,602 similarity judgments collected for the Symbolic Melodic Similarity (SMS) and Audio Music Similarity and Retrieval (AMS) evaluation tasks in the 2006 Music Information Retrieval Evaluation eXchange (MIREX). We discuss the influence of task definitions, as well as evaluation metrics on user perceptions of music similarity, and provide recommendations for future Music Digital Library/Music Information Retrieval research pertaining to music similarity. Copyright 2007 ACM.",4,,2-s2.0-36348970652,Conference Proceeding,2007-11-29,10.1145/1255175.1255235,308,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,307-308,Proceedings of the ACM International Conference on Digital Libraries,307,http://api.elsevier.com/content/abstract/scopus_id/36348970652,,36348970652,62702,p,Toward an understanding of similarity judgments for music digital library evaluation
"Google, Yahoo and MSN all provide both web user interfaces (WUIs) and application programming interfaces (APIs) to their collections. Whether building collections of resources or studying the search engines themselves, the search engines request that researchers use their APIs and not ""scrape"" the WUIs. However, anecdotal evidence suggests the interfaces produce different results. We provide the first in depth quantitative analysis of the results produced by the Google, MSN and Yahoo API and WUI interfaces. We have queried both interfaces for five months and found significant discrepancies between the interfaces in several categories. In general, we found MSN to produce the most consistent results between their two interfaces. Our findings suggest that the API indexes are not older, but they are probably smaller for Google and Yahoo. We also examined how search results decay over time and built predictive models based on the observed decay rates. Based on our findings, it can take over a year for half of the top 10 results to a popular query to be replaced in Google and Yahoo; for MSN it may take only 2-3 months. Copyright 2007 ACM.",47,,2-s2.0-36349016704,Conference Proceeding,2007-11-29,10.1145/1255175.1255237,318,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,309-318,Proceedings of the ACM International Conference on Digital Libraries,309,http://api.elsevier.com/content/abstract/scopus_id/36349016704,,36349016704,62702,p,Agreeing to disagree: Search engines and their public interfaces
"Hypertext allows users to navigate between related materials in digital libraries. The most fundamental automated hypertexts are those constructed on the basis of semantic similarity. Such hypertexts have been evaluated by a variety of means, but seldom by real users given simulated real-world tasks. We claim that while other methods exist, one of the best ways to prove the usefulness of hypertext is to show the benefits for users performing realistic tasks. We compare the reformulation of queries that users perform in keyword searching, to the query reformulation implicit in browsing between documents linked by similarity of content. We find that a static automatically-constructed similarity hypertext provides useful linking between related items, improving the retrieval of targets when used to augment standard keyword search. Copyright 2007 ACM.",1,,2-s2.0-36349032347,Conference Proceeding,2007-11-29,10.1145/1255175.1255238,328,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,319-328,Proceedings of the ACM International Conference on Digital Libraries,319,http://api.elsevier.com/content/abstract/scopus_id/36349032347,,36349032347,62702,p,Static reformulation: A user study of static hypertext for query-based reformulation
"Open Public Access Catalogs (OPACs) provide patrons with a user interface (UI) to help their information seeking tasks. Even though many OPAC UIs are now web-based, their architectures are often static, which does not allow them to integrate user assistance modules dynamically. We report on a UI that supports integration of such modules, while providing a usable and rich environment. We explore how Asynchronous JavaScript + XML (AJAX) can be employed to create an OPAC UI that offers a better user experience and task support. Our developed UI features a modular architecture that combines several Natural Language Processing (NLP) modules employed to enhance information seeking. Our UI manages queries in a novel way with a tabbed interface featuring an overview/details presentation model, and an AJAX query results data grid. Preliminary user testing results are also presented. Copyright 2007 ACM.",3,,2-s2.0-36348996619,Conference Proceeding,2007-11-29,10.1145/1255175.1255239,330,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,329-330,Proceedings of the ACM International Conference on Digital Libraries,329,http://api.elsevier.com/content/abstract/scopus_id/36348996619,,36348996619,62702,p,A rich OPAC user interface with AJAX
The software technologies used to create web interfaces for digital libraries are discussed using examples from Greenstone 3. Copyright 2007 ACM.,2,,2-s2.0-36348936801,Conference Proceeding,2007-11-29,10.1145/1255175.1255240,332,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,331-332,Proceedings of the ACM International Conference on Digital Libraries,331,http://api.elsevier.com/content/abstract/scopus_id/36348936801,,36348936801,62702,p,Constructing digital library interfaces
"We present a new approach for the retrieval of texts with non-standard spelling, which is important for historic texts e.g. in English or German. In this paper, we describe the overall architecture of our system, followed by its evaluation. Given a search term as lemma, we use a dictionary of contemporary German for finding all inflected and derived forms of the lemma. Then we apply transformation rules (derived from training data) for generating historic spelling variants. For the evaluation, we regard the resulting retrieval quality. The experimental results show that we can improve the retrieval quality for historic collections substantially. Copyright 2007 ACM.",25,,2-s2.0-36348996055,Conference Proceeding,2007-11-29,10.1145/1255175.1255242,341,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,333-341,Proceedings of the ACM International Conference on Digital Libraries,333,http://api.elsevier.com/content/abstract/scopus_id/36348996055,,36348996055,62702,p,Retrieval in text collections with historic spelling using linguistic and spelling variants
"Name ambiguity is a special case of identity uncertainty where one person can be referenced by multiple name variations in different situations or even share the same name with other people. In this paper, we focus on the problem of disambiguating person names within web pages and scientific documents. We present an efficient and effective two-stage approach to disambiguate names. In the first stage, two novel topic-based models are proposed by extending two hierarchical Bayesian text models, namely Probabilistic Latent Semantic Analysis (PLSA) and Latent Dirichlet Allocation (LDA). Our models explicitly introduce a new variable for persons and learn the distribution of topics with regard to persons and words. After learning an initial model, the topic distributions are treated as feature sets and names are disambiguated by leveraging a hierarchical agglomerative clustering method. Experiments on web data and scientific documents from CiteSeer indicate that our approach consistently outperforms other unsupervised learning methods such as spectral clustering and DBSCAN clustering and could be extended to other research fields. We empirically addressed the issue of scalability by disambiguating authors in over 750,000 papers from the entire CiteSeer dataset. Copyright 2007 ACM.",75,,2-s2.0-36348962507,Conference Proceeding,2007-11-29,10.1145/1255175.1255243,351,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,342-351,Proceedings of the ACM International Conference on Digital Libraries,342,http://api.elsevier.com/content/abstract/scopus_id/36348962507,,36348962507,62702,p,Efficient topic-based unsupervised name disambiguation
"Phrase translation lists can enhance cross-language information retrieval. However, finding translations for technical phrases is difficult. Bilingual dictionaries have limited coverage for specialized fields, and even more limited coverage of technical phrases. Since phrases can have very specific meanings in technical fields, this limits the quality of translations produced by generic machine translation systems. We hypothesize that digital libraries of electronic theses and dissertations (ETDs) are a good source of technical phrase translations. We have acquired a collection of 3,086 Spanish ETDs about computer science from Scirus, the Universidad Nacional Autónoma de México (Mexico City), and Universidad de las Américas (Puebla). By using English ETDs from NDLTD, we have a comparable corpus of computing-related documents from which to mine phrase translations. We describe our method and its formative evaluation. Copyright 2007 ACM.",1,,2-s2.0-36349027087,Conference Proceeding,2007-11-29,10.1145/1255175.1255244,353,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,352-353,Proceedings of the ACM International Conference on Digital Libraries,352,http://api.elsevier.com/content/abstract/scopus_id/36349027087,,36349027087,62702,p,Using bilingual ETD collections to mine phrase translations
"We compare various kernel-based link analysis measures on graph nodes to evaluate their utility as a research paper recommendation system. The compared measures include the Kandola et al.'s von Neumann kernel, its extension that takes communities into account, and Smola and Kondor's regularized Laplacian. Chebotarev and Shamis' matrix forest-based algorithm, Kleinberg's HITS authority ranking, and classic co-citation coupling are also evaluated. The experimental result shows that kernel-based methods outperform HITS and co-citation coupling, with the community-based von Neumann kernel achieving the highest score. Copyright 2007 ACM.",3,,2-s2.0-36348932859,Conference Proceeding,2007-11-29,10.1145/1255175.1255245,355,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,354-355,Proceedings of the ACM International Conference on Digital Libraries,354,http://api.elsevier.com/content/abstract/scopus_id/36348932859,,36348932859,62702,p,Evaluation of kernel-based link analysis measures on research paper recommendation
"While digital libraries based on page images and automatically generated text have made possible massive projects such as the Million Book Library, Open Content Alliance, Google, and others, humanists still depend upon textual corpora expensively produced with labor-intensive methods such as double-keyboarding and manual correction. This paper reports the results from an analysis of OCR-generated text for classical Greek source texts. Classicists have depended upon specialized manual keyboarding that costs two or more times as much as keyboarding of English both for accuracy and because classical Greek OCR produced no usable results. We found that we could produce texts by OCR that, in some cases, approached the 99.95% professional data entry accuracy rate. In most cases, OCR-generated text yielded results that, by including the variant readings that digital corpora traditionally have left out, provide better recall and, we argue, can better serve many scholarly needs than the expensive corpora upon which classicists have relied for a generation. As digital collections expand, we will be able to collate multiple editions against each other, identify quotations of primary sources, and provide a new generation of services. Copyright 2007 ACM.",6,,2-s2.0-36349036645,Conference Proceeding,2007-11-29,10.1145/1255175.1255247,365,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,356-365,Proceedings of the ACM International Conference on Digital Libraries,356,http://api.elsevier.com/content/abstract/scopus_id/36349036645,,36349036645,62702,p,A new generation of textual corpora: Mining corpora from very large collections
"Creating a collection of metadata records from disparate and diverse sources often results in uneven, unreliable and variable quality subject metadata. Having uniform, consistent and enriched subject metadata allows users to more easily discover material, browse the collection, and limit keyword search results by subject. We demonstrate how statistical topic models are useful for subject metadata enrichment. We describe some of the challenges of metadata enrichment on a huge scale (10 million metadata records from 700 repositories in the OAIster Digital Library) when the metadata is highly heterogeneous (metadata about images and text, and both cultural heritage material and scientific literature). We show how to improve the quality of the enriched metadata, using both manual and statistical modeling techniques. Finally, we discuss some of the challenges of the production environment, and demonstrate the value of the enriched metadata in a prototype portal. Copyright 2007 ACM.",27,,2-s2.0-34548202975,Conference Proceeding,2007-11-29,10.1145/1255175.1255248,375,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,366-375,Proceedings of the ACM International Conference on Digital Libraries,366,http://api.elsevier.com/content/abstract/scopus_id/34548202975,,34548202975,62702,p,Subject metadata enrichment using statistical topic models
"Large scale library digitization projects such as the Open Content Alliance are producing vast quantities of text, but little has been done to organize this data. Subject headings inherited from card catalogs are useful but limited, while full-text indexing is most appropriate for readers who already know exactly what they want. Statistical topic models provide a complementary function. These models can identify semantically coherent ""topics"" that are easily recognizable and meaningful to humans, but they have been too computationally intensive to run on library-scale corpora. This paper presents DCM-LDA, a topic model based on Dirichlet Compound Multinomial distributions. This model is simultaneously better able to represent observed properties of text and more scalable to extremely large text collections. We train individual topic models for each book based on the cooccurrence of words within pages. We then cluster topics across books. The resulting topical clusters can be interpreted as subject facets, allowing readers to browse the topics of a collection quickly, find relevant books using topically expanded keyword searches, and explore topical relationships between books. We demonstrate this method finding topics on a corpus of 1.49 billion words from 42,000 books in less than 20 hours, and it easily could scale well beyond this. Copyright 2007 ACM.",40,,2-s2.0-36348944093,Conference Proceeding,2007-11-29,10.1145/1255175.1255249,385,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,376-385,Proceedings of the ACM International Conference on Digital Libraries,376,http://api.elsevier.com/content/abstract/scopus_id/36348944093,,36348944093,62702,p,Organizing the OCA: Learning faceted subjects from a library of digital books
"With the increasing focus on interoperability for distributed digital content, resource developers need to take into consideration how they will contribute to large federated collections, potentially at the national and international level. At the same time, their primary objectives are usually to meet the needs of their own institutions and user communities. This tension between local practices and needs and the more global potential of digital collections has been an object of study for the IMLS Digital Collections and Content (IMLS DCC) project. Our practical aim has been to provide integrated access to over 160 IMLS-funded digital collections through a centralized collection registry and metadata repository. During the course of development, the research team has investigated how collections and items can best be represented to meet the needs of local resource developers and aggregators of distributed content, as well as the diverse user communities they may serve. This paper presents results from a longitudinal analysis of IMLS DCC development trends between 2003 and 2006. Changes in metadata applications have not been pronounced. However, multi-scheme use has become less common, and use of Dublin Core remains high, even as recognition of its limitations grows. Locally developed schemes are used as much as MARC, and may be on the increase as new collections are incorporating less traditional library and museum materials, and more interactive and multimedia content. Based on our empirical understanding of metadata use in practice, patterns in new content development, and user community indicators, our research has turned toward identifying metadata relationships between items and collections to preserve context and enhance functionality and usefulness for scholarly user communities. Copyright 2007 ACM.",17,,2-s2.0-36349032345,Conference Proceeding,2007-11-29,10.1145/1255175.1255251,395,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,386-395,Proceedings of the ACM International Conference on Digital Libraries,386,http://api.elsevier.com/content/abstract/scopus_id/36349032345,,36349032345,62702,p,Trends in metadata practices: A longitudinal study of collection federation
"We introduce the notion of ""induced tagging"" in the context of learning communities that are supported by digital libraries. We also describe an environment aimed to foster discovery and recommendation of digital library resources based on induced tagging. Copyright 2007 ACM.",3,,2-s2.0-36349022122,Conference Proceeding,2007-11-29,10.1145/1255175.1255252,397,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,396-397,Proceedings of the ACM International Conference on Digital Libraries,396,http://api.elsevier.com/content/abstract/scopus_id/36349022122,,36349022122,62702,p,Induced tagging: Promoting resource discovery and recommendation in digital libraries
The research in this paper describes a Machine Learning technique called hierarchical text categorization which is used to solve the problem of finding equivalents from among different state and national education standards. The approach is based on a set of manually aligned standards and utilizes the hierarchical structure present in the standards to achieve a more accurate result. Details of this approach and its evaluation are presented. Copyright 2007 ACM.,6,,2-s2.0-36348943562,Conference Proceeding,2007-11-29,10.1145/1255175.1255253,399,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,398-399,Proceedings of the ACM International Conference on Digital Libraries,398,http://api.elsevier.com/content/abstract/scopus_id/36348943562,,36348943562,62702,p,Standards alignment for metadata assignment
"At present, little evidence is available about how people want to interact with their photos in a personal photo digital library. Analysis of a set of 22 user needs summaries and critiques of existing photo management systems provides insight into potentially useful features. Copyright 2007 ACM.",6,,2-s2.0-36348929979,Conference Proceeding,2007-11-29,10.1145/1255175.1255254,401,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,400-401,Proceedings of the ACM International Conference on Digital Libraries,400,http://api.elsevier.com/content/abstract/scopus_id/36348929979,,36348929979,62702,p,Identifying personal photo digital library features
"Traditional implementations provide only limited assistance for locating the information in narrative texts relevant to a certain point of interest. We are investigating providing a ""reading wheel"" for such purposes. The first step of the bigger picture, as inspired by the editorial compilation of a textbook's index, is an attempt to locate thematically coherent sentences to a given short phrase. In this paper, we propose a two-step methodology to increase the search performance and examine its effectiveness in a test study. We describe the experimental setup and report on the quantitative evaluation of the techniques involved. Copyright 2007 ACM.",0,,2-s2.0-36348967222,Conference Proceeding,2007-11-29,10.1145/1255175.1255256,410,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,402-410,Proceedings of the ACM International Conference on Digital Libraries,402,http://api.elsevier.com/content/abstract/scopus_id/36348967222,,36348967222,62702,p,Locating thematic pinpoints in narrative texts with short phrases: A test study on Don Quixote
"We describe a multidisciplinary effort in the creation of an electronic repository of poems of John Donne - the renowned 17th-century English poet. We discuss the workflow we have adopted and the Web-based tools we have developed for maintaining a collection of transcriptions and images, a concordance of poems, a list of press variants, and a browsing interface that enables readers to access these materials. A complement to the multi-volume Variorum Edition of the Poetry of John Donne, this endeavor shows how a traditional scholarly edition can be enhanced by resources made available by computers and the Internet. Copyright 2007 ACM.",3,,2-s2.0-36348962504,Conference Proceeding,2007-11-29,10.1145/1255175.1255257,412,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,411-412,Proceedings of the ACM International Conference on Digital Libraries,411,http://api.elsevier.com/content/abstract/scopus_id/36348962504,,36348962504,62702,p,"Digital Donne: Workflow, editing tools, and the reader's interface of a collection of 17th-century english poetry"
"Shipbuilding treatises are technical manuscripts written in a variety of languages and spanning several centuries that describe the construction of ships. Given their technical content, understanding terms, concepts, and construction sequences is a challenging task. In this paper we describe a scalable approach and a multilingual web-based interface for enabling a group of scholars to edit a glossary of nautical terms in multiple languages. Copyright 2007 ACM.",4,,2-s2.0-36349025931,Conference Proceeding,2007-11-29,10.1145/1255175.1255258,414,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,413-414,Proceedings of the ACM International Conference on Digital Libraries,413,http://api.elsevier.com/content/abstract/scopus_id/36349025931,,36349025931,62702,p,A multilingual approach to technical manuscripts: 16th and 17th-century Portuguese shipbuilding treatises
"We discuss a crucial part of infrastructure for the Web-delivery of medieval chant resources. Although widely accepted by software professionals, the distributed-content model is sharply opposed by some chant scholars. We advocate for a paradigm of the Web as a massive database where each ""first class object"" acts like a record; metadata about, and links to such objects are compiled in virtual libraries. Scholarly-edited indexes determine which objects are in libraries, and unreliable content is excluded. Special metadata ontologies can be defined without modifying the primary content. Copyright 2007 ACM.",1,,2-s2.0-36348937356,Conference Proceeding,2007-11-29,10.1145/1255175.1255259,416,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,415-416,Proceedings of the ACM International Conference on Digital Libraries,415,http://api.elsevier.com/content/abstract/scopus_id/36348937356,,36348937356,62702,p,First class objects and indexes for chant manuscripts
"An important goal for digital libraries is to enable researchers to more easily explore related work. While citation data is often used as an indicator of relatedness, in this paper we demonstrate that digital access records (e.g. http-server logs) can be used as indicators as well. In particular, we show that measures based on co-access provide better coverage than co-citation, that they are available much sooner, and that they are more accurate for recent papers. Copyright 2007 ACM.",15,,2-s2.0-36348977556,Conference Proceeding,2007-11-29,10.1145/1255175.1255260,418,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,417-418,Proceedings of the ACM International Conference on Digital Libraries,417,http://api.elsevier.com/content/abstract/scopus_id/36348977556,,36348977556,62702,p,Recommending related papers based on digital library access records
"Classifying and organizing documents in repositories is an active research topic in digital library studies. Manually classifying the large volume of patents and patent applications managed by patent offices is a labor-intensive task. Many previous studies have employed patent contents for patent classification with the aim of automating this process. In this research we propose to use patent citation information, especially the citation network structure information, to address the patent classification problem. We adopt a kernel-based approach and design kernel functions to capture content information and various citation-related information in patents. These kernels. performances are evaluated on a testbed of patents related to nanotechnology. Evaluation results show that our proposed labeled citation graph kernel, which utilized citation network structures, significantly outperforms the kernels that use no citation information or only direct citation information. Copyright 2007 ACM.",21,,2-s2.0-36348987776,Conference Proceeding,2007-11-29,10.1145/1255175.1255262,427,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,419-427,Proceedings of the ACM International Conference on Digital Libraries,419,http://api.elsevier.com/content/abstract/scopus_id/36348987776,,36348987776,62702,p,Automatic patent classification using citation network information: An experimental study in nanotechnology
"We developed a multi-agent framework where agents had limited/distributed knowledge for document classification and collaborated with each other to overcome the knowledge distribution. Each agent was equipped with a certain learning algorithm for predicting potential collaborators, or helping agents. We conducted experimental research on a standard news corpus to examine the impact of two learning algorithms: Pursuit Learning and Nearest Centroid Learning. For a fundamental retrieval operation, namely classification, both algorithms achieved competitive classification effectiveness and efficiency. Subsequently, the impact of the learning exploration rate and the maximum collaboration range on classification effectiveness and efficiency were examined. Close investigation of agent learning dynamics revealed increasing and stabilizing patterns that were enhanced by the learning algorithms. Copyright 2007 ACM.",6,,2-s2.0-36348959153,Conference Proceeding,2007-11-29,10.1145/1255175.1255263,437,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,428-437,Proceedings of the ACM International Conference on Digital Libraries,428,http://api.elsevier.com/content/abstract/scopus_id/36348959153,,36348959153,62702,p,Collaborative classifier agents: Studying the impact of learning in distributed document classification
"This paper proposes a news articles clustering and summarization system. It provides integrated access to news articles from various news sites. The system consists of a crawler, topic detector, and summarizer. This paper describes its efficient summarization technique to handle large amounts of crawled news articles. Copyright 2007 ACM.",6,,2-s2.0-36349019816,Conference Proceeding,2007-11-29,10.1145/1255175.1255264,439,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,438-439,Proceedings of the ACM International Conference on Digital Libraries,438,http://api.elsevier.com/content/abstract/scopus_id/36349019816,,36349019816,62702,p,UpdateNews: A news clustering and summarization system using efficient text processing
"Syllabi are important educational resources. However, searching for a syllabus on the Web using a generic search engine is an error-prone process and often yields too many non-relevant links. In this paper, we present a syllabus classifier to filter noise out from search results. We discuss various steps in the classification process, including class definition, training data preparation, feature selection, and classifier building using SVM and Nave Bayes. Empirical results indicate that the best version of our method achieves a high classification accuracy, i.e., an F1 value of 83% on average. Copyright 2007 ACM.",2,,2-s2.0-36348950328,Conference Proceeding,2007-11-29,10.1145/1255175.1255265,441,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,440-441,Proceedings of the ACM International Conference on Digital Libraries,440,http://api.elsevier.com/content/abstract/scopus_id/36348950328,,36348950328,62702,p,Automatic syllabus classification
"In this paper we present the results of a study that investigates the relationships between search tasks, information architecture, and interaction style. Three kinds of search tasks (simple lookup, complex lookup and exploratory) were performed using three different user interfaces (standard web site, hierarchical text-based faceted interface, and dynamic query faceted interface) for a large-scale public corpus containing semi-structured statistical data and reports. Twenty-eight people conducted the three kinds of searches in a between-subjects study and twelve others conducted the three kinds of searches on all three systems in a within-subjects study. Quantitative results demonstrate that the alternative general-purpose user interfaces that accept automated structuring of data offer comparable effectiveness, efficiency, and aesthetics to manually constructed architectures. Qualitative results demonstrate the manual architectures are favored. Copyright 2007 ACM.",39,,2-s2.0-36348948051,Conference Proceeding,2007-11-29,10.1145/1255175.1255267,451,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,442-451,Proceedings of the ACM International Conference on Digital Libraries,442,http://api.elsevier.com/content/abstract/scopus_id/36348948051,,36348948051,62702,p,Effects of structure and interaction style on distinct search tasks
This paper describes the results of a study designed to validate the use of domain competency models to diagnose student scientific misconceptions and to generate personalized instruction plans using digital libraries. Digital library resources provided the content base for human experts to construct a domain competency model for earthquakes and plate tectonics encoded as a knowledge map. The experts then assessed student essays using comparisons against the constructed domain competency model and prepared personalized instruction plans using the competency model and digital library resources. The results from this study indicate that domain competency models generated from select digital library resources may provide the desired degree of content coverage to support both automated diagnosis and personalized instruction in the context of nationally-recognized science learning goals. These findings serve to inform the design of personalized instruction tools for digital libraries. Copyright 2007 ACM.,14,,2-s2.0-36348942994,Conference Proceeding,2007-11-29,10.1145/1255175.1255268,461,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,452-461,Proceedings of the ACM International Conference on Digital Libraries,452,http://api.elsevier.com/content/abstract/scopus_id/36348942994,,36348942994,62702,p,Towards automatic conceptual personalization tools
"Integrated with G-Portal, a Web-based geospatial digital library of geography resources, this paper describes the implementation of Mobile G-Portal, a group of mobile devices as learning assistant tools supporting collaborative sharing and learning for geography fieldwork. Based on a modified Technology Acceptance Model and a Task-Technology Fit model, an initial study with Mobile G-Portal was conducted involving 39 students in a local secondary school. The findings suggested positive indication of acceptance of Mobile G-Portal for geography fieldwork. The paper concludes with a discussion on technological challenges, recommendations for refinement of Mobile G-Portal, and design implications in general for digital libraries and personal digital assistants supporting mobile learning. Copyright 2007 ACM.",26,,2-s2.0-36349023299,Conference Proceeding,2007-11-29,10.1145/1255175.1255269,471,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,462-471,Proceedings of the ACM International Conference on Digital Libraries,462,http://api.elsevier.com/content/abstract/scopus_id/36349023299,,36349023299,62702,p,Mobile G-Portal supporting collaborative sharing and learning in geography fieldwork: An empirical study
"Science is a complex, but highly structured, activity. We propose that reports about science would benefit by reflecting that structure. We provide an example based on the research paradigm and we explore more complex examples in which workflow models describe the conceptual model, the research procedure, the data analysis, and the conclusions. Copyright 2007 ACM.",2,,2-s2.0-36348983368,Conference Proceeding,2007-11-29,10.1145/1255175.1255271,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,472,http://api.elsevier.com/content/abstract/scopus_id/36348983368,,36348983368,62702,p,Highly structured scientific publications
This poster describes a collaboration involving two NSDL projects: the Materials Digital Library Pathway (MatDL) and the iVia Data Fountains Project. MatDL is testing and providing feedback for refinement of the iVia tools while streamlining its metadata assignment process. Copyright 2007 ACM.,0,,2-s2.0-36348935649,Conference Proceeding,2007-11-29,10.1145/1255175.1255272,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,473,http://api.elsevier.com/content/abstract/scopus_id/36348935649,,36348935649,62702,p,Cooperative collection building in NSDL MatDL pathway through IVIa data fountains
"Ensuring long-term access to valuable online content is complicated by legal constraints and practical difficulties. We introduce a new technique for ensuring the long-term availability of digital content on the internet. The technique combines legal and technical measures to guarantee that a document remains available when its original goes offline, either permanently or long-term: a ""publisher of last resort"". Copyright 2007 ACM.",0,,2-s2.0-36348993168,Conference Proceeding,2007-11-29,10.1145/1255175.1255274,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,475,http://api.elsevier.com/content/abstract/scopus_id/36348993168,,36348993168,62702,p,A publisher of last resort: Enduring document access
"The value of a digital repository increases tremendously when applications use the content in innovative ways. Tufts University has developed its repository based on the Fedora framework using the principles of service oriented architecture. The repository features innovative content models allowing the digital objects within the Tufts Digital Repository to be accessible through a variety of applications, including Perseus, Artifact, Tufts Digital Library (TDL) and Visual Understanding Environment (VUE). The poster will present the underlying architecture including latest services and their use in Educational Applications. Copyright 2007 ACM.",0,,2-s2.0-36349029762,Conference Proceeding,2007-11-29,10.1145/1255175.1255275,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,476,http://api.elsevier.com/content/abstract/scopus_id/36349029762,,36349029762,62702,p,Educational application integration with digital repository
"A study using a modified think aloud protocol of University of Rochester undergraduate students' interactions with a general, humanities scholarly database helped a research team gain insight into their information-seeking behavior and thus the impact of the digital library. Copyright 2007 ACM.",0,,2-s2.0-36348966664,Conference Proceeding,2007-11-29,10.1145/1255175.1255278,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,479,http://api.elsevier.com/content/abstract/scopus_id/36348966664,,36348966664,62702,p,Examining perception of digital information space
"This poster summarizes the results from a quantitative analysis of the tags and associated metadata used to describe more than one million videos by 537,246 contributors at the YouTube video sharing site. Results from this work suggest methodological and design considerations that could enhance the effectiveness of sharing within communities devoted to online video. Copyright 2007 ACM.",26,,2-s2.0-36349002365,Conference Proceeding,2007-11-29,10.1145/1255175.1255279,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,480,http://api.elsevier.com/content/abstract/scopus_id/36349002365,,36349002365,62702,p,Tagging video: Conventions and strategies of the YouTube community
"NESCent (The National Evolutionary Synthesis Center) is developing DRIADE (Digital Repository of Information and Data for Evolution) to address synthetic research challenges fundamental to advancing the field of evolutionary biology. This poster highlights results from a survey of selected repositories' functionalities, DRIADE's functional requirements, and DRIADE's functional model. We also summarize ongoing research activities, studying evolutionary biologists' data preservation practices and use requirements. Copyright 2007 ACM.",3,,2-s2.0-36349024775,Conference Proceeding,2007-11-29,10.1145/1255175.1255280,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,481,http://api.elsevier.com/content/abstract/scopus_id/36349024775,,36349024775,62702,p,DRIADE: A data repository for evolutionary biology
This poster provides an overview of the AlouetteCanada Metadata Toolkit. Copyright 2007 ACM.,0,,2-s2.0-36448991535,Conference Proceeding,2007-11-30,10.1145/1255175.1255281,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,482,http://api.elsevier.com/content/abstract/scopus_id/36448991535,,36448991535,62702,p,AlouetteCanada metadata toolkit
This paper describes technique of converting modern Mongolian text input to traditional Mongolian script and integrating the result into the Greenstone Digital Library (GSDL). This work is part of on-going research to create a digital library of traditional Mongolian historical documents. Copyright 2007 ACM.,1,,2-s2.0-36348934040,Conference Proceeding,2007-11-29,10.1145/1255175.1255282,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,483,http://api.elsevier.com/content/abstract/scopus_id/36348934040,,36348934040,62702,p,Building a digital library of traditional Mongolian historical documents
"We report preliminary lessons from a year of webmetrics research with two digital libraries. Despite the apparent 'plug-and-play-and-report' nature of webmetrics tools, much work was required to extract useful data from the tools used. Copyright 2007 ACM.",2,,2-s2.0-36348966663,Conference Proceeding,2007-11-29,10.1145/1255175.1255283,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,484,http://api.elsevier.com/content/abstract/scopus_id/36348966663,,36348966663,62702,p,Evaluating digital libraries with Webmetrics
"In this poster, we give the preliminary results of our project to acquire Atmospheric Science Data Center (ASDC) project-related web resources, not with focused crawling, but by using the search engine (SE) APIs directly. We aggregate the results and create archive-ready complex objects. Copyright 2007 ACM.",1,,2-s2.0-36348941845,Conference Proceeding,2007-11-29,10.1145/1255175.1255285,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,486,http://api.elsevier.com/content/abstract/scopus_id/36348941845,,36348941845,62702,p,Augmenting OAI-PMH repository holdings using search engine APIs
"The strengths within six library collections were automatically determined through automated enrichment and analysis of bibliographic level metadata records, with a view towards efficient resource sharing and collaborative collection management. This involved very large scale deduplicantion, enrichment and automatic reclassification of records using machine learning processes. Copyright 2007 ACM.",0,,2-s2.0-36349009341,Conference Proceeding,2007-11-29,10.1145/1255175.1255288,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,489,http://api.elsevier.com/content/abstract/scopus_id/36349009341,,36349009341,62702,p,Automated collection strength analysis
"The poster will compare and contrast the design and usage assumptions of existing educational digital libraries and repositories to challenge digital library developers to meet the needs of their increasingly sophisticated users. Traditionally, assumptions have focused on access to a site and discovery of content, whereas we define use as content and its application (context, audience, etc.). In this poster we will review the assumptions that have driven the design of digital libraries, their services and evaluation. Measures of success such as page views of metadata rest on assumptions associated with access, i.e., the number of times a metadata record is displayed. This measure provides a very limited view of how a digital library is used. We believe that educational digital libraries need to go beyond such a limited view and think about what people actually do with material: Are they using it? Are they returning to it? Are they modifying it? Are they sharing it with others? We will explore an alternate set of metrics for determining the success (or failure) of educational digital libraries by examining metrics focused on use of the contents of educational digital libraries. Copyright 2007 ACM.",0,,2-s2.0-36348999833,Conference Proceeding,2007-11-29,10.1145/1255175.1255291,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,492,http://api.elsevier.com/content/abstract/scopus_id/36348999833,,36348999833,62702,p,Use vs. access: Design and use in educational digital libraries
"In this paper, we report on the results of a national survey of faculty members concerning their use of digital resources (DRs), collections of resources and digital libraries (DLs). The research reported here explored issues such as: value of DRs, motivation for using DRs and barriers to use of these resources in teaching. The results have implications for how DLs might develop education and outreach efforts to increase visibility and use of their collections. Copyright 2007 ACM.",1,,2-s2.0-36349002933,Conference Proceeding,2007-11-29,10.1145/1255175.1255292,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,493,http://api.elsevier.com/content/abstract/scopus_id/36349002933,,36349002933,62702,p,What do faculty need and want from digital libraries?
"We share our experience with developing interactive, crossbrowser strand maps using SVG. These maps will provide educators with free and easy access to carefully selected instructional resources linked to national and state learning goals. We will show the interface in at least two browsers, Internet Explorer with Adobe's SVG Viewer plug-in and Mozilla Firefox. Copyright 2007 ACM.",3,,2-s2.0-36349026525,Conference Proceeding,2007-11-29,10.1145/1255175.1255293,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,494,http://api.elsevier.com/content/abstract/scopus_id/36349026525,,36349026525,62702,p,Building cross-browser interfaces for digital libraries with scalable vector graphics (SVG)
"Through an investigation of the needs and practices of researchers in the humanities and social sciences, we identify key issues in the use of an online digital reference library, the Electronic Cultural Atlas Initiatives' ""Support for the Learner: What, When, Where and Who"". In this poster we present an examination of results from survey data and user tasks, and discuss implications for future design and implementation based on our findings. Copyright 2007 ACM.",1,,2-s2.0-36348976994,Conference Proceeding,2007-11-29,10.1145/1255175.1255294,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,495,http://api.elsevier.com/content/abstract/scopus_id/36348976994,,36348976994,62702,p,Understanding target users of a digital reference library
"We report on work in progress on the merging of the Norwegian Gazetteer and the ADL gazetteer to create a gazetteer with both detailed local coverage and global scope suitable for indexing articles from a local newspaper. We describe a mapping on the schema level, a strategy for identifying duplicates in the merged gazeetteer and some identified challenges. Copyright 2007 ACM.",0,,2-s2.0-36349036634,Conference Proceeding,2007-11-29,10.1145/1255175.1255296,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,497,http://api.elsevier.com/content/abstract/scopus_id/36349036634,,36349036634,62702,p,Merging the Norwegian gazetteer with the ADL gazetteer
The Information System Media Education (in German: Informationssystem Medienpaedagogik ISM) is the most extensive digital reference tool on the topic of media education in the German-speaking area. Copyright 2007 ACM.,0,,2-s2.0-36349033005,Conference Proceeding,2007-11-29,10.1145/1255175.1255297,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,498,http://api.elsevier.com/content/abstract/scopus_id/36349033005,,36349033005,62702,p,Information System Media Education (ISM): Cooperating for media literacy
This paper describes a digitization project focused on developing a metadata modeling schema for album liner notes. Copyright 2007 ACM.,0,,2-s2.0-36348946928,Conference Proceeding,2007-11-29,10.1145/1255175.1255298,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,499,http://api.elsevier.com/content/abstract/scopus_id/36348946928,,36348946928,62702,p,Digitizing & providing access to contextual cultural materials: The liner notes digitization project
"In this paper, we describe the results of a national survey of higher education faculty concerning their use of digital resources and collections of these resources. We explore the differences in resource use by discipline groups and suggest implications for development of discipline specific libraries and faculty development practices. Copyright 2007 ACM.",0,,2-s2.0-36348947492,Conference Proceeding,2007-11-29,10.1145/1255175.1255299,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,500,http://api.elsevier.com/content/abstract/scopus_id/36348947492,,36348947492,62702,p,Use of online digital learning materials and digital libraries: Comparison by discipline
The Cité de la musique in Paris has recently opened a new media Library. One of the Library's assignments is the dissemination of the Cité de la musique's collection of recorded concerts. This paper presents the concert's description model implemented into the MARC Catalogue and emphasizes the central position in the library information system architecture of automatically generated XML representations of each concert. Copyright 2007 ACM.,0,,2-s2.0-36349011394,Conference Proceeding,2007-11-29,10.1145/1255175.1255301,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,501,http://api.elsevier.com/content/abstract/scopus_id/36349011394,,36349011394,62702,p,XML as the articulation between information retrieval and multimedia in a musical heritage dissemination
"This paper introduces a novel interaction for supporting rapid between-page comparison of texts within a limited screen estate. In comparison with existing interfaces and interactions, it gives a high degree of visual feedback and allows rapid between-page flicking, similar to what is readily achieved in physical environments using the fingers and thumbs of a reader as they flip between related pages. Copyright 2007 ACM.",5,,2-s2.0-36348952055,Conference Proceeding,2007-11-29,10.1145/1255175.1255303,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,503,http://api.elsevier.com/content/abstract/scopus_id/36348952055,,36348952055,62702,p,Rapid document navigation for information triage support
We explore in this paper the interface requirements for user's navigation within a mixed collection of 3D digitalized objects and textual documents. A specific application is history of technology where 3D and 2D documents are most of the time inter-related. Copyright 2007 ACM.,1,,2-s2.0-36348997601,Conference Proceeding,2007-11-29,10.1145/1255175.1255304,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,504,http://api.elsevier.com/content/abstract/scopus_id/36348997601,,36348997601,62702,p,Fluid interaction for the document in context
"The FacetedDBLP demonstrator allows to search computer science publications starting from some keyword and shows the result set along with a set of facets, e.g., distinguishing publication years, authors, or conferences. Furthermore, it uses GrowBag graphs, i.e., automatically created categorization systems, to create a topic facet, with which a user can characterize the result set in terms of main research topics and filter it according to certain subtopics. Copyright 2007 ACM.",25,,2-s2.0-36348933407,Conference Proceeding,2007-11-29,10.1145/1255175.1255305,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,505,http://api.elsevier.com/content/abstract/scopus_id/36348933407,,36348933407,62702,p,Demonstrating the semantic growbag: Automatically creating topic facets for FacetedDBLP
"We describe the creation of a specialized media collection in the Stanford MediaServer highlighting the David L. Bassett Stereoscopic Atlas of Human Anatomy. Previous reports have outlined the underlying architecture and features of the MediaServer developed to support biomedical media-based education 1,2. Here we focus on specific design principles and technical aspects of a focused project that may be beneficial to those developing digital media collections. Copyright 2007 ACM.",0,,2-s2.0-36348943533,Conference Proceeding,2007-11-29,10.1145/1255175.1255306,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,506,http://api.elsevier.com/content/abstract/scopus_id/36348943533,,36348943533,62702,p,The David L. Bassett stereoscopic atlas of human anatomy: Developing a specialized collection within the stanford mediaserver digital library
"Digital video data have proliferated in recent years due to the rapid development of multimedia computing and computer technologies. Management of video data is thus becoming an indispensable part in digital library. However, currently most digital video library systems are lack of the support of content-based video search and an easy-to-use query interface. In this work, we develop a digital video management system called VCenter, which provides lightweight mobile search functionality based on image taken from camera phone. By the proposed framework, both end user and content owner are easier to enjoy the multimedia contents in digital video libraries. Copyright 2007 ACM.",0,,2-s2.0-36348946361,Conference Proceeding,2007-11-29,10.1145/1255175.1255308,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,508,http://api.elsevier.com/content/abstract/scopus_id/36348946361,,36348946361,62702,p,VCenter: A digital video management system with mobile search service
"Creativity support is an important and challenging emerging area of research. combinFormation is being developed as a tool to support creativity through a mixed-initiative composition space. The system combines searches and information feeds, representing relevant information collections as compositions of image and text surrogates. The composition space affords human manipulation. This method has been shown to support information discovery in The Design Process, an interdisciplinary undergraduate course. In this demo, we demonstrate how combinFormation can be used to explore and discover information in digital libraries such as ACM Digital Library and the International Children's Digital Library. Copyright 2007 ACM.",0,,2-s2.0-36348949733,Conference Proceeding,2007-11-29,10.1145/1255175.1255309,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,509,http://api.elsevier.com/content/abstract/scopus_id/36348949733,,36348949733,62702,p,Creativity support: The mixed-initiative composition space
"The Visual Understanding Environment (VUE) project at Tufts' Academic Technology department aims at providing faculty and students with tools to successfully integrate digital resources into their teaching and learning. VUE not only provides a visual environment for structuring, presenting, and sharing digital information but also viewing digital resources along with their metadata. The demonstration will showcase the federated search capabilities of VUE that enable users to search across multiple digital repositories. We will also present concept maps created using digital objects from repositories. Copyright 2007 ACM.",4,,2-s2.0-36349007046,Conference Proceeding,2007-11-29,10.1145/1255175.1255310,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,510,http://api.elsevier.com/content/abstract/scopus_id/36349007046,,36349007046,62702,p,Visual understanding environment
"This demonstration explores the Internet Public Library (www.ipl.org), a shared online facility for testing innovations in digital libraries and for training a skilled work force in digital library services, systems, and collections. Hypatia 2.0 and QRC software used in IPL's digital library collections and services are shown, with discussion of IPL in education, digital collections, digital reference services, digital library systems, and research. Copyright 2007 ACM.",0,,2-s2.0-36348984449,Conference Proceeding,2007-11-29,10.1145/1255175.1255312,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,512,http://api.elsevier.com/content/abstract/scopus_id/36348984449,,36348984449,62702,p,The Internet public library: An online learning laboratory for digital libraries
"What do Eleanor Roosevelt, Frank Lloyd Wright, Margaret Sanger, and Henry Kissinger have in common? All of them, and 55 other celebrities were interviewed by Mike Wallace in 1957-58, and the corresponding kinescopes have resided in the Harry Ransom Humanities Research Center at the University of Texas since the early 1960's. This demonstration will showcase an online searchable video digital library of the Wallace interviews created by researchers, staff, and students at the University of Texas School of Information and the Universidad Francisco Marroquín. Copyright 2007 ACM.",0,,2-s2.0-36348984474,Conference Proceeding,2007-11-29,10.1145/1255175.1255315,,"[{'$': '1595936440'}, {'$': '9781595936448'}]",,,Proceedings of the ACM International Conference on Digital Libraries,515,http://api.elsevier.com/content/abstract/scopus_id/36348984474,,36348984474,62702,p,From kinescope to rich media: 50 years (ago) with Mike Wallace
"This work shows how the content of a digital library can be enhanced to better satisfy its users' needs. Missing content is identified by finding missing content topics in the system's query log or in a pre-defined taxonomy of required knowledge. The collection is then enhanced with new relevant knowledge, which is extracted from external sources that satisfy those missing content topics. Experiments we conducted measure the precision of the system before and after content enhancement. The results demonstrate a significant improvement in the system effectiveness as a result of content enhancement and the superiority of the missing content enhancement policy over several other possible policies. Copyright 2008 ACM.",8,,2-s2.0-57649148899,Conference Proceeding,2008-12-22,10.1145/1378889.1378891,10,9781595939982,,1-10,Proceedings of the ACM International Conference on Digital Libraries,1,http://api.elsevier.com/content/abstract/scopus_id/57649148899,,57649148899,62702,p,Enhancing digital libraries using missing content analysis
"We describe here in detail our work toward creating a dynamic lexicon from the texts in a large digital library. By leveraging a small structured knowledge source (a 30,457 word treebank), we are able to extract selectional preferences for words from a 3.5 million word Latin corpus. This is promising news for low-resource languages and digital collections seeking to leverage a small human investment into much larger gain. The library architecture in which this work is developed allows us to query customized subcorpora to report on lexical usage by author, genre or era and allows us to continually update the lexicon as new texts are added to the collection. Copyright 2008 ACM.",11,,2-s2.0-57649200254,Conference Proceeding,2008-12-22,10.1145/1378889.1378892,20,9781595939982,,11-20,Proceedings of the ACM International Conference on Digital Libraries,11,http://api.elsevier.com/content/abstract/scopus_id/57649200254,,57649200254,62702,p,Building a dynamic lexicon from a digital library
"We propose and evaluate a ""content-driven search keyword suggester"" for keyword-based search in literature digital libraries. Suggesting search keywords at an early stage, i.e., while the user is entering search terms, is helpful for constructing more accurate, less ambiguous, and focused search keywords for queries. Our search keyword suggestion approach is based on an a priori analysis of the publication collection in the digital library at hand, and consists of the following steps. We (i) parse the document collection using the Link Grammar parser, a syntactic parser of English, (ii) group publications based on their ""most-specific"" research topics, (iii) use the parser output to build a hierarchical structure of simple and compound tokens to be used to suggest search terms, (iv) use TextRank, a text summarization tool, to assign topic-sensitive scores to keywords, and (v) use the identified research-topics to help user aggregate search keywords prior to the actual search query execution. We experimentally show that tine proposed framework, which is optimized to work on literature digital libraries, promises a more scalable, high quality, and user-friendly search-keyword suggester when compared to its competitors. We validate our proposal experimentally using a subset of the ACM SIGMOD Anthology digital library as a testbed, and by employing the research-pyramid model to identify the ""most-specific"" research topics. Copyright 2008 ACM.",1,,2-s2.0-57649143141,Conference Proceeding,2008-12-22,10.1145/1378889.1378893,24,9781595939982,,21-24,Proceedings of the ACM International Conference on Digital Libraries,21,http://api.elsevier.com/content/abstract/scopus_id/57649143141,,57649143141,62702,p,On content-driven search-keyword suggesters for literature digital libraries
"This paper reports the further development of machine learning techniques for semantic markup of biodiversity literature, especially morphological descriptions of living organisms such as those hosted at efloras.org and algaebase.org. Syntactic parsing and supervised machine learning techniques have been explored by earlier research. Limitations of these techniques promoted our investigation of an unsupervised learning approach that combines the strength of earlier techniques and avoids the limitations. Semantic markup at the organ and character levels is discussed. Research on semantic markup of natural heritage literature has direct impact on the development of semantic-based access in biodiversity digital libraries. Copyright 2008 ACM.",6,,2-s2.0-57749115937,Conference Proceeding,2008-12-23,10.1145/1378889.1378894,28,9781595939982,,25-28,Proceedings of the ACM International Conference on Digital Libraries,25,http://api.elsevier.com/content/abstract/scopus_id/57749115937,,57749115937,62702,p,Unsupervised semantic markup of literature for biodiversity digital libraries
"There are opposing views on whether readers gain any advantage from using a computer model of a 3D physical book. There is enough evidence, both anecdotal and from formal user studies, to suggest that the usual HTML or PDF presentation of documents is not always the most convenient, or the most comfortable, for the reader. On the other hand it is quite clear that while 3D book models have been prototyped and demonstrated, none are in routine use in today's digital libraries. And how do 3D book models compare with actual books? This paper reports on a user study designed to compare the performance of a practical Realistic Book implementation with conventional formats (HTML and PDF) and with physical books. It also evaluates the annotation features that the implementation provides. Copyright 2008 ACM.",21,,2-s2.0-57649233064,Conference Proceeding,2008-12-22,10.1145/1378889.1378896,38,9781595939982,,29-38,Proceedings of the ACM International Conference on Digital Libraries,29,http://api.elsevier.com/content/abstract/scopus_id/57649233064,,57649233064,62702,p,Seeking information in realistic books: A user study
"We report on our user study on the information seeking behavior of cultural heritage experts and the sources they use to carry out search tasks. Seventeen experts from nine cultural heritage institutes in the Netherlands were interviewed and asked to answer questionnaires about their daily search activities. The interviews helped us to better understand their search motivations, types, sources and tools. A key finding of our study is that the majority of search tasks involve relatively complex information gathering. This is in contrast to the relatively simple fact-finding oriented support provided by current tools. We describe a number of strategies that experts have developed to overcome the inadequacies of their tools. Finally, based on the analysis, we derive general trends of cultural heritage experts' information seeking needs and discuss our preliminary experiences with potential solutions. Copyright 2008 ACM.",24,,2-s2.0-57649210179,Conference Proceeding,2008-12-22,10.1145/1378889.1378897,47,9781595939982,,39-47,Proceedings of the ACM International Conference on Digital Libraries,39,http://api.elsevier.com/content/abstract/scopus_id/57649210179,,57649210179,62702,p,Understanding cultural heritage experts' information seeking needs
"The ubiquitous within-document text search feature (Ctrl-F) is considered by users to be a key advantage in electronic information seeking [1]. However what people say they do and what they actually do are not always consistent. It is necessary to understand, acknowledge and identify the cause of this inconsistency. We must identify the physical and cognitive factors to develop better methods and tools, assisting with the search process. This paper discusses the limitations and myths of Ctrl-f in information seeking. A prototype system for within-document search is introduced. Three user studies portray shared behaviour and attitudes, common between participants regarding within-document searching. Copyright 2008 ACM.",9,,2-s2.0-57649217279,Conference Proceeding,2008-12-22,10.1145/1378889.1378898,51,9781595939982,,48-51,Proceedings of the ACM International Conference on Digital Libraries,48,http://api.elsevier.com/content/abstract/scopus_id/57649217279,,57649217279,62702,p,The myth of find: User behaviour and attitudes towards the basic search feature
"Digital libraries are concerned with improving the access to collections to make their service more effective and valuable to users. In this paper, we present the results of a four-week longitudinal study investigating the use of both exploratory and keyword forms of search within an online video archive, where both forms of search were available concurrently in a single user interface. While we expected early use to be more exploratory and subsequent use to be directed, over the whole period there was a balance of exploratory and keyword searches and they were often used together. Further, to support the notion that facets support exploration, there were more than five times as many facet clicks than more complex forms of keyword search (boolean and advanced). From these results, we can conclude that there is real value in investing in exploratory search support, which was shown to be both popular and useful for extended use of the system. Copyright 2008 ACM.",26,,2-s2.0-57649194915,Conference Proceeding,2008-12-22,10.1145/1378889.1378899,55,9781595939982,,52-55,Proceedings of the ACM International Conference on Digital Libraries,52,http://api.elsevier.com/content/abstract/scopus_id/57649194915,,57649194915,62702,p,A longitudinal study of exploratory and keyword search
"The growing availability of online K-12 curriculum is increasing the need for meaningful alignment of this curriculum with state-specific standards. Promising automated and semi-automated alignment tools have recently become available. Unfortunately, recent alignment evaluation studies report low inter-rater reliability, e.g., 32% with two raters and 35 documents. While these results are in line with studies in other domains, low reliability makes it difficult to accurately train automatic systems and complicates comparison of different services. We propose that inter-rater reliability of broadly defined, abstract concepts such as 'alignment' or 'relevance' must be expected to be low due to the real-world complexity of teaching and the multidimensional nature of the curricular documents. Hence, we suggest decomposing these concepts into less abstract, more precise measures anchored in the daily practice of teaching. This article reports on the integration of automatic alignment results into the interface of the TeachEngineering collection and on an evaluation methodology intended to produce more consistent document relevance ratings. Our results (based on 14 raters × 6 documents) show high inter-rater reliability (61 - 95%) on less abstract relevance dimensions while scores on the overall 'relevance' concept are (as expected) lower (64%). Despite a relatively small sample size, regression analysis of our data resulted in an explanatory (R 2 = .75) and statistically stable (p-values < .05) model for overall relevance as indicated by matching concepts, related background material, adaptability to grade level, and anticipated usefulness of exercises. Our results suggest that more detailed relevance evaluation which includes several dimensions of relevance would produce better data for comparing and training alignment tools. Copyright 2008 ACM.",4,,2-s2.0-57649171091,Conference Proceeding,2008-12-22,10.1145/1378889.1378901,65,9781595939982,,57-65,Proceedings of the ACM International Conference on Digital Libraries,57,http://api.elsevier.com/content/abstract/scopus_id/57649171091,,57649171091,62702,p,Exploring educational standard alignment: In search of 'relevance'
"NSDL is a premier provider of digital educational collections and services, which has been supported by NSF for eight years. As a mature program, NSDL has reached a point where it could either change direction or wind down. In this paper we argue there are reasons to continue the program and we outline several possible new program directions. These build on NSDL's learning platform, and they also look towards NSF's emerging interest in supporting work at the intersection of cyberinfrastructure and education. We consider NSDL's potential roles in several grand challenges that confront education, including: tailoring educational resources to students' needs, providing educators with a cyber-teaching environment, developing a cyber-workbench for researchers, and integrating education research and practice. Copyright 2008 ACM.",11,,2-s2.0-57649213513,Conference Proceeding,2008-12-22,10.1145/1378889.1378902,69,9781595939982,,66-69,Proceedings of the ACM International Conference on Digital Libraries,66,http://api.elsevier.com/content/abstract/scopus_id/57649213513,,57649213513,62702,p,From NSDL 1.0 to NSDL 2.0: Towards a comprehensive cyberinfrastructure for teaching and learning
"This paper discusses a digital library designed to help undergraduate students draw connections across disciplines, beginning with introductory discipline-specific science courses (including chemistry, materials science, and biophysics). The collection serves as the basis for a design experiment for interdisciplinary educational libraries and is discussed in terms of the three models proposed by Sumner and Marlino. As a cognitive tool, the library is organized around recurring patterns in molecular science, with one such pattern being developed for this initial design experiment. As a component repository, the library resources support learning of these patterns and how they appear in different disciplines. As a knowledge network, the library integrates design with use and assessment. Copyright 2008 ACM.",5,,2-s2.0-57649165534,Conference Proceeding,2008-12-22,10.1145/1378889.1378903,73,9781595939982,,70-73,Proceedings of the ACM International Conference on Digital Libraries,70,http://api.elsevier.com/content/abstract/scopus_id/57649165534,,57649165534,62702,p,Cross-disciplinary molecular science education in introductory science courses: An NSDL MatDL collection
"This paper describes the design and implementation of a curriculum overlay model for the representation of adaptable curriculum using educational digital library resources. We focus on representing curriculum to enable the incorporation of digital resources into curriculum and curriculum sharing and customization by educators. We defined this model as a result of longitudinal studies on educators' development and customization of curriculum and user interface design studies of prototypes representing curriculum. Like overlay journals or the information network overlay model, our curriculum overlay model defines curriculum as a compound object with internal semantic relationships and relationships to digital library metadata describing resources. We validated this model by instantiating the model using science curriculum which uses digital library resources and using this instantiation within an application that, built on FEDORA, supports curriculum customization. Findings from this work can support the design of digital library services for customizing curriculum which embeds digital resources. Copyright 2008 ACM.",3,,2-s2.0-57649213512,Conference Proceeding,2008-12-22,10.1145/1378889.1378904,83,9781595939982,,74-83,Proceedings of the ACM International Conference on Digital Libraries,74,http://api.elsevier.com/content/abstract/scopus_id/57649213512,,57649213512,62702,p,Curriculum overlay model for embedding digital resources
"Geolocalized databases are becoming necessary in a wide variety of application domains. Thus far, the creation of such databases has been a costly, manual process. This drawback has stimulated interest in automating their construction, for example, by mining geographical information from the Web. Here we present and evaluate a new automated technique for creating and enriching a geographical gazetteer, called Gazetiki. Our technique merges disparate information from Wikipedia, Panoramio, and web search, engines in order to identify geographical names, categorize these names, find their geographical coordinates and rank them. The information produced in Gazetiki enhances and complements the Geonames database, using a similar domain model. We show that our method provides a richer structure and an improved coverage compared to another known attempt at automatically building a geographic database and, where possible, we compare our Gazetiki to Geonames. Copyright 2008 ACM.",29,,2-s2.0-57649223705,Conference Proceeding,2008-12-22,10.1145/1378889.1378906,93,9781595939982,,85-93,Proceedings of the ACM International Conference on Digital Libraries,85,http://api.elsevier.com/content/abstract/scopus_id/57649223705,,57649223705,62702,p,Gazetiki: Automatic creation of a geographical gazetteer
"In this paper, we consider the problem of discovering GIS data sources on the web. Source discovery queries for GIS data are specified using keywords and a region of interest. A source is considered relevant if it contains data that matches the keywords in the specified region. Existing techniques simply rely on textual metadata accompanying such datasets to compute relevance to user-queries. Such approaches result in poor search results, often missing the most relevant sources on the web. We address this problem by developing more meaningful summaries of GIS datasets that preserve the spatial distribution of keywords. We conduct experiments showing the effectiveness of proposed summarization techniques by significantly improving the quality of query results over baseline approaches, while guaranteeing scalability and high performance. Copyright 2008 ACM.",4,,2-s2.0-57649210170,Conference Proceeding,2008-12-22,10.1145/1378889.1378907,103,9781595939982,,94-103,Proceedings of the ACM International Conference on Digital Libraries,94,http://api.elsevier.com/content/abstract/scopus_id/57649210170,,57649210170,62702,p,Discovering GIS sources on the Web using summaries
"Web 2.0 promises rich opportunities for information sharing, electronic commerce, and new modes of social interaction, all centered around the ""social Web"" of user-contributed content, social annotations, and person-to-person social connections. But the increasing reliance on this ""social Web"" also places individuals and their computer systems at risk, creating opportunities for malicious participants to exploit the tight social fabric of these networks. With these problems in mind, we propose the SOOIALTRUST framework for tamperresilient trust establishment in online communities. SOCIAL-TRUST provides community users with dynamic trust values by (i) distinguishing relationship quality from trust; (ii) incorporating a personalized feedback mechanism for adapting as the community evolves; and (iii) tracking user behavior. We experimentally evaluate the SOCIALTRUST framework using real online social networking data consisting of millions of My Space profiles and relationships. We find that SOCIALTRUST supports robust trust establishment even in the presence of large-scale collusion by malicious participants. Copyright 2008 ACM.",46,,2-s2.0-57649158750,Conference Proceeding,2008-12-22,10.1145/1378889.1378908,113,9781595939982,,104-113,Proceedings of the ACM International Conference on Digital Libraries,104,http://api.elsevier.com/content/abstract/scopus_id/57649158750,,57649158750,62702,p,SocialTrust: Tamper-resilient trust establishment in online communities
"Digital objects require appropriate measures for digital preservation to ensure that they can be accessed and used in the near and far future. While heritage institutions have been addressing the challenges posed by digital preservation needs for some time, private users and SOHOs (Small Office/Home Office) are less prepared to handle these challenges. Yet, both have increasing amounts of data that represent considerable value, be it office documents or family photographs. Backup, common practice of home users, avoids the physical loss of data, but it does not prevent the loss of the ability to render and use the data in the long term. Research and development in the area of digital preservation is driven by memory institutions and large businesses. The available tools, services and models are developed to meet the demands of these professional settings. This paper analyses the requirements and challenges of preservation solutions for private users and SOHOs. Based on the requirements and supported by available tools and services, we are designing and implementing a home archiving system to provide digital preservation solutions specifically for digital holdings in the small office and home environment. It hides the technical complexity of digital preservation challenges and provides simple and automated services based on established best practice examples. The system combines bitstream preservation and logical preservation strategies to avoid loss of data and the ability to access and use them. A first software prototype, called Hoppla, is presented in this paper. Copyright 2008 ACM.",5,,2-s2.0-57649155222,Conference Proceeding,2008-12-22,10.1145/1378889.1378910,123,9781595939982,,115-123,Proceedings of the ACM International Conference on Digital Libraries,115,http://api.elsevier.com/content/abstract/scopus_id/57649155222,,57649155222,62702,p,Personal & SOHO archiving
"Our previous research has shown that the collective behavior of search engine caches (e.g., Google, Yahoo, Live Search) and web archives (e.g., Internet Archive) results in the uncoordinated but large-scale refreshing and migrating of web resources. Interacting with these caches and archives, which we call the Web Infrastructure (WI), allows entire websites to be reconstructed in an approach we call lazy preservation. Unfortunately, the WI only captures the client-side view of a web resource. While this may be useful for recovering much of the content of a website, it is not helpful for restoring the scripts, web server configuration, databases, and other server-side components responsible for the construction of the website's resources. This paper proposes a novel technique for storing and recovering the server-side components of a website from the WI. Using erasure codes to embed the server-side components as HTML comments throughout the website, we can effectively reconstruct all the server components of a website when only a portion of the client-side resources have been extracted from the WI. We present the results of a preliminary study that baselines the lazy preservation of ten EPrints repositories and then examines the preservation of an EPrints repository that uses the erasure code technique to store the server-side EPrints software throughout the website. We found nearly 100% of the EPrints components were recoverable from the WI just two weeks after the repository came online, and it remained recoverable four months after it was ""lost"". Copyright 2008 ACM.",2,,2-s2.0-57649217319,Conference Proceeding,2008-12-22,10.1145/1378889.1378911,133,9781595939982,,124-133,Proceedings of the ACM International Conference on Digital Libraries,124,http://api.elsevier.com/content/abstract/scopus_id/57649217319,,57649217319,62702,p,Recovering a Website's server components from the Web infrastructure
"The National Geospatial Digital Archive, one of eight initial projects funded under the Library of Congress's NDIIPP program, has been researching how geospatial data can be preserved on a national scale and be made available to future generations. In this paper we describe an archive architecture that provides a minimal approach to the long-term preservation of digital objects based on co-archiving of object semantics, uniform representation of objects and semantics, explicit storage of all objects and semantics as files, and abstraction of the underlying storage system. This architecture ensures that digital objects can be easily migrated from archive to archive over time and that the objects can, in principle, be made usable again at any point in the future; its primary benefit is that it serves as a fallback strategy against, and as a foundation for, more sophisticated (and costly) preservation strategies. We describe an implementation of this architecture in a protoype archive running at UCSB that also incorporates a suite of ingest and access components. Copyright 2008 ACM.",16,,2-s2.0-57649219475,Conference Proceeding,2008-12-22,10.1145/1378889.1378912,143,9781595939982,,134-143,Proceedings of the ACM International Conference on Digital Libraries,134,http://api.elsevier.com/content/abstract/scopus_id/57649219475,,57649219475,62702,p,A data model and architecture for long-term preservation
"Data visualization has historically been accessible only to the elite in academia, business, and government. It is ""serious"" technology done by experts for experts. But in recent years web-based visualizations-ranging from political art projects to news stories-have reached audiences of millions. Unfortunately, while lay users can view many sophisticated visualizations, they have few ways to create them. In order to ""democratize"" visualization and data analysis, we have built Many Eyes, a web site where people may upload their own data, create interactive visualizations, and carry on conversations. By making these tools available to anyone on the web, the site fosters a social style of data analysis that empowers users to engage with public data through discussion and collaboration. Political discussions, citizen activism, religious conversations, game playing, and educational exchanges are all happening on Many Eyes. As we will discuss in this talk, the public nature of these visualizations provide users with a transformative path to information literacy.",1,,2-s2.0-57649148822,Conference Proceeding,2008-12-22,10.1145/1378889.1378914,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,145,http://api.elsevier.com/content/abstract/scopus_id/57649148822,,57649148822,62702,p,"Shakespeare, god, and lonely hearts: Transforming data access with many eyes"
"Collaborative, social tagging and annotation systems have exploded on the Internet as part of the Web 2.0 phenomenon. Systems such as Flickr, Del.icio.us, Technorati, Connotea and LibraryThing, provide a community-driven approach to classifying information and resources on the Web, so that they can be browsed, discovered and re-used. Although social tagging sites provide simple, user-relevant tags, there are issues associated with the quality of the metadata and the scalability compared with conventional indexing systems. In this paper we propose a hybrid approach that enables authoritative metadata generated by traditional cataloguing methods to be merged with community annotations and tags. The HarvANA (Harvesting and Aggregating Networked Annotations) system uses a standardized but extensible RDF model for representing the annotations/tags and OAI-PMH to harvest the annotations/tags from distributed community servers. The harvested annotations are aggregated with the authoritative metadata in a centralized metadata store. This streamlined, interoperable, scalable approach enables libraries, archives and repositories to leverage community enthusiasm for tagging and annotation, augment their metadata and enhance their discovery services. This paper describes the HarvANA system and its evaluation through a collaborative testbed with the National Library of Australia using architectural images from PictureAustralia. Copyright 2008 ACM.",32,,2-s2.0-57649158661,Conference Proceeding,2008-12-22,10.1145/1378889.1378916,156,9781595939982,,147-156,Proceedings of the ACM International Conference on Digital Libraries,147,http://api.elsevier.com/content/abstract/scopus_id/57649158661,,57649158661,62702,p,HarvANA - Harvesting community tags to enrich collection metadata
"In this paper we present a system called paperBase that aids users in entering metadata for preprints. PaperBase extracts metadata from the preprint. Using a Dublin-Core based REST API, third-party repository software populates a web form that the user can then proofread and complete. Paper-Base also predicts likely keywords for the preprints, based on a controlled vocabulary of keywords that the archive uses and a Bayesian classifier. We have tested the system on 12 individuals, and measured the time that it took them to enter data, and the accuracy of the entered metadata. We find that our system appears to be faster than manual entry, but a larger sample needs to be tested before it can be deemed statistically significant. All but two participants perceived it to be faster. Some metadata, in particular the title of preprints, contains significantly fewer mistakes when entered automatically; even though the automatic system is not perfect, people tend to correct mistakes that paperBase makes, but would leave their own mistakes in place. Copyright 2008 ACM.",8,,2-s2.0-57649165571,Conference Proceeding,2008-12-22,10.1145/1378889.1378917,166,9781595939982,,157-166,Proceedings of the ACM International Conference on Digital Libraries,157,http://api.elsevier.com/content/abstract/scopus_id/57649165571,,57649165571,62702,p,Semi automated metadata extraction for preprints archives
"Large scale digitization projects have been conducted at digital libraries to preserve cultural artifacts and to provide permanent access. The increasing amount of digitized resources, including scanned books and scientific publications, requires development of tools and methods that will efficiently analyze and manage large collections of digitized resources. In this work, we tackle the problem of extracting metadata from scanned volumes of journals. Our goal is to extract information describing internal structures and content of scanned volumes, which is necessary for providing effective content access functionalities to digital library users. We propose methods for automatically generating volume level, issue level, and article level metadata based on format and text features extracted from OCRed text. We show the performance of our system on scanned bound historical documents nearly two centuries old. We have developed the system and integrated it into an operational digital library, the Internet Archive, for real-world usage. Copyright 2008 ACM.",12,,2-s2.0-57649210210,Conference Proceeding,2008-12-22,10.1145/1378889.1378918,176,9781595939982,,167-176,Proceedings of the ACM International Conference on Digital Libraries,167,http://api.elsevier.com/content/abstract/scopus_id/57649210210,,57649210210,62702,p,A metadata generation system for scanned scientific volumes
"Key Ideas is a technique for exploring digital libraries by navigating passages that repeat across multiple books. From these popular passages emerge quotations that authors have copied from book to book because they capture an idea particularly well: Jefferson on liberty; Stanton on women's rights; and Gibson on cyberpunk. We augment Popular Passages by extracting key terms from the surrounding context and computing sets of related key terms. We then create an interaction model where readers fluidly explore the library by viewing popular quotations on a particular key term, and follow links to quotations on related key terms. In this paper we describe our vision and motivation for Key Ideas, present an implementation running over a massive, real-world digital library consisting of over a million scanned books, and describe some of the technical and design challenges. The principal contribution of this paper is the interaction model and prototype system for browsing digital libraries of books using key terms extracted from the aggregate context of popularly quoted passages. Copyright 2008 ACM.",6,,2-s2.0-57649198427,Conference Proceeding,2008-12-22,10.1145/1378889.1378920,186,9781595939982,,177-186,Proceedings of the ACM International Conference on Digital Libraries,177,http://api.elsevier.com/content/abstract/scopus_id/57649198427,,57649198427,62702,p,Exploring a digital library through key ideas
"We report on the user requirements study and preliminary implementation phases in creating a digital library that indexes and retrieves educational materials on math. We first review the current approaches and resources for math retrieval, then report on the interviews of a small group of potential users to properly ascertain their needs. While preliminary, the results suggest that meta-search and resource categorization are two basic requirements for a math search engine. In addition, we implement a prototype categorization system and show that the generic features work well in identifying the math contents from the webpage but perform less well at categorizing them. We discuss our long term goals, where we plan to investigate how math expressions and text search may be best integrated. Copyright 2008 ACM.",21,,2-s2.0-57649174646,Conference Proceeding,2008-12-22,10.1145/1378889.1378921,196,9781595939982,,187-196,Proceedings of the ACM International Conference on Digital Libraries,187,http://api.elsevier.com/content/abstract/scopus_id/57649174646,,57649174646,62702,p,Math information retrieval: User requirements and prototype implementation
"Most information workers query digital libraries many times a day. Yet people have little opportunity to hone their skills in a controlled environment, or compare their performance with others in an objective way. Conversely, although search engine logs record how users evolve queries, they lack crucial information about the user's intent. This paper describes an environment for exploratory query expansion that pits users against each other and lets them compete, and practice, in their own time and on their own workstation. The system captures query evolution behavior on predetermined information-seeking tasks. It is publicly available, and the code is open source so that others can set up their own competitive environments. Copyright 2008 ACM.",4,,2-s2.0-57649194945,Conference Proceeding,2008-12-22,10.1145/1378889.1378922,200,9781595939982,,197-200,Proceedings of the ACM International Conference on Digital Libraries,197,http://api.elsevier.com/content/abstract/scopus_id/57649194945,,57649194945,62702,p,A competitive environment for exploratory query expansion
"At present very little is known about how people locate and view videos 'in the wild'. This study draws a rich picture of everyday video seeking strategies and video information needs, based on an ethnographic study of New Zealand university students. These insights into the participants' activities and motivations suggest potentially useful facilities for a video digital library. Copyright 2008 ACM.",35,,2-s2.0-57649171114,Conference Proceeding,2008-12-22,10.1145/1378889.1378924,210,9781595939982,,201-210,Proceedings of the ACM International Conference on Digital Libraries,201,http://api.elsevier.com/content/abstract/scopus_id/57649171114,,57649171114,62702,p,How people find videos
"Digital curators are faced with decisions about what part of the ever-growing, ever-evolving space of digital information to collect and preserve. The recent explosion of web video on sites such as YouTube presents curators with an even greater challenge - how to sort through and filter a large amount of information to find, assess and ultimately preserve important, relevant, and interesting video. In this paper, we describe research conducted to help inform digital curation of on-line video. Since May 2007, we have been monitoring the results of 57 queries on YouTube related to the 2008 U.S. presidential election. We report results comparing these data to blogs that point to candidate videos on YouTube and discuss the effects of query-based harvesting as a collection development strategy. Copyright 2008 ACM.",11,,2-s2.0-57649233075,Conference Proceeding,2008-12-22,10.1145/1378889.1378925,220,9781595939982,,211-220,Proceedings of the ACM International Conference on Digital Libraries,211,http://api.elsevier.com/content/abstract/scopus_id/57649233075,,57649233075,62702,p,Selection and context scoping for digital video collections: An investigation of YouTube and blogs
"Awareness of another's activity is an important aspect of facilitating collaboration between users, enabling an ""understanding of the activities of others"" [1]. Techniques such as collaborative filtering enable a form of asynchronous awareness, providing recommendations generated from the past activity of a community of users. In this paper we investigate the role of awareness and its effect on search behavior in collaborative multimedia retrieval. We focus on the scenario where two users are searching at the same time on the same task, and via the interface, can see the activity of the other user. The main research question asks: does awareness of another searcher aid a user when carrying out a multimedia search session? To encourage awareness, an experimental study was designed where two users were asked to find as many relevant video shots as possible under different awareness conditions. These were individual search (no awareness of each other), mutual awareness (where both user's could see each other's search screen), and unbalanced awareness (where one user is able to see the other's screen, but not vice-versa). Twelve pairs of users were recruited, and the four worst performing TRECVID 2006 search topics were used as search tasks, under four different awareness conditions. We present the results of this study, followed by a discussion of the implications for multimedia digital library systems. Copyright 2008 ACM.",12,,2-s2.0-57649143139,Conference Proceeding,2008-12-22,10.1145/1378889.1378926,230,9781595939982,,221-230,Proceedings of the ACM International Conference on Digital Libraries,221,http://api.elsevier.com/content/abstract/scopus_id/57649143139,,57649143139,62702,p,A study of awareness in multimedia search
"Scholarly usage data holds the potential to be used as a tool to study the dynamics of scholarship in real time, and to form the basis for the definition of novel metrics of scholarly impact. However, the formal groundwork to reliably and validly exploit usage data is lacking, and the exact nature, meaning and applicability of usage-based metrics is poorly understood. The MESUR project funded by the Andrew W. Mellon Foundation constitutes a systematic effort to define, validate and cross-validate a range of usage-based metrics of scholarly impact. MESUR has collected nearly 1 billion usage events as well as all associated bibliographic and citation data from significant publishers, aggregators and institutional consortia to construct a large-scale usage data reference set. This paper describes some major challenges related to aggregating and processing usage data, and discusses preliminary results obtained from analyzing the MESUR reference data set. The results confirm the intrinsic value of scholarly usage data, and support the feasibility of reliable and valid usage-based metrics of scholarly impact.",24,,2-s2.0-57649219462,Conference Proceeding,2008-12-22,10.1145/1378889.1378928,240,9781595939982,,231-240,Proceedings of the ACM International Conference on Digital Libraries,231,http://api.elsevier.com/content/abstract/scopus_id/57649219462,,57649219462,62702,p,Towards usage-based impact metrics: First results from the MESUR project
"A digital video library of over 900 hours of video and 18000 stories from The HistoryMakers is used to investigate the role of motion video for users of recorded life oral histories. Stories in the library are presented in one of two ways in two within-subjects experiments: either as audio accompanied by a single still photographic image per story, or as the same audio within a motion video of the interviewee speaking. Twenty-four participants given a treasure-hunt fact-finding task, i.e., very directed search, showed no significant preference for either the still or video treatment, and no difference in task performance. Fourteen participants in a second study worked on an exploratory task in the same within-subjects experimental framework, and showed a significant preference for video. For exploratory work, video has a positive effect on user satisfaction. Implications for use of video in collecting and accessing recorded life oral histories, in student assignments and more generally, are discussed, along with reflections on long term user studies to complement the ones presented here. Copyright 2008 ACM.",9,,2-s2.0-57649155206,Conference Proceeding,2008-12-22,10.1145/1378889.1378929,250,9781595939982,,241-250,Proceedings of the ACM International Conference on Digital Libraries,241,http://api.elsevier.com/content/abstract/scopus_id/57649155206,,57649155206,62702,p,Evaluating the contributions of video representation for a life oral history collection
"This paper reports the results of a qualitative field study of the scholarly writing, collaboration, information management, and long-term archiving practices of researchers in five related subdisciplines. The study focuses on the kinds of artifacts the researchers create in the process of writing a paper, how they exchange and store materials over the short term, how they handle references and bibliographic resources, and the strategies they use to guarantee the long term safety of their scholarly materials. The findings reveal: (1) the adoption of a new CIM infrastructure relies crucially on whether it compares favorably to email along six critical dimensions; (2) personal scholarly archives should be maintained as a side-effect of collaboration and the role of ancillary material such as datasets remains to be worked out; and (3) it is vital to consider agency when we talk about depositing new types of scholarly materials into disciplinary repositories. Copyright 2008 ACM.",11,,2-s2.0-57649171112,Conference Proceeding,2008-12-22,10.1145/1378889.1378930,260,9781595939982,,251-260,Proceedings of the ACM International Conference on Digital Libraries,251,http://api.elsevier.com/content/abstract/scopus_id/57649171112,,57649171112,62702,p,From writing and analysis to the repository: Taking the scholars' perspective on scholarly archiving
"We describe a user-assisted framework for correcting ink-bleed in old handwritten documents housed at the National Archives of Singapore (NAS). Our approach departs from traditional correction techniques that strive for full automation. Fully-automated approaches make assumptions about ink-bleed characteristics that are not valid for all inputs. Furthermore, fully-automated approaches often have to set algorithmic parameters that have no meaning for the end-user. In our system, the user needs only to provide simple examples of ink-bleed, foreground ink, and background. These training examples are used to classify the remaining pixels in the document to produce a computer-generated result that is equal to or better than existing fully-automated approaches. To offer a complete system, we also provide tools that allow any errors in the computer-generated results to be quickly ""cleaned up"" by the user. The initial training markup, together with the computer-generated results, and manual edits are all recorded with the final output, allowing subsequent viewers to see how a corrected document was created and to make changes or updates. While an ongoing project, our feedback from the NAS staff has been overwhelmingly positive that this user-assisted framework is a practical way to address the ink-bleed problem. Copyright 2008 ACM.",6,,2-s2.0-57649217308,Conference Proceeding,2008-12-22,10.1145/1378889.1378934,271,9781595939982,,263-271,Proceedings of the ACM International Conference on Digital Libraries,263,http://api.elsevier.com/content/abstract/scopus_id/57649217308,,57649217308,62702,p,User-assisted ink-bleed correction for handwritten documents
"Authors' names are a critical bibliographic element when searching or browsing academic articles stored in digital libraries. Therefore, those creating metadata for digital libraries would appreciate an automatic method to extract such bibliographic data from printed documents. In this paper, we describe an automatic author name tagger for academic articles scanned with optical character recognition (OCR) mark-up. The method uses conditional random fields (CRF) for labeling the unsegmented character strings in authors' blocks as those of either an author or a delimiter. We applied the tagger to Japanese academic articles. The results of the experiments showed that it correctly labeled more than 99% of the author name strings, which compares favorably with the under 96% correct rate of our previous tagger based on a hidden Markov model (HMM). Copyright 2008 ACM.",5,,2-s2.0-57649219461,Conference Proceeding,2008-12-22,10.1145/1378889.1378935,275,9781595939982,,272-275,Proceedings of the ACM International Conference on Digital Libraries,272,http://api.elsevier.com/content/abstract/scopus_id/57649219461,,57649219461,62702,p,CRF-based authors' name tagging for scanned documents
"Most search engines index the textual content of documents in digital libraries. However, scholarly articles frequently report important findings in figures for visual impact and the contents of these figures are not indexed. These contents are often invaluable to the researcher in various fields, for the purposes of direct comparison with their own work. Therefore, searching for figures and extracting figure data are important problems. To the best of our knowledge, there exists no tool to automatically extract data from figures in digital documents. If we can extract data from these images automatically and store them in a database, an end-user can query and combine data from multiple digital documents simultaneously and efficiently. We propose a framework based on image analysis and machine learning to extract information from 2-D plot images and store them in a database. The proposed algorithm identifies a 2-D plot and extracts the axis labels, legend and the data points from the 2-D plot. We also segregate overlapping shapes that correspond to different data points. We demonstrate performance of individual algorithms, using a combination of generated and real-life images. Copyright 2008 ACM.",6,,2-s2.0-57649219455,Conference Proceeding,2008-12-22,10.1145/1378889.1378936,279,9781595939982,,276-279,Proceedings of the ACM International Conference on Digital Libraries,276,http://api.elsevier.com/content/abstract/scopus_id/57649219455,,57649219455,62702,p,Segregating and extracting overlapping data points in two-dimensional plots
"This paper describes a simple method for extracting metadata fields from citations using hidden Markov models. The method is easy to implement and can achieve levels of precision and recall for heterogeneous citations comparable to or greater than other HMM-based methods. The method consists largely of string manipulation and otherwise depends only on an implementation of the Viterbi algorithm, which is widely available, and so can be implemented by diverse digital library systems. Copyright 2008 ACM.",27,,2-s2.0-57649187095,Conference Proceeding,2008-12-22,10.1145/1378889.1378937,284,9781595939982,,280-284,Proceedings of the ACM International Conference on Digital Libraries,280,http://api.elsevier.com/content/abstract/scopus_id/57649187095,,57649187095,62702,p,A simple method for citation metadata extraction using Hidden Markov models
"We have developed a method for determining whether data found on the Web are for the same or different objects that takes into account the possibility of changes in their attribute values over time. Specifically, we estimate the probability that observed data were generated for the same object that has undergone changes in its attribute values over time and the probability that the data are for different objects, and we define similarities between observed data using these probabilities. By giving a specific form to the distributions of time-varying attributes, we can calculate the similarity between given data and identify objects by using agglomerative clustering on the basis of the similarity. Experiments in which we compared identification accuracies between our proposed method and a method that regards all attribute values as constant showed that the proposed method improves the precision and recall of object identification. Copyright 2008 ACM.",7,,2-s2.0-57649198469,Conference Proceeding,2008-12-22,10.1145/1378889.1378939,294,9781595939982,,285-294,Proceedings of the ACM International Conference on Digital Libraries,285,http://api.elsevier.com/content/abstract/scopus_id/57649198469,,57649198469,62702,p,Identification of time-varying objects on the Web
"Citations to publication venues in the form of journal, conference and workshop contain spelling variants, acronyms, abbreviated forms and misspellings, all of which make more difficult to retrieve the item of interest. The task of discovering and reconciling these variant forms of bibliographic references is known as authority work. The key goal is to create the so called authority files, which maintain, for any given bibliographic item, a list of variant labels (i.e., variant strings) used as a reference to it. In this paper we propose to use information available on the Web to create high quality publication venue authority files. Our idea is to recognize (and extract) references to publication venues in the text snippets of the answers returned by a search engine. References to a same publication venue are then reconciled in an authority file. Each entry in this file is composed of a canonical name for the venue, an acronym, the venue type (i.e., journal, conference, or workshop), and a mapping to various forms of writing its name in bibliographic citations. Experimental results show that our Web-based method for creating authority files is superior to previous work based on straight string matching techniques. Considering the average precision in finding correct venue canonical names, we observe gains up to 41.7%. Copyright 2008 ACM.",4,,2-s2.0-57649219448,Conference Proceeding,2008-12-22,10.1145/1378889.1378940,304,9781595939982,,295-304,Proceedings of the ACM International Conference on Digital Libraries,295,http://api.elsevier.com/content/abstract/scopus_id/57649219448,,57649219448,62702,p,Using Web information for creating publication venue authority files
"Information on the Internet, especially blog content, changes rapidly. Users of information collections, such as the blogs hosted by technorati.com, have little, if any, control over the content or frequency of these changes. However, it is important for users to be able to monitor content for deviations in the expected pattern of change. If a user is interested in political blogs and a blog switches subjects to a literary review blog, the user would want to know of this change in behavior. Since pages may change too frequently for manual inspection for ""unwanted"" changes, an automated approach is wanted. In this paper, we explore methods for indentifying unexpected change by using Kalman filters to model blog behavior over time. Using this model, we examine the history of several blogs and determine methods for flagging the significance of a blog's change from one time step to the next. We are able to predict large deviations in blog content, and allow user-defined sensitivity parameters to tune a statistical threshold of significance for deviation from expectation. Copyright 2008 ACM.",3,,2-s2.0-57649187093,Conference Proceeding,2008-12-22,10.1145/1378889.1378941,312,9781595939982,,305-312,Proceedings of the ACM International Conference on Digital Libraries,305,http://api.elsevier.com/content/abstract/scopus_id/57649187093,,57649187093,62702,p,Application of kalman filters to identify unexpected change in blogs
"NCore is an open source architecture and software platform for creating flexible, collaborative digital libraries. NCore was developed by the National Science Digital Library (NSDL) project, and it serves as the central technical infrastructure for NSDL. NCore consists of a central Fedora-based digital repository, a specific data model, an API, and a set of backend services and frontend tools that create a new model for collaborative, contributory digital libraries. This paper describes NCore, presents and analyzes its architecture, tools and services; and reports on the experience of NSDL in building and operating a major digital library on it over the past year and the experience of the Digital Library for Earth Systems Education in porting their existing digital library and tools to the NCore platform. Copyright 2008 ACM.",16,,2-s2.0-57649217299,Conference Proceeding,2008-12-22,10.1145/1378889.1378943,322,9781595939982,,313-322,Proceedings of the ACM International Conference on Digital Libraries,313,http://api.elsevier.com/content/abstract/scopus_id/57649217299,,57649217299,62702,p,"NCore: Architecture and implementation of a flexible, collaborative digital library"
"University libraries in Developing Countries (DCs), hampered by developmental problems, find it hard to provide electronic services. Donor communities have come in to bridge this technology gap by providing funds to university libraries for information technology infrastructure, enabling these university libraries to provide electronic library services to patrons. However, for these services to be utilized effectively, library end-users must accept and use them. To investigate this process in Uganda, this study modifies ""The Unified Theory of Acceptance and Use of Technology"" (UTAUT) by replacing ""effort expectancy"" and ""voluntariness"" with ""relevancy"", ""awareness"" and ""benefits"" factors. In so doing, we developed the Service Oriented UTAUT (SOUTAUT) model whose dependent constructs predict 133% of the variances in user acceptance and use of e-library services. The study revealed that relevancy moderated by awareness plays a major factor in acceptance and use of e-library services in DCs. Copyright 2008 ACM.",9,,2-s2.0-57649158639,Conference Proceeding,2008-12-22,10.1145/1378889.1378944,332,9781595939982,,323-332,Proceedings of the ACM International Conference on Digital Libraries,323,http://api.elsevier.com/content/abstract/scopus_id/57649158639,,57649158639,62702,p,Acceptance and use of electronic library services in ugandan universities
"This paper describes the facilities we built to run a self-contained digital library on an iPod. The digital library software used was the open source package Greenstone, and the paper highlights the technical problems that were encountered and solved. It attempts to convey a feeling for the kind of issues that must be faced when adapting standard DL software for non-standard, leading-edge devices. Copyright 2008 ACM.",7,,2-s2.0-57649219438,Conference Proceeding,2008-12-22,10.1145/1378889.1378945,336,9781595939982,,333-336,Proceedings of the ACM International Conference on Digital Libraries,333,http://api.elsevier.com/content/abstract/scopus_id/57649219438,,57649219438,62702,p,Portable digital libraries on an iPod
"This paper analyzes problems encountered by our team while creating an educational digital library of program examples. We present approaches to resolving these problems, and evaluations of the suggested approaches. Copyright 2008 ACM.",0,,2-s2.0-57649143123,Conference Proceeding,2008-12-22,10.1145/1378889.1378946,340,9781595939982,,337-340,Proceedings of the ACM International Conference on Digital Libraries,337,http://api.elsevier.com/content/abstract/scopus_id/57649143123,,57649143123,62702,p,Annotated program examples as first class objects in an educational digital library
"Recent initiatives like the Million Book Project and Google Print Library Project have already archived several million books in digital format, and within a few years a significant fraction of world's books will be online. While the majority of the data will naturally be text, there will also be tens of millions of pages of images. Many of these images will defy automation annotation for the foreseeable future, but a considerable fraction of the images may be amiable to automatic annotation by algorithms that can link the historical image with a modern contemporary, with its attendant metatags. In order to perform this linking we must have a suitable distance measure which appropriately combines the relevant features of shape, color, texture and text. However the best combination of these features will vary from application to application and even from one manuscript to another. In this work we propose a simple technique to learn the distance measure by perturbing the training set in a principled way. We show the utility of our ideas on archives of manuscripts containing images from natural history and cultural artifacts. Copyright 2008 ACM.",10,,2-s2.0-57649213527,Conference Proceeding,2008-12-22,10.1145/1378889.1378948,350,9781595939982,,341-350,Proceedings of the ACM International Conference on Digital Libraries,341,http://api.elsevier.com/content/abstract/scopus_id/57649213527,,57649213527,62702,p,Annotating historical archives of images
"A novel technique for semi-automatic photo annotation is proposed and evaluated. The technique, sLab, uses face processing algorithms and a simplified user interface for labeling family photos. A user study compared our system with two others. One was Adobe Photoshop Element. The other was an in-house implementation of a face clustering interface recently proposed in the research community. Nine participants performed an annotation task with each, system on faces extracted from a set of 150 images from their own family photo albums. As the faces were all well known to participants, accuracy was near perfect with all three systems. On annotation time, sLab was 25% faster than Photoshop Element and 16% faster than the face clustering interface. Copyright 2008 ACM.",0,,2-s2.0-57649233053,Conference Proceeding,2008-12-22,10.1145/1378889.1378949,354,9781595939982,,351-354,Proceedings of the ACM International Conference on Digital Libraries,351,http://api.elsevier.com/content/abstract/scopus_id/57649233053,,57649233053,62702,p,sLab: Smart labeling of family photos through an interactive interface
"Text search on libraries of 3D models has traditionally worked poorly, as text annotations on 3D models are often unreliable or incomplete. We attempt to improve the recall of text search by automatically assigning appropriate tags to models. Our algorithm finds relevant tags by appealing to a large corpus of partially labeled example models, which does not have to be preclassified or otherwise prepared. For this purpose we use a copy of Google 3DWarehouse, a library of user contributed models which is publicly available on the Internet. Given a model to tag, we find geometrically similar models in the corpus, based on distances in a reduced dimensional space derived from Zernike descriptors. The labels of these neighbors are used as tag candidates for the model with probabilities proportional to the degree of geometric similarity. We show experimentally that text based search for 3D models using our computed tags can approach the quality of geometry based search. Finally, we describe our 3D model search engine that uses this algorithm. Copyright 2008 ACM.",19,,2-s2.0-57649174629,Conference Proceeding,2008-12-22,10.1145/1378889.1378950,358,9781595939982,,355-358,Proceedings of the ACM International Conference on Digital Libraries,355,http://api.elsevier.com/content/abstract/scopus_id/57649174629,,57649174629,62702,p,Autotagging to improve text search for 3D models
"We consider the task of automatic slide image retrieval, in which slide images are ranked for relevance against a textual query. Our implemented system, SLIDIR caters specifically for this task using features specifically designed for synthetic images embedded within slide presentation. We show promising results in both the ranking and binary relevance task and analyze the contribution of different features in the task performance. Copyright 2008 ACM.",8,,2-s2.0-57649165547,Conference Proceeding,2008-12-22,10.1145/1378889.1378951,362,9781595939982,,359-362,Proceedings of the ACM International Conference on Digital Libraries,359,http://api.elsevier.com/content/abstract/scopus_id/57649165547,,57649165547,62702,p,Slide image retrieval: A preliminary study
"A novel online news extraction approach based on human perception is presented in this paper. The approach simulates how a human perceives and identifies online news content. It first detects news areas based on content function, space continuity, and formatting continuity of news information. It further identifies detailed news content based on the position, format, and semantic of detected news areas. Experiment results show that our approach, achieves much better performance (in average more than 99% in terms of F1 Value) compared to previous approaches such as Tree Edit Distance and Visual Wrapper based approaches. Furthermore, our approach does not assume the existence of Web templates in the tested Web pages as required by Tree Edit Distance based approach, nor does it need training sets as required in Visual Wrapper based approach. The success of our approach demonstrates the strength of the perception-oriented Web information extraction methodology and represents a promising approach for automatic information extraction from sources with presentation design for humans. Copyright 2008 ACM.",10,,2-s2.0-57649171100,Conference Proceeding,2008-12-22,10.1145/1378889.1378952,366,9781595939982,,363-366,Proceedings of the ACM International Conference on Digital Libraries,363,http://api.elsevier.com/content/abstract/scopus_id/57649171100,,57649171100,62702,p,Perception-oriented online news extraction
"The fast changes of technologies in today's information landscape have considerably shortened the lifespan of digital objects. Digital preservation has become a pressing challenge. Different strategies such as migration and emulation have been proposed; however, the decision for a specific tool e.g. for format migration or an emulator is very complex. The process of evaluating potential solutions against specific requirements and building a plan for preserving a given set of objects is called preservation planning. So far, it is a mainly manual, sometimes ad-hoc process with little or no tool support. This paper presents a service-oriented architecture and decision support tool that implements a solid preservation planning process and integrates services for content characterisation, preservation action and automatic object comparison to provide maximum support for preservation planning endeavours. Copyright 2008 ACM.",16,,2-s2.0-57649213525,Conference Proceeding,2008-12-22,10.1145/1378889.1378954,370,9781595939982,,367-370,Proceedings of the ACM International Conference on Digital Libraries,367,http://api.elsevier.com/content/abstract/scopus_id/57649213525,,57649213525,62702,p,Plato: A service oriented decision support system for preservation planning
"The Web is increasingly the medium by which information is published today, but due to its ephemeral nature, web pages and sometimes entire websites are often ""lost"" due to server crashes, viruses, hackers, run-ins with the law, bankruptcy and loss of interest. When a website is lost and backups are unavailable, an individual or third party can use Warrick to recover the website from several search engine caches and web archives (the Web Infrastructure). In this short paper, we present Warrick usage data obtained from Brass, a queueing system for Warrick hosted at Old Dominion University and made available to the public for free. Over the last six months, 520 individuals have reconstructed more than 700 websites with 800K resources from the Web Infrastructure. Sixty-two percent of the static web pages were recovered, and 41% of all website resources were recovered. The Internet Archive was the largest contributor of recovered resources (78%). Copyright 2008 ACM.",2,,2-s2.0-57649219436,Conference Proceeding,2008-12-22,10.1145/1378889.1378955,374,9781595939982,,371-374,Proceedings of the ACM International Conference on Digital Libraries,371,http://api.elsevier.com/content/abstract/scopus_id/57649219436,,57649219436,62702,p,Usage analysis of a public website reconstruction tool
"We discuss the use of web metrics at four digital libraries, the Instructional Architect, the Library of Congress, the National Science Digital Library, and WGBH Teachers' Domain. We describe practical issues involved in implementing and using web metrics to track web site performance. We also report on the focused data mining of web metrics. Using session length as our example, we recommend that this metric, which was developed to track e-commerce, be reconsidered when applied in non-e-commerce settings, such as digital libraries. We conclude by discussing some of the limitations and possibilities in using web metrics to analyze and evaluate digital library use and impact. Copyright 2008 ACM.",27,,2-s2.0-57649223724,Conference Proceeding,2008-12-22,10.1145/1378889.1378956,384,9781595939982,,375-384,Proceedings of the ACM International Conference on Digital Libraries,375,http://api.elsevier.com/content/abstract/scopus_id/57649223724,,57649223724,62702,p,Using Web metrics to analyze digital libraries
"We describe a Web-based metadata quality tool that provides statistical descriptions and visualisations of Dublin Core metadata harvested via the OAI protocol. The lightweight nature of development allows it to be used to gather contextualized requirements and some initial user feedback, is discussed. Copyright 2008 ACM.",12,,2-s2.0-57649210176,Conference Proceeding,2008-12-22,10.1145/1378889.1378957,388,9781595939982,,385-388,Proceedings of the ACM International Conference on Digital Libraries,385,http://api.elsevier.com/content/abstract/scopus_id/57649210176,,57649210176,62702,p,A lightweight metadata quality tool
"This paper investigates novel interactions for supporting withindocument navigation. We focus on one specific interaction: the following of figure references. Through this interaction we illuminate factors also found in other forms of navigation. Three alternative interactions for supporting figure navigation are described and evaluated through a user study. Experimentation proves the advantages of our interaction design, and the degree to which the interaction of existing reader software can be improved. Copyright 2008 ACM.",9,,2-s2.0-57649165542,Conference Proceeding,2008-12-22,10.1145/1378889.1378959,392,9781595939982,,389-392,Proceedings of the ACM International Conference on Digital Libraries,389,http://api.elsevier.com/content/abstract/scopus_id/57649165542,,57649165542,62702,p,Improving navigation interaction in digital documents
"We describe a novel interface by which a user can browse, bookmark and retrieve previously used working environments, i.e., desktop status, enabling the retention of the history of use of various sets of information. Significant tasks often require reuse of (sets of) information that was used earlier. Particularly, if a task involves extended interaction, then the task's environment has been through a lot of changes and can get complex. Under the current prevailing desktop-based computing environment, after an interruption to the task users can gain little assistance to get back to the context that they previously worked on. A user thus encounters increased discontinuity in continuing extended tasks. Copyright 2008 ACM.",7,,2-s2.0-57649213519,Conference Proceeding,2008-12-22,10.1145/1378889.1378960,396,9781595939982,,393-396,Proceedings of the ACM International Conference on Digital Libraries,393,http://api.elsevier.com/content/abstract/scopus_id/57649213519,,57649213519,62702,p,Keeping narratives of a desktop to enhance continuity of on-going tasks
"Our research develops note-taking applications for educational environments. Previous studies found that while copy-pasting notes can be more efficient than typing, for some users it reduces attention and learning. This paper presents two studies aimed at designing and evaluating interfaces that encourage focusing. While we were able to produce interfaces that increased desirable behaviors and improved satisfaction, the new interfaces did not improve learning. We suggest design recommendations derived from these studies, and describe a ""selecting-to-read"" behavior we encountered, which has implications for the design of reading and note-taking applications. Copyright 2008 ACM.",2,,2-s2.0-57649155184,Conference Proceeding,2008-12-22,10.1145/1378889.1378961,406,9781595939982,,397-406,Proceedings of the ACM International Conference on Digital Libraries,397,http://api.elsevier.com/content/abstract/scopus_id/57649155184,,57649155184,62702,p,"Note-taking, selecting, and choice: Designing interfaces that encourage smaller selections"
"The Fedora content management system embodies a powerful and flexible digital object model. This paper describes a new open-source software front-end that enables end-user librarians to transfer documents and metadata in a variety of formats into a Fedora repository. The main graphical facility that Fedora itself provides for this task operates on one document at a time and is not librarian-friendly. A batch driven alternative is possible, but requires documents to be converted beforehand into the XML format used by the repository, necessitating a need for programming skills. In contrast, our new scheme allows arbitrary collections of documents residing on the user's computer (or the web at large) to be ingested into a Fedora repository in one operation, without a need for programming expertise. Provision is also made for editing existing documents and metadata, and adding new ones. The documents can be in a wide variety of different formats, and the user interface is suitable for practicing librarians. The design capitalizes on our experience in building the Greenstone librarian interface and participating in dozens of workshops with librarians worldwide. Copyright 2008 ACM.",4,,2-s2.0-57649171098,Conference Proceeding,2008-12-22,10.1145/1378889.1378962,416,9781595939982,,407-416,Proceedings of the ACM International Conference on Digital Libraries,407,http://api.elsevier.com/content/abstract/scopus_id/57649171098,,57649171098,62702,p,A fedora librarian interface
"This demonstration presents a digital library for educators at all levels to easily identify, select, and use educational resources that have been shown through research to be effective for increasing the participation of women and under-represented minorities in information technology. The library consists of practices from the Broadening Participation in Computing (BPC) program in NSF CISE and elsewhere that have been researched or evaluated for their promise or effectiveness to recruit, retain, or advance underrepresented groups in IT fields of study or research careers. We do not develop the practices, but instead describe them and make them easy for users to find and evaluate in a central location.",1,,2-s2.0-57649198451,Conference Proceeding,2008-12-22,10.1145/1378889.1378964,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,417,http://api.elsevier.com/content/abstract/scopus_id/57649198451,,57649198451,62702,p,Broadening participation in computing with the K-gray engineering pathway digital library
"The open source digital library software Greenstone is demonstrated running on an iPod. The standalone configuration supports browsing, searching and displaying documents in a range of media formats. Plugged in to a host computer (Mac, Linux, or Windows), the exact same facilities are made available to the world through a built-in web server.",3,,2-s2.0-57649155185,Conference Proceeding,2008-12-22,10.1145/1378889.1378966,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,419,http://api.elsevier.com/content/abstract/scopus_id/57649155185,,57649155185,62702,p,Running greenstone on an iPod
"The Relation Browser (RB) is a tool developed by the Interaction Design Lab at the University of North Carolina at Chapel Hill for understanding relationships between items in a collection and for exploring an information space (e.g., a set of documents or webpages). The RB has been through a number of major design revisions. At JCDL 2007, we reported on two studies of information seeking that we conducted using the RB++ version of the Relation Browser software. Based on the results of those studies, we developed a set of design changes and implemented these in a new version called RB07. We will demonstrate the new RB07 interface and describe the rationale for our design changes.",26,,2-s2.0-57649155183,Conference Proceeding,2008-12-22,10.1145/1378889.1378967,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,420,http://api.elsevier.com/content/abstract/scopus_id/57649155183,,57649155183,62702,p,The relation browser tool for faceted exploratory search
"We would like to demonstrate a machine-learning based semantic markup system that may be used to reformat free-text biodiversity documents in XML format for digital libraries. We named the system MARTT II. It is built on the MARTT engine described in [1], but with new components for example a parallel markup engine using the unsupervised learning algorithm described in [2]. The double Is in the name stand for Intuitive Interaction, which is our goal to make the system truly easy to use. They also mean the system supports two different automated markup engines, allowing the use to choose either one to use and make comparisons between the two.",1,,2-s2.0-57649194921,Conference Proceeding,2008-12-22,10.1145/1378889.1378968,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,421,http://api.elsevier.com/content/abstract/scopus_id/57649194921,,57649194921,62702,p,An application for semantic markup of biodiversity documents
This paper outlines a dynamic classification explorer for music digital library users and researchers. System provides multiple simultaneous classification visualizations and synchronized audio.,2,,2-s2.0-57649198450,Conference Proceeding,2008-12-22,10.1145/1378889.1378969,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,422,http://api.elsevier.com/content/abstract/scopus_id/57649198450,,57649198450,62702,p,Dynamic classification explorer for music digital libraries
This paper introduces the CARDINAL (Computer Assisted Recognition and Discovery in Natural Acoustic Landscapes) interface system for use in Bioacoustic Digital Libraries (BADL).,1,,2-s2.0-57649233049,Conference Proceeding,2008-12-22,10.1145/1378889.1378970,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,423,http://api.elsevier.com/content/abstract/scopus_id/57649233049,,57649233049,62702,p,Novel interface services for Bioacoustic Digital Libraries
"We describe the effort of designing and developing a digital library system able to manage the different types of information resources produced during a large-scale evaluation campaign and to support the different stages of it. In this context, we present DIRECT, the system which has been adopted to manage the CLEF evaluation campaigns since 2005.",5,Association for Computing Machinery acmhelp@acm.org,2-s2.0-57649174624,Conference Proceeding,2008-01-01,10.1145/1378889.1378971,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,424,http://api.elsevier.com/content/abstract/scopus_id/57649174624,,57649174624,62702,p,DIRECT: Applying the DIKW hierarchy to large-scale evaluation campaigns
"In this paper, we describe a downloadable text-mining tool for enhancing subject access to image collections in digital libraries.",1,,2-s2.0-57649171095,Conference Proceeding,2008-12-22,10.1145/1378889.1378974,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,427,http://api.elsevier.com/content/abstract/scopus_id/57649171095,,57649171095,62702,p,Computational linguistics for metadata building
"Creating a concrete plan for preserving an institution's collection of digital objects requires the evaluation of available solutions against clearly defined and measurable criteria. Preservation planning aids in this decision making process to find the best preservation strategy considering the institution's requirements, the planning context and possible actions applicable to the objects contained in the repository. Performed manually, this evaluation of possible solutions against requirements takes a good deal of time and effort. In this demonstration, we present Plato, an interactive software tool aimed at creating preservation plans.",0,,2-s2.0-57649194920,Conference Proceeding,2008-12-22,10.1145/1378889.1378975,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,428,http://api.elsevier.com/content/abstract/scopus_id/57649194920,,57649194920,62702,p,Plato: A preservation planning tool
"InPhO is a system that combines statistical text processing, information extraction, human expert feedback, and logic programming to populate and extend a dynamic ontology for the field of philosophy. Integrated in the editorial workflow of the Stanford Encyclopedia of Philosophy (SEP), it will provide important metadata features such as automated generation of cross-references, semantic search, and ontology driven conceptual navigation.",0,,2-s2.0-57649148787,Conference Proceeding,2008-12-22,10.1145/1378889.1378976,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,429,http://api.elsevier.com/content/abstract/scopus_id/57649148787,,57649148787,62702,p,InPhO: A system for collaboratively populating and extending a dynamic ontology
"The VocalSearch system is a music search engine developed at Northwestern University and available on the internet (vocalsearch.org). This system lets the user query for the desired song in a number of ways: sung queries, queries entered as music notation, and text-based lyrics search. Users are also able to contribute songs to the system, making them searchable for future users. The result is a flexible system that lets the user find the song using their preferred modality (music notation, text, music notation). This demonstration lets users try out the VocalSearch system.",3,,2-s2.0-57649210175,Conference Proceeding,2008-12-22,10.1145/1378889.1378977,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,430,http://api.elsevier.com/content/abstract/scopus_id/57649210175,,57649210175,62702,p,The VocalSearch music search engine
"DIGMAP aims to become the main international resource discovery service for digitized old maps existing in libraries. The service reuses metadata from European national libraries and other relevant third party metadata sources. The gathered metadata is enhanced locally with geographical indexing and with record linking/clustering, leveraging on geographic gazetteers and authority files. When available, the images of the maps are also processed to extract potentially relevant features. This made it possible to develop a rich integrated environment for searching and browsing services with four perspectives: image's features, textual, geographic and temporal information.",4,,2-s2.0-57649143117,Conference Proceeding,2008-12-22,10.1145/1378889.1378978,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,431,http://api.elsevier.com/content/abstract/scopus_id/57649143117,,57649143117,62702,p,DIGMAP: A service for searching and browsing old maps
"We demonstrate ThemExplorer1, a mash-up for geographic image retrieval. The application combines: Geonames, a geographic thesaurus; TagMaps, a tool for visualizing tags on a map; PIRIA -a visual search engine, and pictures collected from Flickr and Google images. The user can query ThemExplorer using both keywords and example images.",0,,2-s2.0-57649223717,Conference Proceeding,2008-12-22,10.1145/1378889.1378979,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,432,http://api.elsevier.com/content/abstract/scopus_id/57649223717,,57649223717,62702,p,See the world with ThemExplorer
Our demonstration system consists of a set of tools for identifying life events in biographical texts and linking them to relevant contextual resources.,1,,2-s2.0-57649213516,Conference Proceeding,2008-12-22,10.1145/1378889.1378981,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,434,http://api.elsevier.com/content/abstract/scopus_id/57649213516,,57649213516,62702,p,Bringing lives to light: Lives and event representation in temporal and geographic context
"Focusing on the intersection of visual data mapping and virtual globe software, this application is part digital library and part analytical tool. It combines data sets into a collaborative database and visualizes the information through Google Earth overlays. This user-centered interface makes previously hard-to-use public information (e.g. census data) accessible and easily interpretable. We are presenting an interactive application named GeoDatum that allows users to upload their databases and display this information through a number of visualization tools, either individually or comparatively. The software is an open source web application with multiple goals. Primarily, it is a central repository for both geographic boundaries and the data related to those boundaries. In addition, it gives users the ability to create dynamic visualizations viewable in Google Earth's extensible KML environment, complete with full 3D renderings and animations. The trade-off is that anyone who wants to use the application to generate visualizations will leave their data for public use. The software's core functionality is to allow users to import their own Shapefiles as well as CSVs containing data about the geographic areas. Shapefiles are an industry standard GIS format supported by numerous software applications including ArcGIS. This software will convert this information into KML files and Google Earth overlays. While it can display publicly available data sets, it also allows a user to include their own information, We will present a case study done with the Brooklyn Public Library that utilizes this tool in the service of a project on urban planning and analysis. thus making it a useful internal analytic tool for private interests as well. We will present a case study done with the Brooklyn Public Library that utilizes this tool in the service of a project on urban planning and analysis.",2,,2-s2.0-57649174621,Conference Proceeding,2008-12-22,10.1145/1378889.1378982,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,435,http://api.elsevier.com/content/abstract/scopus_id/57649174621,,57649174621,62702,p,Data visualization applications in virtual globe software
"The large-scale digital repositories that are emerging today and expected to increase exponentially during this century will require information managers with the skills to archive, preserve, and organize massive amounts of data for use and re-use by a variety of interdisciplinary scholarly communities over time. Where will these managers come from, and what skills will they need? This workshop, organized by the US Institute of Museum and Library Services (IMLS) will address these questions through presentations and discussion among educators and other interested participants. IMLS has invested more than S100 million since 2003 in the education of librarians, archivists and data curators through both formal and continuing education programs. This timely funding has enabled graduate schools of library and information science to reshape their curricula to address the emerging need for digital data managers. Are we prepared to meet the challenge?",0,,2-s2.0-57649223715,Conference Proceeding,2008-12-22,10.1145/1378889.1378986,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,441,http://api.elsevier.com/content/abstract/scopus_id/57649223715,,57649223715,62702,p,"Education for digital stewardship: Librarians, archivists or curators?"
"In digital library search engines, ""no results found"" is a misleading phrase because it masquerades as a definitive answer; in reality, the collection being searched may in fact contain content that matches a user's query. This research examines the effect of null result sets on search behavior and on the perception of contents in digital libraries. In particular, this research supports the hypothesis that interface and design flaws have an effect on the perceived authority and credibility (here defined in terms of being authentic, factual, trustworthy, scholarly, and accurate) of the information being communicated by the interface in question. In short, interface design and the ""form"" of information (or, alternatively, the messenger) can negatively impact the perception of the quality of the ""content"" of information (the message).",0,,2-s2.0-57649178320,Conference Proceeding,2008-12-22,10.1145/1378889.1378988,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,443,http://api.elsevier.com/content/abstract/scopus_id/57649178320,,57649178320,62702,p,Interface effects on digital library credibility judgments
"This poster presents the architecture and user interface of a prototype service that was designed to allow end-users to explore the structure of science and perform assessments of scholarly impact on the basis of large-scale usage data. The underlying usage data set was constructed by the MESUR project which collected 1 billion usage events from a wide range of publishers, aggregators and institutional consortia.",1,,2-s2.0-57649219433,Conference Proceeding,2008-12-22,10.1145/1378889.1378989,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,444,http://api.elsevier.com/content/abstract/scopus_id/57649219433,,57649219433,62702,p,A ranking and exploration service based on large-scale usage data
"We pose the question: what if digital library objects could self-arrange without intervention from repositories and minimal intervention from administrators? We present background information about networks, techniques on how networks can be created based on locally discovered information, and how a small set of controlling policies can profoundly affect network configuration. This poster reflects a work in progress, providing information about the project's genesis, current status and future efforts.",3,,2-s2.0-57649187081,Conference Proceeding,2008-12-22,10.1145/1378889.1378990,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,445,http://api.elsevier.com/content/abstract/scopus_id/57649187081,,57649187081,62702,p,Self-arranging preservation networks
"The content of a tag sequence references both a user's concepts and the user's conceptualization of an information object. The tagging history of 823 users of the Delicious social tagging service is analyzed using WordNet Three semantic measures of the tagging content are developed: the level of category references, the changes in category level for each noun as the tagging sequence unfolds, and the scope of concept coverage as the compactness of the WordNet subgraph for the noun senses. Observed patterns of concept reference as a function of sequence position hint at dynamic properties of the tag production process by marking a trace of cognitive activity. If tagging is object categorization, these measures provide a view of the personal categorization behavior of non-professionals and illuminate biases in the production of 'folksonomies' due to tag production processes.",0,,2-s2.0-57649223714,Conference Proceeding,2008-12-22,10.1145/1378889.1378991,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,446,http://api.elsevier.com/content/abstract/scopus_id/57649223714,,57649223714,62702,p,Tagging semantics: Investigations with WordNet
"IsoveraDL is a digital library and peer review system. IsoveraDL allows you to upload and serve your learning resources along with associated record metadata in a very organized and dynamic way. IsoveraDL uses a resource publication workflow that models the existing off-line record management workflow in use by different AAAS BEN partners. In addition IsoveraDL also provides a Peer Review module which allows users to create and use dynamic Peer Review workflows. Using IsoveraDL, permitted users can upload records and metadata for Peer Reviewed by others. Metadata records can be validated by a different set of users before they are published. The record submission forms used in IsoveraDL for adding resources are highly customizable and administrative users have the option of setting up as many of these forms as required. The Controlled Vocabularies and metadata fields used in IsoveraDL conform to AAAS BEN Learning Object Metadata specification. Administrative users have the ability to edit or add to these vocabularies and fields if needed. Optionally, the IsoveraDL Peer Review module may be used in conjunction with IsoveraDL's record submission forms. If a record submission form is set up for Peer Review then all records submitted through the form are Peer Reviewed beforethey can be validated. Administrative users can create workflows, associated forms and reviewer groups for the Peer Review module. The Peer Review module also has a reporting interface through which administrative users can easily monitor the progress and workload of all records and users associated with the module. Once a record is validated and published, users are able to discover resources through IsoveraDL's search and browse functionality. Records published through IsoveraDL can be easily harvested to the AAAS BEN portal through the built-in Harvester module using OAI-PHM.",0,,2-s2.0-57649148784,Conference Proceeding,2008-12-22,10.1145/1378889.1378992,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,447,http://api.elsevier.com/content/abstract/scopus_id/57649148784,,57649148784,62702,p,Isovera digital library
"This poster will present an overview of metadata mappings needed to support access, collaboration, preservation and aggregation of museum content within and beyond a digital library context.",0,,2-s2.0-57649158630,Conference Proceeding,2008-12-22,10.1145/1378889.1378993,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,448,http://api.elsevier.com/content/abstract/scopus_id/57649158630,,57649158630,62702,p,Museum materials in a digital library context and beyond
"The OER Recommender (www.oerrecommender.org) is a web service that helps people find relevant open educational resources. It links the digital learning resources in the National Science Digital Library (NSDL) disciplinary pathways with courses in OpenCourseWare repositories thereby providing critical contextual information. When a person browses a web page in a participating NSDL Pathway or OpenCourseWare repository, the recommender annotates the page with a ""Recommended resources"" link. The poster will describe the motivations for the project, provide detail on the recommendation engine, display recommendations for participating collections, and describe how other collections can participate in the project.",0,,2-s2.0-57649155180,Conference Proceeding,2008-12-22,10.1145/1378889.1378994,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,449,http://api.elsevier.com/content/abstract/scopus_id/57649155180,,57649155180,62702,p,OER recommender: Linking NSDL pathways and OpenCourseWare repositories
This paper exploit the DIKW hierarchy as a framework for modelling the scientific data produced during large-scale evaluation campaigns for information retrieval systems in order to design a digital library system able to manage and support the course of such evaluation campaigns.,2,Association for Computing Machinery acmhelp@acm.org,2-s2.0-57649223713,Conference Proceeding,2008-01-01,10.1145/1378889.1378995,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,450,http://api.elsevier.com/content/abstract/scopus_id/57649223713,,57649223713,62702,p,The role of the DIKW hierarchy in the design of a digital library system for the scientific data of large-scale evaluation campaigns
"To support the user's on-screen reading, we propose a methodology to translate text into visual expressions. Our prototype system analyses the text and translates them into image and adds movement to the image.",0,,2-s2.0-57649217282,Conference Proceeding,2008-12-22,10.1145/1378889.1378996,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,451,http://api.elsevier.com/content/abstract/scopus_id/57649217282,,57649217282,62702,p,Translation of on-screen text into visual expressions
Maps in journal articles are difficult to access since they are rarely indexed apart from the articles themselves. Our prototype of a searchable map library was built by extracting maps and harvesting metadata from scanned articles to classify each map.,2,,2-s2.0-57649219432,Conference Proceeding,2008-12-22,10.1145/1378889.1378997,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,452,http://api.elsevier.com/content/abstract/scopus_id/57649219432,,57649219432,62702,p,Creating a searchable map library via data mining
"The scientific record and the documentary heritage are increasingly created in digital form. The UK based Digital Curation Centre supports institutions who store, manage and preserve such data to help ensure its enhancement and continuing long-term use. The DCC (Digital Curation Centre) Curation Lifecycle Model provides a generic graphical high-level overview of the stages required for successful curation and preservation of digital material from initial conceptualisation. The model can be used to plan curation and preservation activities, to ensure sustainability of repository content or other digital material, within an organisation or consortium. It will help to ensure that all necessary stages are undertaken, each in the correct sequence. The model enables granular functionality to be mapped against it to define roles and responsibilities, and build a framework of standards and technologies to implement. It can help with the process of identifying additional steps which may be required, or actions which are not required by certain situations or disciplines, and of ensuring that processes and policies are adequately documented. Digital Curation Centre staff developed the model before undertaking a period of public consultation, which was recently completed. The newly ratified model will is being used by the DCC to ensure that information, services and advisory material cover all areas of the lifecycle. Domain-specific variations of the model will be developed, with greater levels of granularity, to help ensure that advice and information are easily accessible from the website. One planned utilisation is the development of domain specific standards frameworks within the DCC DIFFUSE Standards Frameworks project, to help practitioners identify which standards they should be using and where they would be appropriately implemented. This poster will present the DCC Curation Lifecycle Model, incorporating the results of the public consultation period held during December 2007 to February 2008.",2,,2-s2.0-57649174620,Conference Proceeding,2008-12-22,10.1145/1378889.1378998,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,453,http://api.elsevier.com/content/abstract/scopus_id/57649174620,,57649174620,62702,p,The DCC curation lifecycle model
"While research into user-centered text retrieval is based on mature evaluation methodologies, user evaluation in multimedia retrieval is still in its infancy. User evaluations can be expensive and are also often non-repeatable. An alternative way of evaluating such systems is the use of simulations. In this poster, we present an evaluation methodology which is based on exploiting log files recorded from a user-study we conducted.",2,,2-s2.0-57649223712,Conference Proceeding,2008-12-22,10.1145/1378889.1378999,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,454,http://api.elsevier.com/content/abstract/scopus_id/57649223712,,57649223712,62702,p,Exploiting log files in video retrieval
"There are quite a few web archives around the world, such as Internet Archive and Web InfoMall (http://www.infomall.cn). Nevertheless, we have not seen substantial mechanism built on top of the archives to render the value of the data beyond what the Wayback machine offers. One of the reasons for this situation is the lack of a system vision and design which encompasses the oceanic data in a meaningful and cost-effective way. This paper describes an effort in this direction.",0,,2-s2.0-57649165537,Conference Proceeding,2008-12-22,10.1145/1378889.1379000,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,455,http://api.elsevier.com/content/abstract/scopus_id/57649165537,,57649165537,62702,p,Building a story tracer out of a web archive
"The democratization of content creation via ubiquitous Internet tools and infrastructure [1] has fueled an explosion of user-generated content in the commercial and educational markets. Indeed, funding agencies such as the National Science Foundation (NSF) are actively seeking ways to integrate teachers and learners into the education cyber-infrastructure, whereby they become co-creators of educational content [2]. The ease with which this content, often in the form of online learning resources of varying levels of granularity, can be created and disseminated places it outside the usual peer review processes employed by publishers and professional societies. To date, digital library (DL) developers, teachers and school administrators, concerned whether teachers are using peer-reviewed online learning resources, have depended on one or a combination of the following proxies to establish an imprimatur of quality: the reputation and oversight of a funding organization (e.g., NSF's peer review process), the credentials of the content creator (e.g., National Science Teachers Association) or the collection development policies of specific DLs (e.g., DLESE). Now more than ever, though, sites such as YouTube, Flickr and ccMixter and the evolving education cyber-infrastructure, have created an environment where user-generated content is beyond the reach of even these proxy review processes. However, in the omnipresent climate of accountability within K12 education at U.S. federal, state and local levels, education DLs are being challenged to identify the value: of the resources they hold and services they provide to users; and, of what their users create with those resources. For all of these reasons, it is useful, and necessary, to develop a standardized rubric and process to review online education resources. In particular, this work should leverage social and technical networks to enrich, facilitate, and automate the review process. The Digital Libraries go to School project was funded by NSF in 2006 to develop a professional development workshop curriculum that enables teachers to use the Instructional Architect (IA; http://ia.usu.edu) to design their own learning activities for classrooms using online STEM resources from the National Science Digital Library (NSDL.org) and the wider Web. One component of the project is to examine the criteria and approaches for reviewing the quality of teacher-created online learning resources in order to develop a rubric and workflow process. Work to date includes conducting focus groups and surveys with teachers and a 5-person Expert Review Committee, complemented by a literature review to identify elements for a review rubric incorporating the work of other education DLs (e.g., DLESE, MERLOT, NEEDS, among others). Findings are being synthesized, and based on analysis, a draft list of elements has been identified for further testing in Spring 2008. At the same time, a workflow process for conducting reviews with teacher-created resources will be piloted. It will combine human-generated reviews with machine-generated information about online resources (e.g., image and word count; educational standards alignment; currency of updates, provenance) [3]. Further work will identify areas for improving the review rubric and scaling and standardizing the workflow process for Fall 2008. We will also evaluate the usefulness of the reviews to teachers, and to stakeholders such as the IA, NSDL, NSF and other DLs, in providing access to high-quality online content.",2,,2-s2.0-57649174618,Conference Proceeding,2008-12-22,10.1145/1378889.1379002,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,457,http://api.elsevier.com/content/abstract/scopus_id/57649174618,,57649174618,62702,p,Developing a review process for online resources
"Our poster presents recent results from an ongoing research project entitled ""Mechanisms of atomic services for distributed digital libraries"".",6,,2-s2.0-57649223709,Conference Proceeding,2008-12-22,10.1145/1378889.1379003,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,458,http://api.elsevier.com/content/abstract/scopus_id/57649223709,,57649223709,62702,p,Building federation of digital libraries basing on concept of atomic services
"This poster presentation will reflect qualitatively on the challenges and opportunities of PocketKnowledge (http://pocketknowledge.tc.columbia.edu/home. php) as an institutional repository. The main question explored is whether such repositories are best understood as new competitors in the academic publishing world or as on-going documentations of the larger intellectual life of the institution. The early experience of one such repository, PocketKnowledge - a social archive developed and implemented by EdLab, a research unit of the Gottesman Libraries, Teachers College Columbia University - reveals that users are motivated not only to participate in an institutional repository, but also to document their intellectual life understood more broadly than publication. This suggests that the latter understanding of an institutional repository is a more reasonable, incremental expectation in what is surely an uphill battle against the long-established prestige of publishing in printed academic journals, and that institutional repositories such as PocketKnowledge should consider the strategic addition of functionalities that can highlight the intellectual life of the institution, not simply the intellectual production of its members.",1,,2-s2.0-57649221130,Conference Proceeding,2008-12-22,10.1145/1378889.1379004,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,459,http://api.elsevier.com/content/abstract/scopus_id/57649221130,,57649221130,62702,p,Early returns on an institutional repository: An exploration of the validity and functionality of pocketknowledge
Millions of scientific articles are accessible freely on the web. While some of them are stored in institutional repositories many are made available on personal pages which are exposed to the net's transience. We found that nearly 11% of URLs of PDF documents containing references to life science publications were not accessible within 5 months after being harvested using a search engine's (SE) API. For most of them (8.4%) no SE cache backup could be found. Although we have yet to estimate the exact rate at which the scientific literature disappears and the duration of its disappearance the results so far are a clear indicator that web harvesting is needed to preserve the online scientific literature.,4,,2-s2.0-57649155178,Conference Proceeding,2008-12-22,10.1145/1378889.1379005,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,460,http://api.elsevier.com/content/abstract/scopus_id/57649155178,,57649155178,62702,p,Harvesting needed to maintain scientific literature online
"We describe a Knowledge Management System that shifts the focus from the traditional document-centric to a user-centric view. It takes into account users' query and down-load behavior, opinions, reputations, and social connections.",0,,2-s2.0-57649198448,Conference Proceeding,2008-12-22,10.1145/1378889.1379008,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,463,http://api.elsevier.com/content/abstract/scopus_id/57649198448,,57649198448,62702,p,Considering users and their opinions in Knowledge Management Systems
Formalizing collection-level/item-level metadata relationships encounters the problem of trivial satisfaction. We offer a solution related to current work in IR and ontology evaluation.,2,,2-s2.0-57649194917,Conference Proceeding,2008-12-22,10.1145/1378889.1379009,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,464,http://api.elsevier.com/content/abstract/scopus_id/57649194917,,57649194917,62702,p,The return of the trivial: Problems formalizing collection/item metadata relationships
"In late 2006, NITLE launched a pilot program for managed institutional repository services designed for smaller colleges and universities and the non-profit organizations that serve them. Twenty-six participating institutions helped pioneer this pilot effort, which laid the foundation for the development of production-level DSpace Services. These DSpace Services allowed campuses to start and grow their digital repositories with a minimal level of investment, with no hardware to purchase and very little application support expertise to develop. Campuses were able to focus on the work of building digital repositories within the context of a community of campuses sharing ideas and best practices. Lessons learned and next steps will be discussed.",0,,2-s2.0-57649143116,Conference Proceeding,2008-12-22,10.1145/1378889.1379010,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,465,http://api.elsevier.com/content/abstract/scopus_id/57649143116,,57649143116,62702,p,The DSpace repository: Can multiple institutions live in one space-a different approach
"This poster describes online access to a unique collection of Department of Energy (DOE) Research and Development (R&D) accomplishments. The collection features research of DOE and its predecessor agencies, the Energy Research and Development Administration (ERDA) and the Atomic Energy Commission (AEC). This special collection contains historically significant government documents, including items from the Manhattan Project era, that have been specially selected and digitized to make them accessible via the Web. Landmark documents in the collection include The Eightfold Wav: A Theory of Strong Interaction Symmetry (authored by Nobel prize winner Murray Gell-Mann) and The First Weighing of Plutonium (authored by Nobel prize winner Glenn Seaborg). In addition to a database of approximately 250 specially-selected documents, all related aspects of the collection (documents, research areas, and/or Nobel Laureate information) are combined in Feature Topic pages for the added value of a single point of access to each compilation. Over sixty (60) Feature Topic pages include diverse topics such as ""Video Games - Did They Begin at Brookhaven?"" and ""Human Genome Research: Decoding DNA"". This collection features a large number of DOE-associated Nobel Laureates, including Enrico Fermi, winner of the 1938 Nobel prize in physics, and George Smoot, winner of the 2006 Nobel prize in physics, and showcases a diversity in DOE research areas, including solar energy (with related educational materials) and Radioisotope Thermoelectric Generators (RTGs) that are used to power spacecraft. Easy access to this unique collection is provided via DOE R&D Accomplishments at http://www.osti.gov/accomplishments. This special collection is continually growing, with additional Nobel Laureate and/or research topic documents and features being added on a regular basis.",0,,2-s2.0-57649210172,Conference Proceeding,2008-12-22,10.1145/1378889.1379011,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,466,http://api.elsevier.com/content/abstract/scopus_id/57649210172,,57649210172,62702,p,A unique insight into department of energy research accomplishments: A special collection
"Many libraries have recently been devoting significant efforts to modernizing their library catalog web interfaces. One popular approach is to create a faceted search interface to the library catalog. Faceted search interfaces can be complex, requiring designers to make many decisions about the placement and display of faceted search design elements on the page. Unfortunately little empirical research exists on how to optimize faceted search interfaces for library catalogs. To facilitate research in this area, the NCSU Libraries has developed the NCSU Catalog Research Testbed, a tool for developing and evaluating faceted library catalog interfaces.",1,,2-s2.0-57649223707,Conference Proceeding,2008-12-22,10.1145/1378889.1379012,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,467,http://api.elsevier.com/content/abstract/scopus_id/57649223707,,57649223707,62702,p,The NCSU catalog research testbed: A tool for evaluating faceted library catalog interfaces
"The ACM society for computing and professionals provides a digital library whose Computer Classification System (CCS) is based on a taxonomy that has been continuously updated over the years. The CiteSeer digital library contains a large collection of computer science research papers, many of which are tagged with categories from the CCS taxonomy. By analyzing CiteSeer's tagged documents and by considering different time frames, we extracted statistics that shows how the CCS taxonomy covers the publications in computer and information science research subfields. We also studied size and growth of categories over the last four available years. We believe that the identification of such trends within taxonomies would greatly help to improve the structure of classification systems and would help the construction of more efficient browsing and searching systems.",0,,2-s2.0-57649174617,Conference Proceeding,2008-12-22,10.1145/1378889.1379013,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,468,http://api.elsevier.com/content/abstract/scopus_id/57649174617,,57649174617,62702,p,Computer classification system usage in citeseer
This paper describes the architecture of an Information Quality Evaluation Workbench for rapid design and operationalization of information quality assessment models.,3,,2-s2.0-57649217280,Conference Proceeding,2008-12-22,10.1145/1378889.1379014,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,469,http://api.elsevier.com/content/abstract/scopus_id/57649217280,,57649217280,62702,p,A workbench for information quality evaluation
"Specific morphological information is often used by users to search botanical collections. However, traditional systems based on statistical models are often not effective for such search. This study automatically extracts morphological information from botanical collections using an adapted and enhanced information extraction system. Experimental results indicate this approach is promising. This study also indicates that this approach is generalizable to similar collections in the same domain and even to different domains with adaptation of the pattern recognition and knowledge base in the new domain.",0,,2-s2.0-57649178317,Conference Proceeding,2008-12-22,10.1145/1378889.1379015,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,470,http://api.elsevier.com/content/abstract/scopus_id/57649178317,,57649178317,62702,p,Automatic extraction of morphological information from botanical collections
"Bibliographic metadata plays a key role in scientific literature, not only to summarise and establish the facts of the publication record, but also to track citations between publications and hence to establish the impact of individual articles within the literature. Commercial secondary publishers have typically taken on the role of rekeying, mining and analysing this huge corpus of linked data, but as the primary literature has moved to the world of the digital repository, this task is now undertaken by new services such as Citeseer, Citebase or Google Scholar. As institutional and subject-based repositories proliferate and Open Access mandates increase, more of the literature will become openly available in well managed data islands containing a much greater amount of detailed bibliometric metadata in formats such as RDF. Through the use of efficient extraction and inference techniques, complex relations between data items can be established. In this paper we explain the importance of the co-relation in enabling new techniques to rate the impact of a paper or author within a large corpus of publications.",1,,2-s2.0-57649221129,Conference Proceeding,2008-12-22,10.1145/1378889.1379016,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,471,http://api.elsevier.com/content/abstract/scopus_id/57649221129,,57649221129,62702,p,Releasing the power of digital metadata: Examining large networks of co-related publications
"The recent increase of online video has challenged the research in the field of video information retrieval. Video search engines are becoming more and more interactive, helping the user to easily find what he or she is looking for. In this poster, we present a new approach of using an iterative clustering algorithm on text and visual features to simulate users creating new facets in a facet-based interface. Our experimental results prove the usefulness of such an approach.",1,,2-s2.0-57649233045,Conference Proceeding,2008-12-22,10.1145/1378889.1379017,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,472,http://api.elsevier.com/content/abstract/scopus_id/57649233045,,57649233045,62702,p,A cluster-based simulation of facet-based search
"The H.W. Odum Institute for Research in Social Science (Odum), the Renaissance Computing Institute (RENCI), and the School of Information and Library Science (SILS), all part of the University of North Carolina at Chapel Hill (UNC-CH), are collaborating with the San Diego Supercomputer Center (SDSC) on an extension of the National Archives and Records Administration's (NARA) transcontinental persistent archive prototype (TPAP) data grid with the new integrated Rule Oriented Data System (iRODS). The goal of the project is to enable collection interoperability between UNC-CH and SDSC using an iRODS environment. This poster presents the results of one part of that project, which is the development of a crosswalk between the Odum Institute Data Archive (OIDA) Data Document Initiative (DDI) metadata and the NARA TPAP iRODS metadata catalogue (iCAT) via the OAI-PMH.",0,,2-s2.0-57649194916,Conference Proceeding,2008-12-22,10.1145/1378889.1379018,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,473,http://api.elsevier.com/content/abstract/scopus_id/57649194916,,57649194916,62702,p,Integrating DDI metadata into the NARA transcontinental persistent archive prototype via the OAI-PMH
"This poster describes a nascent ethnographic study to examine working scientists' attitudes and perform a needs assessment regarding data collection, representation, and dissemination in terms of cyberinfrastructure initiatives.",0,,2-s2.0-57649178316,Conference Proceeding,2008-12-22,10.1145/1378889.1379019,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,474,http://api.elsevier.com/content/abstract/scopus_id/57649178316,,57649178316,62702,p,The working scientist and the realities of data curation: A qualitative study addressing attitudes and needs
"This poster will present a formal ontology of temporal entities for knowledge sharing and interoperability. This ontology captures the semantic intensions, attributes and properties of temporal entities and their relationships. And it has been applied into temporal knowledge acquisition from un-annotated Chinese texts.",0,,2-s2.0-57649217278,Conference Proceeding,2008-12-22,10.1145/1378889.1379021,,9781595939982,,,Proceedings of the ACM International Conference on Digital Libraries,476,http://api.elsevier.com/content/abstract/scopus_id/57649217278,,57649217278,62702,p,A formal ontology for temporal entities and its application in knowledge extraction
"A three-part study of teachers' use of online resources and of the Digital Library for Earth System Education (DLESE) was conducted from 2004 through summer 2006. The first two phases were qualitative and informed a survey administered to 622 science teachers across the U.S., one-fifth of whom had used DLESE. The findings present a profile of teachers and their access to Internet-connected computers and other hardware/electronic media devices in their classrooms; and teachers' preferences for resource formats (e.g., customizability) and educational web site features (e.g., tagged reading level). Analysis of variance showed that teachers with more than one working computer and teachers with more other devices valued the Internet more highly for teaching than did their less equipped peers. DLESE users valued the Internet more highly for their teaching, had more years teaching experience, and valued customizable resources more than their non-DLESE using peers. Most believed that resources catalogued in DLESE were scientifically accurate. Teachers used DLESE most often for finding hands-on activities, still images and other visual aids, and hand-outs; they were least likely to seek people, games, or assessment tools. The findings provide guidance for developers of K12 educational resources. Copyright 2009 ACM.",9,,2-s2.0-70450233447,Conference Proceeding,2009-11-30,10.1145/1555400.1555402,10,9781605586977,15525996,1-10,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,1,http://api.elsevier.com/content/abstract/scopus_id/70450233447,,70450233447,145752,p,Science teachers' use of online resources and the digital library for earth system education
"Enhancing the experience of digital library users depends, in part, on recognizing and understanding user tasks. In the context of K-12 educational libraries this means that we must understand how K-12 teachers interact with such libraries and how they assess the relevance of documents found or encountered. This paper presents the results of an experiment in which K-12 teachers scored the relevance of curriculum they found themselves and the relevance of documents their colleagues found and recommended. We found that teachers apply a significantly more detailed notion of relevance, both qualitatively and quantitatively, when searching for as compared to evaluating recommended curricula. Differences were observed in both relevance judgments and system interaction logs. These variations may be useful in identifying user intent and in dynamically adapting the behavior of digital libraries of educational material. Copyright 2009 ACM.",2,,2-s2.0-70450275849,Conference Proceeding,2009-11-30,10.1145/1555400.1555403,14,9781605586977,15525996,11-14,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,11,http://api.elsevier.com/content/abstract/scopus_id/70450275849,,70450275849,145752,p,Dimensional standard alignment in K-12 digital libraries: Assessment of self-found vs. recommended curriculum
"The problem of information fragmentation is especially acute for today's college students who manage and assimilate information in various forms while completing many of their academic tasks, and who must do so within the confines of standard software applications. The goal of this research is to provide students with a novel information assimilation and notetaking tool that helps them more efficiently manage their electronic information and overcome some of the fragmentation challenges they routinely experience. Our Global Information Gatherer prototype allows students to view, edit and store files of different types from within a single interface, and provides an integrated web browser and notetaking functionality. Copyright 2009 ACM.",3,,2-s2.0-70450253126,Conference Proceeding,2009-11-30,10.1145/1555400.1555404,18,9781605586977,15525996,15-18,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,15,http://api.elsevier.com/content/abstract/scopus_id/70450253126,,70450253126,145752,p,"Helping Students with information fragmentation, assimilation and notetaking"
"Recent years have seen the rise of subject-themed digital libraries, such as the NSDL pathways and the Digital Library for Earth System Education (DLESE). These libraries often need to manually verify that contributed resources cover top- ics that fit within the theme of the library. We show that such scope judgments can be automated using a combination of text classification techniques and topic modeling. Our models address two significant challenges in making scope judgments: only a small number of out-of-scope resources are typically available, and the topic distinctions required for digital libraries are much more subtle than classic text classification problems. To meet these challenges, our mod- els combine support vector machine learners optimized to diffierent performance metrics and semantic topics induced by unsupervised statistical topic models. Our best model\ is able to distinguish resources that belong in DLESE from resources that don't with an accuracy of around 70%. We see these models as the first steps towards increasing the scalability of digital libraries and dramatically reducing the workload required to maintain them. Copyright 2009 ACM.",2,,2-s2.0-70450246954,Conference Proceeding,2009-11-30,10.1145/1555400.1555405,28,9781605586977,15525996,19-28,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,19,http://api.elsevier.com/content/abstract/scopus_id/70450246954,,70450246954,145752,p,Topic model methods for automatically identifying out-of-scope resources
"A major challenge for content management in intranets and other large scale document storage and retrieval services is the generation of high quality metadata. Manual generation of metadata is resource demanding and is often viewed by collection managers and document authors as inefficient use of their time, and there is a desire for other ways to create the needed metadata. Automatic Metadata Generation (AMG) is methods for generating metadata without manual interaction using computer program(s) to interpret the document and possibly the document context. Current AMG research has been limited to collection of similarly formatted documents. The research presented in this paper expands the field of AMG by presenting an approach that is independent of a common visualization scheme; AMG based on document code analysis. This is done by showing AMG possibilities from Latex, Word and PowerPoint documents and how this approach can significantly increase the quality of the generated metadata. This by avoiding common quality reducing factors as missing completeness, low accuracy, logical consistency and coherence and timeliness by giving AMG algorithms direct access to the user specified intellectual content and the file formatting. This research shows how this AMG approach can be combined with other AMG approaches, drawing on their strengths in order to achieve the desired high quality metadata entities. Copyright 2009 ACM.",4,,2-s2.0-70450246955,Conference Proceeding,2009-11-30,10.1145/1555400.1555406,38,9781605586977,15525996,29-38,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,29,http://api.elsevier.com/content/abstract/scopus_id/70450246955,,70450246955,145752,p,Automatically generating high quality metadata by analyzing the document code of common file types
"Users of digital libraries usually want to know the exact author or authors of an article. But different authors may share the same names, either as full names or as initials and last names (complete name change examples are not considered here). In such a case, the user would like the digital library to differentiate among these authors. Name disambiguation can help in many cases; one being a user in a search of all articles written by a particular author. Disambiguation also enables better bibliometric analysis by allowing a more accurate counting and grouping of publications and citations. In this paper, we describe an algorithm for pairwise disambiguation of author names based on a machine learning classification algorithm, random forests. We define a set of similarity profile features to assist in author disambiguation. Our experiments on the Medline database show that the random forest model outperforms other previously proposed techniques such as those using support-vector machines (SVM). In addition, we demonstrate that the variable importance produced by the random forest model can be used in feature selection with little degradation in the disambiguation accuracy. In particular, the inverse document frequency of author last name and the middle name's similarity alone achieves an accuracy of almost 90%. Copyright 2009 ACM.",75,,2-s2.0-70450273106,Conference Proceeding,2009-11-30,10.1145/1555400.1555408,48,9781605586977,15525996,39-48,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,39,http://api.elsevier.com/content/abstract/scopus_id/70450273106,,70450273106,145752,p,Disambiguating authors in academic publications using random forests
"In digital libraries, ambiguous author names may occur due to the existence of multiple authors with the same name (polysemes) or different name variations for the same author (synonyms). We proposed here a new method that uses information available on the Web to deal with both problems at the same time. Our idea consists of gathering information from input citations and submitting queries to a Web search engine, aiming at finding curricula vitae and Web pages containing publications of the ambiguous authors. From the content of documents in the answer sets returned by the Web search engine, useful information that can help in the disambiguation process is extracted. Using this information, author names are disambiguated by leveraging a hierarchical clustering method that groups citations in the same document together in a bottom-up fashion. Experimental results show that the our method yields results that outperform those of two state-of-the-art unsupervised methods and are statistically comparable with those of a supervised one, but requiring no training. We observe gains of up to 65.2% in the pairwise F1 metric when compared with our best unsupervised baseline method. Copyright 2009 ACM.",52,,2-s2.0-70450250024,Conference Proceeding,2009-11-30,10.1145/1555400.1555409,58,9781605586977,15525996,49-58,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,49,http://api.elsevier.com/content/abstract/scopus_id/70450250024,,70450250024,145752,p,Using web information for author name disambiguation
"The amount of scientific material available electronically is forever increasing. This makes reading the published litera- ture, whether to stay up-to-date on a topic or to get up to speed on a new topic, a dificult task. Yet, this is an activity in which all researchers must be engaged on a regular basis. Based on a user requirements analysis, we developed a new research tool, called the Citation-Sensitive In-Browser Sum- mariser (CSIBS), which supports researchers in this brows- ing task. CSIBS enables readers to obtain information about a citation at the point at which they encounter it. This infor- mation is aimed at enabling the reader to determine whether or not to invest the time in exploring the cited article fur- ther, thus alleviating information overload. CSIBS builds a summary of the cited document, bringing together meta- data about the document and a citation-sensitive preview that exploits the citation context to retrieve the sentences from the cited document that are relevant at this point. This paper brie y presents our user requirements analysis, then describes the system and, finally, discusses the observations from an initial pilot study. We found that CSIBS facilitates the relevancy judgment task, by increasing the users' self-reported confidence in making such judgements. Copyright 2009 ACM.",10,,2-s2.0-70450245161,Conference Proceeding,2009-11-30,10.1145/1555400.1555410,68,9781605586977,15525996,59-68,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,59,http://api.elsevier.com/content/abstract/scopus_id/70450245161,,70450245161,145752,p,Whetting the appetite of scientists: Producing summaries tailored to the citation context
We propose a generative model based on latent Dirichlet allocation for mining distinct topics in document collections by integrating the temporal ordering of documents into the generative process. The document collection is divided into time segments where the discovered topics in each segment is propagated to influence the topic discovery in the subsequent time segments. We conduct experiments on the collection of academic papers from CiteSeer repository. We augment the text corpus with the addition of user queries and tags and integrate the citation graph to boost the weight of the topical terms. The experiment results show that segmented topic model can effectively detect distinct topics and their evolution over time. Copyright 2009 ACM.,15,,2-s2.0-70450267410,Conference Proceeding,2009-11-30,10.1145/1555400.1555411,72,9781605586977,15525996,69-72,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,69,http://api.elsevier.com/content/abstract/scopus_id/70450267410,,70450267410,145752,p,Finding topic trends in digital libraries
"Bibliographic information is essential for many digital library applications, such as citation analysis, academic searching and topic discovery. And bibliographic data extraction has attracted a great deal of attention in recent years. In this paper, we address the problem of automatic extraction of bibliographic data in Chinese electronic book and propose a tool called CEBBIP* for the task, which includes three main systems: data preprocessing, data parsing and data postprocessing. In the data preprocessing system, the tool adopts a rules-based method to locate citation data in a book and to segment citation data into citation strings of individual referencing literature. And a learning-based approach, Conditional Random Fields (CRF), is employed to parse citation strings in the data parsing system. Finally, the tool takes advantage of document intrinsic local format consistency to enhance citation data segmentation and parsing through clustering techniques. CEBBIP has been used in a commercial E-book production system. Experimental results show that CEBBIP's precision rate is very high. More specially, adopting the document intrinsic local format consistency obviously improves the citation data segmenting and parsing accuracy. Copyright 2009 ACM.",7,,2-s2.0-70450240713,Conference Proceeding,2009-11-30,10.1145/1555400.1555412,76,9781605586977,15525996,73-76,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,73,http://api.elsevier.com/content/abstract/scopus_id/70450240713,,70450240713,145752,p,CEBBIP: A parser of bibliographic information in chinese electronic books
"Video is increasingly important to digital libraries and archives as both primary content and as context for the primary objects in collections. Services like YouTube not only offer large numbers of videos but also usage data such as comments and ratings that may help curators today make selections and aid future generations to interpret those selections. A query-based harvesting strategy is presented and results from daily harvests for six topics defined by 145 queries over a 20-month period are discussed with respect to, query specification parameters, topic, and contribution patterns. The limitations of the strategy and these data are considered and suggestions are offered for curators who wish to use query-based harvesting. Copyright 2009 ACM.",4,,2-s2.0-70450255044,Conference Proceeding,2009-11-30,10.1145/1555400.1555414,86,9781605586977,15525996,77-86,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,77,http://api.elsevier.com/content/abstract/scopus_id/70450255044,,70450255044,145752,p,Query parameters for harvesting digital video and associated contextual information
"In this paper, we present ViGOR (Video Grouping, Organisation and Retrieval) a video retrieval system that allows users to group videos in order to facilitate video retrieval tasks. In this way users are able to visualise and conceptualise many aspects of their search tasks and carry out a localised search in order to solve a more global search problem. The main objective of this work is to aid users while carrying out explorative video retrieval tasks; these tasks can be often ambiguous and multi-faceted. Two user evaluations were carried out in order to evaluate the usefulness of this grouping paradigm for assisting users. The first evaluation involved users carrying out broad tasks on YouTube, and gave insights into the application of our interface to a vast online video collection. The second evaluation involved users carrying out focused tasks on the TRECVID 2007 video collection, allowing a comparison over a local collection, on which we could extract a number of content-based features. The results of our evaluations show that the use of the ViGOR system results in an increase in user performance and user satisfaction, showing the potential of a grouping paradigm for video search for various tasks in a variety of diverse video collections. Copyright 2009 ACM.",12,,2-s2.0-70450285118,Conference Proceeding,2009-11-30,10.1145/1555400.1555415,96,9781605586977,15525996,87-96,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,87,http://api.elsevier.com/content/abstract/scopus_id/70450285118,,70450285118,145752,p,ViGOR: A grouping oriented interface for search and retrieval in video libraries
"This article describes the process and challenges of developing a content model that can support the content and metadata present in a complex media archive. Media archives have some of the most diverse requirements in an effort to catalog, preserve, and make accessible a wide range of content with multifaceted relationships between works. We focus particularly on the design and implementation of the WGBH Media Library and Archives' Fedora digital access repository for scholars, educational users and the public. It is our hope that the process and findings from this work can support the architecture and development of other media archives. Copyright 2009 ACM.",4,,2-s2.0-70450285120,Conference Proceeding,2009-11-30,10.1145/1555400.1555416,100,9781605586977,15525996,97-100,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,97,http://api.elsevier.com/content/abstract/scopus_id/70450285120,,70450285120,145752,p,Developing a flexible content model for media repositories: A case study
"Music retrieval systems for Western tonal music digital libraries have to consider rhythmic, timbral, melodic and harmonic information. Most existing retrieval systems only take into account melodies. Melody comparison may induce errors since two musical pieces can be very similar whereas their melodies may differ in a significant way. In this paper, we propose to investigate and experiment a retrieval system based on the comparison of chord progressions. The definition of chords may be ambiguous but their properties can be precisely described and represented. We detail the adaptations of alignment algorithms, successfully applied for the estimation of symbolic melodic similarity, for chord progression retrieval. Several experiments, performed on symbolic databases, show that the system described is robust to variations and outperforms a recent chord retrieval system. Copyright 2009 ACM.",9,,2-s2.0-70450242668,Conference Proceeding,2009-11-30,10.1145/1555400.1555417,104,9781605586977,15525996,101-104,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,101,http://api.elsevier.com/content/abstract/scopus_id/70450242668,,70450242668,145752,p,An alignment based system for chord sequence retrieval
"Users of text retrieval systems input only a few keywords or sometimes just one keyword to the systems even if they had complex information needs. Due to the lack of query keywords, it becomes hard to return relevant search results that satisfy the demands of each user. Because digital documents, in contrast to queries, are generally composed of many kinds of keywords, it is also difficult to estimate the main topic or grasp the inherent intentions of the documents. In this paper, we present techniques to represent users' search intentions and the intentions that digital documents can satisfy by making use of clicked titles and snippets acquired from a click log analysis. We then present a method to match these intentions to boost search result rankings. Through experiments that use click logs and indexes of a commercial search engine, we verified our method's capability of significantly improving search precision. Copyright 2009 ACM.",3,,2-s2.0-70450248375,Conference Proceeding,2009-11-30,10.1145/1555400.1555419,114,9781605586977,15525996,105-114,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,105,http://api.elsevier.com/content/abstract/scopus_id/70450248375,,70450248375,145752,p,Query-page intention matching using clicked titles snippets to boost search rankings
"A lot of future-related information is available in news articles or Web pages. This information can however differ to large extent and may fluctuate over time. It is therefore difficult for users to manually compare and aggregate it, and to re-construct the most probable course of future events. In this paper we approach a problem of automatically generating summaries of future events related to queries using data obtained from news archive collections or from the Web. We propose two methods, explicit and implicit future-related information detection. The former is based on analyzing the context of future temporal expressions in documents, while the latter relies on detecting periodical patterns in historical document collections. We present a graph-based visualization of future-related information and demonstrate its usefulness through several examples. Copyright 2009 ACM.",23,,2-s2.0-70450280529,Conference Proceeding,2009-11-30,10.1145/1555400.1555420,124,9781605586977,15525996,115-124,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,115,http://api.elsevier.com/content/abstract/scopus_id/70450280529,,70450280529,145752,p,Supporting analysis of future-related information in news archives and the web
"Faceted metadata and navigation have become major topics in library science, information retrieval and Human-Computer Interaction (HCI). This work surveys a range of extant approaches in this design space, classifying systems along several relevant dimensions. We use that survey to analyze the organization of data and its querying within faceted browsing systems. We contribute formal entity-relationship (ER) and relational data models that explain that organization and relational query models that explain systems' browsing functionality. We use these types of models since they are widely used to conceptualize data and to model back-end data stores. Their structured nature also suggests ways in which both the models and faceted systems might be extended. Copyright 2009 ACM.",21,,2-s2.0-70450235030,Conference Proceeding,2009-11-30,10.1145/1555400.1555422,134,9781605586977,15525996,125-134,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,125,http://api.elsevier.com/content/abstract/scopus_id/70450235030,,70450235030,145752,p,Generalized formal models for faceted user interfaces
"We describe the implementation of a statewide system for managing and preserving electronic theses and dissertations (ETDs) from Texas universities. We further explain the theoretical, technical and political issues that arose during the implementation of this system. These issues range from technical components developed by TDL-such as a customized workflow management application and adding OAI-ORE capabilities to DSpace-to human-centered issues such as stakeholder engagement and participation. Our experiences reflect the challenges, expected and unexpected, that others will face when attempting to build digital library applications to scale. Copyright 2009 ACM.",7,,2-s2.0-70450233442,Conference Proceeding,2009-11-30,10.1145/1555400.1555423,144,9781605586977,15525996,135-144,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,135,http://api.elsevier.com/content/abstract/scopus_id/70450233442,,70450233442,145752,p,Large-scale ETD repositories: A case study of a digital library application
"There are lots of digitized calligraphy works written by ancient famous calligraphists in CADAL (China-America Digital Academic Library) digital library. To make use of these resources, users want to generate a tablet or a piece of calligraphic works written by some ancient famous calligraphist. But some characters in the tablet or the calligraphic work hadn't been written by the calligraphist or though were ever written but are hard to read because of long time weathering. In this paper, a novel approach is proposed to synthesize Chinese calligraphic characters which are in the same style of some calligraphist, and a corresponding system is developed for calligraphy works generation and tablets design. Calligraphic character is represented by a three-level hierarchical model. A novel approach for determining the character structure is proposed, which takes advantage of both the structure of the same characters of different styles and the structure of similar characters of the same style. A style evaluation model (SEM) is presented to evaluate whether the calligraphic character generated is in the same style of the specified calligraphist and to adjust the calligraphic character generated. Our experiments show that this system is effective. Copyright 2009 ACM.",10,,2-s2.0-70450275842,Conference Proceeding,2009-11-30,10.1145/1555400.1555425,152,9781605586977,15525996,145-152,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,145,http://api.elsevier.com/content/abstract/scopus_id/70450275842,,70450275842,145752,p,Style-consistency calligraphy synthesis system in digital library
"""Data fusion"" refers to the problem in information retrieval (IR) where several lists of documents ranked against a query are to be merged into a single ranked list for presentation to a user. Data fusion is also known as ""metasearch."" In a digital library setting data fusion may support operations such as federated search based on multiple repository representations. This paper presents a novel approach to the fusion problem: generative model-based Metasearch (GeM). We suggest viewing the appearance of documents in a return set as the outcome of a probabilistic process; some documents are likely to occur in the model, while others are unlikely. Using Bayesian parameter estimation to fit a multinomial distribution based on the return sets to be merged, GeM achieves a final ranking by listing documents in decreasing probability of generation under the induced model. We also introduce what we call ""the impatient reader"" approach to normalizing document ranks in service to the fusion operation. We report results from several experiments on TREC data suggesting that GeM, informed with impatient reader document scores, operates at state-of-the-art levels of effectiveness. Copyright 2009 ACM.",10,,2-s2.0-70450245153,Conference Proceeding,2009-11-30,10.1145/1555400.1555426,162,9781605586977,15525996,153-162,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,153,http://api.elsevier.com/content/abstract/scopus_id/70450245153,,70450245153,145752,p,Generative model-based metasearch for data fusion in information retrieval
"The EnTag (Enhanced Tagging for Discovery) project investigated the effect on indexing and retrieval when using only social tagging versus when using social tagging in combination with suggestions from a controlled vocabulary. Two different contexts were explored: tagging by readers of a digital collection and tagging by authors in an institutional repository; also two different controlled vocabularies were examined, Dewey Decimal Classification and ACM Computing Classification Scheme. For each context a separate demonstrator was developed and a user study conducted. The results showed the importance of controlled vocabulary suggestions for both indexing and retrieval: to help produce ideas of tags to use, to make it easier to find focus for the tagging, as well as to ensure consistency and increase the number of access points in retrieval. The value and usefulness of the suggestions proved to be dependent on the quality of the suggestions, both in terms of conceptual relevance to the user and in appropriateness of the terminology. The participants themselves could also see the advantages of controlled vocabulary terms for retrieval if the terms used were from an authoritative source. Copyright 2009 ACM.",12,,2-s2.0-70450275841,Conference Proceeding,2009-11-30,10.1145/1555400.1555427,172,9781605586977,15525996,163-172,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,163,http://api.elsevier.com/content/abstract/scopus_id/70450275841,,70450275841,145752,p,EnTag: Enhancing social tagging for discovery
"Book reviews contributed by readers in social sites contain valuable information on books' content, style and merit, many informative words in which can be used to enrich metadata of books in China-Us Million Book Digital Library. In this paper, we present a system for review-oriented metadata enrichment and propose an Book-Centric Diverse Random Walk algorithm on a four-partite graph containing three kinds of relations among authors, books, reviews and words, in order to produce highly relevant as well as diverse keywords for a book. Experimental results of a user study show that our approach significantly outperforms other methods in terms of relevance and diversity. The metadata generated by our approach also has a large overlap with popular social tags and brief introductions from DouBan for books in the coverage experiments. Copyright 2009 ACM.",7,,2-s2.0-70450231541,Conference Proceeding,2009-11-30,10.1145/1555400.1555428,182,9781605586977,15525996,173-182,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,173,http://api.elsevier.com/content/abstract/scopus_id/70450231541,,70450231541,145752,p,Review-oriented metadata enrichment: A case study
"Due to temporary access restrictions, embargoed data can- not be refreshed to unlimited parties during the embargo time interval. A solution to mitigate the risk of data loss has been developed that uses a data dissemination frame- work, the Timed-Locked Embargo Framework (TLEF), that allows data refreshing of encrypted instances of embargoed content in an open, unrestricted scholarly community. TLEF exploits implementations of existing technologies to ""time-lock "" data using timed-release cryptology so that TLEF can be deployed as digital resources encoded in a complex object format suitable for metadata harvesting. The frame- work successfully demonstrates dynamic record identification, time-lock puzzle encryption, encapsulation and dissemination as XML documents. We implement TLEF and pro- vide a quantitative analysis of its successful data harvest of time-locked embargoed data with minimum time overhead without compromising data security and integrity. Copyright 2009 ACM.",0,,2-s2.0-70450235029,Conference Proceeding,2009-11-30,10.1145/1555400.1555430,192,9781605586977,15525996,183-192,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,183,http://api.elsevier.com/content/abstract/scopus_id/70450235029,,70450235029,145752,p,Using timed release cryptography to mitigate the preservation risk of embargo periods
"Assessing the quality of scientific conferences is an important and useful service that can be provided by digital libraries and similar systems. This is specially true for fields such as Computer Science and Electric Engineering, where conference publications are crucial. However, the majority of the existing approaches for assessing the quality of publication venues has been proposed for journals. In this paper, we characterize a large number of features that can be used as criteria to assess the quality of scientific conferences and study how these several features can be automatically combined by means of machine learning techniques to effectively perform this task. Within the features studied are citations, submission and acceptance rates, tradition of the conference, and reputation of the program committee members. Among our several findings, we can cite that: (1) separating high quality conferences from medium and low quality ones can be performed quite effectively, but separating the last two types is a much harder task; and (2) citation features followed by those associated with the tradition of the conference are the most important ones for the task. Copyright 2009 ACM.",12,,2-s2.0-70450253118,Conference Proceeding,2009-11-30,10.1145/1555400.1555431,202,9781605586977,15525996,193-202,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,193,http://api.elsevier.com/content/abstract/scopus_id/70450253118,,70450253118,145752,p,Learning to assess the quality of scientific conferences: A case study in computer science
"A recommender system is useful for a digital library to suggest the books that are likely preferred by a user. Most recommender systems using collaborative filtering approaches leverage the explicit user ratings to make personalized recommendations. However, many users are reluctant to provide explicit ratings, so ratings-oriented recommender systems do not work well. In this paper, we present a recommender system for CADAL digital library, namely CARES, which makes recommendations using a ranking-oriented collaborative filtering approach based on users' access logs, avoiding the problem of the lack of user ratings. Our approach employs mean AP correlation coefficients for computing similarities among users' implicit preference models and a random walk based algorithm for generating a book ranking personalized for the individual. Experimental results on real access logs from the CADAL web site show the effectiveness of our system and the impact of different values of parameters on the recommendation performance. Copyright 2009 ACM.",30,,2-s2.0-70450240707,Conference Proceeding,2009-11-30,10.1145/1555400.1555432,211,9781605586977,15525996,203-211,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,203,http://api.elsevier.com/content/abstract/scopus_id/70450240707,,70450240707,145752,p,CARES: A ranking-oriented CADAL recommender system
"Recommender systems have demonstrated commercial success in multiple industries. In digital libraries they have the potential to be used as a support tool for traditional information retrieval functions. Among the major recommendation algorithms, the successful collaborative filtering (CF) methods explore the use of user-item interactions to infer user interests. Based on the finding that transitive user-item associations can alleviate the data sparsity problem in CF, multiple heuristic algorithms were designed to take advantage of the user-item interaction networks with both direct and indirect interactions. However, the use of such graph representation was still limited in learning-based algorithms. In this paper, we propose a graph kernel-based recommendation framework. For each user-item pair, we inspect its associative interaction graph (AIG) that contains the users, items, and interactions n steps away from the pair. We design a novel graph kernel to capture the AIG structures and use them to predict possible user-item interactions. The framework demonstrates improved performance on an online bookstore dataset, especially when a large number of suggestions are needed. Copyright 2009 ACM.",8,,2-s2.0-70450235024,Conference Proceeding,2009-11-30,10.1145/1555400.1555433,216,9781605586977,15525996,213-216,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,213,http://api.elsevier.com/content/abstract/scopus_id/70450235024,,70450235024,145752,p,Recommendation as link prediction: A graph kernel-based machine learning approach
"Interactive Query Expansion (IQE) presents suggested terms to the user during their search to enable better Information Retrieval (IR). However, IQE terms are poorly used, and tend to lack information meaningful to the user. The lack of cognitive and functional support during query refinement is a well documented problem, and despite the work carried out, it is still an under researched area. This stagnation in progress has been partly due to the long held belief that users are able to make good IQE term selections, and that the de facto way IQE terms are presented is effective. In this paper, we introduce a novel method to improve the presentation of IQE terms by providing supplementary information alongside them. We describe a user study that compared our novel polyrepresentational approach to IQE against a conventional IQE system and a baseline system. Our findings have shown that a polyrepresentational approach to IQE can address the ambiguity and uncertainty surrounding IQE, and improve the perceived usefulness of the terms. Copyright 2009 ACM.",9,,2-s2.0-70450257595,Conference Proceeding,2009-11-30,10.1145/1555400.1555434,220,9781605586977,15525996,217-220,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,217,http://api.elsevier.com/content/abstract/scopus_id/70450257595,,70450257595,145752,p,A polyrepresentational approach to interactive query expansion
"With the rise of community-generated web content, the need for automatic characterization of resource quality has grown, particularly in the realm of educational digital libraries. We demonstrate how identifying concrete factors of quality for web-based educational resources can make machine learning approaches to automating quality characterization tractable. Using data from several previous studies of quality, we gathered a set of key dimensions and indicators of quality that were commonly identified by educators. We then performed a mixed-method study of digital library curation experts, showing that our characterization of quality captured the subjective processes used by the experts when assessing resource quality for classroom use. Using key indicators of quality selected from a statistical analysis of our expert study data, we developed a set of annotation guidelines and annotated a corpus of 1000 digital resources for the presence or absence of these key quality indicators. Agreement among annotators was high, and initial machine learning models trained from this corpus were able to identify some indicators of quality with as much as an 18% improvement over the baseline. Copyright 2009 ACM.",21,,2-s2.0-70450278680,Conference Proceeding,2009-11-30,10.1145/1555400.1555436,230,9781605586977,15525996,221-230,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,221,http://api.elsevier.com/content/abstract/scopus_id/70450278680,,70450278680,145752,p,Automatically characterizing resource quality for educational digital libraries
"Individual optical character recognition (OCR) engines vary in the types of errors they commit in recognizing text, particularly poor quality text. By aligning the output of multiple OCR engines and taking advantage of the differences between them, the error rate based on the aligned lattice of recognized words is significantly lower than the individual OCR word error rates. This lattice error rate constitutes a lower bound among aligned alternatives from the OCR output. Results from a collection of poor quality midtwentieth century typewritten documents demonstrate an average reduction of 55.0% in the error rate of the lattice of alternatives and a realized word error rate (WER) reduction of 35.8% in a dictionary-based selection process. As an important precursor, an innovative admissible heuristic for the A* algorithm is developed, which results in a significant reduction in state space exploration to identify all optimal alignments of the OCR text output, a necessary step toward the construction of the word hypothesis lattice. On average 0.0079% of the state space is explored to identify all optimal alignments of the documents. Copyright 2009 ACM.",15,,2-s2.0-70450272592,Conference Proceeding,2009-11-30,10.1145/1555400.1555437,240,9781605586977,15525996,231-240,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,231,http://api.elsevier.com/content/abstract/scopus_id/70450272592,,70450272592,145752,p,Improving optical character recognition through efficient multiple system alignment
"User-contributed tags have shown promise as a means of indexing multimedia collections by harnessing the combined efforts and enthusiasm of online communities. But tags are only one way of describing multimedia items. In this study, I compare the characteristics of public tags with other forms of descriptive metadata-titles and narrative captions-that users have assigned to a collection of very similar images gathered from the photosharing service Flickr. The study shows that tags converge on different descriptions than the other forms of metadata do, and that narrative metadata may be more effective than tags for capturing certain aspects of images that may influence their subsequent retrieval and use. The study also examines how photographers use peoples' names to personalize the different types of metadata and how they tell stories across short sequences of images. The study results are then brought to bear on design recommendations for user tagging tools and automated tagging algorithms and on using photo sharing sites as de facto art and architecture resources. Copyright 2009 ACM.",17,,2-s2.0-70450260503,Conference Proceeding,2009-11-30,10.1145/1555400.1555438,250,9781605586977,15525996,241-250,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,241,http://api.elsevier.com/content/abstract/scopus_id/70450260503,,70450260503,145752,p,"No bull, no spin: A comparison of tags with other forms of user metadata"
"Web users are spending more of their time and creative en- ergies within online social networking systems. While many of these networks allow users to export their personal data or expose themselves to third-party web archiving, some do not. Facebook, one of the most popular social networking websites, is one example of a \walled garden"" where users' activities are trapped. We examine a variety of techniques for extracting users' activities from Facebook (and by ex- tension, other social networking systems) for the personal archive and for the third-party archiver. Our framework could be applied to any walled garden where personal user data is being locked. Copyright 2009 ACM.",16,,2-s2.0-70450250018,Conference Proceeding,2009-11-30,10.1145/1555400.1555440,254,9781605586977,15525996,251-254,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,251,http://api.elsevier.com/content/abstract/scopus_id/70450250018,,70450250018,145752,p,What happens when facebook is gone?
"Journals, letters, and other writings are of great value to historians and those who research their own family history; however, it can be difficult to find writings by specific people, and even harder to find what others wrote about them. We present a prototype web-based system that enables users to discover information about historical people (including their own ancestors) by linking digital library content to unique PersonIDs from a genealogical database. Users can contribute content such as scanned journals or information about where items can be found. They can also transcribe content and tag it with PersonIDs to identify who it is about. Additional features provide tools for users to explore historical contexts and relationships. These include the ability to tag places and to create a historical social network by specifying non-family relationships or by using a mechanism we call rosters to imply participation in some group or event. Copyright 2009 ACM.",2,,2-s2.0-70450251975,Conference Proceeding,2009-11-30,10.1145/1555400.1555441,258,9781605586977,15525996,255-258,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,255,http://api.elsevier.com/content/abstract/scopus_id/70450251975,,70450251975,145752,p,Improving historical research by linking digital library information to a global genealogical database
"This paper discusses new work to represent, in a digital library of classical sources, authors whose works themselves are lost and who survive only where surviving authors quote, paraphrase or allude to them. It describes initial works from a digital collection of such fragmentary authors designed not only to capture but to extend the ontologies that traditional scholarship has developed over generations: the aim is representing every nuance of print conventions while using the capabilities of digital libraries to extend our ability to identify fragments, to represent what we have identified, and to render the results of that work intellectually and physically more accessible than was possible in print culture. Copyright 2009 ACM.",6,,2-s2.0-70450233437,Conference Proceeding,2009-11-30,10.1145/1555400.1555442,262,9781605586977,15525996,259-262,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,259,http://api.elsevier.com/content/abstract/scopus_id/70450233437,,70450233437,145752,p,Collecting fragmentary authors in a digital library
"In this paper we present an application of image registration techniques to the specific domain of manuscript images. We show the application of this technique to images of the Vene- tus A, a 10th century manuscript of Homer's Iliad. The same algorithm is used to register images of the MS across time (including photographs separated by over a century), as well as across imaging modalities. Copyright 2009 ACM.",5,,2-s2.0-70450263290,Conference Proceeding,2009-11-30,10.1145/1555400.1555443,266,9781605586977,15525996,263-266,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,263,http://api.elsevier.com/content/abstract/scopus_id/70450263290,,70450263290,145752,p,Robust registration of manuscript images
"The utility of an enterprise search system is determined by three key players: the information retrieval (IR) system (the search engine), the enterprise users, and the service provider who delivers the tailored IR service to its designated enterprise users. Currently, evaluations of enterprise search have been focused largely on the IR system effectiveness and efficiency, only a relatively small amount of effort on the user's involvement, and hardly any effort on the service provider's role. This paper will investigate the role of the service provider. We propose a method that evaluates the cost and benefit for a service provider of using a mediated search engine - in particular, where domain experts intervene on the ranking of the search results from a search engine. We test our cost and benefit evaluation method in a case study and conduct user experiments to demonstrate it. Our study shows that: 1) by making use of domain experts' relevance assessments in search result ranking, the precision and the discount cumulated gain of ranked lists have been improved significantly (144% and 40% respectively); 2) the service provider gains substantial return on investment and higher search success rate by investing in domain experts' relevance assessments; and 3) the cost and benefit evaluation also indicates the type of queries to be selected from a query log for evaluating an enterprise search engine. Copyright 2009 ACM.",6,,2-s2.0-70450227238,Conference Proceeding,2009-11-30,10.1145/1555400.1555445,276,9781605586977,15525996,267-276,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,267,http://api.elsevier.com/content/abstract/scopus_id/70450227238,,70450227238,145752,p,Cost and benefit analysis of mediated enterprise search
"In addition to the frequency of terms in a document collection, the distribution of terms plays an important role in determining the relevance of documents for a given search query. In this paper, term distribution analysis using Fourier series expansion as a novel approach for calculating an abstract representation of term positions in a document corpus is introduced. Based on this approach, two methods for improving the evaluation of document relevance are pro- posed: (a) a function-based ranking optimization representing a user defined document region, and (b) a query expansion technique based on overlapping the term distributions in the top-ranked documents. Experimental results demonstrate the effectiveness of the proposed approach in providing new possibilities for optimizing the retrieval process. Copyright 2009 ACM.",3,,2-s2.0-70450253115,Conference Proceeding,2009-11-30,10.1145/1555400.1555446,284,9781605586977,15525996,277-284,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,277,http://api.elsevier.com/content/abstract/scopus_id/70450253115,,70450253115,145752,p,Document relevance assessment via term distribution analysis using fourier series expansion
"Web 2.0 enables information sharing, collaboration among users and most notably supports active participation and creativity of the users. As a result, a huge amount of manually created metadata describing all kinds of resources is now available. Such semantically rich user generated annotations are especially valuable for digital libraries covering multimedia resources such as music, where these metadata enable retrieval relying not only on content-based (low level) features, but also on the textual descriptions represented by tags. However, if we analyze the annotations users generate for music tracks, we find them heavily biased towards genre. Previous work investigating the types of user provided annotations for music tracks showed that the types of tags which would be really beneficial for supporting retrieval - usage (theme) and opinion (mood) tags - are often neglected by users in the annotation process. In this paper we address exactly this problem: in order to support users in tagging and to fill these gaps in the tag space, we develop algorithms for recommending mood and theme annotations. Our methods exploit the available user annotations, the lyrics of music tracks, as well as combinations of both. We also compare the results for our recommended mood / theme annotations against genre and style recommendations - a much easier and already studied task. Besides evaluating against an expert (AllMusic.com) ground truth, we evaluate the quality of our recommended tags through a Facebook-based user study. Our results are very promising both in comparison to experts as well as users and provide interesting insights into possible extensions for music tagging systems to support music search. Copyright 2009 ACM.",15,,2-s2.0-70450251973,Conference Proceeding,2009-11-30,10.1145/1555400.1555448,294,9781605586977,15525996,285-294,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,285,http://api.elsevier.com/content/abstract/scopus_id/70450251973,,70450251973,145752,p,"How do you feel about ""Dancing Queen""? Deriving mood & theme annotations from user tags"
"The old dream of a universal repository containing all the human knowledge and culture is becoming possible through the Internet and the Web. Moreover, this is happening with the direct collaborative, participation of people. Wikipedia is a great example. It is an enormous repository of information with free access and edition, created by the community in a collaborative manner. However, this large amount of information, made available democratically and virtually without any control, raises questions about its relative quality. In this work we explore a significant number of quality indicators, some of them proposed by us and used here for the first time, and study their capability to assess the quality of Wikipedia articles. Furthermore, we explore machine learning techniques to combine these quality indicators into one single assessment judgment. Through experiments, we show that the most important quality indicators are the easiest ones to extract, namely, textual features related to length, structure and style. We were also able to determine which indicators did not contribute significantly to the quality assessment. These were, coincidentally, the most complex features, such as those based on link analysis. Finally, we compare our combination method with state-of-the-art solution and show significant improvements in terms of effective quality prediction. Copyright 2009 ACM.",47,,2-s2.0-70450235023,Conference Proceeding,2009-11-30,10.1145/1555400.1555449,304,9781605586977,15525996,295-304,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,295,http://api.elsevier.com/content/abstract/scopus_id/70450235023,,70450235023,145752,p,Automatic quality assessment of content created collaboratively by web communities: A case study of wikipedia
"This paper reports on an adaption of the existing PopoutText and ClearText display techniques to mobile phones. It explains the design rationale for a freely available iPhone application to read books from the International Children's Digital Library. Through a combination of applied image processing, a zoomable user interface, and a process of working with children to develop the detailed design, we present an interface that supports clear reading of scanned picture books in multiple languages on a mobile phone. Copyright 2009 ACM.",12,,2-s2.0-70450255036,Conference Proceeding,2009-11-30,10.1145/1555400.1555450,308,9781605586977,15525996,305-308,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,305,http://api.elsevier.com/content/abstract/scopus_id/70450255036,,70450255036,145752,p,Designing the reading experience for scanned multi-lingual picture books on mobile phones
"Millions of people in developed countries routinely create and share digital content; but what about the billions of others in on the wrong side of what has been called the 'global digital divide'? This paper considers three mobile platforms to illustrate their potential in enabling rural Indian villagers to make and share digital stories. We describe our experiences in creating prototypes using mobile phones; high-end media-players; and, paper. Interaction designs are discussed along with findings from various trials within the village and elsewhere. Our approach has been to develop prototypes that can work together in an integrated fashion so that content can flow freely and in interesting ways through the village. While our work has particular relevance to those users in emerging world contexts, we see it also informing needs and practices in the developed world for user-generated content. Copyright 2009 ACM.",6,,2-s2.0-70450267404,Conference Proceeding,2009-11-30,10.1145/1555400.1555451,312,9781605586977,15525996,309-312,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,309,http://api.elsevier.com/content/abstract/scopus_id/70450267404,,70450267404,145752,p,"Mobility, digital libraries and a rural Indian village"
"This study examined how searchers interacted with a webbased, faceted library catalog when conducting exploratory searches. It applied eye tracking, stimulated recall interviews, and direct observation to investigate important aspects of gaze behavior in a faceted search interface: what components of the interface searchers looked at, for how long, and in what order. It yielded empirical data that will be useful for both practitioners (e.g., for improving search interface designs), and researchers (e.g., to inform models of search behavior). Results of the study show that participants spent about 50 seconds per task looking at (fixating on) the results, about 25 seconds looking at the facets, and only about 6 seconds looking at the query itself. These findings suggest that facets played an important role in the exploratory search process. Copyright 2009 ACM.",93,,2-s2.0-70450242652,Conference Proceeding,2009-11-30,10.1145/1555400.1555452,322,9781605586977,15525996,313-322,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,313,http://api.elsevier.com/content/abstract/scopus_id/70450242652,,70450242652,145752,p,What do exploratory searchers look at in a faceted search interface?
"The Open Archives Initiative - Object Reuse and Exchange (OAIORE) specifications provide a flexible set of mechanisms for transferring complex data objects between different systems. In order to serve as an exchange syntax, OAI-ORE must be able to support the import of information from localized data structures serving various communities of practice. In this paper, we examine the Metadata Encoding & Transmission Standard (METS) and the issues that arise when trying to map from a localized structural metadata schema into the OAI-ORE data model and serialization syntaxes. Copyright 2009 ACM.",4,,2-s2.0-70450263289,Conference Proceeding,2009-11-30,10.1145/1555400.1555454,329,9781605586977,15525996,323-329,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,323,http://api.elsevier.com/content/abstract/scopus_id/70450263289,,70450263289,145752,p,Aligning METS with the OAI-ORE data model
"The World Wide Web has become a key source of knowledge pertaining to almost every walk of life. Unfortunately, much of data on the Web is highly ephemeral in nature, with more than 50-80% of content estimated to be changing within a short time. Continuing the pioneering efforts of many national (digital) libraries, organizations such as the International Internet Preservation Consortium (IIPC), the Internet Archive (IA) and the European Archive (EA) have been tirelessly working towards preserving the ever changing Web. However, while these web archiving efforts have paid signi ficant attention towards long term preservation of Web data, they have paid little attention to developing an globalscale infrastructure for collecting, archiving, and performing historical analyzes on the collected data. Based on insights from our recent work on building text analytics for Web Archives, we propose EverLast, a scalable distributed framework for next generation Web archival and temporal text analytics over the archive. Our system is built on a looselycoupled distributed architecture that can be deployed over large-scale peer-to-peer networks. In this way, we allow the integration of many archival efforts taken mainly at a national level by national digital libraries. Key features of EverLast include support of time-based text search & analysis and the use of human-assisted archive gathering. In this paper, we outline the overall architecture of EverLast, and present some promising preliminary results. Copyright 2009 ACM.",6,,2-s2.0-70450233436,Conference Proceeding,2009-11-30,10.1145/1555400.1555455,340,9781605586977,15525996,331-340,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,331,http://api.elsevier.com/content/abstract/scopus_id/70450233436,,70450233436,145752,p,EverLast: A distributed architecture for preserving the web
"In prior work we have demonstrated that search engine caches and archiving projects like the Internet Archive's Wayback Machine can be used to \lazily preserve"" websites and re- construct them when they are lost. We use the term \web repositories"" for collections of automatically refreshed and migrated content, and collectively we refer to these reposi- tories as the \web infrastructure"". In this paper we present a framework for describing web repositories and the status of web resources in them. This includes an abstract API for web repository interaction, the concepts of deep vs. at and light/dark/grey repositories and terminology for describing the recoverability of a web resource. Our API may serve as a foundation for future web repository interfaces. Copyright 2009 ACM.",1,,2-s2.0-70450253111,Conference Proceeding,2009-11-30,10.1145/1555400.1555456,344,9781605586977,15525996,341-344,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,341,http://api.elsevier.com/content/abstract/scopus_id/70450253111,,70450253111,145752,p,A framework for describing web repositories
"Digital preservation aims at maintaining digital objects accessible over a long period of time, regardless of the challenges of organizational or technological changes or failures. In particular, data produced in e-Science domains could be reliably stored in today's data grids, taking advantage of the natural properties of this kind of infrastructure to support redundancy. However, to achieve reliability we must take into account failure interdependency. Taking into account the fact that correlated failures can affect multiple components and potentially cause complete loss of data, we propose a solution to evaluate redundancy strategies in the context of heterogeneous environments such as data grids. This solution is based on a simulation engine that can be used not only to support the process of designing the preservation environment and related policies, but also later on to observe and control the deployed system. Copyright 2009 ACM.",2,,2-s2.0-70450248367,Conference Proceeding,2009-11-30,10.1145/1555400.1555457,348,9781605586977,15525996,345-348,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,345,http://api.elsevier.com/content/abstract/scopus_id/70450248367,,70450248367,145752,p,Preserving digital data in heterogeneous environments
"The prevailing model for digital preservation is that archives should be similar to a ""fortress"": a large, protective infrastructure built to defend a relatively small collection of data from attack by external forces. Such projects are a luxury, suitable only for limited collections of known importance and requiring significant institutional commitment for sustainability. In previous research, we have shown the web infrastructure (i.e., search engine caches, web archives) refreshes and migrates web content in bulk as side-effects of their user-services, and these results can be mined as a useful, but passive preservation service. Our current research involves a number of questions resulting from removing the implicit assumption that web-based data objects must passively await curatorial services: What if data objects were not tethered to repositories? What are the implications if the content were actively seeking out and injecting itself into the web infrastructure (i.e., search engine caches, web archives)? All of this leads to our primary research question: Can we create objects that preserve themselves more effectively than repositories or web infrastructure can? Copyright 2009 ACM.",5,,2-s2.0-70450239534,Conference Proceeding,2009-11-30,10.1145/1555400.1555458,352,9781605586977,15525996,349-352,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,349,http://api.elsevier.com/content/abstract/scopus_id/70450239534,,70450239534,145752,p,Unsupervised creation of small world networks for the preservation of digital objects
"We report on the exploratory stages of multi-university, multiresearch- site, multi-year effort to investigate and compare data practices in multiple cyberinfrastructure projects and their emerging virtual organizations. Our long-term goal is to understand the data practices and data management requirements of virtual organizations and their implications for the design and development of data digital libraries. We have constructed our own virtual organization as a participant-observer approach to the research. Results to date suggest that collaborative technologies are emergent and that defining and scoping the data products of collaborations continues to be problematic. Copyright 2009 ACM.",11,,2-s2.0-70450285110,Conference Proceeding,2009-11-30,10.1145/1555400.1555459,356,9781605586977,15525996,353-356,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,353,http://api.elsevier.com/content/abstract/scopus_id/70450285110,,70450285110,145752,p,Towards a virtual organization for data cyberinfrastructure
"This paper will present some preliminary result on factors that affect the adoption of PREMIS in cultural heritage institutions. The study employed a web-based survey to collect data from 123 participants in 20 countries as well as a semi-structured, follow-up telephone interview with a smaller sample of the survey respondents. Roger's diffusion of innovation theory was used as a theoretical framework. The main constructs considered for the study were relative advantage, compatibility, complexity, trialability, observability, and institution readiness. The study yielded both qualitative and quantitative data, and preliminary analysis showed that all six factors influence the adoption of PREMIS in varying degrees.",0,,2-s2.0-70450251972,Conference Proceeding,2009-11-30,10.1145/1555400.1555461,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,357,http://api.elsevier.com/content/abstract/scopus_id/70450251972,,70450251972,145752,p,Expanding the search for digital preservation solutions: Adopting premis in cultural heritage institutions
"In this article, a universal collaborative and competitive approach is introduced for deployment of digital collections in an ideal Digital Library (DL) for future's educational system. The collaborative and open-source aspects of the system guarantee its growth and the competitive aspects guarantee the accuracy.",0,,2-s2.0-70450240697,Conference Proceeding,2009-11-30,10.1145/1555400.1555462,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,359,http://api.elsevier.com/content/abstract/scopus_id/70450240697,,70450240697,145752,p,Collaborative Digital Library: Enhancing Digital Collections to Improve Learning in Educational Programs
"The online auction site eBay has overtaken face-to-face transactions as the primary means of doing business for collectors and sellers of unique and ephemeral materials. Historical societies, museums, and archives also increasingly collect ephemera as records of social and cultural history. This presentation argues that the digitized flea market, as epitomized by eBay, replaces in-person sales while also providing a stream of rich information about a previously invisible, unquantifiable marketplace. Furthermore, identifying factors that influence collectibles buyers' behavior in online auction sales can also shed light on factors affecting user behaviors in digital libraries. Data from a survey of over 1,000 recent home movie auction listings on eBay suggest how eBay may be used as a data source by collectors, as well as the users and designers of digital libraries.",0,,2-s2.0-70450236993,Conference Proceeding,2009-11-30,10.1145/1555400.1555463,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,361,http://api.elsevier.com/content/abstract/scopus_id/70450236993,,70450236993,145752,p,Digitizing the flea market: eBay as a data source for historic collections
"We previously investigated the support of alerting services across networks of heterogeneous digital libraries. We now report the first generation of semantically enhanced digital library alerting systems. Where previous alerting services have provided users with notifications of new library content using traditional metadata, we demonstrate the advantages and challenges of using semantic technologies. This uncovers key issues that are not yet fully understood in general event-based systems (including alerting systems).",2,,2-s2.0-70450274992,Conference Proceeding,2009-11-30,10.1145/1555400.1555464,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,363,http://api.elsevier.com/content/abstract/scopus_id/70450274992,,70450274992,145752,p,Semantic alerting for digital libraries
"This poster describes a study currently in progress that seeks to identify and address the needs of researchers from multiple disciplines in managing, curating and preserving their data. One output of this study, which is still in its early stages, will be the ""data curation profile,"" a methodological tool designed to enable the comparison of needs across disciplines and help librarians build digital libraries that accurately reflect and address the needs of data producers.",1,,2-s2.0-70450225294,Conference Proceeding,2009-11-30,10.1145/1555400.1555465,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,365,http://api.elsevier.com/content/abstract/scopus_id/70450225294,,70450225294,145752,p,Addressing researchers' needs through the data curation profile
"The evaluation of Palm Leaf Manuscripts Metadata Schema PLMM) aims to examine whether the PLMM satisfactorily meets the user requirements in searching for the PLMs and managing the PLMs collection. (1) An examination of the PLMM's capability in describing the particular characteristics of Northeastern Thai Palm Leaf Manuscripts, and its usefulness in the palm leave manuscripts preservation and rights control management (2) an investigation of users' satisfaction when using PLMM to search for the PLMs and managing the PLMs collection. The evaluation process began with the development of the prototype of PLMs management system to implement the PLMM. Then, more than 200 metadata records describing all types of sample PLMs (with variations in sizes, scripts, languages, titles, and number of content subjects contained in a fascicle) were provided in Extensible Markup Language (XML) format, while system interfaces and queries were developed with Hypertext Preprocessor (PHP). This was followed by the trials with end users and staff in their workplace in order to evaluate the usefulness of PLMM in user tasks according to the FRBR tasks: Find, identify, select, and obtain; and collection development tasks. The research found that 'somewhat high' efficiency of the PLMM was perceived among the participants in the two tasks. The finding also suggests that perceived efficiency of the PLMM was significantly higher with more years of users' experience with the PLMs. The status of users is another factor which positively affected the perceived efficiency of the PLMM.",2,,2-s2.0-70450260488,Conference Proceeding,2009-11-30,10.1145/1555400.1555466,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,367,http://api.elsevier.com/content/abstract/scopus_id/70450260488,,70450260488,145752,p,Implementation and evaluation of palm leaf manuscript metadata schema (PLMM)
We report on the current research activities and results ob-tained through the Concept Learning service for Concept Knowledge (CLICK) and present a demonstration of the sys-tem. This poster session will focus on a demonstration of the CLICK system and the results of the learning study.,0,,2-s2.0-70450274990,Conference Proceeding,2009-11-30,10.1145/1555400.1555467,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,369,http://api.elsevier.com/content/abstract/scopus_id/70450274990,,70450274990,145752,p,A personalized learning environment
"A digital video library of over 900 hours of video and 18000 stories from The HistoryMakers was used by 214 students, faculty, librarians, and life-long learners interacting with a system providing multiple search and viewing capabilities over a trial period of several months. User demographics and actions were logged, providing metrics on how the system was used. This poster overviews a few highlights from these transaction logs of the Informedia digital video library system for life oral histories.",1,,2-s2.0-70450275833,Conference Proceeding,2009-11-30,10.1145/1555400.1555468,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,371,http://api.elsevier.com/content/abstract/scopus_id/70450275833,,70450275833,145752,p,Analysis of transaction logs for insights into use of life oral histories
"In this paper, we describe a visual clustering approach to summarizing user-generated reviews of digital library items and services. The approach consists of the steps of sentence extraction, aspect identification, opinion classification, and review summarization. Our work augments existing work by considering non-standard input and by incorporating clustering and visualization in summarization.",0,,2-s2.0-70450267397,Conference Proceeding,2009-11-30,10.1145/1555400.1555469,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,373,http://api.elsevier.com/content/abstract/scopus_id/70450267397,,70450267397,145752,p,Summarizing user-generated reviews in digital libraries: A visual clustering approach
This poster presents a prototype architecture and potential use-cases for a standards-based service framework to sim-plify development of high-resolution image viewing clients.,0,,2-s2.0-70450277138,Conference Proceeding,2009-11-30,10.1145/1555400.1555470,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,375,http://api.elsevier.com/content/abstract/scopus_id/70450277138,,70450277138,145752,p,An interoperability service framework for high-resolution image applications
We present a re-design of Greenstone to support seniors (aged over 65) in managing documents reflecting their life history.,0,,2-s2.0-70450227231,Conference Proceeding,2009-11-30,10.1145/1555400.1555471,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,377,http://api.elsevier.com/content/abstract/scopus_id/70450227231,,70450227231,145752,p,Tailoring greenstone for seniors
We are in the early stages of developing a unique physical and digital record of New Zealand's early experience of the Internet.,0,,2-s2.0-70450260487,Conference Proceeding,2009-11-30,10.1145/1555400.1555472,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,379,http://api.elsevier.com/content/abstract/scopus_id/70450260487,,70450260487,145752,p,A mixed digital/physical snapshot of early internet/web usage in New Zealand
"In the life sciences one of the pronounced problems is the deluge of new results and data that are produced on a daily basis. This data can take many different forms, e.g. microarray probes, gene sequences, protein structures and is added by hundreds of research centers world-wide in a largely uncoordinated fashion. Thus integration of life science data is growing in importance. Unfortunately, most research centers do not have particular incentive to spend efforts on integrating their data with data produced by others. This task is largely left to large publiclysponsored institutions like the US National Library of Medicine and similar institutions in other countries. Unfortunately, despite their work in this area, the integration of web-based life science resources is still an open issue (and one ever growing in importance) as these organizations cannot cope with the information deluge that is happening on a daily basis in the life sciences. Thus it becomes essential that as many as possible third parties are engaged in the process. Here we demonstrate a simple prototype of a browser plugin that creates a platform for third parties to contribute to cross-linking related online life science data resources and thus improving the search experience and the productivity of the life science community. The plugin creates a convenient programming interface that minimizes the effort that arises for such third-party contributors. We have provided reference implementations using the plugin that cross-link life science literature resources and illustrate the potential for third parties to create mashups that could be applied also in areas other than the life sciences.",1,,2-s2.0-70450236990,Conference Proceeding,2009-11-30,10.1145/1555400.1555473,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,381,http://api.elsevier.com/content/abstract/scopus_id/70450236990,,70450236990,145752,p,Mashing up life science literature resources
"This poster presents a pluralistic approach for representing discipline-specific, cross-disciplinary, and discipline-independent work practices related to scholarly communication. This approach has been applied to qualitative analysis from an investigation of publication and distribution practices of scholars within the biological sciences and the field of communication. The resulting representations illustrate shared work practices and areas where diverse practices exist, both of which can guide the development of digital collections of scholarly materials. This poster also considers challenges related to aligning data collection methods with the application of these representational techniques.",0,,2-s2.0-70450233428,Conference Proceeding,2009-11-30,10.1145/1555400.1555474,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,383,http://api.elsevier.com/content/abstract/scopus_id/70450233428,,70450233428,145752,p,Representing publication and distribution practices for scholarly materials: A cross-disciplinary comparison
"We present a method that uses text mining methods and statistical distributions to infer degrees of collaboration between staff members in an organization, based on the similarity of the documents that that they wrote and exchanged over time.",3,,2-s2.0-70450265239,Conference Proceeding,2009-11-30,10.1145/1555400.1555475,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,385,http://api.elsevier.com/content/abstract/scopus_id/70450265239,,70450265239,145752,p,Inferring intra-organizational collaboration from cosine similarity distributions in text documents
A graph theory based method is proposed to exploit name transformation for personal name-matching. Experiment results on three personal name datasets show that the method is effective.,0,,2-s2.0-70450275831,Conference Proceeding,2009-11-30,10.1145/1555400.1555476,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,387,http://api.elsevier.com/content/abstract/scopus_id/70450275831,,70450275831,145752,p,Personal name-matching through name transformation
"We describe EMU, a system for collecting, managing, and exploring the behavior data collected in the Emory libraries search system. We describe the data capture system based on the LibX browser plugin, the database management system for successfully storing, searching and exploring millions of resulting user interactions, and preliminary results of interesting queries and statistics that we are using to evaluate the effectiveness of library search tools.",2,,2-s2.0-70450277137,Conference Proceeding,2009-11-30,10.1145/1555400.1555477,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,389,http://api.elsevier.com/content/abstract/scopus_id/70450277137,,70450277137,145752,p,EMU: The emory user behavior data management system for automatic library search evaluation
"Among many practical and domain-specific tasks, expertise retrieval (ER) has recently gained increasing attention in the information retrieval and knowledge management communities. ER can be broadly classified into two tasks: expert finding and expert profiling. The expert finding task aims to identify a list of people who carry some certain knowledge specified by the input query [1, 3]. The expert profiling, on the other hand, focuses on identifying the area of expertise associated with a given person [2]. To construct an expert profile, two types of information which can be used to describe an expert are topical and social information. The topical information represents domain and degree of knowledge in which an expert possesses. The social information measures an association aspect among experts such as research project collaboration, publication co-authoring and program committee assignment. This paper describes our ongoing project to design and implement an expert retrieval system with the scope on researchers who work in Thailand. The first step is to build expert profiles for each researcher. To identify expertise in different research areas, we could use many different forms of evidence such as curriculum vitae, personal homepage or professional profiles from social networking website, e.g., LinkedIn. However, there are two main difficulties in using these information sources. The first is due to the distributed nature of the information sources. Gathering individual profiles from the public information source, i.e., the web, could be very tedious. An intelligent information extraction algorithm is required to understand different document templates. Also, the profile collection is most likely to be incomplete, since some researchers do not provide their profiles in public for privacy reason. The second problem is due to the inconsistency of terms used to describe the area of expertise, e.g., association rule mining (hyponym) vs data mining (hypernym) or avian flu virus vs H5N1 (synonym). Although integrating information from multiple sources could be very helpful for providing more supported information, we leavethis issue as our future work. In our current system prototype, we assume that the areas of expertise among researchers can be extracted from bibliographic databases. We use the Science Citation Index (SCI) database to provide the information for representing the expert profiles. From the SCI database, we queried and retrieved publications covering from the year 2001 to 2008 by specifying the affiliation equal to ""Thailand"". The results contain a set of approximately 23,000 publications. We downloaded and extracted four related fields including authors (denoted by AU), controlled terms (denoted by ID), keywords (denoted by DE) and subject category (denoted by SC). To build a researcher network, we consider two types of relationships: Direct and indirect. The direct (or social) relationship is defined as the co-authoring degree between one researcher to others. The co-authoring degree between two researchers, co-authoring(A,B), can be calculated based on the co-occurrence frequency between A and B found in the field AU of 23,000 retrieved records. The indirect (or topical relationship is defined when two researchers have publications under the same topics. The topical degree between two researchers, topical(A,B), can be calculated based on the similarity measure between two sets of extracted keywords, keyword(A) and keyword(B), representing researcher A and B, respectively. The keyword set can be extracted from the fields ID, DE and SC. An author with high frequencies on particular keywords is considered an expert in the corresponding research topics.",2,,2-s2.0-70450277136,Conference Proceeding,2009-11-30,10.1145/1555400.1555478,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,391,http://api.elsevier.com/content/abstract/scopus_id/70450277136,,70450277136,145752,p,Building a Thailand researcher network based on a bibliographic database
"The Open Language Archives Community (OLAC) is an international partnership of institutions which are building a network of interoperating repositories and services to create a worldwide virtual library of language resources (that is, resources that document, describe, or develop the more than 7,000 known languages of the world). OLAC uses a community-specific refinement of qualified Dublin Core [http://www.language-archives.org/OLAC/metadata.htm] along with a community-specific refinement of the OAI Protocol for Metadata Harvesting [http://www.language-archives.org/OLAC/repositories.htm] to maintain an aggregated catalog of the holdings of the 35 participating archives. OLAC recognizes that the language resources of interest to the community come not only from sources within the community but also from many sources outside the community. This poster describes one approach we have developed for addressing this issue, namely, a crosswalk that transforms the MARC21 catalog for a library or archive into an OAI static repository that holds an OLAC metadata record for each MARC record identified as describing a language resource.",0,,2-s2.0-70450278662,Conference Proceeding,2009-11-30,10.1145/1555400.1555479,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,393,http://api.elsevier.com/content/abstract/scopus_id/70450278662,,70450278662,145752,p,Building a MARC-to-OLAC crosswalk: Repurposing library catalog data for the language resources community
"In this paper, we describe a work flow to extract and verify text locations using commercial software, along with free software products and human proofing. To help mid-sized digital libraries, we are making our solution available as open source software.",1,,2-s2.0-70450260486,Conference Proceeding,2009-11-30,10.1145/1555400.1555480,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,395,http://api.elsevier.com/content/abstract/scopus_id/70450260486,,70450260486,145752,p,Locating text in scanned books
"For increasingly frequent use of library resources by remote users, emote usability testing has become a valuable tool for those who would pursue an empirical, user-centered design of the interfaces to their electronic resources and services. This paper describes our implementation of remote usability tests to evaluate prototypes of a web content management application developed by Vignette Corporation, and reports sample results to illustrate the utility of such an approach that can help designing and improving interfaces of digital library projects and their usability.",2,,2-s2.0-70549093097,Conference Proceeding,2009-12-01,10.1145/1555400.1555481,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,397,http://api.elsevier.com/content/abstract/scopus_id/70549093097,,70549093097,145752,p,Remote usability testing: A practice
"Scientific digital libraries serve complex and evolving research communities. Justifications for the development of scientific digital libraries include the desire to preserve science data and the promises of information interconnectedness, correlative science, and system interoperability. Research [1] suggests single shared ontologies are fundamental to fulfilling these promises. We present a tool framework, a set of principles, and a real world case study where shared ontologies are used to develop and manage science information models and subsequently guide the implementation of scientific digital libraries. The tool framework, based on an ontology modeling tool as illustrated in Figure 1, was configured to develop, manage, and keep shared ontologies relevant within changing domains and to promote the interoperability, interconnectedness, and correlation desired by scientists.",0,,2-s2.0-70450239521,Conference Proceeding,2009-11-30,10.1145/1555400.1555482,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,399,http://api.elsevier.com/content/abstract/scopus_id/70450239521,,70450239521,145752,p,"Scientific digital libraries, interoperability, and ontologies"
"We propose a methodology combining symbolic and numeric information to map the structure of research in Information Science between 1996-2008. The visualization of the resulting maps showed that while the two-camp structure of Information Science observed in previous studies is still valid, other research poles like web and user-oriented studies are building bridges between the two hitherto isolated poles.",0,,2-s2.0-70450273088,Conference Proceeding,2009-11-30,10.1145/1555400.1555483,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,401,http://api.elsevier.com/content/abstract/scopus_id/70450273088,,70450273088,145752,p,The landscape of information science: 1996-2008
"Eye tracking was used to analyze which elements of which screens were viewed by users searching an Online Public Access Catalog (OPAC). Eye tracking data was obtained for 32 participants performing a known-item search task. The results show that more than 30% of participants did not make effective use of screens offering additional details, and that participants who did, and found the correct answer, gazed at specific screen elements more frequently than participants who gave incorrect answers. Categories and Subject Descriptors H.3.3 Information Search and Retrieval-Selection process General Terms Experimentation, Human Factors, .",0,,2-s2.0-70450267387,Conference Proceeding,2009-11-30,10.1145/1555400.1555485,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,405,http://api.elsevier.com/content/abstract/scopus_id/70450267387,,70450267387,145752,p,Analyzing opac use with screen views and eye tracking
"The Internet Public Library (IPL) is crosswalking its metadata to Dublin Core. The quality of the crosswalked metadata will be unknown. The IPL is therefore developing a tool for metadata quality control suitable for use by LIS students who have little previous metadata quality control experience. Categories and Subject Descriptors H.3.7 Digital Libraries - collection, standards, user issues. General Terms: Design, Human Factors.",1,,2-s2.0-70450275828,Conference Proceeding,2009-11-30,10.1145/1555400.1555486,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,407,http://api.elsevier.com/content/abstract/scopus_id/70450275828,,70450275828,145752,p,A user-friendly metadata quality control tool for the internet public library
"In this poster, I address practical issues related to using IRs for personal digital collections of retired faculty members.",0,,2-s2.0-70450278661,Conference Proceeding,2009-11-30,10.1145/1555400.1555487,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,409,http://api.elsevier.com/content/abstract/scopus_id/70450278661,,70450278661,145752,p,Using an institutional repository for personal digital collections of retired faculty members
"This paper addresses an approach that integrates two different types of information resources: the Web and libraries. Our method begins from any keywords in Wikipedia, and induces related subject headings of LCSH through the Wikipedia category system.",2,,2-s2.0-70450251965,Conference Proceeding,2009-11-30,10.1145/1555400.1555488,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,411,http://api.elsevier.com/content/abstract/scopus_id/70450251965,,70450251965,145752,p,Exploitation of the Wikipedia category system for enhancing the value of LCSH
We generate lexical signatures (LSs) from web pages and ac- quire the mandatory document frequency values from three different search engine (SE) indexes. We cross-query the LSs against the two SEs they were not generated from and compare the retrieval performance by parsing the result set and analyzing the rank of the source URL.,2,,2-s2.0-70450230376,Conference Proceeding,2009-11-30,10.1145/1555400.1555489,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,413,http://api.elsevier.com/content/abstract/scopus_id/70450230376,,70450230376,145752,p,Inter-search engine lexical signature performance
"We investigate the question whether expert rankings of real- world entities correlate with search engine (SE) rankings of corresponding web resources. We compare Billboards \Hot 100 Airplay"" music charts with SE rankings of asso- ciated web resources. Out of nine comparisons we found two strong, two moderate, two weak and one negative corre- lation. The remaining two comparisons were inconclusive.",1,,2-s2.0-70450233420,Conference Proceeding,2009-11-30,10.1145/1555400.1555490,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,415,http://api.elsevier.com/content/abstract/scopus_id/70450233420,,70450233420,145752,p,Correlation of music charts and search engine rankings
"The representation of information collections needs to be optimized for human cognition. Growing information collections play a crucial role in human experiences. While documents often include rich visual components, collections, including personal collections and those generated by search engines, are typically represented lists of text-only surrogates. By concurrently invoking complementary components of human cognition, combined image-text surrogates help people to more effectively see, understand, think about, and remember information collection. This research develops algorithmic methods that use the structural context of images in HTML documents to associate meaningful text and thus derive combined image-text surrogates.",0,,2-s2.0-70549106083,Conference Proceeding,2009-12-01,10.1145/1555400.1555491,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,417,http://api.elsevier.com/content/abstract/scopus_id/70549106083,,70549106083,145752,p,Toward automatic generation of image-text document surrogates to optimize cognition
This poster describes a procedure for designing exploratory tasks for use in laboratory evaluations of information seeking interfaces. This procedure is grounded in the literature on information seeking and information retrieval and has been refined by an evaluation of four tasks designed for a study of a faceted library catalog. The procedure is intended to be extensible to generate exploratory tasks for other types of interfaces and domains.,13,,2-s2.0-70450265236,Conference Proceeding,2009-11-30,10.1145/1555400.1555492,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,419,http://api.elsevier.com/content/abstract/scopus_id/70450265236,,70450265236,145752,p,Designing exploratory search tasks for user studies of information seeking support systems
"Over the past 10-15 years, educational digital libraries (DLs) have acquired online learning resources of varying levels of granularity (e.g., from images to entire lessons) and of varying sources of authorship (e.g., grant-funded subject matter experts; K12 teachers; graduate students). The challenge is to balance collecting and providing access to online learning resources while maintaining a level of resource quality that distinguishes DLs from internet search engines. In response, many educational DL builders have established review rubrics. Although many rubrics have already been created, they are specific to each DL with little room for re-use outside of the original context. As such, our goals were 1) to synthesize the various dimensions of existing DL rubrics in order to identify a standardized set of criteria that could potentially be used by any DL with online educational resources [1] and 2) to create a review rubric for Instructional Architect (IA; http://ia.usu.edu) projects. IA is a simple, web-based authoring service that supports K12 teachers in finding and assembling online content into lessons for their classroom. To accomplish the second goal, we developed an IA-specific rubric based on prior literature; evaluated its utility and usability with middle school science and math teachers; tested reliability; and, explored how the rubric could foster teacher skills in designing learning resources. Ultimately, reviewed projects will be included in educational DLs, such as the NSDL. After creating the initial IA review rubric [2], we further modified it and conducted formative evaluations during Fall 2007-Spring 2008 with 25 participants, including K12 teachers, researchers, school library media specialists, and administrators. In Fall 2008, we conducted a summative evaluation of the rubric [3]. Participants (N=28) were part of a cohort of U.S. K-12 teachers in an online graduate program, and who completed required activities as part of an online course. Complete data were received from 17 participants. The participants took part in an online learning module in the context of learning how to use the IA and the review rubric. The results of our evaluation indicate that participants found value in the review rubric as a means to improve the quality of their projects through completing and receiving reviews. Teachers reported that before the course module they evaluated an online resource for ""fit with the curriculum, "" ""accuracy, "" ""ease of use, "" ""currency, "" ""text readability, "" and ""recommendations by others."" After participating in the module they added to their evaluation criteria: ""content quality, "" ""distractions on the resource pages, "" ""credibility of the site, "" and ""will it engage participants."" Many of the criteria they added were items listed in the review rubric. Thus, it appeared that use of the rubric helped refine participants' approach to designing learning resources. Participants reported that using the rubric and rating their peers projects helped them be more thoughtful when creating their own online learning resources. Future work will include creating a workflow for using an external review committee to evaluate projects for inclusion into the National Science Digital Library.",3,,2-s2.0-70450267386,Conference Proceeding,2009-11-30,10.1145/1555400.1555493,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,421,http://api.elsevier.com/content/abstract/scopus_id/70450267386,,70450267386,145752,p,Developing a review rubric for learning resources in digital libraries
"Much has been written about the lifecycle of digital objects. This study is instead concerned with the lifecycle of collections and associated services. Online collection environments are built to fulfill specific collecting objectives and constraints. If a collection proves useful within its original hosting environment, it will often be necessary or desirable to move the collection to new environments, in order to support new forms of use and reaggregation or extract resources from legacy data environments. Such a transformation can be extremely expensive, challenging and prone to error, especially if the collections include complex internal structures and services. When ""services make the repository"" moving raw data from one location to another will often not be sufficient. Digital curators can pre-empt costly and problematic system migration efforts by integrating collections into environments specifically designed to support long-term preservation, scalability and interoperability. We report on an integration of content and functionality of a feature-rich collecting environment (ContextMiner) into a robust data curation environment (iRODS).",4,,2-s2.0-70450228403,Conference Proceeding,2009-11-30,10.1145/1555400.1555494,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,423,http://api.elsevier.com/content/abstract/scopus_id/70450228403,,70450228403,145752,p,From harvesting to cultivating: Transformation of a web collecting system into a robust curation environment
"While many research projects in the world have been addressing challenges posed by digital preservation, digital libraries in China have their own native problems that have never been addressed before. Similar problems may occur in other countries, and their memory institutions may be less prepared to handle them. This poster analyses the requirements and challenges of digital libraries in China and describes an integrated and flexible digital preservation system - AOMS.",2,,2-s2.0-70450274986,Conference Proceeding,2009-11-30,10.1145/1555400.1555495,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,425,http://api.elsevier.com/content/abstract/scopus_id/70450274986,,70450274986,145752,p,A semi-automatic system for managing multiple digital preservation risks of digital libraries in China
"In this paper, we undertake a study of inexperienced information seeking scholars, identifying areas for improvement in their electronic information seeking and document triage process[3]. We propose a software aid, currently under development.",1,,2-s2.0-70450267382,Conference Proceeding,2009-11-30,10.1145/1555400.1555496,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,427,http://api.elsevier.com/content/abstract/scopus_id/70450267382,,70450267382,145752,p,What patrons want: supporting interaction for novice information seeking scholars
"The poster presents the concept, implementation and practical application of the OAI-PMH protocol extension which allows OAI-PMH service providers to dynamically create and harvest sets of items from OAI-PMH data providers. The implementation of the presented concept is based on the encoding of dynamic set specifications in OAI-PMH requests with the CQL language. The extension was developed and widely applied in Poland and now it is used in several projects funded by the European Commission.",3,,2-s2.0-70450260483,Conference Proceeding,2009-11-30,10.1145/1555400.1555497,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,429,http://api.elsevier.com/content/abstract/scopus_id/70450260483,,70450260483,145752,p,Selective harvesting of regional digital libraries and national metadata aggregators
This poster reports on user searching behavior within two information gateways developed at the University of Illinois at Urbana-Champaign Library. These gateways are built around a locally developed metasearch engine and are designed to assist users with search query formulation and modification. Search behavior data is being collected in custom transaction logs that gather user search arguments along with any system actions and contextual search assistance suggestions.,0,,2-s2.0-70450257577,Conference Proceeding,2009-11-30,10.1145/1555400.1555498,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,431,http://api.elsevier.com/content/abstract/scopus_id/70450257577,,70450257577,145752,p,User search behaviors within a library gateway
"Fish species identification is critical to the study of fish ecology and management of fisheries. However, learning to identify fish is difficult for Ichthyology students. Traditionally, dichotomous keys are used for fish identification. They ask questions about the observed specimen, and then, based on the answer, ask more questions until the specimen is identified. This rigid approach does not accommodate the range of learning styles actually utilized by Ichthyology students. Further, keys often differ from distinguishing characteristics of fishes such as ""spinous dorsal fin"", ""forked tail"", ""large eye"", etc. This leads students to supplement the use of keys with other methods such as making personal notes and drawings, annotating fish images, and more recently, using fish information websites, such as Fishbase. Although these methods provide useful additional content, this content is dispersed across heterogeneous sources and can be tedious to manage and access. From a digital library (DL) perspective, we believe that electronic support for fish species identification can be improved considerably to address some of the aforementioned problems. There are many issues to consider, including better support for: 1) describing and accessing fish images; 2) easily managing and accessing user created content, especially that related to parts of images such as markings on drawings and images and associated notes; 3) easily sharing all of this information with others; and 4) a well-integrated solution, providing all of the above listed capabilities. Digital libraries researchers have been working on providing such integrated support for managing and accessing multimedia along with user created content, including annotating digital objects. We are working toward general solutions for DLs, running on popular platforms including DSpace and Fedora, and allowing those in a wide range of disciplines to ""mark"" important parts of digital objects, connect annotations with them, and manage the annotations inside the DL so that users can browse, search, and have objects rendered in the right environment with appropriate annotations. We developed SuperlDR, a small DL with image description and retrieval, providing such integrated support. Su- perlDR enables a user to add content in the form of image markings and annotations. In addition, it provides improved image searching: 1) through text-based search on species descriptions and annotations, where the query could be terms, phrases, or their boolean combination; or 2) through content-based image search on images and annotated-image-marks, where the query could be a complete image or part of an image. Finally, in SuperlDR, a user can browse through species information either through a taxonomic organization of species based on family and genera, or through an electronic version of the dichotomous key. In order to assess the effectiveness of SuperlDR as an aid to species identification, we conducted an experiment in an undergraduate Ichthyology class, where we compared the use of SuperlDR with traditional methods of species identification (either by using the key, personal notes, markings on images, use of websites, notecards, etc., or a combination of the aforementioned methods). We found that students identified more unknown fish specimens correctly with SuperlDR than with traditional methods. Through statistical analysis of sample data, we were able to conclude that the use of SuperlDR yielded a higher likelihood of success in species identification than does the use of traditional methods. We have made improvements to SuperlDR based on feedback received, and will be making it available to download. A natural extension of this system is to make it web-enabled, thus supporting content-sharing across data and user (social) networks. We used fish species identification as the specific scholarly task to situate our research ideas. However, we believe that our work is applicable to any scholarly task/domain involving images with a significant number of details, such as analyzing paintings in art history, examining a building style in architecture, understanding trees in dendrology, etc., , .",0,,2-s2.0-70450278654,Conference Proceeding,2009-11-30,10.1145/1555400.1555500,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,435,http://api.elsevier.com/content/abstract/scopus_id/70450278654,,70450278654,145752,p,Species identification: Fish images with CBIR and annotations
"A tension exists between making digitized resources available to users quickly and providing detailed, item-level metadata and semantic markup that make those resources more discoverable. The Our Americas Archive Partnership (OAAP) project, funded by IMLS in the fall of 2007, is facing these challenges as the project progresses. This poster presents a summary of our approach and future thoughts about descriptive approaches for digital resources.",0,,2-s2.0-70450263270,Conference Proceeding,2009-11-30,10.1145/1555400.1555502,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,439,http://api.elsevier.com/content/abstract/scopus_id/70450263270,,70450263270,145752,p,Metababble: A clash of metadata cultures
"This poster evaluates the OAI-ORE specifications through experiments providing access to the JSTOR digital archive and the Flickr website. A browser-based dynamic graph visualization tool was designed and tested to determine if making the topology of the information available would provide end-user benefits in terms of navigation and discovery., , .",1,,2-s2.0-70450242635,Conference Proceeding,2009-11-30,10.1145/1555400.1555503,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,441,http://api.elsevier.com/content/abstract/scopus_id/70450242635,,70450242635,145752,p,Evaluation of OAI-ORE via large-scale information topology visualization
"This poster, from angels of subjects, authors' social network, authors' combination, and students' plagiarism law, apply self-developed ROST Anti-plagiarism Software to check 3781 papers, do a survey among 450 students, quantitatively analyzed academic plagiarism conditions in China, and draw several conclusions.",1,,2-s2.0-70450269274,Conference Proceeding,2009-11-30,10.1145/1555400.1555504,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,443,http://api.elsevier.com/content/abstract/scopus_id/70450269274,,70450269274,145752,p,Empirical analysis on Chinese academic plagiarism
"The next generation of eLearning systems should tailor the learning experience to each individual's learning needs and preferences. PEDAL-NG is a system that supports personalization in an existing, operational eLearning environment, based on prior knowledge and the learning style of users. It is built as a front-end of an existing LMS. The prototype is tested by a group of students. The test results are favorable regarding the personalized course and give valuable feedback for future research.",1,,2-s2.0-70450245127,Conference Proceeding,2009-11-30,10.1145/1555400.1555505,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,445,http://api.elsevier.com/content/abstract/scopus_id/70450245127,,70450245127,145752,p,Adaptive personalized elearning on top of existing LCMS
"Domain-specialized digital collections have been growing rapidly in recent years. A good understanding of how users interact with such collections to accomplish domain-specific information tasks would help inform the design of effective systems. This study investigates users' interaction with a Web-based botanical collection by examining search logs recorded during an experiment. The findings indicate that while users' interactions with such collections demonstrate similar characteristics to those with general purpose search systems, they also demonstrate a domain- and task-specific nature.",0,,2-s2.0-70450249992,Conference Proceeding,2009-11-30,10.1145/1555400.1555506,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,447,http://api.elsevier.com/content/abstract/scopus_id/70450249992,,70450249992,145752,p,User search characteristics on a specialized digital collection for domain- and task-specific information
"MetRe is a prototype interface and service designed to support the metadata revision process. Improving consistency of metadata records within an environment is a common repository management task, due to potential for user error when submitting, as well as of other sources of error, such as systematic error resulting from the chosen deposit process. Evidence to support the metadata correction process may be gathered by automated metadata extraction tools, evidence from within the repository, or by comparison with best practice across the repository landscape. MetRe (Metadata Revision) is a prototype demonstrator that is able to identify several characteristic classes of error, twinned with an interface able to highlight several types of individual and systematic error, including a notion of local (intra-repository) and general (inter-repository) best practice.",0,,2-s2.0-70450245125,Conference Proceeding,2009-11-30,10.1145/1555400.1555507,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,449,http://api.elsevier.com/content/abstract/scopus_id/70450245125,,70450245125,145752,p,MetRe: Supporting the metadata revision process
"Hyperlinks are so useful for searching and browsing modern digital collections that researchers have longer wondered if it is possible to retroactively add hyperlinks to digitized historical documents. There has already been significant research into this endeavor for historical text; however, in this work we consider the problem of adding hyperlinks among graphic elements. While such a system would not have the ubiquitous utility of text-based hyperlinks, there are several domains where it can potentially significantly augment textual information.",0,,2-s2.0-70450265231,Conference Proceeding,2009-11-30,10.1145/1555400.1555508,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,451,http://api.elsevier.com/content/abstract/scopus_id/70450265231,,70450265231,145752,p,Finding centuries-old hyperlinks with a novel semi-supervised learning technique
"Recently, literature analysis has become a hot issue in academic studies. In order to quantify the importance of journals and provide researchers with target vehicles for their work, this poster proposes a novel approach based on the social information through considering the potential relationship between journals quality and authors' affiliation. Based on the formula proposed in this work, the importance of journals can be estimated and ranked.",1,,2-s2.0-70450267377,Conference Proceeding,2009-11-30,10.1145/1555400.1555509,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,453,http://api.elsevier.com/content/abstract/scopus_id/70450267377,,70450267377,145752,p,Journal ranking based on social information
"With support from the National Science Foundation, researchers at Virginia Tech and the University of North Carolina developed a curriculum framework and a number of modules for instruction in the area of digital libraries. In 2008, 15 different modules were field tested by 11 instructors at 10 different institutions. As might be expected, instructors adapted these modules to fit the context of their courses, some of which are described here.",0,,2-s2.0-70450245126,Conference Proceeding,2009-11-30,10.1145/1555400.1555510,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,455,http://api.elsevier.com/content/abstract/scopus_id/70450245126,,70450245126,145752,p,The variety of ways in which instructors implement a modular digital library curriculum
"Recommendation systems have been proven to reduce the time and effort required by users to find relevant items, but there are only sporadic reports on their application in digital libraries. The General Recommendation Engine (GRE) is composed of the text search system Lucene augmented by the well-understood content based and collaborative filtering techniques and the first application of knowledge based recommendation in digital libraries to recommend items from 22 National Science Digital Library collections. In this study comprised of 60 subjects, the GRE statistically outperformed the baseline system Lucene in all areas of evaluation.",1,,2-s2.0-70450275820,Conference Proceeding,2009-11-30,10.1145/1555400.1555511,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,457,http://api.elsevier.com/content/abstract/scopus_id/70450275820,,70450275820,145752,p,GRE: Hybrid recommendations for NSDL collections
This paper describes the initial deposits in The Videogame Archive at the Center for American History at the University of Texas at Austin.,0,,2-s2.0-70450277129,Conference Proceeding,2009-11-30,10.1145/1555400.1555512,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,459,http://api.elsevier.com/content/abstract/scopus_id/70450277129,,70450277129,145752,p,Archiving the videogame industry: Collecting primary materials of new media artifacts
"In a university library, students from different background are connected by co-borrowing behaviors which form a knowledge sharing network. This poster presents a novel idea to study the users' book-loan behavior patterns (knowledge sharing patterns) from the social network perspective which enable us to understand the patterns in both the macro-level and micro-level analysis.",5,,2-s2.0-70450228393,Conference Proceeding,2009-11-30,10.1145/1555400.1555513,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,461,http://api.elsevier.com/content/abstract/scopus_id/70450228393,,70450228393,145752,p,Analyzing user's book-loan behaviors in peking university library from social network perspective
"This extended abstract describes a digital music stand in- tegrated with the Greenstone digital library software. It features text annotation and an animated fast-to-slow page wipe. Figure 1 illustrates both these features, although it is best appreciated in a live demonstration. Digital annota- tion provides a non-destructive alternative to a musician's habit of penciling in notes. In Figure 1, slightly over half way down the page, there is a note to watch the fingering. A user can have as many of these as they like, positioned anywhere on the page. The animated page wipe alleviates (somewhat) the issue of when to turn to the next page. Unlike its physical coun- terpart, where turning to the next page means you can no longer see the current page, with a digital music stand the next page can gradually be overlaid. The page transition occurring in Figure 1 can be seen as a marked horizontal bar not quite half-way down the page. The speed of the wipe is initially fast, but when it reaches the point where the scroll-bar marker is on the right-hand side of the page, it slows down significantly. This is to give the musician time to finishing playing the last line of the current page. In the event they have already finished playing that line, they will have naturally moved on to playing the top of the next page (which is already displayed). Rather than adopt a traditional client-side ""helper"" ap- plication for the digital music stand, we have integrated it within Greenstone using AJAX. For instance: next and pre- vious pages are asynchronously loaded in the background; when generating a page, the dimensions of the user's screen is sent to the DL server so it can produce a version that max- imizes the available space; and interactions such as adding an annotation, or altering the position of the animation- break are immediately stored as metadata associated with that document. Initially the animated page breaks are set to be between the last two staff systems. This is accom- plished as part of the DL ingest process, leveraging off the staff detection step of Optical Music Recognition software.",2,,2-s2.0-70450228391,Conference Proceeding,2009-11-30,10.1145/1555400.1555515,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,463,http://api.elsevier.com/content/abstract/scopus_id/70450228391,,70450228391,145752,p,An ajax-based digital music stand for greenstone
"Densho is a nonprofit organization started in 1996 with the goal of documenting oral histories from Japanese Americans who were incarcerated during World War II. The HistoryMakers is a nonprofit established in 1999 with the goal of documenting video life oral history interviews highlighting the accomplishments of individual African Americans and African-American-led groups and movements. Both collections share the goal of broader, deeper use of the oral history content through digitization and automated processing where appropriate. This demonstration showcases the application of Carnegie Mellon Informedia digital video library processing and interfaces to enhance access into the interview segments.",1,,2-s2.0-70450285098,Conference Proceeding,2009-11-30,10.1145/1555400.1555516,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,465,http://api.elsevier.com/content/abstract/scopus_id/70450285098,,70450285098,145752,p,Accessing the densho and historymakers oral history collections via informedia technologies
"This paper describes techniques for automatically extracting and classifying maps found within articles. The process uses image analysis to find text in maps, document structure to find captions and titles, and then text mining to assign each map to a subject category, a geographical place, and a time period. The text analysis is based on authority lists taken from gazetteers and from library classifications.",0,,2-s2.0-70450231516,Conference Proceeding,2009-11-30,10.1145/1555400.1555517,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,467,http://api.elsevier.com/content/abstract/scopus_id/70450231516,,70450231516,145752,p,Text mining for indexing
"The Our Americas Archive Partnership (OAAP) project is in year 2 of a 3-year IMLS funded grant led by Rice University in Partnership with the University of Maryland's Maryland Institute for Technology in the Humanities (MITH). Designed to meet the needs of American studies scholars researching the Americas from a hemispheric perspective, OAAP is developing an integrated framework for the discovery of digital resources that are managed in heterogeneous distributed repositories. This demonstration will show the current state of the project's common interface to support resource discovery.",0,,2-s2.0-70450249991,Conference Proceeding,2009-11-30,10.1145/1555400.1555518,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,469,http://api.elsevier.com/content/abstract/scopus_id/70450249991,,70450249991,145752,p,Our Americas archive partnership demonstration
"In Second Life (SL), a popular general-purpose 3D virtual world, we are supporting the Digital Library community in a variety of ways, including through virtual poster sessions. This brings together the interests of those involved in JCDL 2009, IEEETCDL, and NSF-supported work in SL aimed to assist education, training, and dissemination in the digital preservation area.",3,,2-s2.0-70450269267,Conference Proceeding,2009-11-30,10.1145/1555400.1555520,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,473,http://api.elsevier.com/content/abstract/scopus_id/70450269267,,70450269267,145752,p,Virtual DL poster sessions in second life
"collections of materials suitable for inclusion in digital libraries. While limited funding can be allocated over time to digitize paper-based materials, those stored upon magnetic media often suffer from decay, and threaten the loss of the original. The School of Information embarked upon a major expansion of its digitization curriculum as the result of an IMLS grant received in 2004. Facilities were constructed and curriculum was designed, developed, and successfully implemented, using a team-based teaching approach. Extensive efforts were made to utilize university archival materials in the curriculum with some success, but other factors led to changes in the curriculum, and the abandonment of hands-on digitization of university materials. Since 2001, the School of Information has maintained a working relationship with the Conservation History Association of Texas, a 501c non-profit organization dedicated to capturing oral history interviews with Texas conservation pioneers. Students at the School helped develop the ""Texas Legacy"" website to make this information available to scholars, researchers, and the general public, and the video interviews and archives are housed at the Dolph Briscoe Center for American History at UT. In 2006, Quinn Stewart and Grete Pasch created the ""Creating and Using Digital Media Collections"" course, and began creating rich-media resources from a video collection. Rich-media tutorials were created to teach students how to use the Glifos rich-media authoring tools, and various user interfaces were created and evaluated for the collection. In 2007, another section of the course taught by Gary Geisler processed the initial twelve interviews from the Texas Legacy collection. The Glifos digital library software allows the synchronization of the interview text transcripts with the video footage, and students prepared tables of contents and geographic location indices integrated with Google Earth for each interview. The software allows for searching both within each interview, and across the entire collection, as well as synchronized annotations. Based upon the success of the richmedia tutorials developed for the course, and faced with over 250 hours of remaining content, Stewart approached Philip Doty and Luis Francisco-Revilla about incorporating the project into their core course ""Uses and Users of Information"" which encompassed some 60 students. Francisco-Revilla wrote a text-preprocessing program to assist with ingesting transcripts into the Glifos software, while Stewart encoded and made available some 60 hours of online video content. Using the rich-media tutorial, each student was responsible for synchronizing the transcript to a onehour video interview, creating a table of contents, and creating a geographic index linked to Google Earth for each interview. All students were able to complete the project successfully, and students processed another 50+ hours in fall 2008, with another 60 hours underway in spring 2009. Through this assignment, students are exposed to a wide variety of technology tasks required to create a digital rich-media collection, as well as augment a large university collection. By working with digital surrogate files, handling the original artifact is unnecessary, and greatly enhanced access can be provided to the materials in the online rich-media format. Use of an online rich-media tutorial provides 24/7 access to resources necessary to complete the project, and preserves valuable class time for other purposes. In addition to the technical skills learned by the students, Doty and Francisco-Revilla worked to incorporate the video interviews into their curriculum, and guided students to create additional resources for the collection for various user communities. Using university archival materials in digital library education is a complex process, requiring informed management, mutual trust, willing faculty, and recognition of the fact that with magnetic media there is often little to lose if something is not done. The use of digital surrogates allows students to work on real-world projects that often would go undone given the funding levels of university archives. By providing greatly enhanced access to richmedia collections, it is hoped that greater attention will come to these collections, perhaps improving funding sources for the preservation of these collections.",1,,2-s2.0-70450251949,Conference Proceeding,2009-11-30,10.1145/1555400.1555522,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,477,http://api.elsevier.com/content/abstract/scopus_id/70450251949,,70450251949,145752,p,Using university collections in digital library education
"We demonstrate a prototype Curriculum Customization Service designed and developed with significant teacher input. This prototype illustrates a model for embedding digital library resources into mainstream classroom use. A 10 week pilot study suggests that this Service can increase teachers' use of digital library resources in their class, and encourage them to use resources to customize instruction.",2,,2-s2.0-70450228385,Conference Proceeding,2009-11-30,10.1145/1555400.1555523,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,479,http://api.elsevier.com/content/abstract/scopus_id/70450228385,,70450228385,145752,p,A curriculum customization service
"We propose a new document container format (XEB?, eXtensible Electronic Book) based on block mechanism to efficiently process markup language documents in handheld devices. And random document access is also supported in the format through a pagination mechanism. The format has already been applied to a number of handheld devices' Chinese E-book readers and XEB documents can be downloaded from a Chinese E-book store1.",0,,2-s2.0-70450283988,Conference Proceeding,2009-11-30,10.1145/1555400.1555524,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,481,http://api.elsevier.com/content/abstract/scopus_id/70450283988,,70450283988,145752,p,XEB: A markup language document container format suitable for handheld devices
"We introduce our QA system AskDragon which employs a novel lightweight local context analysis technique to handling two broad classes of factoid questions, entity and numeric questions. The local context analysis module dramatically improves the efficiency of QA systems without sacrificing high accuracy performance.",0,,2-s2.0-70450230366,Conference Proceeding,2009-11-30,10.1145/1555400.1555525,,9781605586977,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,483,http://api.elsevier.com/content/abstract/scopus_id/70450230366,,70450230366,145752,p,AskDragon: A redundancy-based factoid question answering system with lightweight local context analysis
"As Digital Libraries (DL) become more aligned with the web architecture, their functional components need to be fundamentally rethought in terms of URIs and HTTP. Annotation, a core scholarly activity enabled by many DL solutions, exhibits a clearly unacceptable characteristic when existing models are applied to the web: due to the representations of web resources changing over time, an annotation made about a web resource today may no longer be relevant to the representation that is served from that same resource tomorrow. We assume the existence of archived versions of resources, and combine the temporal features of the emerging Open Annotation data model with the capability offered by the Memento framework that allows seamless navigation from the URI of a resource to archived versions of that resource, and arrive at a solution that provides guarantees regarding the persistence of web annotations over time. More specifically, we provide theoretical solutions and proof-of-concept experimental evaluations for two problems: reconstructing an existing annotation so that the correct archived version is displayed for all resources involved in the annotation, and retrieving all annotations that involve a given archived version of a web resource. © 2010 ACM.",19,,2-s2.0-77955099767,Conference Proceeding,2010-08-05,10.1145/1816123.1816125,10,9781450300858,,1-10,Proceedings of the ACM International Conference on Digital Libraries,1,http://api.elsevier.com/content/abstract/scopus_id/77955099767,,77955099767,62702,p,Making web annotations persistent over time
"We present here a method for automatically projecting structural information across translations, including canonical citation structure (such as chapters and sections), speaker information, quotations, markup for people and places, and any other element in TEI-compliant XML that delimits spans of text that are linguistically symmetrical in two languages. We evaluate this technique on two datasets, one containing perfectly transcribed texts and one containing error-ful OCR, and achieve an accuracy rate of 88.2% projecting 13,023 XML tags from source documents to their transcribed translations, with an 83.6% accuracy rate when projecting to texts containing uncorrected OCR. This approach has the potential to allow a highly granular multilingual digital library to be bootstrapped by applying the knowledge contained in a small, heavily curated collection to a much larger but unstructured one. © 2010 ACM.",4,,2-s2.0-77955122218,Conference Proceeding,2010-08-05,10.1145/1816123.1816126,20,9781450300858,,11-20,Proceedings of the ACM International Conference on Digital Libraries,11,http://api.elsevier.com/content/abstract/scopus_id/77955122218,,77955122218,62702,p,Transferring structural markup across translations using multilingual alignment and projection
"Digitizing legacy documents and marking them up with XML is important for many scientific domains. However, creating comprehensive semantic markup of high quality is challenging. Respective processes consist of many steps, with automated markup generation and intermediate manual correction. These corrections are extremely laborious. To reduce this effort, this paper makes two contributions: First, it proposes ProcessTron, a lightweight markup-process-control mechanism. ProcessTron assists users in two ways: It ensures that the steps are executed in the appropriate order, and it points the user to possible errors during manual correction. Second, ProcessTron has been deployed in real-world projects, and this paper reports on our experiences. A core observation is that ProcessTron more than halves the time users need to mark up a document. Results from laboratory experiments, which we have conducted as well, confirm this finding. © 2010 ACM.",0,,2-s2.0-77955110692,Conference Proceeding,2010-08-05,10.1145/1816123.1816127,28,9781450300858,,21-28,Proceedings of the ACM International Conference on Digital Libraries,21,http://api.elsevier.com/content/abstract/scopus_id/77955110692,,77955110692,62702,p,ProcessTron: Efficient semi-automated markup generation for scientific documents
"We examine the effect of modeling a researcher's past works in recommending scholarly papers to the researcher. Our hypothesis is that an author's published works constitute a clean signal of the latent interests of a researcher. A key part of our model is to enhance the profile derived directly from past works with information coming from the past works' referenced papers as well as papers that cite the work. In our experiments, we differentiate between junior researchers that have only published one paper and senior researchers that have multiple publications. We show that filtering these sources of information is advantageous - when we additionally prune noisy citations, referenced papers and publication history, we achieve statistically significant higher levels of recommendation accuracy. © 2010 ACM.",67,,2-s2.0-77955106773,Conference Proceeding,2010-08-05,10.1145/1816123.1816129,38,9781450300858,,29-38,Proceedings of the ACM International Conference on Digital Libraries,29,http://api.elsevier.com/content/abstract/scopus_id/77955106773,,77955106773,62702,p,Scholarly paper recommendation via user's recent research interests
"Name ambiguity in the context of bibliographic citation records is a hard problem that affects the quality of services and content in digital libraries and similar systems. Supervised methods that exploit training examples in order to distinguish ambiguous author names are among the most effective solutions for the problem, but they require skilled human annotators in a laborious and continuous process of manually labeling citations in order to provide enough training examples. Thus, addressing the issues of (i) automatic acquisition of examples and (ii) highly effective disambiguation even when only few examples are available, are the need of the hour for such systems. In this paper, we propose a novel two-step disambiguation method, SAND (Self-training Associative Name Disambiguator), that deals with these two issues. The first step eliminates the need of any manual labeling effort by automatically acquiring examples using a clustering method that groups citation records based on the similarity among coauthor names. The second step uses a supervised disambiguation method that is able to detect unseen authors not included in any of the given training examples. Experiments conducted with standard public collections, using the minimum set of attributes present in a citation (i.e., author names, work title and publication venue), demonstrated that our proposed method outperforms representative unsupervised disambiguation methods that exploit similarities between citation records and is as effective as, and in some cases superior to, supervised ones, without manually labeling any training example. © 2010 ACM.",38,,2-s2.0-77955097505,Conference Proceeding,2010-08-05,10.1145/1816123.1816130,48,9781450300858,,39-48,Proceedings of the ACM International Conference on Digital Libraries,39,http://api.elsevier.com/content/abstract/scopus_id/77955097505,,77955097505,62702,p,Effective self-training author name disambiguation in scholarly digital libraries
"The question of citation behavior has always intrigued scientists from various disciplines. While general citation patterns have been widely studied in the literature we develop the notion of citation projection graphs by investigating the citations among the publications that a given paper cites. We investigate how patterns of citations vary between various scientific disciplines and how such patterns reflect the scientific impact of the paper. We find that idiosyncratic citation patterns are characteristic for low impact papers; while narrow, discipline-focused citation patterns are common for medium impact papers. Our results show that crossing-community, or bridging citation patters are high risk and high reward since such patterns are characteristic for both low and high impact papers. Last, we observe that recently citation networks are trending toward more bridging and interdisciplinary forms. © 2010 ACM.",10,,2-s2.0-77955105971,Conference Proceeding,2010-08-05,10.1145/1816123.1816131,58,9781450300858,,49-58,Proceedings of the ACM International Conference on Digital Libraries,49,http://api.elsevier.com/content/abstract/scopus_id/77955105971,,77955105971,62702,p,Citing for high impact
"Missing web pages (pages that return the 404 ""Page Not Found"" error) are part of the browsing experience. The manual use of search engines to rediscover missing pages can be frustrating and unsuccessful. We compare four automated methods for rediscovering web pages. We extract the page's title, generate the page's lexical signature (LS), obtain the page's tags from the bookmarking website delicious.com and generate a LS from the page's link neighborhood. We use the output of all methods to query Internet search engines and analyze their retrieval performance. Our results show that both LSs and titles perform fairly well with over 60% URIs returned top ranked from Yahoo!. However, the combination of methods improves the retrieval performance. Considering the complexity of the LS generation, querying the title first and in case of insufficient results querying the LSs second is the preferable setup. This combination accounts for more than 75% top ranked URIs. © 2010 ACM.",10,,2-s2.0-77955099622,Conference Proceeding,2010-08-05,10.1145/1816123.1816133,68,9781450300858,,59-68,Proceedings of the ACM International Conference on Digital Libraries,59,http://api.elsevier.com/content/abstract/scopus_id/77955099622,,77955099622,62702,p,Evaluating methods to rediscover missing web pages from the web infrastructure
"Personalization of information retrieval tailors search towards individual users to meet their particular information needs by taking into account information about users and their contexts, often through implicit sources of evidence such as user behaviors. Task types have been shown to influence search behaviors including usefulness judgments. This paper reports on an investigation of user behaviors associated with different task types. Twenty-two undergraduate journalism students participated in a controlled lab experiment, each searching on four tasks which varied on four dimensions: complexity, task product, task goal and task level. Results indicate regular differences associated with different task characteristics in several search behaviors, including task completion time, decision time (the time taken to decide whether a document is useful or not), and eye fixations, etc. We suggest these behaviors can be used as implicit indicators of the user's task type. © 2010 ACM.",49,,2-s2.0-77955112126,Conference Proceeding,2010-08-05,10.1145/1816123.1816134,78,9781450300858,,69-78,Proceedings of the ACM International Conference on Digital Libraries,69,http://api.elsevier.com/content/abstract/scopus_id/77955112126,,77955112126,62702,p,Search behaviors in different task types
"Query expansion of named entities can be employed in order to increase the retrieval effectiveness. A peculiarity of named entities compared to other vocabulary terms is that they are very dynamic in appearance, and synonym relationships between terms change with time. In this paper, we present an approach to extracting synonyms of named entities over time from the whole history of Wikipedia. In addition, we will use their temporal patterns as a feature in ranking and classifying them into two types, i.e., time-independent or time-dependent. Time-independent synonyms are invariant to time, while time-dependent synonyms are relevant to a particular time period, i.e., the synonym relationships change over time. Further, we describe how to make use of both types of synonyms to increase the retrieval effectiveness, i.e., query expansion with time-independent synonyms for an ordinary search, and query expansion with time-dependent synonyms for a search wrt. temporal criteria. Finally, through an evaluation based on TREC collections, we demonstrate how retrieval performance of queries consisting of named entities can be improved using our approach. © 2010 ACM.",21,,2-s2.0-77955102954,Conference Proceeding,2010-08-05,10.1145/1816123.1816135,88,9781450300858,,79-88,Proceedings of the ACM International Conference on Digital Libraries,79,http://api.elsevier.com/content/abstract/scopus_id/77955102954,,77955102954,62702,p,Exploiting time-based synonyms in searching document archives
"Word sense discrimination is the first, important step towards automatic detection of language evolution within large, historic document collections. By comparing the found word senses over time, we can reveal and use important information that will improve understanding and accessibility of a digital archive. Algorithms for word sense discrimination have been developed while keeping today's language in mind and have thus been evaluated on well selected, modern datasets. The quality of the word senses found in the discrimination step has a large impact on the detection of language evolution. Therefore, as a first step, we verify that word sense discrimination can successfully be applied to digitized historic documents and that the results correctly correspond to word senses. Because accessibility of digitized historic collections is influenced also by the quality of the optical character recognition (OCR), as a second step we investigate the effects of OCR errors on word sense discrimination results. All evaluations in this paper are performed on The Times Archive, a collection of newspaper articles from 1785 - 1985. © 2010 ACM.",7,,2-s2.0-77955114448,Conference Proceeding,2010-08-05,10.1145/1816123.1816137,98,9781450300858,,89-98,Proceedings of the ACM International Conference on Digital Libraries,89,http://api.elsevier.com/content/abstract/scopus_id/77955114448,,77955114448,62702,p,Using word sense discrimination on historic document collections
"Manifesting the handwriting characters with the specific style of a famous artwork is fascinating. In this paper, a system is built to render the user's handwriting characters with a specific style. A stroke database is established firstly. When rendering a character, the strokes are extracted and recognized, then proper radicals and strokes are filtered, finally these strokes are deformed and the result is generated. The Special Nine Grid (SNG) is presented to help recognize radicals and strokes. The Rule-base Stroke Deformation Algorithm (RSDA) is proposed to deform the original strokes according to the handwriting strokes. The rendering result manifests the specific style with high quality. It is feasible for people to generate the tablet or other artworks with the proposed system. © 2010 ACM.",13,,2-s2.0-77955121161,Conference Proceeding,2010-08-05,10.1145/1816123.1816138,108,9781450300858,,99-108,Proceedings of the ACM International Conference on Digital Libraries,99,http://api.elsevier.com/content/abstract/scopus_id/77955121161,,77955121161,62702,p,Chinese calligraphy specific style rendering system
"The Bleek and Lloyd Collection is a collection of artefacts documenting the life and language of the Bushman people of southern Africa in the 19th century. Included in this collection is a handwritten dictionary that contains English words and their corresponding |xam Bushman language translations. This dictionary allows for the manual translation of |xam words that appear in the notebooks of the Bleek and Lloyd collection. This, however, is not practical due to the size of the dictionary, which contains over 14000 entries. To solve this problem a content-based image retrieval system was built that allows for the selection of a |xam word from a notebook and returns matching words from the dictionary. The system shows promise with some search keys returning relevant results. © 2010 ACM.",3,,2-s2.0-77955103247,Conference Proceeding,2010-08-05,10.1145/1816123.1816139,118,9781450300858,,109-118,Proceedings of the ACM International Conference on Digital Libraries,109,http://api.elsevier.com/content/abstract/scopus_id/77955103247,,77955103247,62702,p,Translating handwritten Bushman texts
"Wikipedia is one of the most successful online knowledge bases, attracting millions of visits daily. Not surprisingly, its huge success has in turn led to immense research interest for a better understanding of the collaborative knowledge building process. In this paper, we performed a (terrorism) domain-specific case study, comparing and contrasting the knowledge evolution in Wikipedia with a knowledge base created by domain experts. Specifically, we used the Terrorism Knowledge Base (TKB) developed by experts at MIPT. We identified 409 Wikipedia articles matching TKB records, and went ahead to study them from three aspects: creation, revision, and link evolution. We found that the knowledge building in Wikipedia had largely been independent, and did not follow TKB - despite the open and online availability of the latter, as well as awareness of at least some of the Wikipedia contributors about the TKB source. In an attempt to identify possible reasons, we conducted a detailed analysis of contribution behavior demonstrated by Wikipedians. It was found that most Wikipedians contribute to a relatively small set of articles each. Their contribution was biased towards one or very few article(s). At the same time, each article's contributions are often championed by very few active contributors including the article's creator. We finally arrive at a conjecture that the contributions in Wikipedia are more to cover knowledge at the article level rather than at the domain level. © 2010 ACM.",8,,2-s2.0-77955101412,Conference Proceeding,2010-08-05,10.1145/1816123.1816141,128,9781450300858,,119-128,Proceedings of the ACM International Conference on Digital Libraries,119,http://api.elsevier.com/content/abstract/scopus_id/77955101412,,77955101412,62702,p,Do wikipedians follow domain experts?: A domain-specific study on wikipedia knowledge building
"Space and time are important dimensions in the representation of a large number of concepts. However there exists no available resource that provides spatiotemporal mappings of generic concepts. Here we present a link-analysis based method for extracting the main locations and periods associated to all Wikipedia concepts. Relevant locations are selected from a set of geotagged articles, while relevant periods are discovered using a list of people with associated life periods. We analyze article versions over multiple languages and consider the strength of a spatial/temporal reference to be proportional to the number of languages in which it appears. To illustrate the utility of the spatiotemporal mapping of Wikipedia concepts, we present an analysis of cultural interactions and a temporal analysis of two domains. The Wikipedia mapping can also be used to perform rich spatiotemporal document indexing by extracting implicit spatial and temporal references from texts. © 2010 ACM.",7,,2-s2.0-77955099625,Conference Proceeding,2010-08-05,10.1145/1816123.1816142,138,9781450300858,,129-138,Proceedings of the ACM International Conference on Digital Libraries,129,http://api.elsevier.com/content/abstract/scopus_id/77955099625,,77955099625,62702,p,Spatiotemporal mapping of Wikipedia concepts
"The ""wisdom of crowds"" is accomplishing tasks that are cumbersome for individuals yet cannot be fully automated by means of specialized computer algorithms. One such task is the construction of thesauri and other types of concept hierarchies. Human expert feedback on the relatedness and relative generality of terms, however, can be aggregated to dynamically construct evolving concept hierarchies. The InPhO (Indiana Philosophy Ontology) project bootstraps feedback from volunteer users unskilled in ontology design into a precise representation of a specific domain. The approach combines statistical text processing methods with expert feedback and logic programming to create a dynamic semantic representation of the discipline of philosophy. In this paper, we show that results of comparable quality can be achieved by leveraging the workforce of crowdsourcing services such as the Amazon Mechanical Turk (AMT). In an extensive empirical study, we compare the feedback obtained from AMT's workers with that from the InPhO volunteer users providing an insight into qualitative differences of the two groups. Furthermore, we present a set of strategies for assessing the quality of different users when gold standards are missing. We finally use these methods to construct a concept hierarchy based on the feedback acquired from AMT workers. © 2010 ACM.",25,,2-s2.0-77955108670,Conference Proceeding,2010-08-05,10.1145/1816123.1816143,148,9781450300858,,139-148,Proceedings of the ACM International Conference on Digital Libraries,139,http://api.elsevier.com/content/abstract/scopus_id/77955108670,,77955108670,62702,p,Crowdsourcing the assembly of concept hierarchies
"We describe the evaluation of a personal digital library environment designed to help musicians capture, enrich and store their ideas using a spatial hypermedia paradigm. The target user group is musicians who primarily use audio and text for composition and arrangement, rather than with formal music notation. Using the principle of user-centered design, the software implementation was guided by a diary study involving nine musicians which suggested five requirements for the software to support: capturing, overdubbing, developing, storing, and organizing. Moreover, the underlying spatial data-model was exploited to give raw audio compositions a hierarchical structure, and - to aid musicians in retrieving previous ideas - a search facility is available to support both query by humming and text-based queries. A user evaluation of the completed design with eleven subjects indicated that musicians, in general, would find the hypermedia environment useful for capturing and managing their moments of musical creativity and exploration. More specifically they would make use of the query by humming facility and the hierarchical track organization, but not the overdubbing facility as implemented. © 2010 ACM.",4,,2-s2.0-77955115062,Conference Proceeding,2010-08-05,10.1145/1816123.1816145,158,9781450300858,,149-158,Proceedings of the ACM International Conference on Digital Libraries,149,http://api.elsevier.com/content/abstract/scopus_id/77955115062,,77955115062,62702,p,A user-centered design of a personal digital library for music exploration
"Mood is an emerging metadata type and access point in music digital libraries (MDL) and online music repositories. In this study, we present a comprehensive investigation of the usefulness of lyrics in music mood classification by evaluating and comparing a wide range of lyric text features including linguistic and text stylistic features. We then combine the best lyric features with features extracted from music audio using two fusion methods. The results show that combining lyrics and audio significantly outperformed systems using audio-only features. In addition, the examination of learning curves shows that the hybrid lyric + audio system needed fewer training samples to achieve the same or better classification accuracies than systems using lyrics or audio singularly. These experiments were conducted on a unique large-scale dataset of 5,296 songs (with both audio and lyrics for each) representing 18 mood categories derived from social tags. The findings push forward the state-of-the-art on lyric sentiment analysis and automatic music mood classification and will help make mood a practical access point in music digital libraries. © 2010 ACM.",45,,2-s2.0-77955115533,Conference Proceeding,2010-08-05,10.1145/1816123.1816146,168,9781450300858,,159-168,Proceedings of the ACM International Conference on Digital Libraries,159,http://api.elsevier.com/content/abstract/scopus_id/77955115533,,77955115533,62702,p,Improving mood classification in music digital libraries by combining lyrics and audio
This paper describes the use of relational database management system (RDBMS) and treemap visualization to represent and analyze a group of personal digital collections created in the context of work and with no external metadata. We evaluated the visualization vis a vis the results of previous personal information management (PIM) studies. We suggest that this visualization supports analysis that allows understanding PIM practices overtime. © 2010 ACM.,4,,2-s2.0-77955104106,Conference Proceeding,2010-08-05,10.1145/1816123.1816147,172,9781450300858,,169-172,Proceedings of the ACM International Conference on Digital Libraries,169,http://api.elsevier.com/content/abstract/scopus_id/77955104106,,77955104106,62702,p,Visualizing personal digital collections
"Digital libraries must support assistive technologies that allow people with disabilities such as blindness to use, navigate and understand their documents. Increasingly, many documents are Web-based and present their contents using complex layouts. However, approaches that translate two-dimensional layouts to one-dimensional speech produce a very different user experience and loss of information. To address this issue, we conducted a study of how blind people navigate and interpret layouts of news and shopping Web pages using current assistive technology. The study revealed that blind people do not parse Web pages fully during their first visit, and that they can miss important parts. The study also provided insights for improving assistive technologies. © 2010 ACM.",7,,2-s2.0-77955121828,Conference Proceeding,2010-08-05,10.1145/1816123.1816148,176,9781450300858,,173-176,Proceedings of the ACM International Conference on Digital Libraries,173,http://api.elsevier.com/content/abstract/scopus_id/77955121828,,77955121828,62702,p,Interpretation of web page layouts by blind users
"For open-ended information tasks, users must sift through many potentially relevant documents, a practice we refer to as document triage. Normally, people perform triage using multiple applications in concert: a search engine interface presents lists of potentially relevant documents; a document reader displays their contents; and a third tool - a text editor or personal information management application - is used to record notes and assessments. To support document triage, we have developed an extensible multi-application architecture that initially includes an information workspace and a document reader. An Interest Profile Manager infers users' interests from their interactions with the triage applications, coupled with the characteristics of the documents they are interacting with. The resulting interest profile is used to generate visualizations that direct users' attention to documents or parts of documents that match their inferred interests. The novelty of our approach lies in the aggregation of activity records across applications to generate fine-grained models of user interest. © 2010 ACM.",5,,2-s2.0-77955115660,Conference Proceeding,2010-08-05,10.1145/1816123.1816150,186,9781450300858,,177-186,Proceedings of the ACM International Conference on Digital Libraries,177,http://api.elsevier.com/content/abstract/scopus_id/77955115660,,77955115660,62702,p,Supporting document triage via annotation-based multi-application visualizations
"Photo libraries are growing in quantity and size, requiring better support for locating desired photographs. MediaGLOW is an interactive visual workspace designed to address this concern. It uses attributes such as visual appearance, GPS locations, user-assigned tags, and dates to filter and group photos. An automatic layout algorithm positions photos with similar attributes near each other to support users in serendipitously finding multiple relevant photos. In addition, the system can explicitly select photos similar to specified photos. We conducted a user evaluation to determine the benefit provided by similarity layout and the relative advantages offered by the different layout similarity criteria and attribute filters. Study participants had to locate photos matching probe statements. In some tasks, participants were restricted to a single layout similarity criterion and filter option. Participants used multiple attributes to filter photos. Layout by similarity without additional filters turned out to be one of the most used strategies and was especially beneficial for geographical similarity. Lastly, the relative appropriateness of the single similarity criterion to the probe significantly affected retrieval performance. © 2010 ACM.",8,,2-s2.0-77955103833,Conference Proceeding,2010-08-05,10.1145/1816123.1816151,196,9781450300858,,187-196,Proceedings of the ACM International Conference on Digital Libraries,187,http://api.elsevier.com/content/abstract/scopus_id/77955103833,,77955103833,62702,p,"Flexible access to photo libraries via time, place, tags, and visual features"
"We describe a novel video player that uses Temporal Semantic Compression (TSC) to present a compressed summary of a movie. Compression is based on tempo which is derived from film rhythms. The technique identifies periods of action, drama, foreshadowing and resolution, which can be mixed in different amounts to vary the kind of summary presented. The compression algorithm is embedded in a video player, so that the summary can be interactively recomputed during playback. © 2010 ACM.",1,,2-s2.0-77955122701,Conference Proceeding,2010-08-05,10.1145/1816123.1816152,200,9781450300858,,197-200,Proceedings of the ACM International Conference on Digital Libraries,197,http://api.elsevier.com/content/abstract/scopus_id/77955122701,,77955122701,62702,p,"Interactively browsing movies in terms of action, foreshadowing and resolution"
"Attending a complex scheduled social event, such as a multi-day music festival, requires a significant amount of planning before and during its progression. Advancements in mobile technology and social networks enable attendees to contribute content in realtime that can provide useful information to many. Currently access to and presentation of such information is challenging to use during an event. The Timeline Interactive Multimedia Experience (TIME) system aggregates information posted to multiple social networks and presents the flow of information in a multi-touch timeline interface. TIME was designed to be placed on location to allow real-time access to relevant information that helps attendees to make plans and navigate their crowded surroundings. © 2010 ACM.",2,,2-s2.0-77955104816,Conference Proceeding,2010-08-05,10.1145/1816123.1816153,204,9781450300858,,201-204,Proceedings of the ACM International Conference on Digital Libraries,201,http://api.elsevier.com/content/abstract/scopus_id/77955104816,,77955104816,62702,p,Timeline Interactive Multimedia Experience (TIME): On location access to aggregate event information
"We present a new algorithm to measure domain-specific readability. It iteratively computes the readability of domain-specific resources based on the difficulty of domain-specific concepts and vice versa, in a style reminiscent of other bipartite graph algorithms such as Hyperlink-Induced Topic Search (HITS) and the Stochastic Approach for Link-Structure Analysis (SALSA). While simple, our algorithm outperforms standard heuristic measures and remains competitive among supervised-learning approaches. Moreover, it is less domain-dependent and portable across domains as it does not rely on an annotated corpus or expensive expert knowledge that supervised or domain-specific methods require. © 2010 ACM.",8,,2-s2.0-77955107415,Conference Proceeding,2010-08-05,10.1145/1816123.1816155,214,9781450300858,,205-214,Proceedings of the ACM International Conference on Digital Libraries,205,http://api.elsevier.com/content/abstract/scopus_id/77955107415,,77955107415,62702,p,Domain-specific iterative readability computation
"Topic models could have a huge impact on improving the ways users find and discover content in digital libraries and search interfaces, through their ability to automatically learn and apply subject tags to each and every item in a collection, and their ability to dynamically create virtual collections on the fly. However, much remains to be done to tap this potential, and empirically evaluate the true value of a given topic model to humans. In this work, we sketch out some sub-tasks that we suggest pave the way towards this goal, and present methods for assessing the coherence and inter-pretability of topics learned by topic models. Our large-scale user study includes over 70 human subjects evaluating and scoring almost 500 topics learned from collections from a wide range of genres and domains. We show how a scoring model - based on pointwise mutual information of word-pairs using Wikipedia, Google and MEDLINE as external data sources - performs well at predicting human scores. This automated scoring of topics is an important first step to integrating topic modeling into digital libraries. © 2010 ACM.",60,,2-s2.0-77955114158,Conference Proceeding,2010-08-05,10.1145/1816123.1816156,224,9781450300858,,215-224,Proceedings of the ACM International Conference on Digital Libraries,215,http://api.elsevier.com/content/abstract/scopus_id/77955114158,,77955114158,62702,p,Evaluating topic models for digital libraries
"This paper addresses the problem of using the FRBR model to support the presentation of results. It describes a service implementing new algorithms and techniques for transforming existing MARC records into the FRBR model for this specific purpose. This work was developed in the context of the TELPlus project and processed 100,000 bibliographic and authority records from multilingual catalogs of 12 European countries. © 2010 ACM.",12,,2-s2.0-77955120624,Conference Proceeding,2010-08-05,10.1145/1816123.1816157,234,9781450300858,,225-234,Proceedings of the ACM International Conference on Digital Libraries,225,http://api.elsevier.com/content/abstract/scopus_id/77955120624,,77955120624,62702,p,FRBRization of MARC records in multiple catalogs
"In recent years, the vast amount of digitally available content has lead to the creation of many topic-centered digital libraries. Also in the domain of chemistry more and more digital collections are available, but the complex query formulation still hampers their intuitive adoption. This is because information seeking in chemical documents is focused on chemical entities, for which current standard search relies on complex structures which are hard to extract from documents. Moreover, although simple keyword searches would often be sufficient, current collections simply cannot be indexed by Web search providers due to the ambiguity of chemical substance names. In this paper we present a framework for automatically generating metadata-enriched index pages for all documents in a given chemical collection. All information is then linked to the respective documents and thus provides an easy to crawl metadata repository promising to open up digital chemical libraries. Our experiments, indexing an open access journal, show that not only the documents can be found using a simple Google search via the automatically created index pages, but also that the quality of the search is much more efficient than fulltext indexing in terms of both precision/recall and performance. Finally, we compare our indexing against a classical structure search and figured out that keyword-based search can indeed solve at least some of the daily tasks in chemical workflows. To use our framework thus promises to expose a large part of the currently still hidden chemical Web, making the techniques employed interesting for chemical information providers like digital libraries and open access journals. © 2010 ACM.",6,,2-s2.0-77955113884,Conference Proceeding,2010-08-05,10.1145/1816123.1816159,244,9781450300858,,235-244,Proceedings of the ACM International Conference on Digital Libraries,235,http://api.elsevier.com/content/abstract/scopus_id/77955113884,,77955113884,62702,p,Exposing the hidden web for chemical digital libraries
"Representing the semantics of unstructured scientific publications will certainly facilitate access and search and hopefully lead to new discoveries. However, current digital libraries are usually limited to classic flat structured metadata even for scientific publications that potentially contain rich semantic metadata. In addition, how to search the scientific literature of linked semantic metadata is an open problem. We have developed a semantic digital library oreChem ChemxSeer that models chemistry papers with semantic metadata. It stores and indexes extracted metadata from a chemistry paper repository ChemxSeer using ""compound objects"". We use the Open Archives Initiative Object Reuse and Exchange (OAI-ORE))1 standard to define a compound object that aggregates metadata fields related to a digital object. Aggregated metadata can be managed and retrieved easily as one unit resulting in improved ease-of-use and has the potential to improve the semantic interpretation of shared data. We show how metadata can be extracted from documents and aggregated using OAI-ORE. ORE objects are created on demand; thus, we are able to search for a set of linked metadata with one query. We were also able to model new types of metadata easily. For example, chemists are especially interested in finding information related to experiments in documents. We show how paragraphs containing experiment information in chemistry papers can be extracted and tagged based on a chemistry ontology with 470 classes, and then represented in ORE along with other document-related metadata. Our algorithm uses a classifier with features that are words that are typically only used to describe experiments, such as ""apparatus"", ""prepare"", etc. Using a dataset comprised of documents from the Royal Society of Chemistry digital library, we show that the our proposed method performs well in extracting experiment-related paragraphs from chemistry documents. © 2010 ACM.",11,,2-s2.0-77955100039,Conference Proceeding,2010-08-05,10.1145/1816123.1816160,253,9781450300858,,245-253,Proceedings of the ACM International Conference on Digital Libraries,245,http://api.elsevier.com/content/abstract/scopus_id/77955100039,,77955100039,62702,p,OreChem ChemXSeer: A semantic digital library for chemistry
"Converting a scanned document to a binary format (black and white) is a key step in the digitization process. While many existing binarization algorithms operate robustly for well-kept documents, these algorithms often produce less than satisfactory results when applied to old documents, especially those degraded with stains and other discolorations. For these challenging documents, user assistance can be advantageous in directing the binarization procedure. Many existing algorithms, however, are poorly designed to incorporate user assistance. In this paper, we discuss a software framework, BinarizationShop, that combines a series of bi-narization approaches that have been tailored to exploit user assistance. This framework provides a practical approach for converting difficult documents to black and white. © 2010 ACM.",5,,2-s2.0-77955109403,Conference Proceeding,2010-08-05,10.1145/1816123.1816161,258,9781450300858,,255-258,Proceedings of the ACM International Conference on Digital Libraries,255,http://api.elsevier.com/content/abstract/scopus_id/77955109403,,77955109403,62702,p,BinarizationShop: A user-assisted software suite for converting old documents to black-and-white
"Access to materials in digital collections has been extensively studied within digital libraries. Exploring a collection requires customized indices and novel interfaces to allow users new exploration mechanisms. Materials or objects can then be found by way of full-text, faceted, or thematic indexes. There has been a marked interest not only in finding objects in a collection, but in discovering relationships and properties. For example, multiple representations of the same object enable the use of visual aids to augment collection exploration. Depending on the domain and characteristics of the objects in a collection, relationships among components can be used to enrich the process of understanding their contents. In this context, the Nautical Archaeology Digital Library (NADL) includes multilingual textual- and visual-rich objects (shipbuilding treatises, illustrations, photographs, and drawings). In this paper we describe an approach for enhancing access to a collection of ancient technical documents, illustrations, and photographs documenting archaeological excavations. Because of the nature of our collection, we exploit a multilingual glossary along with an ontology. Preliminary tests of our prototype suggest the feasibility of our method for enhancing access to the collection. © 2010 ACM.",3,,2-s2.0-77955119266,Conference Proceeding,2010-08-05,10.1145/1816123.1816162,262,9781450300858,,259-262,Proceedings of the ACM International Conference on Digital Libraries,259,http://api.elsevier.com/content/abstract/scopus_id/77955119266,,77955119266,62702,p,Using an ontology and a multilingual glossary for enhancing the nautical archaeology digital library
"Digital map is getting increasingly popular as an intuitive and interactive platform for data presentation recently. Thus applications integrated with digital map have attracted much attention. But no offtheshelf systems or services could we use if the time span of maps be extended to historical ones. There are a large number of valuable ancient atlases in CADAL digital library. However, they are seldom made use of because the ones which are in image format are not convenient for users to read or search. In this paper, we propose a novel hybrid approach to utilizing these atlases directly and constructing some applications based on ancient maps. We call it CAMAME which means Chinese Ancient Maps Automatic Marking and Extraction. We create a gazetteer to store the geographic information of sites which will be project on the map, then use kernel method to do the regression and correct the estimated results with image processing and local regression methods. The empirical results show that CAMAME is effective and efficient, by which most valuable data in the map images is marked and identified. Some Chinese literary chronicle applications that exhibit ancient literary and related historical information over those digitized atlas resources in CADAL digital library were developed. © 2010 ACM.",3,,2-s2.0-77955113309,Conference Proceeding,2010-08-05,10.1145/1816123.1816164,271,9781450300858,,263-271,Proceedings of the ACM International Conference on Digital Libraries,263,http://api.elsevier.com/content/abstract/scopus_id/77955113309,,77955113309,62702,p,In-depth utilization of Chinese ancient maps: A hybrid approach to digitizing map resources in CADAL
"This paper reports an investigation into the connection of the workspace of physical libraries with digital library services. Using simple sensor technology, we provide focused access to digital resources on the basis of the user's physical context, including the topic of the stacks they are next to, and the content of books on their reading desks. Our research developed the technological infrastructure to support this fused interaction, investigated current patron behavior in physical libraries, and evaluated our system in a user-centred pilot study. The outcome of this research demonstrates the potential utility of the fused library, and provides a starting point for future exploitation. © 2010 ACM.",7,,2-s2.0-77955106114,Conference Proceeding,2010-08-05,10.1145/1816123.1816165,282,9781450300858,,273-282,Proceedings of the ACM International Conference on Digital Libraries,273,http://api.elsevier.com/content/abstract/scopus_id/77955106114,,77955106114,62702,p,The fused library: Integrating digital and physical libraries with location-aware sensors
"Despite the growing prominence of digital libraries as tools to support humanities scholars, little is known about the work practices and needs of these scholars as they pertain to working with source documents. In this paper we present our findings from a formative user study consisting of semi-structured interviews with eight scholars. We find that the use of source materials (by which we mean the original physical documents or digital facsimiles with minimal editorial intervention) in scholarship is not a simple, straightforward examination of a document in isolation. Instead, scholars study source materials as an integral part of a complex ecosystem of inquiry that seeks to understand both the text being studied and the context in which that text was created, transmitted and used. Drawing examples from our interviews, we address critical questions of why scholars use source documents and what information they hope to gain by studying them. We also briefly summarize key note-taking practices as a means for assessing the potential to design user interfaces that support scholarly work-practices. © 2010 ACM.",17,,2-s2.0-77955116081,Conference Proceeding,2010-08-05,10.1145/1816123.1816166,292,9781450300858,,283-292,Proceedings of the ACM International Conference on Digital Libraries,283,http://api.elsevier.com/content/abstract/scopus_id/77955116081,,77955116081,62702,p,What humanists want: How scholars use source materials
"Identification of contexts associated with sentences is becoming increasingly necessary for developing intelligent information retrieval systems. This article describes a supervised learning mechanism employing a conditional random field (CRF) for context identification and sentence classification. Specifically, we focus on sentences in related work sections in research articles. Based on a generic rhetorical pattern, a framework for modelling the sequential flow in these sections is proposed. Adopting a generalization strategy, each of these sentences is transformed into a set of features, which forms our dataset. We distinguish between two kinds of features for each of these sentences viz., citation features and sentence features. While an overall accuracy of 96.51% is achieved by using a combination of both citation and sentence features, the use of sentence features alone yields an accuracy of 93.22%. The results also show F-Scores ranging from 0.99 to 0.90 for various classes indicating the robustness of our application. © 2010 ACM.",13,,2-s2.0-77955098289,Conference Proceeding,2010-08-05,10.1145/1816123.1816168,302,9781450300858,,293-302,Proceedings of the ACM International Conference on Digital Libraries,293,http://api.elsevier.com/content/abstract/scopus_id/77955098289,,77955098289,62702,p,Context identification of sentences in related work sections using a conditional random field: Towards intelligent digital libraries
"Developing methods for searching image databases is a challenging and ongoing area of research. A common approach is to use manual annotations, although generating annotations can be expensive in terms of time and money, and therefore may not be justified in many situations. Content-based search techniques which extract visual features from image data can be used, but users are typically forced to express their information need using example images, or through sketching interfaces. This can be difficult if no visual example of the information need is available, or when the information need cannot be easily drawn. In this paper, we consider an alternative approach which allows a user to search for images through an intermediate database. In this approach, a user can search using text in the intermediate database as a way of finding visual examples of their information need. The visual examples can then be used to search a database that lacks annotations. Three experiments are presented which investigate this process. The first experiment automatically selects the image queries from the intermediary database; the second instead uses images which have been hand-picked by users. A third experiment, an interactive study, is then presented this study compares the intermediary interface to text search, where we consider text as an upper bound of performance. For this last study, an interface which supports the intermediary search process is described. Results show that while performance does not match manual annotations, users are able to find relevant material without requiring collection annotations. © 2010 ACM.",2,,2-s2.0-77955111123,Conference Proceeding,2010-08-05,10.1145/1816123.1816169,312,9781450300858,,303-312,Proceedings of the ACM International Conference on Digital Libraries,303,http://api.elsevier.com/content/abstract/scopus_id/77955111123,,77955111123,62702,p,Can an intermediary collection help users search image databases without annotations?
"In search engines, ranking algorithms measure the importance and relevance of documents mainly based on the contents and relationships between documents. User attributes are usually not considered in ranking. This user-neutral approach, however, may not meet the diverse interests of users, who may demand different documents even with the same queries. To satisfy this need for more personalized ranking, we propose a ranking framework, Social Network Document Rank (SNDocRank), that considers both document contents and the relationship between a searcher and document owners in a social network. This method combines the traditional tf-idf ranking for document contents with our Multi-level Actor Similarity (MAS) algorithm to measure to what extent document owners and the searcher are structurally similar in a social network. We implemented our ranking method in a simulated video social network based on data extracted from YouTube and tested its effectiveness on video search. The results show that compared with the traditional ranking method like tf-idf, the SNDocRank algorithm returns more relevant documents. More specifically, a searcher can get significantly better results by being in a larger social network, having more friends, and being associated with larger local communities in a social network. © 2010 ACM.",16,,2-s2.0-77955112273,Conference Proceeding,2010-08-05,10.1145/1816123.1816170,322,9781450300858,,313-322,Proceedings of the ACM International Conference on Digital Libraries,313,http://api.elsevier.com/content/abstract/scopus_id/77955112273,,77955112273,62702,p,Social network document ranking
"File format obsolescence has so far been considered the major risk in long-term storage of digital objects. There are, however, growing indications that file transfer may be a real threat as the migration time, i.e., the time required to migrate Petabytes of data, may easily spend years. However, hardware support is usually limited to 3-4 years and a situation can emerge when a new migration has to be started although the previous one is still not finished yet. This paper chooses a process modeling approach to obtain estimates of upper and lower bounds for the required migration time. The advantage is that information about potential bottlenecks can be acquired. Our theoretical considerations are validated by migration tests at the National Library of Norway (NB) as well as at our department. © 2010 ACM.",0,,2-s2.0-77955123274,Conference Proceeding,2010-08-05,10.1145/1816123.1816172,331,9781450300858,,323-331,Proceedings of the ACM International Conference on Digital Libraries,323,http://api.elsevier.com/content/abstract/scopus_id/77955123274,,77955123274,62702,p,A mathematical framework for modeling and analyzing migration time
"Science and technology research is becoming not only more distributed and collaborative, but more highly instrumented. Digital libraries provide a means to capture, manage, and access the data deluge that results from these research enterprises. We have conducted research on data practices and participated in developing data management services for the Center for Embedded Networked Sensing since its founding in 2002 as a National Science Foundation Science and Technology Center. Over the course of eight years, our digital library strategy has shifted dramatically in response to changing technologies, practices, and policies. We report on the development of several DL systems and on the lessons learned, which include the difficulty of anticipating data requirements from nascent technologies, building systems for highly diverse work practices and data types, the need to bind together multiple single-purpose systems, the lack of incentives to manage and share data, the complementary nature of research and development in understanding practices, and sustainability. © 2010 ACM.",20,,2-s2.0-77955102357,Conference Proceeding,2010-08-05,10.1145/1816123.1816173,340,9781450300858,,333-340,Proceedings of the ACM International Conference on Digital Libraries,333,http://api.elsevier.com/content/abstract/scopus_id/77955102357,,77955102357,62702,p,Digital libraries for scientific data discovery and reuse: From vision to practical reality
"Ensemble, the National Science Digital Library (NSDL) Pathways project for Computing, builds upon a diverse group of prior NSDL, DL-I, and other projects. Ensemble has shaped its activities according to principles related to design, development, implementation, and operation of distributed portals. Here we articulate 8 key principles for distributed portals (PDPs). While our focus is on education and pedagogy, we expect that our experiences will generalize to other digital library application domains. These principles inform, facilitate, and enhance the Ensemble R&D and production activities. They allow us to provide a broad range of services, from personalization to coordination across communities. The eight PDPs can be briefly summarized as: (1) Articulation across communities using ontologies. (2) Browsing tailored to collections. (3) Integration across interfaces and virtual environments. (4) Metadata interoperability and integration. (5) Social graph construction using logging and metrics. (6) Superimposed information and annotation integrated across distributed systems. (7) Streamlined user access with IDs. (8) Web 2.0 multiple social network system interconnection. © 2010 ACM.",8,,2-s2.0-77955107004,Conference Proceeding,2010-08-05,10.1145/1816123.1816174,344,9781450300858,,341-344,Proceedings of the ACM International Conference on Digital Libraries,341,http://api.elsevier.com/content/abstract/scopus_id/77955107004,,77955107004,62702,p,Ensemble PDP-8: Eight principles for distributed portals
"Access to data crucial to research is often slow and difficult. When research problems cross disciplinary boundaries, problems are exacerbated. This paper argues that it is important to make it easier to find and access data that might be found in an institution, in a disciplinary data store, in a government department, or held privately. We explore how to meet ad hoc needs that cannot easily be supported by a disciplinary ontology, and argue that web pages that describe data collections with rich links and rich text are valuable. We describe the approach followed by the Australian National Data Service (ANDS) in making such pages available. Finally, we discuss how we plan to evaluate this approach. © 2010 ACM.",6,,2-s2.0-77955101805,Conference Proceeding,2010-08-05,10.1145/1816123.1816175,348,9781450300858,,345-348,Proceedings of the ACM International Conference on Digital Libraries,345,http://api.elsevier.com/content/abstract/scopus_id/77955101805,,77955101805,62702,p,Discovering Australia's research data
"Many user-centred studies of digital libraries (DLs) include a think-aloud element and are usually conducted with the purpose of identifying usability issues related to the DLs used or understanding aspects of users' information behaviour. However, few of these studies present detailed accounts of how their think-aloud data was collected and analysed or reflect on this process. In this paper, we discuss and reflect on the decisions made when planning and conducting a think-aloud study of lawyers' interactive information behaviour. Our discussion is framed by Blandford et al.'s PRET A Rapporter ('ready to report') framework - a framework that can be used to plan, conduct and describe user-centred studies of DL use from an information work perspective. © 2010 ACM.",1,,2-s2.0-77955122700,Conference Proceeding,2010-08-05,10.1145/1816123.1816177,352,9781450300858,,349-352,Proceedings of the ACM International Conference on Digital Libraries,349,http://api.elsevier.com/content/abstract/scopus_id/77955122700,,77955122700,62702,p,This is what I'm doing and why: Reflections on a think-aloud study of DL users' information behaviour
The Curriculum Customization Service enables science educators to customize their instruction with interactive digital library resources. Preliminary results from a field trial with 124 middle and high school teachers suggest that the Service offers a promising model for embedding educational digital libraries into teaching practices and for supporting teachers to integrate customizing into their curriculum planning. © 2010 ACM.,14,,2-s2.0-77955104971,Conference Proceeding,2010-08-05,10.1145/1816123.1816178,356,9781450300858,,353-356,Proceedings of the ACM International Conference on Digital Libraries,353,http://api.elsevier.com/content/abstract/scopus_id/77955104971,,77955104971,62702,p,Customizing science instruction with educational digital libraries
"This paper presents our ongoing study of the current/future impact of social bookmarks (or social tags) on information retrieval (IR). Our main research question asked in the present work is ""How are social tags compared with conventional, yet reliable manual indexing from the viewpoint of IR performance?"". To answer the question, we look at the biomedical literature and begin with examining basic statistics of social tags from CiteULike in comparison with Medical Subject Headings (MeSH) annotated in the Medline bibliographic database. Then, using the data, we conduct various experiments in an IR setting, which reveals that social tags work complementarily with MeSH and that retrieval performance would improve as the coverage of CiteULike grows. © 2010 ACM.",7,,2-s2.0-77955105237,Conference Proceeding,2010-08-05,10.1145/1816123.1816179,360,9781450300858,,357-360,Proceedings of the ACM International Conference on Digital Libraries,357,http://api.elsevier.com/content/abstract/scopus_id/77955105237,,77955105237,62702,p,Impact and prospect of social bookmarks for bibliographic information retrieval
"Digital library interoperability relies on the use of a common metadata format. However, implementing a common metadata format among multiple digital libraries is not always a straightforward exercise. This paper reviews some of the metadata issues that arose during the merger of two digital libraries, the Internet Public Library and the Librarian's Internet Index. As part of the merger, each library's metadata was crosswalked to Dublin Core. This required considerable work. A sociotechnical analysis suggests that the metadata for each library had been shaped in complex ways over time by local factors, and that this complexity negatively impacted the efficiency of the crosswalk. Some implications of this finding for digital library interoperability are discussed. © 2010 ACM.",11,,2-s2.0-77955120885,Conference Proceeding,2010-08-05,10.1145/1816123.1816180,364,9781450300858,,361-364,Proceedings of the ACM International Conference on Digital Libraries,361,http://api.elsevier.com/content/abstract/scopus_id/77955120885,,77955120885,62702,p,Merging metadata: A sociotechnical study of crosswalking and interoperability
"The creation of most digital objects occurs solely in interactive graphical user interfaces which were available at the particular time period. Archiving and preservation organizations are posed with large amounts of such objects of various types. At some point they will need to process these automatically to make them available to their users or convert them to a commonly used format. A substantial problem is to provide a wide range of different users with access to ancient environments and to allow using the original environment for a given object. We propose an abstract architecture for emulation services in digital preservation to provide remote user interfaces to emulation over computer networks without the need to install additional software components. Furthermore, we describe how these ideas can be integrated in a framework of web services for common preservation tasks like viewing or migrating digital objects. © 2010 ACM.",4,,2-s2.0-77955116303,Conference Proceeding,2010-08-05,10.1145/1816123.1816182,368,9781450300858,,365-368,Proceedings of the ACM International Conference on Digital Libraries,365,http://api.elsevier.com/content/abstract/scopus_id/77955116303,,77955116303,62702,p,Emulation based services in digital preservation
The Ensemble computing education portal is part of the US NSF's National Science Digital Library (NSDL). The underlying assumption in Ensemble's design is that people will not come just because we build something new. The information must be available from wherever potential users are. This poster describes early efforts to provide multiple community oriented entry points to multiple sources relevant to computing educators.,2,,2-s2.0-77955101410,Conference Proceeding,2010-08-05,10.1145/1816123.1816184,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,369,http://api.elsevier.com/content/abstract/scopus_id/77955101410,,77955101410,62702,p,Many-to-many information connection connections in a distributed digital library portal
"This poster describes SPIRO-V, a collaborative controlled vocabulary development system integrating automatic and manual approaches for domain-specific vocabulary acquisition, and leveraging the knowledge of field experts.",0,,2-s2.0-77955116586,Conference Proceeding,2010-08-05,10.1145/1816123.1816185,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,371,http://api.elsevier.com/content/abstract/scopus_id/77955116586,,77955116586,62702,p,SPIRO-V: A collaborative approach to controlled vocabularies gathering and management
"Science is characterized nowadays by unprecedented growth in the number of publications. Thus it would be helpful if there were a way to summarize the contents of the publications or explain the argumentative relationship between them (e.g. support, further improvement, critique). Such semantic analysis might involve analyzing the citation contexts (the paragraphs where a certain publication is referred to by another publication). Here we present our work on a system that creates the pre-requisites for such analysis by harvesting publications from the web, extracting the contexts from them, and aggregating them into citation digests that are retrieved in the context of user interactions with web sites that mention these publications.",0,,2-s2.0-77955104970,Conference Proceeding,2010-08-05,10.1145/1816123.1816186,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,373,http://api.elsevier.com/content/abstract/scopus_id/77955104970,,77955104970,62702,p,Generating citation digests for scientific publications
"Astrobiology is an inherently interdisciplinary field concerned with questions of life in the universe. This paper describes the design and ongoing implementation of the Astrobiology Integrative Research Framework (AIRFrame), an open source, ontology-driven information system designed to ingest and analyze heterogeneous inputs of both published and unpublished data, and to identify and illustrate latent connections between research in astrobiology's diverse constituent fields.",1,,2-s2.0-77955117626,Conference Proceeding,2010-08-05,10.1145/1816123.1816187,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,375,http://api.elsevier.com/content/abstract/scopus_id/77955117626,,77955117626,62702,p,AIRFrame: Integrating diverse digital collections in astrobiology
"As described in this paper, we proposed a public education tools for Tsunami Disasters based on TDL.",0,,2-s2.0-77955108527,Conference Proceeding,2010-08-05,10.1145/1816123.1816188,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,377,http://api.elsevier.com/content/abstract/scopus_id/77955108527,,77955108527,62702,p,A public education tool for Tsunami Disasters based on walking tours in TDL
A search engine for Japanese academic papers rendered in PDF is described. Evaluation results indicate fewer zero-result queries and higher precision in the top-10 documents than was obtained for the same Japanese queries using Google Scholar or Scirus.,2,,2-s2.0-77955108850,Conference Proceeding,2010-08-05,10.1145/1816123.1816189,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,379,http://api.elsevier.com/content/abstract/scopus_id/77955108850,,77955108850,62702,p,A search engine for Japanese academic papers
"We examine the eye movements of children who can read books on their own as they read printed picture books. Our analysis focuses on two points; 1) Is it the pictures or the text that they most frequently gaze at?, and 2) In what sequence do they read picture books? Our results indicate that children look at both text and pictures, but that there are large variations in the ratio of viewing time for each child. Both circular and linear patterns are found in the sequence of eye movements.",0,,2-s2.0-77955118820,Conference Proceeding,2010-08-05,10.1145/1816123.1816190,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,381,http://api.elsevier.com/content/abstract/scopus_id/77955118820,,77955118820,62702,p,Analyzing viewing patterns while reading picture books
"Welcome to JCDL 2010! As a participant in the digital library community for more than a decade, I am delighted and proud to be the program chair of the 10th Annual Joint Conference on Digital Libraries. For the past decade, JCDL has continued to mature and maintain its position as the premier international forum for research and practice in the dynamic and multidisciplinary field of digital library research. I'm happy to report that the papers and presentations that form the basis of this year's conference continue to exemplify both the breadth and depth of the field and the superb scholarship taking place within it. The theme of JCDL 2010, ""Digital Libraries - 10 Years Past, 10 Years Forward, A 2020 Vision"", addresses both the historical legacy of this conference and the challenges that lie ahead as the technical, cultural, political, and social contexts in which the field is situated continue to change. During the past 10 years, we have witnessed dramatic changes in the broader information context and in our perception of the nature of information and the institutions responsible for its dissemination, management, and preservation. The World Wide Web, the development of which is coincident with the history of digital libraries as a research area, has dramatically evolved from a read-only document space to a semantically rich, participatory and dynamic global database. This rate of change will only accelerate. The positioning of digital libraries and the institutional and technical models that they embody in this volatile context is an area that we as a community must address. I look forward to seeing the next decade unfold as we define this position and contribute to the networked information context. This JCDL has a number of ""firsts."" It is the first JCDL held outside of North America, moving literally almost halfway across the world to the Gold Coast of Australia. This is an exciting opportunity for more international participation in the conference and the inevitable cross-fertilization of ideas resulting from that. In addition, this is the first JCDL to be held in conjunction with ICADL, the International Conference on Asian Digital Libraries. There will be ample opportunity for mixing of conference attendees and I look forward to the possibility of new research collaborations that cross and investigate cultural boundaries. The authors of the papers that were selected by the program committee for presentation at the conference should be very proud of their achievement. This 2010 version maintains the competitive nature of JCDL, with 110 long papers submitted and 32 accepted. This computes to an acceptance rate of around 29%. The acceptance rate for short papers was equally competitive with 13 of 45 papers accepted. While there are a number of familiar names (to me) amongst the authors of the accepted papers, it is exciting to see the number of new, young researchers entering the field and look forward to their fresh perspectives. Mixed in with the presentations of these papers, the conference program includes excellent keynote speakers and panels, both of which we have designed to challenge existing assumptions and provoke new questions and thinking. Like any research field, the future of digital libraries as an active intellectual context depends on facing these challenges and, as a community, shifting course when necessary. © 2010 ACM.",5,,2-s2.0-77955106501,Conference Proceeding,2010-08-05,10.1145/1816123.1816191,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,383,http://api.elsevier.com/content/abstract/scopus_id/77955106501,,77955106501,62702,p,Personalizing information retrieval for people with different levels of topic knowledge
"For securing digital longevity, the processes of preservation planning and evaluation are fundamentally implicit and share similar complexity. Means are required for the identification, documentation and association of those properties of data, representation and management mechanisms that in combination lend value, facilitate interaction and influence the preservation process. These properties may be almost limitless in terms of diversity, but are integral to the establishment of classes of risk exposure, and the planning and deployment of appropriate preservation strategies. We present PORRO, an ontology based approach for documenting objects, repositories and risk information, intended to support preservation decision making and evaluation.",0,,2-s2.0-77955099359,Conference Proceeding,2010-08-05,10.1145/1816123.1816192,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,385,http://api.elsevier.com/content/abstract/scopus_id/77955099359,,77955099359,62702,p,Rethinking preservation validation with the preserved object and repository risks ontology (PORRO)
"We present ForeCite (FC), a prototype reader-centric digital library that supports the scholar in using scholarly documents. FC integrates three user interfaces: a bibliometric component, a document reader and annotation system, and a bibliographic management application.",1,,2-s2.0-77955110969,Conference Proceeding,2010-08-05,10.1145/1816123.1816193,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,387,http://api.elsevier.com/content/abstract/scopus_id/77955110969,,77955110969,62702,p,ForeCite: Towards a reader-centric scholarly digital library
"This poster describes the architecture of a new kind of digital repository service that includes components that run on desktop computers, designed to close the gap between Institutional Repositories (IRs) and the day-to-day electronic work environment used by researchers, and to address the too-often heard cry from repository managers of ""we built it but they didn't come"". The team at the Australian Digital Futures Institute are working with researchers to provide software that can (a) index and expose the research data content on their hard disks (b) extract metadata from files (c) automatically process data according to highly configurable workflows including producing web-ready renditions of research objects including documents, domain specific data visualizations (such as chemical molecules) and converting video and images so that they may be easily previewed. The architecture is inspired by the success of consumer software in two ways; the way entertainment programs organize content via faceted browse and search interfaces using embedded metadata, and the way photographic software allows content to be grouped into collections and pushed to online services, which are essentially repositories.",0,,2-s2.0-77955108668,Conference Proceeding,2010-08-05,10.1145/1816123.1816194,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,389,http://api.elsevier.com/content/abstract/scopus_id/77955108668,,77955108668,62702,p,An architecture for a distributed digital library from the desktop up: The fascinator
"In this paper, we presented a service infrastructure based on distributed file system for massive storage in digital library. In addition, we addressed the small-file problem by merging small files into big ones, and proposed a novel dynamic replica number adjustment scheme to ensure the maximal availability and reliability in a limited storage space.",5,,2-s2.0-77955102948,Conference Proceeding,2010-08-05,10.1145/1816123.1816195,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,391,http://api.elsevier.com/content/abstract/scopus_id/77955102948,,77955102948,62702,p,A digital library architecture supporting massive small files and efficient replica maintenance
"Important words, which usually exist in part of Title, Subject and Keywords, can briefly reflect the main topic of a document. In recent years, it is a common practice to exploit the semantic topic of documents and utilize important words to achieve document clustering, especially for short texts such as news articles. This paper proposes a novel method to extract important words from Subject and Keywords of articles, and then partition documents only with those important words. Considering the fact that frequencies of important words are usually low and the scale matrix dataset for important words is small, a normalization method is then proposed to normalize the scale dataset so that more accurate results can be achieved by sufficiently exploiting the limited information. The experiments validate the effectiveness of our method.",4,,2-s2.0-77955115793,Conference Proceeding,2010-08-05,10.1145/1816123.1816196,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,393,http://api.elsevier.com/content/abstract/scopus_id/77955115793,,77955115793,62702,p,Text clustering with important words using normalization
"The Web has changed the way we create, consume, share and disseminate scientific knowledge. Publishing is now almost real time and free and papers are not longer the only form of scientific dissemination. We can now publish early ideas in blogs at ScienceBlogs.com, put pre-prints in online repositories, such as arXiv.org, experiments on MyExper-iment.org and datasets on our homepages. A brand new world of possibilities is open for scientific knowledge creation, dissemination and evaluation, causing the evolution of the notions of scientific contribution and scientific journal to serve the need of scientists to learn about novel, interesting research ideas and results. This new context poses also new challenges. Attention is now the obstacle to dissemination as opposed to the pre-web era in which publication and distribution were the limiting resources. However, the majority of existing journal models and tools remains unaware of the new opportunities and challenges posed by the Web. They are still constrained to the traditional notion of paper and do not propose any effective mechanism to face the problem of attention. In this demo we introduce a platform and a model of journal in the age of the Web called liquid journal [1]. The goal of the model is to disseminate knowledge in the best possible way while also supporting scientists in the credit attribution. In a nutshell, liquid journals are collections of ""interesting"" links to scientific contributions, such as papers, blogs, datasets, that are related to certain topics. The content gets to the journal either by querying both conventional and non conventional sources on the Web or manually by the group of editors. Liquid journals combines depth and breath in bringing a wider spectrum of scientific contributions from different communities, while also focusing editors' and readers' attention on the things they care about. Liquid journals represent a family of publication models that range from the traditional to the more web-aware ones. Each model contains the following phases (Figure 1): (i) in the definition phase, editors define the rules for the content gathering by defining a query over the Web. The query specifies the type and properties of the content to include, the ranking and grouping criteria. Editors can also define the process to follow: to allow submission, perform peer-review, or simply filter out results from the query. (ii) in the content selection phase the editors review the results of the query and manually added contributions, deciding what to include in the journal. (iii) in the publication phase, editors group content in issues or update the existing journal. (iv) in the consumption phase, the journal is read and tagged by its followers. The consumption influences the reputation of the articles, journals, and authors. Once up and running, the query results will provide the input to the selection process, in which editors decide what to include in the journal. Thus, liquid journals are always evolving, as new scientific contributions matching the query definition appear and are selected by the editors. This is indeed the reason why we call it liquid journal as opposed to the ""solid"" and fixed traditional journals. The platform described here is available online1 along with demonstration videos and additional material.",3,,2-s2.0-77955100621,Conference Proceeding,2010-08-05,10.1145/1816123.1816198,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,395,http://api.elsevier.com/content/abstract/scopus_id/77955100621,,77955100621,62702,p,Liquid journals: Scientific journals in the web 2.0 era
This demonstration is an overview of our Ensemble pathway project with group members on-location at the conference and in the virtual world of Second Life from remote locations providing a live walk-through tour of our project online. This approach allows the demonstration to extend beyond the allocated conference session as a means to attract people to JCDL/ICADL.,1,,2-s2.0-77955115655,Conference Proceeding,2010-08-05,10.1145/1816123.1816199,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,397,http://api.elsevier.com/content/abstract/scopus_id/77955115655,,77955115655,62702,p,Multiple sources with multiple portals: A demonstration of the ensemble computing portal in second life
"Verifiability and reproducibility are core tenets of the scholarly communication process. For many scientific publications, however, it is often the case that supporting datasets are not preserved, even when the article text is. And when they are, it is usually as a collection of files without relationships amongst one another or to the articles with which they are associated. There are some existing approaches that attempt to link datasets with articles after the fact (e.g., NED1), but they are relatively few and involve substantial human intervention. The Digital Research and Curation Center in the Johns Hopkins University Sheridan Libraries, in conjunction with its partners has developed a proof-of-concept system that demonstrates an approach to capturing datasets during the process of submitting the associated article. As part of this process, linkages are established between the datasets and the article.",0,,2-s2.0-77955115179,Conference Proceeding,2010-08-05,10.1145/1816123.1816200,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,399,http://api.elsevier.com/content/abstract/scopus_id/77955115179,,77955115179,62702,p,Capturing and curating published data
"In this paper, we show how Semantic Web technologies can be used for information connection and fusion in academic research information service and empowered by linguistic knowledge.",0,,2-s2.0-77955102694,Conference Proceeding,2010-08-05,10.1145/1816123.1816201,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,401,http://api.elsevier.com/content/abstract/scopus_id/77955102694,,77955102694,62702,p,OntoFrame S3: Academic research information portal service using semantic web technologies and linguistic knowledge
"This research explores and demonstrates the use of Second Life (the popular 3D virtual world) for the purpose of digitally preserving various aspects of video game and music history. Physical game interfaces like joysticks, advertisements used for games, and famous game characters and cultural icons over the history are displayed and preserved in multiple video game exhibits for different eras. Selected game characters are digitally recreated in 3D format as Second Life avatar appearances. Historical changes of musical instruments, musicians, and genres are displayed and preserved likewise. Selected musical instruments are digitally recreated as 3D models playing their real sounds. Some of them will be available for the visitors to play in basic ways.",0,,2-s2.0-77955099916,Conference Proceeding,2010-08-05,10.1145/1816123.1816202,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,403,http://api.elsevier.com/content/abstract/scopus_id/77955099916,,77955099916,62702,p,Entertainment history museums in virtual worlds: Video game and music preservation in second life
"This extended abstract describes recent work in combining interactive map functionality with the Greenstone 3 digital library software research framework.1 Figure 1 shows a snapshot from the implemented system, and is discussed further below. The software implementation needed to achieve this involved development of both the build-time and runtime components of Greenstone. For build-time, the main change required place names in the text to be identified and marked up. This was accomplished by linking Greenstone's document processing plugins with ANNIE, the part of the open source text-mining tool GATE2 that is specifically designed for named entity identification problems. Beyond the disambiguation techniques employed to ANNIE, to further differentiate which place name is being referred to in a document (e.g., just which of the dozen or so places in the world called Hamilton), a spatial clustering algorithm was devised. This collated the place names identified in a specific document, and then exploited the hierarchical structure of the gazetteer to assign weights to each place name. The weighted information could then be used to list the place names in order of likelihood, or alternatively (in the case of a clear winner, determined by using an empirically set threshold) a definitive (but potentially error-prone) decision was made. For the runtime system, the design approach taken was to maintain two interlocked views, displayed side-by-side: one the traditional text-based digital library view, the other an interactive map view. At any stage of the user's interaction the two views represent the same information, only displayed differently. The views are interlocked, in that the user can interact with either view, and as a result both views are updated. For instance, Figure 1 captures the moment just after a text search has been issued. The left-hand panel shows the traditional ranked result list, augmented to use different colors for each matching document. The right-hand panel shows the map based view of the same information, where place names in the text of the result set are displayed on the map. The color used to display a place name is color-coded to match that used in the corresponding document in the text view. Clicking on a document presents the text with place names marked up; marked up place names in turn linked to pop-up information displayed in the map view when clicked upon. A fish-eye view is also available to provide a gestalt to the user of place names the document mentions. Spatial searching is also supported. For example, the next thing the user might do from Figure 1 is click out a region in the map and search for only documents that mention place names included in that area. Implementation of the runtime interface is AJAX based. It uses the Google Widget Toolkit to provide the map interface through its API for Google Maps. PostgresGIS is used to support the spatial searching capabilities.",1,,2-s2.0-77955102058,Conference Proceeding,2010-08-05,10.1145/1816123.1816203,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,405,http://api.elsevier.com/content/abstract/scopus_id/77955102058,,77955102058,62702,p,Integrating greenstone with an interactive map visualizer
"Welcome to JCDL 2010! As a participant in the digital library community for more than a decade, I am delighted and proud to be the program chair of the 10th Annual Joint Conference on Digital Libraries. For the past decade, JCDL has continued to mature and maintain its position as the premier international forum for research and practice in the dynamic and multidisciplinary field of digital library research. I'm happy to report that the papers and presentations that form the basis of this year's conference continue to exemplify both the breadth and depth of the field and the superb scholarship taking place within it. The theme of JCDL 2010, ""Digital Libraries -- 10 Years Past, 10 Years Forward, A 2020 Vision"", addresses both the historical legacy of this conference and the challenges that lie ahead as the technical, cultural, political, and social contexts in which the field is situated continue to change. During the past 10 years, we have witnessed dramatic changes in the broader information context and in our perception of the nature of information and the institutions responsible for its dissemination, management, and preservation. The World Wide Web, the development of which is coincident with the history of digital libraries as a research area, has dramatically evolved from a read-only document space to a semantically rich, participatory and dynamic global database. This rate of change will only accelerate. The positioning of digital libraries and the institutional and technical models that they embody in this volatile context is an area that we as a community must address. I look forward to seeing the next decade unfold as we define this position and contribute to the networked information context. This JCDL has a number of ""firsts."" It is the first JCDL held outside of North America, moving literally almost halfway across the world to the Gold Coast of Australia. This is an exciting opportunity for more international participation in the conference and the inevitable cross-fertilization of ideas resulting from that. In addition, this is the first JCDL to be held in conjunction with ICADL, the International Conference on Asian Digital Libraries. There will be ample opportunity for mixing of conference attendees and I look forward to the possibility of new research collaborations that cross and investigate cultural boundaries. The authors of the papers that were selected by the program committee for presentation at the conference should be very proud of their achievement. This 2010 version maintains the competitive nature of JCDL, with 110 long papers submitted and 32 accepted. This computes to an acceptance rate of around 29%. The acceptance rate for short papers was equally competitive with 13 of 45 papers accepted. While there are a number of familiar names (to me) amongst the authors of the accepted papers, it is exciting to see the number of new, young researchers entering the field and look forward to their fresh perspectives. Mixed in with the presentations of these papers, the conference program includes excellent keynote speakers and panels, both of which we have designed to challenge existing assumptions and provoke new questions and thinking. Like any research field, the future of digital libraries as an active intellectual context depends on facing these challenges and, as a community, shifting course when necessary. © 2010 ACM.",10,,2-s2.0-77955117382,Conference Proceeding,2010-08-05,10.1145/1816123.1816204,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,407,http://api.elsevier.com/content/abstract/scopus_id/77955117382,,77955117382,62702,p,Subject metadata support powered by Maui
"In this demonstration, we show a recommender system for the Music Information Retrieval (MIR) research community. We extract the key topics and tags by analyzing the ten-year cumulative ISMIR proceedings, and recommend papers and research colleagues to users in an interactive way.",0,,2-s2.0-77955099768,Conference Proceeding,2010-08-05,10.1145/1816123.1816205,,9781450300858,,,Proceedings of the ACM International Conference on Digital Libraries,409,http://api.elsevier.com/content/abstract/scopus_id/77955099768,,77955099768,62702,p,Recommender system for MIR research community
"We describe here a method for automatically identifying word sense variation in a dated collection of historical books in a large digital library. By leveraging a small set of known translation book pairs to induce a bilingual sense inventory and labeled training data for a WSD classifier, we are able to automatically classify the Latin word senses in a 389 million word corpus and track the rise and fall of those senses over a span of two thousand years. We evaluate the performance of seven different classifiers both in a tenfold test on 83,892 words from the aligned parallel corpus and on a smaller, manually annotated sample of 525 words, measuring both the overall accuracy of each system and how well that accuracy correlates (via mean square error) to the observed historical variation. © 2011 ACM.",10,,2-s2.0-79960475561,Conference Proceeding,2011-07-25,10.1145/1998076.1998078,10,9781450307444,15525996,1-10,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,1,http://api.elsevier.com/content/abstract/scopus_id/79960475561,,79960475561,145752,p,Measuring historical word sense variation
"Nowadays PDF documents have become a dominating knowledge repository for both the academia and industry largely because they are very convenient to print and exchange. However, the methods of automated structure information extraction are yet to be fully explored and the lack of effective methods hinders the information reuse of the PDF documents. To enhance the usability for PDF-formatted electronic books, we propose a novel computational framework to analyze the underlying physical structure and logical structure. The analysis is conducted at both page level and document level, including global typographies, reading order, logical elements, chapter/section hierarchy and metadata. Moreover, two characteristics of PDF-based books, i.e., style consistency in the whole book document and natural rendering order of PDF files, are fully exploited in this paper to improve the conventional image-based structure extraction methods. This paper employs the bipartite graph as a common structure for modeling various tasks, including reading order recovery, figure and caption association, and metadata extraction. Based on the graph representation, the optimal matching (OM) method is utilized to find the global optima in those tasks. Extensive benchmarking using real-world data validates the high efficiency and discrimination ability of the proposed method. © 2011 ACM.",18,,2-s2.0-79960541737,Conference Proceeding,2011-07-25,10.1145/1998076.1998079,20,9781450307444,15525996,11-20,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,11,http://api.elsevier.com/content/abstract/scopus_id/79960541737,,79960541737,145752,p,Structure extraction from PDF-based book documents
"Topic models are emerging tools for improved browsing and searching within digital libraries. These techniques collapse words within documents into unordered ""bags of words,"" ignoring word order. In this paper, we present a method that examines syntactic dependency parse trees from Wikipedia article titles to learn expected patterns between relative lexical arguments. This process is highly dependent on the global word ordering of a sentence, modeling how each word interacts with other words to gain an aggregate perspective on how words interact over all 3.2 million titles. Using this information, we analyze how coherent a given topic is by comparing the relative usage vectors between the top 5 words in a topic. Results suggest that this technique can identify poor topics based on how well the relative usages align with each other within a topic, potentially aiding digital library indexing. © 2011 ACM.",1,,2-s2.0-79960541312,Conference Proceeding,2011-07-25,10.1145/1998076.1998080,24,9781450307444,15525996,21-24,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,21,http://api.elsevier.com/content/abstract/scopus_id/79960541312,,79960541312,145752,p,Word order matters: Measuring topic coherence with lexical argument structure
"Retrieval of subtopical concepts from scholarly communication systems is now possible through a combination of text and metadata analysis, augmented by user search queries and click logs. Here we investigate how a ""phrase"", defined as a variable length sequence of vocabulary words, can be used to represent a concept. We present a method to extract such phrases from a text corpus, and rank them using a citation network measure, the compensated normalized link count (CNLC), which measures the extent to which they are propagated along the citation structure of articles. We validate the ranking with actively and passively determined metrics: comparison with human-assigned keywords, and comparison with passively harvested terms from search query logs. This method is demonstrated on full texts and abstracts from 7 years of high energy physics articles from the arXiv preprint database. © 2011 ACM.",1,,2-s2.0-79960478485,Conference Proceeding,2011-07-25,10.1145/1998076.1998081,28,9781450307444,15525996,25-28,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,25,http://api.elsevier.com/content/abstract/scopus_id/79960478485,,79960478485,145752,p,Phrases as subtopical concepts in scholarly text
"Videogames and other new media artifacts constitute an important part of our cultural and economic landscape and collecting institutions have a responsibility to collect and preserve these materials for future access. Unfortunately, these kinds of materials present unique challenges for collecting institutions including problems of collection development, technological preservation, and access. This paper presents findings from a grant-funded project focused on examining documentation of the creative process in game development. Data includes twelve qualitative interviews conducted with individuals involved in the game development process, spanning a number of different roles and institution types. The most pressing findings are related to the nature of documentation in the videogame industry: project interviews indicate that the game development process does produce significant and important documentation as traditionally conceived by collecting institutions, ranging from game design documents to email correspondence and business reports. However, while it does exist, traditional documentation does not adequately, or even, at times, truthfully represent the project or the game creation process as a whole. In order to adequately represent the development process, collecting institutions also need to seek out and procure numerous versions of games and game assets as well as those game assets that are natural byproducts of the design process like gamma and beta versions of the game, for example, vertical slices, or different renderings of graphical elements. © 2011 ACM.",7,,2-s2.0-79960487185,Conference Proceeding,2011-07-25,10.1145/1998076.1998083,38,9781450307444,15525996,29-38,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,29,http://api.elsevier.com/content/abstract/scopus_id/79960487185,,79960487185,145752,p,Game development documentation and institutional collection development policy
In this paper we present a novel system for user-driven integration of name variants when interacting with web-based information systems. The growth and diversity of online information means that many users experience disambiguation and collocation errors in their information searching. We approach these issues via a client-side JavaScript browser extension that can reorganise web content and also integrate remote data sources. The system is illustrated through three worked examples using existing digital libraries. © 2011 ACM.,5,,2-s2.0-79960498041,Conference Proceeding,2011-07-25,10.1145/1998076.1998084,48,9781450307444,15525996,39-48,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,39,http://api.elsevier.com/content/abstract/scopus_id/79960498041,,79960498041,145752,p,That's 'é' not 'p' '?' or '□': A user-driven context-aware approach to erroneous metadata in digital libraries
"This paper explores a technique to improve searcher access to library collections by providing a faceted search interface built on a data model based on the Functional Requirements for Bibliographic Records (FRBR). The prototype provides a Work-centric view of a moving image collection that is integrated with bibliographic and holdings data. Two sets of facets address important user needs: ""what do you want?"" and ""how/where do you want it?"" enabling patrons to narrow, broaden and pivot across facet values instead of limiting them to the tree-structured hierarchy common with existing FRBR applications. The data model illustrates how FRBR is being adapted and applied beyond the traditional library catalog. © 2011 ACM.",1,,2-s2.0-79960522069,Conference Proceeding,2011-07-25,10.1145/1998076.1998085,52,9781450307444,15525996,49-52,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,49,http://api.elsevier.com/content/abstract/scopus_id/79960522069,,79960522069,145752,p,"FRBR and facets provide flexible, work-centric access to items in library collections"
"In this paper, we describe an exploratory study comparing the abstracting and indexing practices of a semi-expert LIS community (metadata creators for the digital library, ipl2) and the social tags generated by Delicious users for the same corpus of materials. We find over 88% of the resources in the ipl2 History collection were tagged at least once in Delicious. Overlap between the tags applied to ipl2 resources and indexing shows terms that the two groups are similar enough to be useful, yet dissimilar enough to provide new access points and description. © 2011 ACM.",4,,2-s2.0-79960498835,Conference Proceeding,2011-07-25,10.1145/1998076.1998086,56,9781450307444,15525996,53-56,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,53,http://api.elsevier.com/content/abstract/scopus_id/79960498835,,79960498835,145752,p,What do you call it? A comparison of library-created and user-created tags
"Disk images (bitstreams extracted from physical media) can play an essential role in the acquisition and management of digital collections by serving as containers that support data integrity and chain of custody, while ensuring continued access to the underlying bits without depending on physical carriers. Widely used today by practitioners of digital forensics, disk images can serve as baselines for comparison for digital preservation activities, as they provide fail-safe mechanisms when curatorial actions make unexpected changes to data; enable access to potentially valuable data that resides below the file system level; and provide options for future analysis. We discuss established digital forensics techniques for acquiring, preserving and annotating disk images, provide examples from both research and educational collections, and describe specific forensic tools and techniques, including an object-oriented data packaging framework called the Advanced Forensic Format (AFF) and the Digital Forensics XML (DFXML) metadata representation. © 2011 ACM.",7,,2-s2.0-79960521652,Conference Proceeding,2011-07-25,10.1145/1998076.1998088,66,9781450307444,15525996,57-66,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,57,http://api.elsevier.com/content/abstract/scopus_id/79960521652,,79960521652,145752,p,Extending digital repository architectures to support disk image preservation and access
"Decisions in digital preservation pose the delicate mission of balancing desired goals of authentic long-term access with the technical means available to date. Organisations with a commitment to the long-term value of information and knowledge have to take decisions on several levels to achieve their business goals with the evolving technology of the day. This article explores the decision space in digital preservation, with a focus on what can be called the core decision: how to preserve content information. We undertake a critical analysis of the challenges, constraints and objectives of decision making, and discuss the experience in applying the Planets preservation planning method, supported by the planning tool Plato, to real-world business decisions. Based on this methodology and substantial real-world experience in decision making, we present a set of observation points that address issues frequently raised in decision making. The conclusions shall contribute to a clarified understanding of the state of the art and future challenges in scalable decision making for long-term preservation. © 2011 ACM.",9,,2-s2.0-79960519905,Conference Proceeding,2011-07-25,10.1145/1998076.1998089,76,9781450307444,15525996,67-76,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,67,http://api.elsevier.com/content/abstract/scopus_id/79960519905,,79960519905,145752,p,"Preservation decisions: Terms and conditions apply - Challenges, misperceptions and lessons learned in preservation planning"
"This paper discusses the creation of Ember, a collection of borndigital artifacts generated in the aftermath of the 1999 Aggie Bonfire collapse. Ember is an example of a previously unexamined class of cultural heritage digital libraries, which we describe as a digital memorial museum. Ember's artifacts consist of emails, photos, documents, and web pages that the communities surrounding the tragedy created. Due to the community investment and the personal nature of the artifacts, concerns arise on how the collection should be properly handled, which leads us to propose ""Sensitivity"" as an addition to the 5S model. Initially, we are focusing on the email portion of the collection, which can be viewed as the basis of an emerging oral tradition surrounding the Bonfire tragedy. © 2011 ACM.",0,,2-s2.0-79960491693,Conference Proceeding,2011-07-25,10.1145/1998076.1998090,80,9781450307444,15525996,77-80,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,77,http://api.elsevier.com/content/abstract/scopus_id/79960491693,,79960491693,145752,p,Ember: A case study of a digital memorial museum of born-digital artifacts
"We propose a digital library design to support epidemic and public health simulation experiments in which model ontologies direct collection organization, user interface construction, and discovery. We have developed a SimDL instantiation of the ontological design tailored for a typical experimentation workflow. SimDL relies on an XML Schema description of a simulation model to form a domain and model specific ontology. We show this approach useful in building digital libraries to support collaborative simulation efforts. © 2011 ACM.",7,,2-s2.0-79960548566,Conference Proceeding,2011-07-25,10.1145/1998076.1998091,84,9781450307444,15525996,81-84,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,81,http://api.elsevier.com/content/abstract/scopus_id/79960548566,,79960548566,145752,p,SimDL: A model ontology driven digital library for simulation systems
"Entity resolution is the task of identifying entities that refer to the same real-world object. It has important applications in the context of digital libraries, such as citation matching and author disambiguation. Blocking is an established methodology for efficiently addressing this problem; it clusters similar entities together, and compares solely entities inside each cluster. In order to effectively deal with the current large, noisy and heterogeneous data collections, novel blocking methods that rely on redundancy have been introduced: they associate each entity with multiple blocks in order to increase recall, thus increasing the computational cost, as well. In this paper, we introduce novel techniques that remove the superfluous comparisons from any redundancy-based blocking method. They improve the time-efficiency of the latter without any impact on the end result. We present the optimal solution to this problem that discards all redundant comparisons at the cost of quadratic space complexity. For applications with space limitations, we also present an alternative, lightweight solution that operates at the abstract level of blocks in order to discard a significant part of the redundant comparisons. We evaluate our techniques on two large, real-world data sets and verify the significant improvements they convey when integrated into existing blocking methods. © 2011 ACM.",26,,2-s2.0-79960519872,Conference Proceeding,2011-07-25,10.1145/1998076.1998093,94,9781450307444,15525996,85-94,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,85,http://api.elsevier.com/content/abstract/scopus_id/79960519872,,79960519872,145752,p,Eliminating the redundancy in blocking-based entity resolution methods
"Individuals contribute content on the Web at an unprecedented rate, accumulating immense quantities of (semi-)structured data. Wisdom of the Crowds theory advocates that such information (or parts of it) is constantly overwritten, updated, or even deleted by other users, with the goal of rendering it more accurate, or up-to-date. This is particularly true for the collaboratively edited, semi-structured data of entity repositories, whose entity profiles are consistently kept fresh. Therefore, their core information that remain stable with the passage of time, despite being reviewed by numerous users, are particularly useful for the description of an entity. Based on the above hypothesis, we introduce a classification scheme that predicts, on the basis of statistical and content patterns, whether an attribute (i.e., name-value pair) is going to be modified in the future. We apply our scheme on a large, real-world, versioned dataset and verify its effectiveness. Our thorough experimental study also suggests that reducing entity profiles to their stable parts conveys significant benefits to two common tasks in computer science: information retrieval and information integration. © 2011 ACM.",3,,2-s2.0-79960545856,Conference Proceeding,2011-07-25,10.1145/1998076.1998094,104,9781450307444,15525996,95-104,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,95,http://api.elsevier.com/content/abstract/scopus_id/79960545856,,79960545856,145752,p,Detecting and exploiting stability in evolving heterogeneous information spaces
"User interest in topics and resources is known to be recurrent and to follow specific patterns, depending on the type of topic or resource. Traditional methods for predicting reoccurring patterns are based on ranking and associative models. In this paper we identify several 'canonical' patterns by clustering keywords related to visited resources, making use of a large repository of Web usage data. The keywords are derived from a 'virtual' folksonomy of tags assigned to these resources using a collaborative bookmarking system. © 2011 ACM.",4,,2-s2.0-79960489222,Conference Proceeding,2011-07-25,10.1145/1998076.1998095,108,9781450307444,15525996,105-108,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,105,http://api.elsevier.com/content/abstract/scopus_id/79960489222,,79960489222,145752,p,Classification of user interest patterns using a virtual folksonomy
"If researchers use tags in retrieval applications they might assume, implicitly, that tags represent novel information, e.g., when they attribute performance improvement in their retrieval algorithm(s) to the use of tags. In this work, we investigate whether this assumption is true. We focus on the use of tags in domain-specific websites because such websites are more likely to have a coherent, discernible website structure and because the users that are searching for and tagging pages in such a site may have specific information needs (as opposed to the broad range of information needs that users have when browsing/searching the Internet at large). For this study, we assume that the application of the same tag to multiple pages provides an indication that those pages are related. To determine whether this indication of relatedness is contributing new information, we first measure whether pages with common tag(s) could have been deemed as related based on site structure as measured by shortest navigational distance between pages. Second, we measure whether or not tags could have been determined algorithmically based on standard tf-idf scores of terms on the page. Based on our analysis of two different sites, we found that tags contribute novel information that is not discernible from site structure or site/page content. © 2011 ACM.",1,,2-s2.0-79960478903,Conference Proceeding,2011-07-25,10.1145/1998076.1998096,112,9781450307444,15525996,109-112,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,109,http://api.elsevier.com/content/abstract/scopus_id/79960478903,,79960478903,145752,p,Tags in domain-specific sites: New information?
"A pattern is a model or a template used to summarize and describe the behavior (or the trend) of a data having generally some recurrent events. Patterns have received a considerable attention in recent years and were widely studied in the data mining field. Various pattern mining approaches have been proposed and used for different applications such as network monitoring, moving object tracking, financial or medical data analysis, scientific data processing, etc. In these different contexts, discovered patterns were useful to detect anomalies, to predict data behavior (or trend), or more generally, to simplify data processing or to improve system performance. However, to the best of our knowledge, patterns have never been used in the context of web archiving. Web archiving is the process of continuously collecting and preserving portions of the World Wide Web for future generations. In this paper, we show how patterns of page changes can be useful tools to efficiently archive web sites. We first define our pattern model that describes the changes of pages. Then, we present the strategy used to (i) extract the temporal evolution of page changes, to (ii) discover patterns and to (iii) exploit them to improve web archives. We choose the archive of French public TV channels France Télévisions as a case study in order to validate our approach. Our experimental evaluation based on real web pages shows the utility of patterns to improve archive quality and to optimize indexing or storing. © 2011 ACM.",17,,2-s2.0-79960525082,Conference Proceeding,2011-07-25,10.1145/1998076.1998098,122,9781450307444,15525996,113-122,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,113,http://api.elsevier.com/content/abstract/scopus_id/79960525082,,79960525082,145752,p,Archiving the web using page changes patterns: A case study
"Academic homepages are rich sources of information on scientific research and researchers. Most researchers provide information about themselves and links to their research publications on their homepages. In this study, we address the following questions related to academic homepages: (1) How many academic homepages are there on the web? (2) Can we accurately discriminate between academic homepages and other webpages? and (3) What information can be extracted about researchers from their homepages? For addressing the first question, we use mark-recapture techniques commonly employed in biometrics to estimate animal population sizes. Our results indicate that academic homepages comprise a small fraction of the Web making automatic methods for discriminating them crucial. We study the performance of content-based features for classifying webpages. We propose the use of topic models for identifying content-based features for classification and show that a small set of LDA-based features out-perform term features selected using traditional techniques such as aggregate term frequencies or mutual information. Finally, we deal with the extraction of name and research interests information from an academic homepage. Term-topic associations obtained from topic models are used to design a novel, unsupervised technique to identify short segments corresponding to research interests of the researchers specified in academic homepages. We show the efficacy of our proposed methods on all the three tasks by experimentally evaluating them on multiple publicly-available datasets. © 2011 ACM.",12,,2-s2.0-79960522068,Conference Proceeding,2011-07-25,10.1145/1998076.1998099,132,9781450307444,15525996,123-132,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,123,http://api.elsevier.com/content/abstract/scopus_id/79960522068,,79960522068,145752,p,On identifying academic homepages for digital libraries
"The Memento Project's archive access additions to HTTP have enabled development of new web archive access user interfaces. After experiencing this web time travel, the in- evitable question that comes to mind is ""How much of the Web is archived?"" This question is studied by approximating the Web via sampling URIs from DMOZ, Delicious, Bitly, and search engine indexes and measuring number of archive copies available in various public web archives. The results indicate that 35%-90% of URIs have at least one archived copy, 17%-49% have two to five copies, 1%-8% have six to ten copies, and 8%-63% at least ten copies. The number of URI copies varies as a function of time, but only 14.6-31.3% of URIs are archived more than once per month. © 2011 ACM.",35,,2-s2.0-79960506624,Conference Proceeding,2011-07-25,10.1145/1998076.1998100,136,9781450307444,15525996,133-136,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,133,http://api.elsevier.com/content/abstract/scopus_id/79960506624,,79960506624,145752,p,How much of the web is archived?
"For discovering the new URI of a missing web page, lexical signatures, which consist of a small number of words chosen to represent the ""aboutness"" of a page, have been previously proposed. However, prior methods relied on computing the lexical signature before the page was lost, or using cached or archived versions of the page to calculate a lexical signature. We demonstrate a system of constructing a lexical signature for a page from its link neighborhood, that is the ""backlinks"", or pages that link to the missing page. After testing various methods, we show that one can construct a lexical signature for a missing web page using only ten backlink pages. Further, we show that only the first level of backlinks are useful in this effort. The text that the backlinks use to point to the missing page is used as input for the creation of a four-word lexical signature. That lexical signature is shown to successfully find the target URI in more than half of the test cases. © 2011 ACM.",9,,2-s2.0-79960529075,Conference Proceeding,2011-07-25,10.1145/1998076.1998101,140,9781450307444,15525996,137-140,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,137,http://api.elsevier.com/content/abstract/scopus_id/79960529075,,79960529075,145752,p,Rediscovering missing web pages using link neighborhood lexical signatures
"Sharing news is a popular activity in social media and influence both individuals and society. However, little empirical research has been conducted to explore the motivations underlying users' news sharing behavior. Adopting the uses and gratifications perspective, this study examined the role of gratification factors and user experience in explaining users' news sharing intention on social media. Hierarchical regression was employed to analyze the data collected from 144 undergraduate and graduate students. The results show that status seeking was the strongest motivation in predicting news sharing intention, followed by sociality and informativeness. However, entertainment/escapism was not a significant predictor in contrast to prior work. Further, we examined user experience in predicting news sharing intention and identified it as a significant factor. © 2011 ACM.",6,,2-s2.0-79960517172,Conference Proceeding,2011-07-25,10.1145/1998076.1998103,144,9781450307444,15525996,141-144,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,141,http://api.elsevier.com/content/abstract/scopus_id/79960517172,,79960517172,145752,p,That's news to me: The influence of perceived gratifications and personal experience on news sharing in social media
"In conjunction with Iowa City's designation as a UNESCO ""City of Literature,"" an interdisciplinary research team at The University of Iowa collaborated to develop a digital library featuring important Iowa City authors and locations. The ""City of Lit"" digital library consists of a mobile application for the general public and a set of web-based interfaces for researchers and content creators. This paper explains the motivation and describes the design and implementation of the digital library, its framework, the user-side mobile app and our future plans. We also outline a pilot study, in which undergraduate students conducted scholarly research and created content for the digital collection. © 2011 ACM.",3,,2-s2.0-79960525080,Conference Proceeding,2011-07-25,10.1145/1998076.1998104,148,9781450307444,15525996,145-148,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,145,http://api.elsevier.com/content/abstract/scopus_id/79960525080,,79960525080,145752,p,"Facilitating content creation and content research in building the ""City of Lit"" digital library"
"In CADAL, there preserve a lot of Chinese classical literatures, including graceful prose and verse. These works written in ancient Chinese comparatively are concise in vocabulary and sentence patterns. But they express rich feelings and convey a wealth of information. Although can be explained in modern Chinese, the aesthetic sense in those works disappears. So we aim to illustrate the feeling in these works using Chinese traditional music which is also another part of Chinese culture. This is an interesting and challenging work. In this paper, the correlation between the text and music is studied. A novel approach is proposed to model the latent semantic association underlying the two medium. Based on the correlation model we learned from training data, we can associate a literary work (mainly verse and prose in our digital library) with a few music pieces automatically. When a reader is appreciating a literary work, a piece of background music is playing meanwhile, the information and emotion implied by the work and music blend together. The reader may be immersed into the emotion and obtain aesthetic enjoyment intensively. We implement the proposed method and design experiments to evaluate the performance of it. The experimental result substantiates the feasibility of the proposed approach in this paper. © 2011 ACM.",0,,2-s2.0-79960505312,Conference Proceeding,2011-07-25,10.1145/1998076.1998105,152,9781450307444,15525996,149-152,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,149,http://api.elsevier.com/content/abstract/scopus_id/79960505312,,79960505312,145752,p,Towards a new reading experience via semantic fusion of text and music
"With the growing presence of large collections of musical content, methods for facilitating efficient browsing and fast comparisons of audio pieces become more and more useful. Notably, methods that isolate relevant parts in audio pieces give an insight of the musical content and can be used to improve similarity evaluation systems. In this context, we propose an indexing method that allows retrieving in audio signals particular parts, namely a major repetition. We use harmonic representations together with string matching techniques to strictly define and isolate such segments. Experiments on state-of-the-art structural datasets show a strong correlation between the retrieved parts and the perceived structure of pieces. © 2011 ACM.",3,,2-s2.0-79960541310,Conference Proceeding,2011-07-25,10.1145/1998076.1998106,156,9781450307444,15525996,153-156,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,153,http://api.elsevier.com/content/abstract/scopus_id/79960541310,,79960541310,145752,p,Indexing musical pieces using their major repetition
"This paper presents the results of a study of the ownership and reuse of visual media. A survey was administered to 250 social media-savvy respondents to investigate their attitudes about saving, sharing, publishing, and removing online photos; the survey also explored participants' current photo-sharing and reuse practices, and their general expectations of photo reuse. Our probe of respondent attitudes revealed that respondents felt: (1) people should be able to save visual media, regardless of its source; (2) people have slightly less right to reuse photos than they do to save them; (3) a photo's subject has a slightly greater right than the photographer to reuse the photo in non-commercial situations; (4) removal is controversial, but trends more positive when it involves only metadata (e.g. tags); and (5) access to institutional archives of personal photos is better deferred for 50 years. Participants explained their own reuse of online photos in pragmatic terms that included the nature of the content, the aim and circumstances of reuse, their sense of the photo's original use, and their understanding of existing laws and restrictions. In the abstract, the same general question revealed a 'reuse paradox'; while respondents trust themselves to make this judgment, they do not trust the reciprocal judgment of unknown others. © 2011 ACM.",20,,2-s2.0-79960548703,Conference Proceeding,2011-07-25,10.1145/1998076.1998108,166,9781450307444,15525996,157-166,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,157,http://api.elsevier.com/content/abstract/scopus_id/79960548703,,79960548703,145752,p,The ownership and reuse of visual media
"In the process of digitizing a book, a library needs to clear the rights associated with it. Rights clearance is a time consuming process, and possibly, with higher costs than the actual digitization. To analyze the rights situation, a range of information is required, which is distributed across several national databases hosted in national libraries, publishers and collective rights organizations. National bibliographies are key data sources in these processes, as they are the only source to identify all the publications of a specific intellectual work per country. However, national bibliographies are not built for rights clearance purposes. The information in bibliographic records results from cataloguing practices with users and library management in mind, and links between different publications of a single intellectual work are not available. This paper presents a study on the implications of data quality problems of national bibliographies for the identification of all publications of a work. It also presents an approach for work data extraction and matching based on similarity of the most discriminatory attributes of works. Evaluation has shown that the data quality problems are difficult to overcome, as our best approach achieved an F0,5-measure of 0,91. These results help to speed up the process of discovering all relevant publications per work significantly, with sufficient recall. © 2011 ACM.",1,,2-s2.0-79960495246,Conference Proceeding,2011-07-25,10.1145/1998076.1998109,174,9781450307444,15525996,167-174,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,167,http://api.elsevier.com/content/abstract/scopus_id/79960495246,,79960495246,145752,p,Using national bibliographies for rights clearance
"In this paper we present a model based on the principles of Linked Data that can be used to describe the interrelationships of images, texts and other resources to facilitate the interoperability of repositories of medieval manuscripts or other culturally important handwritten documents. The model is designed from a set of requirements derived from the real world use cases of some of the largest digitized medieval content holders, and instantiations of the model are intended as the input to collection-independent page turning and scholarly presentation interfaces. A canvas painting paradigm, such as in PDF and SVG, was selected based on the lack of a one to one correlation between image and page, and to fulfill complex requirements such as when the full text of a page is known, but only fragments of the physical object remain. The model is implemented using technologies such as OAI-ORE Aggregations and OAC Annotations, as the fundamental building blocks of emerging Linked Digital Libraries. The model and implementation are evaluated through prototypes of both content providing and consuming applications. Although the system was designed from requirements drawn from the medieval manuscript domain, it is applicable to any layout-oriented presentation of images of text. © 2011 ACM.",10,,2-s2.0-79960475155,Conference Proceeding,2011-07-25,10.1145/1998076.1998111,184,9781450307444,15525996,175-184,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,175,http://api.elsevier.com/content/abstract/scopus_id/79960475155,,79960475155,145752,p,SharedCanvas: A collaborative model for medieval manuscript layout dissemination
"Many scholarly tasks involve working with subdocuments, or contextualized fine-grain information, i.e., with information that is part of some larger unit. A digital library (DL) facilitates management, access, retrieval, and use of collections of data and metadata through services. However, most DLs do not provide infrastructure or services to support working with subdocuments. Superimposed information (SI) refers to new information that is created to reference subdocuments in existing information resources. We combine this idea of SI with traditional DL services, to define and develop a DL with SI (SI-DL). We explored the use of subimages and evaluated the use of SuperIDR, a prototype SI-DL, in fish species identification, a scholarly task that involves working with subimages. The contexts and strategies of working with subimages in SuperIDR suggest new and enhanced support (SI-DL services) for scholarly tasks that involve working with subimages, including new ways of querying and searching for subimages and associated information. The main conceptual contributions of our work are the insights gained from these findings of the use of subimages and of SuperIDR, which lead to recommendations for the design of digital libraries with superimposed information. © 2011 ACM.",2,,2-s2.0-79960537816,Conference Proceeding,2011-07-25,10.1145/1998076.1998112,194,9781450307444,15525996,185-194,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,185,http://api.elsevier.com/content/abstract/scopus_id/79960537816,,79960537816,145752,p,Use of subimages in fish species identification: A qualitative study
"Some digital libraries support annotations, but sharing these annotations with other systems or across the web is difficult because of the need of special applications to read and decode these annotations. Due to the frequent change of web resources, the annotation's meaning can change if the underlying resources change. This project concentrates on minting a new URI for every annotation and creating a persistent and independent archived version of all resources. Users should be able to select a segment of an image or a video to be part of the annotation. The media fragment URIs described in the Open Annotation Collaboration data model can be used, but in practice they have limits, and they face the lack of support by the browsers. So in this project the segments of images, and videos can be used in the annotations without using media fragment URIs. © 2011 ACM.",0,,2-s2.0-79960498038,Conference Proceeding,2011-07-25,10.1145/1998076.1998113,198,9781450307444,15525996,195-198,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,195,http://api.elsevier.com/content/abstract/scopus_id/79960498038,,79960498038,145752,p,Persistent annotations deserve new URIs
"Historic maps are valuable scholarly resources that record information often retained by no other written source. With the YUMA Map Annotation Tool we want to facilitate collaborative annotation for scholars studying historic maps, and allow for semantic augmentation of annotations with structured, contextually relevant information retrieved from Linked Open Data sources. We believe that the integration of Web resource linkage into the scholarly annotation process is not only relevant for collaborative research, but can also be exploited to improve search and retrieval. In this paper, we introduce the COMPASS Experiment, an ongoing crowdsourcing effort in which we are collecting data that can serve as a basis for evaluating our assumption. We discuss the scope and setup of the experiment framework and report on lessons learned from the data collected so far. © 2011 ACM.",9,,2-s2.0-79960481212,Conference Proceeding,2011-07-25,10.1145/1998076.1998114,202,9781450307444,15525996,199-202,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,199,http://api.elsevier.com/content/abstract/scopus_id/79960481212,,79960481212,145752,p,Semantically augmented annotations in digitized map collections
"We need to harness the growing wealth of information in digital libraries to support intellectual work involving creative and exploratory processes. Prior research on hypertext authoring shifted the focus from explicit structure to direct presentation of content aided by ""implicit"" spatial representation of structure. We likewise shift the field of information visualization. Using hypertext's rubric, we redefine what most people think of as ""information visualization"" as explicit structure visualization. We alternatively address implicit structure visualization, presenting content directly, representing structure with spatiality and other visual features. We integrate authoring to emphasize the role of human thought in learning and ideation. Prior research has shown that people iteratively collect and organize information by clipping magazines, piling clippings in somewhat messy ways, and organizing them. MessyOrganizer is an iterative implicit structure visualization algorithm which, like human practice, gradually collects and organizes information clippings. Content is depicted directly. Structural relationships are visualized implicitly through spatial positioning of related elements, with overlap and translucence. The simulated annealing algorithm is applied to a model of semantic relatedness over a spatial grid. We develop an experiment comparing products created with the integrated environment versus separated visualization and authoring spaces. Results reveal that participants have more novel and varied ideas when visualization is integrated with authoring. © 2011 ACM.",4,,2-s2.0-79960495245,Conference Proceeding,2011-07-25,10.1145/1998076.1998116,212,9781450307444,15525996,203-212,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,203,http://api.elsevier.com/content/abstract/scopus_id/79960495245,,79960495245,145752,p,Integrating implicit structure visualization with authoring promotes ideation
"This paper presents the design rationale and initial findings derived from preliminary usage of OntoStarFish, a visualization technique aimed at taking advantage of implicit relationships that can be inferred from large collections of documents in digital libraries. OntoStarFish makes such relationships explicit so users may visualize them and detect potential collaboration networks. Users that may be interested in exploring collaboration networks include researchers looking for partners for specific projects as well as funding agencies concerned with the strength of associations among participants of competing proposals. OntoStarFish is based upon the use of multiple fisheye views that can be placed on top of starfields, dynamic scatter plots for which each axis is determined by a lightweight ontology of attributes associated to potential collaborators. © 2011 ACM.",2,,2-s2.0-79960551067,Conference Proceeding,2011-07-25,10.1145/1998076.1998117,221,9781450307444,15525996,213-221,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,213,http://api.elsevier.com/content/abstract/scopus_id/79960551067,,79960551067,145752,p,Visualizing collaboration networks implicit in digital libraries using OntoStarFish
"This paper introduces HMpara, a new search engine that aims to make Wikipedia easier to explore. It works on top of the encyclopedia's existing link structure, abstracting away from document content and allowing users to navigate the resource at a higher level. It utilizes semantic relatedness measures to emphasize articles and connections that are most likely to be of interest, visualization to expose the structure of how the available information is organized, and lightweight information extraction to explain itself. © 2011 ACM.",1,,2-s2.0-79960529481,Conference Proceeding,2011-07-25,10.1145/1998076.1998118,226,9781450307444,15525996,223-226,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,223,http://api.elsevier.com/content/abstract/scopus_id/79960529481,,79960529481,145752,p,A link-based visual search engine for Wikipedia
"Web browsers provide only little support for users to revisit pages that they do not visit very often. We developed a browser toolbar that reminds users of visited pages related to the page that they currently viewing. The recommendation method combines ranking with propagation methods. A user evaluation shows that on average 22.7% of the revisits were triggered by the toolbar, a considerable change on the participants' revisitation routines. In this paper we discuss the value of the recommendations and the implications derived from the evaluation. © 2011 ACM.",4,,2-s2.0-79960489217,Conference Proceeding,2011-07-25,10.1145/1998076.1998119,230,9781450307444,15525996,227-230,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,227,http://api.elsevier.com/content/abstract/scopus_id/79960489217,,79960489217,145752,p,Supporting revisitation with contextual suggestions
"Collaborative research has been increasingly popular and important in academic circles. However, there is no open platform available for scholars or scientists to effectively discover potential collaborators. This paper discusses CollabSeer, an open system to recommend potential research collaborators for scholars and scientists. CollabSeer discovers collaborators based on the structure of the coauthor network and a user's research interests. Currently, three different network structure analysis methods that use vertex similarity are supported in CollabSeer: Jaccard similarity, cosine similarity, and our relation strength similarity measure. Users can also request a recommendation by selecting a topic of interest. The topic of interest list is determined by CollabSeer's lexical analysis module, which analyzes the key phrases of previous publications. The CollabSeer system is highly modularized making it easy to add or replace the network analysis module or users' topic of interest analysis module. CollabSeer integrates the results of the two modules to recommend collaborators to users. Initial experimental results over a subset of the CiteSeerX database show that CollabSeer can efficiently discover prospective collaborators. © 2011 ACM.",56,,2-s2.0-79960548564,Conference Proceeding,2011-07-25,10.1145/1998076.1998121,240,9781450307444,15525996,231-240,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,231,http://api.elsevier.com/content/abstract/scopus_id/79960548564,,79960548564,145752,p,CollabSeer: A search engine for collaboration discovery
"We investigate how author name homonymy distorts clustered large-scale co-author networks, and present a simple, effective, scalable and generalizable algorithm to ameliorate such distortions. We evaluate the performance of the algorithm to improve the resolution of mesoscopic network structures, that is those meso-level structures of a network resulting from groupings of nodes and their interlinking. To this end, we establish the ground truth for a sample of author names that is statistically representative of different types of nodes in the co-author network, distinguished by their role for the connectivity of the network. We finally observe that this distinction of node roles based on the mesoscopic structure of the network, in combination with a quantification of the commonality of last names, suggests a new approach to assess network distortion by homonymy and to analyze the reduction of distortion in the network after disambiguation, without requiring ground truth sampling. © 2011 ACM.",9,,2-s2.0-79960534136,Conference Proceeding,2011-07-25,10.1145/1998076.1998122,250,9781450307444,15525996,241-250,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,241,http://api.elsevier.com/content/abstract/scopus_id/79960534136,,79960534136,145752,p,Resolving author name homonymy to improve resolution of structures in co-author networks
"Searching for people with expertise on a particular topic also known as expert search is a common task in digital libraries. Most models for this task use only documents as evidence for expertise while ranking people. In digital libraries, other sources of evidence are available such as a document's association with venues and citation links with other documents. We propose graph-based models that accommodate multiple sources of evidence in a PageRank-like algorithm for ranking experts. Our studies on two publicly-available datasets indicate that our model despite being general enough to be directly useful for ranking other types of objects performs on par with probabilistic models commonly used for expert ranking. © 2011 ACM.",24,,2-s2.0-79960525937,Conference Proceeding,2011-07-25,10.1145/1998076.1998123,254,9781450307444,15525996,251-254,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,251,http://api.elsevier.com/content/abstract/scopus_id/79960525937,,79960525937,145752,p,Ranking authors in digital libraries
"Various approaches for plagiarism detection exist. All are based on more or less sophisticated text analysis methods such as string matching, fingerprinting or style comparison. In this paper a new approach called Citation-based Plagiarism Detection is evaluated using a doctoral thesis, in which a volunteer crowd-sourcing project called GuttenPlag identified substantial amounts of plagiarism through careful manual inspection. This new approach is able to identify similar and plagiarized documents based on the citations used in the text. It is shown that citation-based plagiarism detection performs significantly better than text-based procedures in identifying strong paraphrasing, translation and some idea plagiarism. Detection rates can be improved by combining citation-based with text-based plagiarism detection. © 2011 ACM.",19,,2-s2.0-79960524251,Conference Proceeding,2011-07-25,10.1145/1998076.1998124,258,9781450307444,15525996,255-258,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,255,http://api.elsevier.com/content/abstract/scopus_id/79960524251,,79960524251,145752,p,Comparative evaluation of text- and citation-based plagiarism detection approaches using GuttenPlag
"With the growth in operational digital libraries, the need for automatic methods capable of characterizing adoption and use has grown. We describe a computational methodology for producing two, inter-related, user typologies based on use diffusion. Use diffusion theory views technology adoption as a process that can lead to widely different patterns of use across a given population of potential users; these models use measures of frequency and variety to characterize and describe these usage patterns. The methodology uses computational techniques such as clickstream entropy and clustering to produce both coarse-grained and fine-grained user typologies. A case study demonstrates the utility and applicability of the method: it is used to understand how middle and high school science teachers participating in an academic year-long field trial adopted and integrated digital library resources into their instructional planning and teaching. The resulting fine-grained user typology identified five different types of teacher-users, including ""interactive resource specialists"" and ""community seeker specialists"" This typology was validated through comparison with qualitative and quantitative data collected using traditional educational field research methods. © 2011 ACM.",7,,2-s2.0-79960509328,Conference Proceeding,2011-07-25,10.1145/1998076.1998126,268,9781450307444,15525996,259-268,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,259,http://api.elsevier.com/content/abstract/scopus_id/79960509328,,79960509328,145752,p,Understanding digital library adoption: A use diffusion approach
"Users' search tactics often appear naïve. Much research has endeavored to understand the rudimentary query typically seen in log analyses and user studies. Researchers have tested a number of approaches to supporting query development, including information literacy training and interaction design these have tried and often failed to induce users to use more complex search strategies. To further investigate this phenomenon, we combined established HCI methods with models from cultural studies, and observed customers' mediated searches for books in bookstores. Our results suggest that sophisticated search techniques demand mental models that many users lack. © 2011 ACM.",17,,2-s2.0-79960522456,Conference Proceeding,2011-07-25,10.1145/1998076.1998127,278,9781450307444,15525996,269-278,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,269,http://api.elsevier.com/content/abstract/scopus_id/79960522456,,79960522456,145752,p,In the bookshop: Examining popular search strategies
"Although initiatives are underway in the educational community to consolidate disparate collections of educational standards, little has been done to explore the impact of educational standard formulation on information retrieval. Recent research contrasts two categories of educational standards: 'World' (topical domain-related concepts) and 'Method' (investigative and epistemological principles). This paper explores the information retrieval implications of the World vs. Method distinction. We find that experts are more likely to agree about which educational resources align with a Method standard but that a typical automatic standard assignment tool is more likely to assign a World standard to an educational resource. Further, a text-based information retrieval system is more likely to be accurate in retrieving documents relevant to a World standard as compared to a Method standard. These findings have implications both for educational standard formulation (combining World and Method components in a standard may improve retrieval) and for digital library builders who want to help teachers identify useful, standards-aligned learning objects. © 2011 ACM.",4,,2-s2.0-79960553035,Conference Proceeding,2011-07-25,10.1145/1998076.1998128,282,9781450307444,15525996,279-282,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,279,http://api.elsevier.com/content/abstract/scopus_id/79960553035,,79960553035,145752,p,World vs. method: Educational standard formulation impacts document retrieval
"Assessing the quality of online educational resources in a cost effective manner is a critical issue for educational digital libraries. This study reports on the approach for extending the Open Educational Resource Assessments (OPERA) algorithm from assessing vetted to peer-produced content. This article reports details of changes to the algorithm, comparisons between human raters and the algorithm, and the extent the algorithm can automate the review process. © 2011 ACM.",0,,2-s2.0-79960535721,Conference Proceeding,2011-07-25,10.1145/1998076.1998129,286,9781450307444,15525996,283-286,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,283,http://api.elsevier.com/content/abstract/scopus_id/79960535721,,79960535721,145752,p,Automating open educational resources assessments: A machine learning generalization study
"A book recommender system is very useful for a digital library. Good book recommender systems can effectively help users find interesting and relevant books from the massive resources, by providing individual recommendation book list for each end-user. By now, a variety of collaborative filtering algorithms have been invented, which are the cores of most recommender systems. However, because of the explosion of information, especially in the Internet, the improvement of the efficiency of the collaborative filting (CF) algorithm becomes more and more important. In this paper, we first propose a parallel Top-N recommendation algorithm in CUDA (Compute Unified Device Architecture) which combines the collaborative filtering and trust-based approach to deal with the cold-start user problem. Then based on this algorithm, we present a parallel book recommender system on a GPU (Graphics Processor unit) for CADAL digital library platform. Our experimental results show our algorithm is very efficient to process the large-scale datasets with good accuracy, and we report the impact of different values of parameters on the recommendation performance. © 2011 ACM.",5,,2-s2.0-79960526998,Conference Proceeding,2011-07-25,10.1145/1998076.1998131,296,9781450307444,15525996,287-296,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,287,http://api.elsevier.com/content/abstract/scopus_id/79960526998,,79960526998,145752,p,A social network-aware top-N recommender system using GPU
"As the number of research papers available on the Web has increased enormously over the years, paper recommender systems have been proposed to help researchers on automatically finding works of interest. The main problem with the current approaches is that they assume that recommending algorithms are provided with a rich set of evidence (e.g., document collections, citations, profiles) which is normally not widely available. In this paper we propose a novel source independent framework for research paper recommendation. The framework requires as input only a single research paper and generates several potential queries by using terms in that paper, which are then submitted to existing Web information sources that hold research papers. Once a set of candidate papers for recommendation is generated, the framework applies content-based recommending algorithms to rank the candidates in order to recommend the ones most related to the input paper. This is done by using only publicly available metadata (i.e., title and abstract). We evaluate our proposed framework by performing an extensive experimentation in which we analyzed several strategies for query generation and several ranking strategies for paper recommendation. Our results show that good recommendations can be obtained with simple and low cost strategies. © 2011 ACM.",30,,2-s2.0-79960475558,Conference Proceeding,2011-07-25,10.1145/1998076.1998132,306,9781450307444,15525996,297-306,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,297,http://api.elsevier.com/content/abstract/scopus_id/79960475558,,79960475558,145752,p,A source independent framework for research paper recommendation
"Serendipity occurs when one finds an interesting discovery while searching for something else. While search engines seek to report work relevant to a targeted query, recommendation engines are particularly well-suited for serendipitous recommendations as such processes do not need to fulfill a targeted query. Junior researchers can use such an engine to broaden their horizon and learn new areas, while senior researchers can discover interdisciplinary frontiers to apply integrative research. We adapt a state-of-the-art scholarly paper recommendation system's user profile construction to make use of information drawn from 1) dissimilar users and 2) co-authors to specifically target serendipitous recommendation. © 2011 ACM.",13,,2-s2.0-79960513748,Conference Proceeding,2011-07-25,10.1145/1998076.1998133,310,9781450307444,15525996,307-310,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,307,http://api.elsevier.com/content/abstract/scopus_id/79960513748,,79960513748,145752,p,Serendipitous recommendation for scholarly papers considering relations among researchers
"With product reviews growing in depth and becoming more numerous, it is growing challenge to acquire a comprehensive understanding of their contents, for both customers and product manufacturers. We built a system that automatically summarizes a large collection of product reviews to generate a concise summary. Importantly, our system not only extracts the review sentiments but also the underlying justification for their opinion. We solve this problem through a novel application of clustering and validate our approach through an empirical study, obtaining good performance as judged by F-measure (the harmonic mean of purity and inverse purity). © 2011 ACM.",15,,2-s2.0-79960550660,Conference Proceeding,2011-07-25,10.1145/1998076.1998134,314,9781450307444,15525996,311-314,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,311,http://api.elsevier.com/content/abstract/scopus_id/79960550660,,79960550660,145752,p,Product review summarization from a deeper perspective
"This paper explores the cognitive processes and online behaviors in which preservice teachers engage when seeking educational resources for classroom instruction. Participants used graphical and keyword search interfaces provided by a large-scale digital library (NSDL.org) and a keyword search interface from a large, commercial search engine (Google.com) to complete searches for online materials that would support classroom instruction. Overall, findings from the current work indicate that a graphical search interface can support comprehension by providing a conceptual organization of domain content during digital search and evaluation. Findings also show that digital libraries allow users to offload processing related to resource trustworthiness, thereby increasing cognitive capacity for other purposes. © 2011 ACM.",4,,2-s2.0-79960486386,Conference Proceeding,2011-07-25,10.1145/1998076.1998136,324,9781450307444,15525996,315-324,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,315,http://api.elsevier.com/content/abstract/scopus_id/79960486386,,79960486386,145752,p,Do graphical search interfaces support effective search for and evaluation of digital library resources
"Nowadays, the information access is conducted almost exclusively using the Web. Simple keyword based Web search engines, e.g. Google or Yahoo!, offer suitable retrieval and ranking features. In contrast, for highly specialized domains, represented by digital libraries, these features are insufficient. Considering the domain of chemistry, where searching for relevant literature is essentially centered on chemical entities. Beside commercial information providers such as Chemical Abstract Service (CAS) numerous groups are working on building free chemical search engines to overcome the expensive access to chemical literature. However, due to the nature of chemical queries these are often overspecialized. Often we need meaningful similarity measures for chemical entities for query relaxation. In chemistry, the similarity measures are vast; more than 40 similarity measures are available and focus on different aspects of chemical entities. This vast number of similarity measures is obvious, because the desired search results highly depend on the working field of the chemist. In this paper we present a personalized retrieval system for chemical documents taking into account the background knowledge of the individual chemist. This is done by a query relaxation for chemical entities using similar substances. We evaluate our approach extensively by analyzing the correlation of commonly used chemical similarity measures and fingerprint representations. All uncorrelated measures are finally used by our feedback engine to learn preferred similarity measures for each user. We also conducted a user study with domain experts showing that our system can assign a unique similarity measure for 75% of the users after only 10 feedback cycles. © 2011 ACM.",3,,2-s2.0-79960494007,Conference Proceeding,2011-07-25,10.1145/1998076.1998137,333,9781450307444,15525996,325-333,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,325,http://api.elsevier.com/content/abstract/scopus_id/79960494007,,79960494007,145752,p,Taking chemistry to the task - Personalized queries for chemical digital libraries
"Physics Pathway is a digital library available through an Adobe Flash portal whose contents are a series of interviews with four experts who answer questions about the pedagogy of teaching physics. The answers were collected over a broad time span, but are presented to the user as if he or she is conducting the personal interview, similar to naturally conversing with the expert. This ""synthetic interview"" style is discussed in this paper, with a mixed methods evaluation by 19 high school teachers who used Physics Pathway for a 14-week period at the end of 2010. The evaluation with teachers showed that the synthetic interviews validated or reinforced their ideas on their course materials and delivery. As these are teachers who are relatively new to physics instruction, confirmation that they are teaching well is important. Physics Pathway is linked with comPADRE, a member of the National Science Digital Library. © 2011 ACM.",0,,2-s2.0-79960492108,Conference Proceeding,2011-07-25,10.1145/1998076.1998138,338,9781450307444,15525996,335-338,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,335,http://api.elsevier.com/content/abstract/scopus_id/79960492108,,79960492108,145752,p,Physics pathway: A digital library filled with synthetic interviews
"This paper describes an approach for performing recognition and resolution of place names mentioned over the descriptive metadata records of typical digital libraries. Our approach exploits evidence provided by the existing structured attributes within the metadata records to support the place name recognition and resolution, in order to achieve better results than by just using lexical evidence from the textual values of these attributes. In metadata records, lexical evidence is very often insufficient for this task, since short sentences and simple expressions are predominant. Our implementation uses a dictionary based technique for recognition of place names (with names provided by Geonames), and machine learning for reasoning on the evidences and choosing a possible resolution candidate. The evaluation of our approach was performed in data sets with a metadata schema rich in Dublin Core elements. Two evaluation methods were used. First, we used cross-validation, which showed that our solution is able to achieve a very high precision of 0,99 at 0,55 recall, or a recall of 0,79 at 0,86 precision. Second, we used a comparative evaluation with an existing commercial service, where our solution performed better on any confidence level (p<0,001). © 2011 ACM.",12,,2-s2.0-79960540449,Conference Proceeding,2011-07-25,10.1145/1998076.1998140,348,9781450307444,15525996,339-348,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,339,http://api.elsevier.com/content/abstract/scopus_id/79960540449,,79960540449,145752,p,A metadata geoparsing system for place name recognition and resolution in metadata records
"A large number of news articles are generated every day on the Web. Automatically identifying events from a large document collection is a challenging problem. In this paper, we propose two event detection approaches using generative models. We combine the popular LDA model with temporal segmentation and spatial clustering. In addition, we adapt an image segmentation model, SLDA, for spatial-temporal event detection on text. The results of our experiments show that both approaches outperform the traditional content-based clustering approaches on our datasets. © 2011 ACM.",27,,2-s2.0-79960534133,Conference Proceeding,2011-07-25,10.1145/1998076.1998141,358,9781450307444,15525996,349-358,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,349,http://api.elsevier.com/content/abstract/scopus_id/79960534133,,79960534133,145752,p,Event detection with spatial latent Dirichlet allocation
"Nowadays, digital libraries contain more and more videos in them, and how to organize and retrieve those videos effectively has become very urgent. Text in videos is a very meaningful clue for video semantic understanding, and it can be used for video organization and retrieval. However, existing text recognizing methods can not deal with multilingual texts or texts embedded in a complex background very well. In this paper, we propose a novel video text detection method. Edge detection and candidate region extraction are firstly used to obtain all rough candidate text regions, and then region refinement is used to obtain the accurate location of each region. Based on our observation that a real text region has a uniform distribution with its non-zero pixels in its binary image, an entropy filter is used to remove non-text regions. Experiments on various videos show that our method is effective and robust against different languages, background complexities and font styles. © 2011 ACM.",1,,2-s2.0-79960509326,Conference Proceeding,2011-07-25,10.1145/1998076.1998142,362,9781450307444,15525996,359-362,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,359,http://api.elsevier.com/content/abstract/scopus_id/79960509326,,79960509326,145752,p,A new video text detection method
"Increasing amounts of data are collected in many areas of research and application. The degree to which this data can be accessed, retrieved, and analyzed is decisive to obtain progress in fields such as scientific research or industrial production. We present a novel method supporting content-based retrieval and exploratory search in repositories of multivariate research data. In particular, functional dependencies are a key characteristic of data that researchers are often interested in. Our methods are able to describe the functional form of such dependencies, e.g., the relationship between inflation and unemployment in economics. Our basic idea is to use feature vectors based on the goodness-of-fit of a set of regression models, to describe the data mathematically. We denote this approach Regressional Features and use it for content-based search and, since our approach motivates an intuitive definition of interestingness, for exploring the most interesting data. We apply our method on considerable real-world research datasets, showing the usefulness of our approach for user-centered access to research data in a Digital Library system. © 2011 ACM.",12,,2-s2.0-79960533716,Conference Proceeding,2011-07-25,10.1145/1998076.1998144,372,9781450307444,15525996,363-372,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,363,http://api.elsevier.com/content/abstract/scopus_id/79960533716,,79960533716,145752,p,Retrieval and exploratory search in multivariate research data repositories using regressional features
"In 2008, the National Science Foundation released the DataNet solicitation, which presents an ambitious vision for a comprehensive data curation cyberinfrastructure in support of fourth paradigm science. The program subsequently funded two projects, DataONE and the Data Conservancy. The authors put forth an uncertainty framework for understanding the larger socio-cultural issues that influence the progress of DataNet projects and cyberinfrastructure projects in general. This framework highlights the key technical, organizational, scientific, and institutional contexts that the projects must consider as they mature. © 2011 ACM.",7,,2-s2.0-79960503142,Conference Proceeding,2011-07-25,10.1145/1998076.1998145,382,9781450307444,15525996,373-382,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,373,http://api.elsevier.com/content/abstract/scopus_id/79960503142,,79960503142,145752,p,A research agenda for data curation cyberinfrastructure
"As science becomes more dependent upon digital data, the need for data curation and for data digital libraries becomes more urgent. Questions remain about what researchers consider to be their data, their criteria for selecting and trusting data, and their orientation to data challenges. This paper reports findings from the first 18 months of research on astronomy data practices from the Data Conservancy. Initial findings suggest that issues for data production, use, preservation, and sharing revolve around factors that rarely are accommodated in use cases for digital library system design including trust in data, funding structures, communication channels, and perceptions of scientific value. © 2011 ACM.",6,,2-s2.0-79960521229,Conference Proceeding,2011-07-25,10.1145/1998076.1998146,386,9781450307444,15525996,383-386,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,383,http://api.elsevier.com/content/abstract/scopus_id/79960521229,,79960521229,145752,p,"When use cases are not useful: Data practices, astronomy, and digital libraries"
"Traditional information retrieval models do not necessarily provide users with optimal search experience because the top ranked documents may contain the same piece of relevant information, i.e., the same subtopic of a query. The goal of search result diversification is to return search results that not only are relevant to the query but also cover different subtopics. Therefore, the subtopic modeling is an important research topic in search result diversification. In this paper, we propose a novel pattern based method to extract subtopics from retrieved documents. The basic idea is to explicitly model a query subtopic as a semantically meaningful text unit in relevant documents. We apply a frequent pattern mining algorithm to efficiently extract these text units (patterns) from retrieved documents. We then model a query subtopic with a single pattern and rank subtopics based on their similarity with the query. These pattern based subtopics are then used to diversify search results. © 2011 Authors.",9,,2-s2.0-79960532909,Conference Proceeding,2011-07-25,10.1145/1998076.1998148,388,9781450307444,15525996,387-388,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,387,http://api.elsevier.com/content/abstract/scopus_id/79960532909,,79960532909,145752,p,An exploration of pattern-based subtopic modeling for search result diversification
"We consider the problem of efficient and template-independent news extraction on the Web. The popular news extraction methods are based on visual information, and they can achieve good accuracy performance, but the computational efficiency is poor, because it is very time-consuming to render web page to obtain visual information. In this paper we propose an efficient and effective news extraction approach based on novel features. Our approach neither needs training nor needs visual information, so it is simple and very efficient. And it can extract news information from various news sites without using templates. In our experiments, the proposed approach achieves 99% accuracy over 5,671 news pages from 20 different news sites. And the efficiency is much faster than the baseline machine learning method using visual information. © 2011 Authors.",3,,2-s2.0-79960551066,Conference Proceeding,2011-07-25,10.1145/1998076.1998149,390,9781450307444,15525996,389-390,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,389,http://api.elsevier.com/content/abstract/scopus_id/79960551066,,79960551066,145752,p,A very efficient approach to news title and content extraction on the web
"This paper proposes a new idea and approach for the web video search. Instead of only using the surrounding text of video in webpage, our approach boosts mutually and utilizes jointly the inside and outside text of video to support the video-based and frame-based search. In our approach, the inside text is the video caption, while the outside text is the surrounding text of video in webpage. In our view, the caption text, although has some wrong characters and words caused by the automatic caption recognition, is a useful indicator for the content of video. While the relevant surrounding texts of video, although is difficult to locate and confirm, have the correct characters and words which usually indicate the video content, especially the title and introduction of video. In this paper, we integrate their advantages and alleviate their disadvantages by the mutual boosting idea, that is, to employ the inside text to confirm the relevance of outside text, and to utilize the relevant outside text to correct the inside text. Mutual boosting not only enhances the query-by-text video search, but also further supports the query-by-text frame search with the corrected caption. Based on the above idea, our approach can be divided into three phases: Firstly, we proposed a new approach for automatic caption detection and extraction. Then, we extract the surrounding text candidates of video. Finally, the mutual boosting approach is employed to get the relevant and accurate text of web video. The experiments show the proposed approach can achieve good performance. © 2011 Authors.",0,,2-s2.0-79960529480,Conference Proceeding,2011-07-25,10.1145/1998076.1998150,392,9781450307444,15525996,391-392,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,391,http://api.elsevier.com/content/abstract/scopus_id/79960529480,,79960529480,145752,p,Web video search by mutual boosting between the inside and outside text of video
"Exploration is an activity that people undertake to broaden their knowledge on a certain topic. In contrast to regular search, which is typically aimed at obtaining a specific answer to a specific question, exploratory search should give a more complete overview of a topic. Further it should enable the discovery of related aspects, such as people, places, times and locations. Exploration demands more time, effort and creativity from the user, but rewards the user with deeper knowledge. Therefore, users need to be stimulated to bring exploration in regular goal-directed search activities. In this paper we present a user study in which we investigate different kinds of exploratory behavior and goals, as well as different kinds of visualizations to support exploration. © 2011 Authors.",3,,2-s2.0-79960487179,Conference Proceeding,2011-07-25,10.1145/1998076.1998151,394,9781450307444,15525996,393-394,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,393,http://api.elsevier.com/content/abstract/scopus_id/79960487179,,79960487179,145752,p,Visual interfaces for stimulating exploratory search
"This paper describes the design and evaluation of a distributed information resource system (IRS) shared between field and laboratory settings for higher education geology students. An investigation of geo-science scholarship and technical pilot studies highlighted the importance of situational specific and distributed information usage. To advance our understanding of novel resource approaches (i.e. from tabletops to tablets) and collaborative learning, two in-depth field trials evaluated 21 students' information journeys (i.e. initiating information needs, facilitating information and collaborative interpretation). Analysis identified how a designing for a varied device ecology supported information filtering and empathy between locations provoking deeper reflection and abstract understanding in the field, while live collaborative remote interaction provided an engaging yet distinct learning experience for those in the laboratory. © 2011 Authors.",7,,2-s2.0-79960541306,Conference Proceeding,2011-07-25,10.1145/1998076.1998152,396,9781450307444,15525996,395-396,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,395,http://api.elsevier.com/content/abstract/scopus_id/79960541306,,79960541306,145752,p,Designing interconnected distributed resources for collaborative inquiry based science education
"In this paper we propose an attribute retrieval approach which extracts and ranks attributes from Web tables. We combine simple heuristics to filter out improbable attributes and we rank attributes based on frequencies and a table match score. Ranking is reinforced with external evidence from Web search, DBPedia and Wikipedia. Our approach can be applied to whatever instance (e.g. Canada) to retrieve its attributes (capital, GDP). It is shown it has a much higher recall than DBPedia and Wikipedia and that it works better than lexico-syntactic rules for the same purpose. © 2011 Authors.",6,,2-s2.0-79960532908,Conference Proceeding,2011-07-25,10.1145/1998076.1998153,398,9781450307444,15525996,397-398,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,397,http://api.elsevier.com/content/abstract/scopus_id/79960532908,,79960532908,145752,p,Retrieving attributes using web tables
"Building digital libraries for preserving scientific digital data, ensuring its continued access, has emerged as a major initiative for funding agencies and academic institutions. Understanding the environments in which data is created, quality is assessed, and data is managed is a necessary antecedent to developing appropriate technologies to support the preservation and ongoing access to data. This paper reports on a study of 11 laboratories and research centers at three U.S. universities. Using the grounded theory methodology, this paper develops a new, generalized view of the e-Science data that attempts to explain the environment in which data is created, managed, documented, and preserved. © 2011 Author.",0,,2-s2.0-79960530835,Conference Proceeding,2011-07-25,10.1145/1998076.1998154,400,9781450307444,15525996,399-400,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,399,http://api.elsevier.com/content/abstract/scopus_id/79960530835,,79960530835,145752,p,Towards a model of the e-science data environment
"Citation-based methods have been widely studied and employed for clustering academic resources and mapping science. Although effective, these methods suffer from citation delay. In this study, we extend reference and citation analysis to a broader notion from social perspective. We coin the term ""social reference"" to refer to the references of literatures in social academic web environment. We propose clustering methods using social reference information from CiteULike. We experiment for journal clustering and author clustering using social reference and compare with citation-based methods. Our experiments indicate: first, social reference implies connections among literatures which are as effective as citation in clustering academic resources; second, in practical settings, social reference-based clustering methods are not as effective as citation-based ones due to the sparseness of social reference data, but they can outperform in clustering new resources that have few citation. © 2011 Authors.",12,,2-s2.0-79960488001,Conference Proceeding,2011-07-25,10.1145/1998076.1998155,402,9781450307444,15525996,401-402,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,401,http://api.elsevier.com/content/abstract/scopus_id/79960488001,,79960488001,145752,p,Social reference: Aggregating online usage of scientific literature in CiteULike for clustering academic resources
"The National Chung Hsing University Library has built a digital archive about Taiwan agricultural history. The content is unique in that it covers historical materials about Taiwan during the Japanese colonial period from 1895 to 1945, and that they are all available in full text, in addition to metadata. To make these materials more accessible to the research and education community, a user-centered retrieval system incorporated with multi-language, subject browsing, cluster analysis, topic map, post-query classification methods was developed to help users find the inter-relationships among documents and the collective meaning of a sub-collection. Such system is anticipated to help advance research in Taiwan agricultural history and set a model for other similar endeavor. © 2011 Authors.",0,,2-s2.0-79960519893,Conference Proceeding,2011-07-25,10.1145/1998076.1998156,404,9781450307444,15525996,403-404,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,403,http://api.elsevier.com/content/abstract/scopus_id/79960519893,,79960519893,145752,p,Digital archives of Taiwan agricultural history during the Japanese colonial period
"In this paper, we describe our Concept Extraction technique for Educational Digital libraries (CEED) which applies Conditional Random Fields (CRFs) to extract concepts from the Ensemble Pathway collection. In addition, we discuss how we implement RESTful APIs for concept extraction. © 2011 Authors.",0,,2-s2.0-79960520863,Conference Proceeding,2011-07-25,10.1145/1998076.1998157,406,9781450307444,15525996,405-406,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,405,http://api.elsevier.com/content/abstract/scopus_id/79960520863,,79960520863,145752,p,Developing a concept extraction technique with ensemble pathway
"This poster describes the development of international standards to publish oceanographic datasets. Research areas include the assignment of persistent identifiers, tracking provenance, linking datasets to publications, attributing credit to data providers, and best practices for the physical composition and semantic description of the content. © 2011 Authors.",0,,2-s2.0-79960521639,Conference Proceeding,2011-07-25,10.1145/1998076.1998158,408,9781450307444,15525996,407-408,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,407,http://api.elsevier.com/content/abstract/scopus_id/79960521639,,79960521639,145752,p,SCOR/IODE/MBLWHOI library collaboration on data publication
"The newly issued requirement for a data management plan in proposals submitted to the U.S. National Science Foundation and other federal funding agencies prompted many institutions to develop their own policies to conform to this new requirement as well as to more effectively manage, share, publish, and provide access to research data. While the need for guidelines or a framework in developing such data policies is imminent, research is lacking in this area. The study reported here addresses this need by using a content analysis of 58 policy documents from 20 institutions. Our preliminary findings reveal an uneven distribution of data policies among the institutions and disciplines included in this study. We are currently analyzing our results. © 2011 Authors.",4,,2-s2.0-79960510201,Conference Proceeding,2011-07-25,10.1145/1998076.1998159,410,9781450307444,15525996,409-410,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,409,http://api.elsevier.com/content/abstract/scopus_id/79960510201,,79960510201,145752,p,A content analysis of institutional data policies
"Topic models, through their ability to automatically learn and assign topics to documents in a collection, have the potential to greatly improve how content is organized and searched in digital libraries. However, much remains to be done to assess the value of topic models in digital library applications. In this work, we present results from a user study, in which participants evaluated the similarity of books clustered using matched topics and Library of Congress Subject Headings (LCSH). Topics outperformed LCSH in 11 cases; LCSH outperformed topics in 4. These results suggest that topics are a viable alternative to LCSH. © 2011 Authors.",2,,2-s2.0-79960537380,Conference Proceeding,2011-07-25,10.1145/1998076.1998160,412,9781450307444,15525996,411-412,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,411,http://api.elsevier.com/content/abstract/scopus_id/79960537380,,79960537380,145752,p,Are learned topics more useful than subject headings?
"Our research goal is to develop a search engine for open access to academic papers. English and Japanese test sets were built for detection of academic papers from 20,000 PDF files in each language using five annotators. Six classifiers were trained using similar features for each language. We report F1 of 0.74 for English and 0.54 for Japanese and argue that similar features could easily be generated for other languages as well. © 2011 Authors.",0,,2-s2.0-79960504404,Conference Proceeding,2011-07-25,10.1145/1998076.1998161,414,9781450307444,15525996,413-414,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,413,http://api.elsevier.com/content/abstract/scopus_id/79960504404,,79960504404,145752,p,Detecting academic papers on the web
"The newer generation of web browsers supports the client-side database, making it possible to run the full web application stacks entirely in the web clients. Still, the server side database is indispensable as the central hub for exchanging persistent data between the web clients. Assuming this characterization, we propose a novel web application framework in which the server archives its database states at predefined periods then makes them available on the web. The clients then use these archives to synchronize their local databases. Although the main purpose is to reduce the database scalability bottleneck, this approach also promotes self-archiving and can be used for time traveling. We discuss the consistency properties provided by this framework, as well as the tradeoffs imposed. © 2011 Authors.",0,,2-s2.0-79960536075,Conference Proceeding,2011-07-25,10.1145/1998076.1998162,416,9781450307444,15525996,415-416,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,415,http://api.elsevier.com/content/abstract/scopus_id/79960536075,,79960536075,145752,p,Improving scalability by self-archiving
"We have been developing a system to support the management of collections of web-based resources called the Distributed Collection Manager (DCM). As work on DCM has progressed, questions about the characteristics of people's collections of web pages have arisen. Simultaneously, work in the area of social media technology has ignored investigating how people are trying to maintain their collections. In order to address these concerns, we performed an online user study of 125 individuals from a variety of online and offline communities. From this study we were able to examine the needs for a system to manage web-based distributed collections, how current tools affect maintenance, and the characteristics of current practices and problems in maintaining web-based collections. © 2011 Authors.",1,,2-s2.0-79960512122,Conference Proceeding,2011-07-25,10.1145/1998076.1998163,418,9781450307444,15525996,417-418,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,417,http://api.elsevier.com/content/abstract/scopus_id/79960512122,,79960512122,145752,p,An analysis of personal collections among users of social media
"The Walden's Paths Project, as part of our philosophy of continual evaluation, seeks out user communities who may find our tool useful. However, our users, in the last few years, have reported a series of common issues and desired features. In order to support our users, we initiated a redesign of Walden's Paths to solve these problems and enable us to rapidly prototype and experiment with features and interfaces. In order to accomplish these goals, we have created a web service that handles the storage and representation of our Path data structure. This service is isolated from user interface layers, allowing multiple interface designs to be implemented on top of the same Path data structures. Our prototype interfaces also represent new areas for Paths such as collaborative work, offline presentation, and mobile computing. © 2011 Authors.",5,,2-s2.0-79960552624,Conference Proceeding,2011-07-25,10.1145/1998076.1998164,420,9781450307444,15525996,419-420,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,419,http://api.elsevier.com/content/abstract/scopus_id/79960552624,,79960552624,145752,p,WPv4: A re-imagined Walden's paths to support diverse user communities
"This paper investigates the occurrence of tags in different languages in a collaborative bookmarking and publication sharing service - BibSonomy. Social tags assigned to URLs in multiple languages and users tagging these URLs multilingually are the main focus of this study. The results show that multilingual tags occur for the same URL and that users tag in different languages. Furthermore, the results give indications that the language of the content of a URL does not imply that its tags are in the same language. © 2011 Authors.",3,,2-s2.0-79960498034,Conference Proceeding,2011-07-25,10.1145/1998076.1998165,422,9781450307444,15525996,421-422,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,421,http://api.elsevier.com/content/abstract/scopus_id/79960498034,,79960498034,145752,p,Is tagging multilingual? A case study with BibSonomy
"The back-of-book indexes for test collections of digital books in the domains of Economics and Geology have been deconstructed and analyzed, and the entries aggregated to create domain-level meta-indexes. Metrics comparing the two domains are presented. © 2011 Authors.",1,,2-s2.0-79960507048,Conference Proceeding,2011-07-25,10.1145/1998076.1998166,424,9781450307444,15525996,423-424,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,423,http://api.elsevier.com/content/abstract/scopus_id/79960507048,,79960507048,145752,p,Creating meta-indexes for digital domains
"Realizing the vision of networked data collections and services requires large bodies of scientific data that can be used in new ways. Adapting the concept of epistemological potential, we illustrate an approach for assessing the value of data for reuse in new domains. Two criteria for this analytic potential - integrity and fit-for-purpose - are recognized aspects of data curation, however identifying potential domains of interest for reuse requires knowledge of practices and needs across disciplines. Evaluating analytic potential will become increasingly important for libraries and repositories to make informed decisions about recruitment and curation of data for interdisciplinary science. © 2011 Authors.",0,,2-s2.0-79960539333,Conference Proceeding,2011-07-25,10.1145/1998076.1998167,426,9781450307444,15525996,425-426,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,425,http://api.elsevier.com/content/abstract/scopus_id/79960539333,,79960539333,145752,p,Analytic potential of data: Assessing reuse value
"In this poster paper, we present an overview of CiênciaBrasil, a research social network involving researchers within the Brazilian INCT program. We describe its architecture and the solutions adopted for data collection, extraction, and deduplication, and for materializing and visualizing the network. © 2011 Authors.",5,,2-s2.0-79960550658,Conference Proceeding,2011-07-25,10.1145/1998076.1998168,428,9781450307444,15525996,427-428,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,427,http://api.elsevier.com/content/abstract/scopus_id/79960550658,,79960550658,145752,p,Building a research social network from an individual perspective
"This paper describes a conceptualization of collection understanding task and its implementation in a map-based visualization (MBV) prototype that represents a library collection. Unlike previous conceptualizations that treat a collection as a whole composed of documents, our conceptualization is grounded in widely-researched concepts ""collection"" and ""understanding. © 2011 Author.",3,,2-s2.0-79960474310,Conference Proceeding,2011-07-25,10.1145/1998076.1998169,430,9781450307444,15525996,429-430,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,429,http://api.elsevier.com/content/abstract/scopus_id/79960474310,,79960474310,145752,p,Designing map-based visualizations for collection understanding
"Finding a good book can be difficult, particularly for young readers. This paper adds to our understanding of how children select books for recreational reading by exploring the 'native' strategies (both successful and ineffective) that children employ in bookstores and libraries. © 2011 Author.",2,,2-s2.0-79960546907,Conference Proceeding,2011-07-25,10.1145/1998076.1998170,432,9781450307444,15525996,431-432,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,431,http://api.elsevier.com/content/abstract/scopus_id/79960546907,,79960546907,145752,p,How children find books for leisure reading: Implications for the digital library
"Repurposing of data raises a number of issues for use across the disciplines of climate science and social science. The issues we present are results of the work we are currently carrying out as part of the Data Conservancy Project1 which aims to preserve data for long-term known and unanticipated use over time, across disciplines and over a variety of spatial, temporal and organizational scales. © 2011 Authors.",1,,2-s2.0-79960525073,Conference Proceeding,2011-07-25,10.1145/1998076.1998171,434,9781450307444,15525996,433-434,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,433,http://api.elsevier.com/content/abstract/scopus_id/79960525073,,79960525073,145752,p,Repurposing data across disciplines: A study of data reuse issues between climate science and social science
"Content from simulation systems is useful in defining domain ontologies. We describe a digital library process to generate and leverage domain ontologies to support simulation systems tasks. Workflow ontologies may be used to define compositions of simulation-related services. Simulation model ontologies may be used in customizing collection management systems for tasks such as organization, interface construction, and metadata record generation. © 2011 Authors.",0,,2-s2.0-79960505306,Conference Proceeding,2011-07-25,10.1145/1998076.1998172,436,9781450307444,15525996,435-436,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,435,http://api.elsevier.com/content/abstract/scopus_id/79960505306,,79960505306,145752,p,Improving simulation management systems through ontology generation and utilization
"We describe our work in collecting, analyzing and visualizing online information (e.g., Web documents, images, tweets), which are to be maintained by the Crisis, Tragedy and Recovery Network (CTRnet) digital library. We have been collecting resources about disaster events, as well as campus and other major shooting events, in collaboration with the Internet Archive (IA). Social media data (e.g., tweets, Facebook data) also have been collected and analyzed. Analyzed results are visualized using graphs and tag clouds. Exploratory content-based image retrieval has been applied in one of our image collections. We explain our CTR ontology development methodology and collaboration with Arlington County, VA and IBM, in a Center for Community Security and Resilience funded project. © 2011 Authors.",3,,2-s2.0-79960536940,Conference Proceeding,2011-07-25,10.1145/1998076.1998173,438,9781450307444,15525996,437-438,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,437,http://api.elsevier.com/content/abstract/scopus_id/79960536940,,79960536940,145752,p,CTRnet DL for disaster information services
A rubric for representing the educational content of digital resources was developed and tested in an experiment with preservice teachers. The ADMIRE (Analyzing Digital Materials In Resources for Education) rubric codes 11 types of digital content organized into five major categories; codes and categories are drawn from learning science and instructional research. The ADMIRE rubric was used to analyze the types of content present in digital resources that preservice teachers accepted or rejected for classroom use during instructional planning. Results show that the ADMIRE rubric provides a useful method to understand teachers' success in online search and the types of educational content that they value during instructional planning. © 2011 Authors.,0,,2-s2.0-79960508480,Conference Proceeding,2011-07-25,10.1145/1998076.1998174,440,9781450307444,15525996,439-440,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,439,http://api.elsevier.com/content/abstract/scopus_id/79960508480,,79960508480,145752,p,Representing educational content in digital library resources
"Digital libraries (DLs) are adapting to accommodate research data and related services. The complexities of this new content spans the elements of DL development, and there are questions concerning data selection, service development, and how best to align these with local, institutional initiatives for cyberinfrastructure, data-intensive research, and data stewardship. Small science disciplines are of particular relevance due to the prevalence of this mode of research in the academy, and the anticipated magnitude of data production. To support data acquisition into DLs - and subsequent data reuse - there is a need for new knowledge on the range and complexities inherent in practice-data-curation arrangements for small science research. We present a flexible methodological approach crafted to generate data units to analyze these relationships and facilitate cross-disciplinary comparisons. © 2011 Authors.",4,,2-s2.0-79960534130,Conference Proceeding,2011-07-25,10.1145/1998076.1998175,442,9781450307444,15525996,441-442,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,441,http://api.elsevier.com/content/abstract/scopus_id/79960534130,,79960534130,145752,p,Units of evidence for analyzing subdisciplinary difference in data practice studies
"Governments produce vast amounts of electronic information geared for the public, but research points to a mismatch between the communicative intents of the government and the information needs of the public. Initial results of semi-structured interviews with government content creators suggest that learning more about why and how government information is produced may lead to the establishment of greater common ground. © 2011 Authors.",0,,2-s2.0-79960539616,Conference Proceeding,2011-07-25,10.1145/1998076.1998176,444,9781450307444,15525996,443-444,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,443,http://api.elsevier.com/content/abstract/scopus_id/79960539616,,79960539616,145752,p,E-informing the public: Communicative intents in the production of online government information
"The Bushman texts in the Bleek and Lloyd Collection contain complex diacritics that make automatic transcription difficult. Transcriptions of these texts would allow for enhanced digital library services to be created for interacting with the collection. In this study, an investigation into automatic transcription of the Bushman texts was performed using the popular method of using a Hidden Markov Model for text line recognition. The results show that while this technique may be well suited to well-constrained and understood scripts, its application to more complex scripts introduces a number of difficulties that need to be overcome. © 2011 Authors.",2,,2-s2.0-79960486383,Conference Proceeding,2011-07-25,10.1145/1998076.1998177,446,9781450307444,15525996,445-446,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,445,http://api.elsevier.com/content/abstract/scopus_id/79960486383,,79960486383,145752,p,Using a hidden Markov model to transcribe handwritten bushman texts
"This poster demonstrates the program of consultation and associated technical workflow developed by the Aboriginal and Torres Strait Islander Data Archive (ATSIDA) to support the digital return of research data to Indigenous Australian communities, while also facilitating data preservation and reuse in the research community and by the general public. © 2011 Authors.",1,,2-s2.0-79960540037,Conference Proceeding,2011-07-25,10.1145/1998076.1998178,448,9781450307444,15525996,447-448,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,447,http://api.elsevier.com/content/abstract/scopus_id/79960540037,,79960540037,145752,p,Connecting research data and indigenous communities
"Research Field Visualizer (RFV) is a system designed to visualize citation chains for publications within specific disciplines. RFV overlays publication information on geographical displays to aid in locating dense areas of research based on different search criteria, thus exposing a network of interconnected ideas across the world. Within this geographical context, RFV provides an interactive visualization of citation networks, allowing the user to explore chains of publication Our intention is to help people that want to learn about a field, such as prospective graduate students, understand current research directions, track research history, and ultimately find the places where authors are conducting relevant and interesting research. © 2011 Authors.",0,,2-s2.0-79960527833,Conference Proceeding,2011-07-25,10.1145/1998076.1998179,450,9781450307444,15525996,449-450,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,449,http://api.elsevier.com/content/abstract/scopus_id/79960527833,,79960527833,145752,p,RFV: Interactive geographical visualization for citation network exploration
"Experimental evaluation and comparison of techniques, algorithms or complete systems is a crucial requirement to assess the practical impact of research results. The quality of published experimental results is usually limited due to several reasons such as: limited time, unavailability of standard benchmarks or shortage of computing resources. Moreover, achieving an independent, consistent, complete and insightful assessment for different alternatives in the same domain is a time and resource consuming task. We demonstrate Liquid Benchmark as a cloud-based service that provides collaborative platforms to simplify the task of peer researchers in performing high quality experimental evaluations and guarantee a transparent scientific crediting process. The service allows building repositories of competing research implementations, sharing testing computing platforms, collaboratively building the specifications of standard benchmarks and allowing end-users to easily create and run testing experiments and share their results. © 2011 Authors.",1,,2-s2.0-79960494836,Conference Proceeding,2011-07-25,10.1145/1998076.1998181,452,9781450307444,15525996,451-452,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,451,http://api.elsevier.com/content/abstract/scopus_id/79960494836,,79960494836,145752,p,Liquid benchmarks: Benchmarking-as-a-service
"The FRBR model has received much attention due to its potential for greatly improving user interaction with digital libraries. However, the amount of information found on the Web is far larger than in digital libraries. In this demo, we present an approach to transform Web-based resources to a FRBR compatible form, a process known as FRBRization. The FRBRized collection is then linked to DBpedia, thus providing a basis for information sharing and verification. © 2011 Authors.",2,,2-s2.0-79960492728,Conference Proceeding,2011-07-25,10.1145/1998076.1998183,456,9781450307444,15525996,455-456,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,455,http://api.elsevier.com/content/abstract/scopus_id/79960492728,,79960492728,145752,p,FRBRPedia: A tool for FRBRizing web products and linking FRBR entities to DBpedia
"Automatic speech alignment and natural language processing technologies provide full content search and retrieval access into oral history collections. These tools have been field-tested with The HistoryMakers and Harrisburg Living Legacy oral history archives, showing the value of an Adobe Flash front-end interface. Built with Adobe Flex 3, the interface works across browsers and operating systems, supports deep linking and browser-based navigation, provides synchronized transcripts that can be fully searched and tracked while watching the interviews, and incorporates filtering by facets, a menu bar breadcrumb interface, and a user play list to collect stories of interest. Refinements to the interface are discussed following the first six months of web deployment, with suggestions offered for other digital video libraries, particularly oral histories. © 2011 Authors.",1,,2-s2.0-79960502293,Conference Proceeding,2011-07-25,10.1145/1998076.1998184,458,9781450307444,15525996,457-458,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,457,http://api.elsevier.com/content/abstract/scopus_id/79960502293,,79960502293,145752,p,An interactive flash website for oral histories
"CADAL has been a large-scale non-profit digital library. Besides various search facilities in the CADAL portal, we designed and implemented the iCADAL system for providing the user-oriented micro-content services on one million books in CADAL. Users of iCADAL can receive the stream of short messages of lending, annotation and the other reading activities shared by their followees in a twitter-like way, which combines socialization with personalization. Our implementation makes extensive use of open source softwares, i.e. Pylons, Cassandra, in order to support the high-traffic online micro-content services. © 2011 Authors.",5,,2-s2.0-79960546906,Conference Proceeding,2011-07-25,10.1145/1998076.1998185,460,9781450307444,15525996,459-460,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,459,http://api.elsevier.com/content/abstract/scopus_id/79960546906,,79960546906,145752,p,When personalization meets socialization: An iCADAL approach
"Educational digital libraries have become an effective source of sharing information and dissemination of knowledge. Like paintings, personal stories containing pictures, music, and text will exist for a long time to come and will be enjoyed long after their creation. In this demo, we present a system called Creaza Education. The system offers an engaging suit of are user-friendly web-based applications where users can use their imagination by creating, publishing and sharing digital stories. © 2011 Author.",0,,2-s2.0-79960525487,Conference Proceeding,2011-07-25,10.1145/1998076.1998186,462,9781450307444,15525996,461-462,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,461,http://api.elsevier.com/content/abstract/scopus_id/79960525487,,79960525487,145752,p,Supporting creative work in educational digital libraries
"In this demonstration-paper we present Mr. DLib, a machine-readable digital library. Mr. DLib provides access to several millions of articles in full-text and their metadata in XML and JSON format via a RESTful Web Service. In addition, Mr. DLib provides related documents for given academic articles. The service is intended to serve researchers who need bibliographic data and full-text of scholarly literature for their analyses (e.g. impact and trend analysis); providers of academic services who need additional information to enhance their own services (e.g. literature recommendations); and providers who want to build their own services based on data from Mr. DLib. © 2011 Authors.",8,,2-s2.0-79960483870,Conference Proceeding,2011-07-25,10.1145/1998076.1998187,464,9781450307444,15525996,463-464,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,463,http://api.elsevier.com/content/abstract/scopus_id/79960483870,,79960483870,145752,p,"Introducing Mr. DLib, a Machine-readable Digital Library"
"In this demonstration-paper we introduce Docear, an 'academic literature suite'. Docear offers to scientists what an office suite like Microsoft Office offers to office workers. While an office suite bundles various applications for office workers (word processing, spreadsheets, presentation software, etc.), Docear bundles several applications for scientists: academic search engine, PDF reader, reference manager, word processor, mind mapping module, and recommender system. Besides Docear's general concept, its special features are presented in this paper, namely a modular composition, free full-text access to literature, information management as mind map, automatic metadata extraction of PDFs and recommendations. © 2011 Authors.",20,,2-s2.0-79960497650,Conference Proceeding,2011-07-25,10.1145/1998076.1998188,466,9781450307444,15525996,465-466,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,465,http://api.elsevier.com/content/abstract/scopus_id/79960497650,,79960497650,145752,p,"Docear: An academic literature suite for searching, organizing and creating academic literature"
"The Digital Library of Historical Cartography of the University of São Paulo makes available a set of high-resolution digital versions of maps printed between the XV and the XIX centuries belonging to the University's collections. Each map is available along with extensive carto-bibliographic and biographic references, and relevant technical, editorial and historical information for cartographic documents analysis. The Digital Library was also conceived to pursue data from other similar sites, constituting itself as a useful research tool. It provides facilities to gather relevant information to acknowledge the production, circulation and appropriation of historical maps in different contexts and media. © 2011 Authors.",0,,2-s2.0-79960491272,Conference Proceeding,2011-07-25,10.1145/1998076.1998189,468,9781450307444,15525996,467-468,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,467,http://api.elsevier.com/content/abstract/scopus_id/79960491272,,79960491272,145752,p,The digital library of historical cartography of the University of São Paulo
"In this work, we present GreenWiki, which is a wiki with a panel of quality indicators to assist the reader of a Wikipedia article in assessing its quality. © 2011 Authors.",1,,2-s2.0-79960491688,Conference Proceeding,2011-07-25,10.1145/1998076.1998190,470,9781450307444,15525996,469-470,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,469,http://api.elsevier.com/content/abstract/scopus_id/79960491688,,79960491688,145752,p,GreenWiki: A tool to support users' assessment of the quality of Wikipedia articles
"In this extended abstract we detail how the open source digital library toolkit Greenstone [4] can help users of the XOlaptop produced by the One Laptop Per Child Foundation manage and share electronic documents. The idea draws upon mobile libraries (bookmobiles) for its inspiration, which first appeared in Victorian times. The implemented technique works by building on the mesh network that is instrumental to the XO-laptop approach. To use the technique, on each portable XO-laptop a version of Greenstone is installed, allowing the owner to develop and manage their own set of books. The version of Greenstone has been adapted to support a form of interoperability we have called Digital Library Talkback. On the mesh, when two XO-laptops ""see"" each other, the two users can search and browse the other user's digital library; when they see a book they like, they can have it transferred to their library with a single click using the Digital Library Talkback mechanism. © 2011 Authors.",0,,2-s2.0-79960553029,Conference Proceeding,2011-07-25,10.1145/1998076.1998191,472,9781450307444,15525996,471-472,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,471,http://api.elsevier.com/content/abstract/scopus_id/79960553029,,79960553029,145752,p,Perambulating libraries: Demonstrating how a Victorian idea can help OLPC users share books
"This demonstration will show the prototype access and search system for the Social Networks and Archival Context project. The system is built on a database of merged Encoded Archival Context - Corporate Bodies, Persons, and Families (EAC-CPF) records derived from Encoded Archival Description (EAD) records held by the Library of Congress, the California Digital Library, the Northwest Digital Archives, and Virginia Heritage, combined with information from name authority files from the Library of Congress, OCLC Research, and the Getty Vocabulary Program. The database merges information from each instance of an individual name in these resources, along with variant names, biographical notes and their topical descriptions. The prototype interface makes this information searchable while retaining links to the various data sources, other resources (such as books by or about a person) and to other individuals, families and organizations associated with that name. © 2011 Author.",0,,2-s2.0-79960483253,Conference Proceeding,2011-07-25,10.1145/1998076.1998192,474,9781450307444,15525996,473-474,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,473,http://api.elsevier.com/content/abstract/scopus_id/79960483253,,79960483253,145752,p,SNAC: The social networks and archival context project
"Missing web pages (pages that return the 404 ""Page Not Found"" error) are part of the browsing experience. The manual use of search engines to rediscover such pages can be frustrating and unsuccessful. We introduce Synchronicity, a Mozilla Firefox add-on that supports the Internet user in (re-)discovering missing web pages in real time. © 2011 Authors.",0,,2-s2.0-79960482801,Conference Proceeding,2011-07-25,10.1145/1998076.1998193,476,9781450307444,15525996,475-476,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,475,http://api.elsevier.com/content/abstract/scopus_id/79960482801,,79960482801,145752,p,Synchronicity: Automatically rediscover missing web pages in real time
"Iowa City is one of only four designated Cities of Literature worldwide by UNESCO. To highlight the city's rich local literary history, a University of Iowa interdisciplinary research team de-veloped a digital library featuring Iowa City authors and locations. The Iowa City UNESCO City of Literature ""City of Lit"" digital library consists of a mobile application for the general public and a web-based information system for researcher/content creators. © 2011 Authors.",1,,2-s2.0-79960509757,Conference Proceeding,2011-07-25,10.1145/1998076.1998194,478,9781450307444,15525996,477-478,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,477,http://api.elsevier.com/content/abstract/scopus_id/79960509757,,79960509757,145752,p,The Iowa City UNESCO City of literature digital library
This demonstration presents a music structure-based audio/visual interface for the navigation of very large scale music digital libraries. This work is a product of the Structural Analysis of Large Amounts of Music Information (SALAMI) project. © 2011 Authors.,3,,2-s2.0-79960546491,Conference Proceeding,2011-07-25,10.1145/1998076.1998195,480,9781450307444,15525996,479-480,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,479,http://api.elsevier.com/content/abstract/scopus_id/79960546491,,79960546491,145752,p,Exploiting music structures for digital libraries
"Social media records the thoughts and activities of countless cultures and subcultures around the globe. Yet institutional efforts to archive social media content remain controversial. We report on 988 responses across six surveys of social media users that included questions to explore this controversy. The quantitative and qualitative results show that the way people think about the issue depends on how personal and ephemeral they view the content to be. They use concepts such as creator privacy, content characteristics, technological capabilities, perceived legal rights, and intrinsic social good to reason about the boundaries of institutional social media archiving efforts. © 2012 ACM.",8,,2-s2.0-84863553179,Conference Proceeding,2012-07-11,10.1145/2232817.2232819,10,9781450311540,15525996,1-10,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,1,http://api.elsevier.com/content/abstract/scopus_id/84863553179,,84863553179,145752,p,On the institutional archiving of social media
Diverse digital resources are commonly used by different types of users. It is common practice to develop those application having in mind a set of requirements for a specific target category of users. We envisaged and designed the IPSA archive and system using a similar approach: the identification of a set of requirements for researchers in illuminated manuscripts as a target group of domain professional users. The IPSA system has been in use as a research tool by domain professionals. The consideration that the content of the archive managed by the IPSA system could be of interest for other types of users suggested reconsidering its approach to envisage a new system designed around the same archive of illuminated manuscripts for their access by diverse categories of users. The paper reports on the work that was conducted to re-design and re-engineer the system to match requirements and expectations of non-domain users. © 2012 ACM.,3,,2-s2.0-84863539717,Conference Proceeding,2012-07-11,10.1145/2232817.2232820,14,9781450311540,15525996,11-14,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,11,http://api.elsevier.com/content/abstract/scopus_id/84863539717,,84863539717,145752,p,To envisage and design the transition from a digital archive system developed for domain experts to one for non-domain users
"Archive-It, a subscription service from the Internet Archive, allows users to create, maintain and view digital collections of web resources. The current interface of Archive-It is largely text-based, supporting drill-down navigation using lists of URIs. To provide an overview of each collection and highlight the collection's underlying characteristics, we present four alternate visualizations (image plot with histogram, wordle, bubble chart and timeline). The sites in an Archive-It collection may be organized by the collection curator into groups for easier navigation. However, many collections do not have such groupings, making them difficult to explore. We introduce a heuristics-based categorization for such collections. © 2012 ACM.",9,,2-s2.0-84863550835,Conference Proceeding,2012-07-11,10.1145/2232817.2232821,18,9781450311540,15525996,15-18,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,15,http://api.elsevier.com/content/abstract/scopus_id/84863550835,,84863550835,145752,p,Visualizing digital collections at archive-it
"Data are proliferating far faster than they can be captured, managed, or stored. What types of data are most likely to be used and reused, by whom, and for what purposes? Answers to these questions will inform information policy and the design of digital libraries. We report findings from semi-structured interviews and field observations to investigate characteristics of data use and reuse and how those characteristics vary within and between scientific communities. The two communities studied are researchers at the Center for Embedded Network Sensing (CENS) and users of the Sloan Digital Sky Survey (SDSS) data. The data practices of CENS and SDSS researchers have implications for data curation, system evaluation, and policy. Some data that are important to the conduct of research are not viewed as sufficiently valuable to keep. Other data of great value may not be mentioned or cited, because those data serve only as background to a given investigation. Metrics to assess the value of documents do not map well to data. © 2012 ACM.",11,,2-s2.0-84863544281,Conference Proceeding,2012-07-11,10.1145/2232817.2232822,22,9781450311540,15525996,19-22,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,19,http://api.elsevier.com/content/abstract/scopus_id/84863544281,,84863544281,145752,p,"Data, data use, and scientific inquiry: Two case studies of data practices"
"Important biomedical information is often recorded, published or archived in unstructured and semi-structured textual form. Artificial intelligence and knowledge discovery techniques may be applied to large volumes of such data to identify and extract useful metadata, not only for providing access to these documents, but also for conducting analyses and uncovering patterns and trends in a field. The System for Preservation of Electronic Resources (SPER), an information management tool developed at the U.S. National Library of Medicine, provides these capabilities by integrating machine learning, data mining and digital preservation techniques. In this paper, we present an overview of SPER and its ability to retrieve information from one such dataset. We show how SPER was applied to the semi-structured records of an international health science program, the 46-year continuous archive of conference publications and related documents from the Joint Cholera Panel of the U.S.-Japan Cooperative Medical Science Program (CMSP). We explain the techniques by which metadata was extracted automatically from the semi-structured document contents to preserve these publications, and show how such data was used to quantitatively describe the activity of a research community toward a preliminary study of a subset of its specific health science program goals. © 2012 ACM.",1,,2-s2.0-84863548612,Conference Proceeding,2012-07-11,10.1145/2232817.2232823,26,9781450311540,15525996,23-26,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,23,http://api.elsevier.com/content/abstract/scopus_id/84863548612,,84863548612,145752,p,Digital preservation and knowledge discovery based on documents from an international health science program
"Understanding the social aspects of digital resource utilization is an area of active research. In this study, we examine the digital library resource utilization and social behaviors of middle and high school Earth Science teachers of a large United States urban school district. We present the results of three analysis based on teachers using an online curriculum planning tool called the Curriculum Customization Service (CCS), and examine the social networks that emerge among the participating teachers. We explore these networks in the context of the digital library resources that were part of the CCS and the use of socio-centric features around those resources. Our initial findings show promise toward developing a broader understanding of the social networks of teachers, their behaviors around and usage of digital library resources, as well as the diffusion of information through those networks. © 2012 ACM.",0,,2-s2.0-84863541705,Conference Proceeding,2012-07-11,10.1145/2232817.2232825,30,9781450311540,15525996,27-30,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,27,http://api.elsevier.com/content/abstract/scopus_id/84863541705,,84863541705,145752,p,Teacher sociality and information diffusion in educational digital libraries
The growing number of digital libraries providing open educational resources (OER) requires effective resource discovery mechanisms to optimally exploit the benefits of their openness. This paper discusses the OER repositories role and presents a study aimed at understanding how educators find OER by seeking answers to questions such as: what proportion of users seeking OER go directly to OER repositories and what proportion uses search engines or some other means and why. Understanding how and with what tools users discover and access resources can have an impact on the OER repositories strategic development. © 2012 ACM.,4,,2-s2.0-84863550118,Conference Proceeding,2012-07-11,10.1145/2232817.2232826,34,9781450311540,15525996,31-34,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,31,http://api.elsevier.com/content/abstract/scopus_id/84863550118,,84863550118,145752,p,Is it time to change the OER repositories role?
"This paper describes the results of a study designed to assess human expert ratings of educational concept features for use in automatic core concept extraction systems. Digital library resources provided the content base for human experts to annotate automatically extracted concepts on seven dimensions: coreness, local importance, topic, content, phrasing, structure, and function. The annotated concepts were used as training data to build a machine learning classifier as part of a tool used to predict the core concepts in the document. These predictions were compared with the experts' judgment of concept coreness. © 2012 ACM.",3,,2-s2.0-84863544687,Conference Proceeding,2012-07-11,10.1145/2232817.2232827,42,9781450311540,15525996,35-42,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,35,http://api.elsevier.com/content/abstract/scopus_id/84863544687,,84863544687,145752,p,Identifying core concepts in educational resources
"By analyzing the behavior of previous users, digital libraries can be made to provide new users with more support to find the best information. The AlgoViz Portal collects metadata on algorithm visualizations and associated research literature. We show how logs can be used to discover latent relationships between users, deducing an implicit social network. By clustering the log data, we find different page-viewing patterns, which provide practical information about the different groups of users. © 2012 ACM.",3,,2-s2.0-84863537874,Conference Proceeding,2012-07-11,10.1145/2232817.2232828,46,9781450311540,15525996,43-46,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,43,http://api.elsevier.com/content/abstract/scopus_id/84863537874,,84863537874,145752,p,Deduced social networks for an educational digital library
"In this paper we describe preliminary results from two ongoing research projects that investigate the dissemination practices surrounding digital STEM learning materials for undergraduates. This research consists of two related studies, : 1) survey research about the dissemination practices of NSF-funded PIs; and, 2) a case study on the dissemination practices of courseware developers who won the Premier Award for Excellence in Engineering Education. The vast majority of PIs reported in the survey that they do not take advantage of digital dissemination methods such as education digital libraries. Premier Award-winning innovators reported using multiple dissemination methods - traditional and digital. Recommendations are provided regarding how digital library developers might work with PIs to improve dissemination. © 2012 ACM.",3,,2-s2.0-84863549152,Conference Proceeding,2012-07-11,10.1145/2232817.2232829,50,9781450311540,15525996,47-50,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,47,http://api.elsevier.com/content/abstract/scopus_id/84863549152,,84863549152,145752,p,A tale of two studies: Is dissemination working?
"Usually scientists breed research ideas inspired by previous publications, but they are unlikely to follow all publications in the unbounded literature collection. The volume of literature keeps on expanding extremely fast, whilst not all papers contribute equal impact to the academic society. Being aware of potentially influential literature would put one in an advanced position in choosing important research references. Hence, estimation of potential influence is of great significance. We study a challenging problem of identifying potentially influential literature. We examine a set of hypotheses on what are the fundamental characteristics for highly cited papers and find some interesting patterns. Based on these observations, we learn to identify potentially influential literature via Future Influence Prediction (FIP), which aims to estimate the future influence of literature. The system takes a series of features of a particular publication as input and produces as output the estimated citation counts of that article after a given time period. We consider several regression models to formulate the learning process and evaluate their performance based on the coefficient of determination (R 2). Experimental results on a real-large data set show a mean average predictive performance of 83.6% measured in R 2. We apply the learned model to the application of bibliography recommendation and obtain prominent performance improvement in terms of Mean Average Precision (MAP). © 2012 ACM.",33,,2-s2.0-84863553490,Conference Proceeding,2012-07-11,10.1145/2232817.2232831,60,9781450311540,15525996,51-60,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,51,http://api.elsevier.com/content/abstract/scopus_id/84863553490,,84863553490,145752,p,To better stand on the shoulder of giants
"Bibliographic documents are basically associated with many entities including authors, venues, affiliations, etc. While bibliographic search engines addressed mainly relevant document ranking according to a query topic, ranking other related relevant bibliographic entities is still challenging. Indeed, document relevance is the primary level that allows inferring the relevance of the other entities regardless of the query topic. In this paper, we propose a novel integrated ranking model, called BibRank, that aims at ranking both document and author entities in bibliographic networks. The underlying algorithm propagates entity scores through the network by means of citation and authorship links. Moreover, we propose to weight these relationships using content-based indicators that estimate the topical relatedness between entities. In particular, we estimate the common similarity between homogeneous entities by analyzing marginal citations. We also compare document and author language models in order to evaluate the level of author's knowledge on the document topic and the document representativeness of author's knowledge. Experiment results on the representative CiteSeerX dataset show that BibRank model outperforms baseline ranking models with a significant improvement. © 2012 ACM.",2,,2-s2.0-84863539856,Conference Proceeding,2012-07-11,10.1145/2232817.2232832,70,9781450311540,15525996,61-70,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,61,http://api.elsevier.com/content/abstract/scopus_id/84863539856,,84863539856,145752,p,BibRank: A language-based model for co-ranking entities in bibliographic networks
"Recently expertise retrieval has received increasing interests in both academia and industry. Finding experts with demonstrated expertise for a given query is a nontrivial task especially from a large-scale Web 2.0 systems, such as question answering and bibliography data, where users are actively publishing useful content online, interacting with each other, and forming social networks in various ways, leading to heterogeneous networks in addition to the large amounts of textual content information. Many approaches have been proposed and shown to be useful for expertise ranking. However, most of these methods only consider the textual documents while ignoring heterogeneous network structures or can merely integrate with one additional kind of information. None of them can fully exploit the characteristics of heterogeneous networks. In this paper, we propose a joint regularization framework to enhance expertise retrieval by modeling heterogeneous networks as regularization constraints on top of document-centric model. We argue that multi-typed linking edges reveal valuable information which should be treated differently. Motivated by this intuition, we formulate three hypotheses to capture unique characteristics for different graphs, and mathematically model those hypotheses jointly with the document and other information. To illustrate our methodology, we apply the framework to expert finding applications using a bibliography dataset with 1.1 million papers and 0.7 million authors. The experimental results show that our proposed approach can achieve significantly better results than the baseline and other enhanced models. © 2012 ACM.",28,,2-s2.0-84863555300,Conference Proceeding,2012-07-11,10.1145/2232817.2232833,80,9781450311540,15525996,71-80,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,71,http://api.elsevier.com/content/abstract/scopus_id/84863555300,,84863555300,145752,p,Modeling and exploiting heterogeneous bibliographic networks for expertise ranking
"The number of channels of digital television is increasing, particularly the number that are free-to-air. However due to the nature of broadcasting, this morass of information is not, for the main part, organized - -it is principally a succession of images and sound transmitted as multiplexed streams of data. Compare this deluge that terrestrially bombards our homes with the information available in the digital libraries we access over the Internet - -stored using software purpose built to help organize carefully curated sets of documents. This project brings together these two seemingly incompatible concepts to develop a software environment that concurrently captures all the available live television channels - -so a user does not need to proactively choose what to record - -and segments them into files which are then imported into a digital video library with a user interface designed to work from a multimedia remote control. A shifting time-based ""window"" of all recordings is maintained - -we settled on from the last two weeks so as to be practicably operable on a regular desktop PC. The system leverages off the information contained in the electronic program guide and the video recordings to generate metadata suitable for the digital library. A user evaluation of the developed prototype showed a high level of participant satisfaction across a range of attributes, notably date-based searching. © 2012 ACM.",1,,2-s2.0-84863550125,Conference Proceeding,2012-07-11,10.1145/2232817.2232835,90,9781450311540,15525996,81-90,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,81,http://api.elsevier.com/content/abstract/scopus_id/84863550125,,84863550125,145752,p,Live television in a digital library
"Digitized physical books offer access to tremendous amounts of knowledge, even for people with print-related disabilities. Various projects and standard activities are underway to make all of our past and present books accessible. However digitizing books requires extensive human efforts such as correcting the results of OCR (optical character recognition) and adding structural information such as headings. Some Asian languages need extra efforts for the OCR errors because of their many and varied character sets. Japanese has used more than 10,000 characters compared with a few hundred in English. This heavy workload is inhibiting the creation of accessible digital books. To facilitate digitization, we are developing a new system for processing physical books. We reduce and disperse the human efforts and accelerate conversions by combining automatic inference and human capabilities. Our system preserves the original page images for the entire digitization process to support gradual refinement and distributes the work as micro-tasks. We conducted trials with the Japanese National Diet Library (NDL) to evaluate the required effort for digitizing books with a variety of layouts and years of publication. The results showed old Japanese books had specific problems when correcting the OCR errors and adding structures. Drawing on our results, we discuss further workload reductions and future directions for international digitization systems. © 2012 ACM.",10,,2-s2.0-84863538203,Conference Proceeding,2012-07-11,10.1145/2232817.2232836,100,9781450311540,15525996,91-100,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,91,http://api.elsevier.com/content/abstract/scopus_id/84863538203,,84863538203,145752,p,Transforming Japanese archives into accessible digital books
"In this paper, we present the Invertebrate Paleontology Knowledgebase (IPKB), an effort to digitize and share the Treatise on Invertebrate Paleontology. The Treatise is the most authoritative compilation of invertebrate fossil records. Unfortunately, the PDF version is simply a clone of paper publications and the content is in no way organized to facilitate search and knowledge discovery. We extracted texts and images from the Treatise, stored them in a database, and built a system for efficient browsing and searching. For image processing in particular, we segmented fossil photos from figures, recognized the embedded labels, and linked the images to the corresponding data entries. The detailed information of each genus, including fossil images, is delivered to users through a web access module. Some external applications (e.g. Google Earth) are acquired through web services APIs to improve user experience. Given the rich information in the Treatise, analyzing, modeling and understanding paleontological data are significant in many areas, such as: understanding evolution; understanding climate change; finding fossil fuels, etc. IPKB builds a general framework that aims to facilitate knowledge discovery activities in invertebrate paleontology, and provides a solid foundation for future explorations. In this article, we report our initial accomplishments. The specific techniques we employed in the project, such as those involved in text parsing, image-label association and meta data extraction, can be insightful and serve as examples for other researchers. © 2012 ACM.",1,,2-s2.0-84863548409,Conference Proceeding,2012-07-11,10.1145/2232817.2232837,110,9781450311540,15525996,101-110,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,101,http://api.elsevier.com/content/abstract/scopus_id/84863548409,,84863548409,145752,p,IPKB: A digital library for invertebrate paleontology
"Early Modern emblems combined text and image. Though there were many variants, the archetypical emblem literary form (mid-sixteenth through mid-eighteenth centuries) consisted of an image (the pictura), a text inscription (the inscriptio), and a text epigram (the subscriptio), the last usually in verse. Digitized emblem literature poses interesting challenges as regards content and metadata granularity, the use of interdisciplinary controlled vocabularies, and the need to present digitized primary sources in a complex network of associated sources, derivatives, and contemporaneous context. In this paper, we describe a digital library Web application designed to better support the ways emblem scholars search for and use digitized emblem books, focusing on metadata design, issues of resource granularity and identification, and the use of Linked Data Web services for Iconclass, a multilingual classification system for cultural heritage art and images. Outcomes to date, achieved by emblem scholars and librarians working in collaboration, provide a case study for multi-faceted, interactive approaches to curating mixed text-image digital resources and the use of Linked Data vocabulary services. Lessons learned highlight the value of librarian-scholar collaboration and help to illustrate why digital libraries need to move beyond merely disseminating digitized book surrogates. © 2012 ACM.",4,,2-s2.0-84863550127,Conference Proceeding,2012-07-11,10.1145/2232817.2232839,120,9781450311540,15525996,111-120,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,111,http://api.elsevier.com/content/abstract/scopus_id/84863550127,,84863550127,145752,p,"Descriptive metadata, iconclass, and digitized emblem literature"
The Ensemble Portal harvests resources from multiple heterogeneous federated collections. Managing these dynamically increasing collections requires an automatic mechanism to categorize records in to corresponding topics. We propose an approach to use existing ACM DL metadata to build classifiers for harvested resources in the Ensemble project. We also present our experience with utilizing the Amazon Mechanical Turk platform to build ground truth training data sets from Ensemble collections. © 2012 ACM.,1,,2-s2.0-84863557918,Conference Proceeding,2012-07-11,10.1145/2232817.2232840,124,9781450311540,15525996,121-124,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,121,http://api.elsevier.com/content/abstract/scopus_id/84863557918,,84863557918,145752,p,Categorization of computing education resources with utilization of crowdsourcing
"This work will introduce a new approach to ranking bibliographic records in library search, which is currently dominated by an OPAC style search paradigm, where results are typically not ranked by relevance. The approach we propose in the paper provides the user with the ability to access bibliographic records in a way responsive to his or her preferences, which is essentially done by looking at a community or a group of people who share interests with the user and making use of their publication records to re-rank search results. The experiment found that the present approach gives a clear edge over conventional search methods. © 2012 ACM.",0,,2-s2.0-84863544688,Conference Proceeding,2012-07-11,10.1145/2232817.2232841,128,9781450311540,15525996,125-128,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,125,http://api.elsevier.com/content/abstract/scopus_id/84863544688,,84863544688,145752,p,Re-ranking bibliographic records for personalized library search
"Mood is an important access point in music digital libraries and online music repositories, but generating ground truth for evaluating various music mood classification algorithms is a challenging problem. This is because collecting enough human judgments is time-consuming and costly due to the subjectivity of music mood. In this study, we explore the viability of crowdsourcing music mood classification judgments using Amazon Mechanical Turk (MTurk). Specifically, we compare the mood classification judgments collected for the annual Music Information Retrieval Evaluation eXchange (MIREX) with judgments collected using MTurk. Our data show that the overall distribution of mood clusters and agreement rates from MIREX and MTurk were comparable. However, Turkers tended to agree less with the pre-labeled mood clusters than MIREX evaluators. The system evaluation results generated using both sets of data were mostly the same except for detecting one statistically significant pair using Friedman's test. We conclude that MTurk can potentially serve as a viable alternative for ground truth collection, with some reservation with regards to particular mood clusters. © 2012 ACM.",11,,2-s2.0-84863549107,Conference Proceeding,2012-07-11,10.1145/2232817.2232842,138,9781450311540,15525996,129-138,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,129,http://api.elsevier.com/content/abstract/scopus_id/84863549107,,84863549107,145752,p,Generating ground truth for music mood classification using mechanical turk
"Today's digital libraries (DLs) archive vast amounts of information in the form of text, videos, images, data measurements, etc. User access to DL content can rely on similarity between metadata elements, or similarity between the data itself (content-based similarity). We consider the problem of exploratory search in large DLs of time-oriented data. We propose a novel approach for overview-first exploration of data collections based on user-selected metadata properties. In a 2D layout representing entities of the selected property are laid out based on their similarity with respect to the underlying data content. The display is enhanced by compact summarizations of underlying data elements, and forms the basis for exploratory navigation of users in the data space. The approach is proposed as an interface for visual exploration, leading the user to discover interesting relationships between data items relying on content-based similarity between data items and their respective metadata labels. We apply the method on real data sets from the earth observation community, showing its applicability and usefulness. © 2012 ACM.",13,,2-s2.0-84863542697,Conference Proceeding,2012-07-11,10.1145/2232817.2232844,148,9781450311540,15525996,139-148,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,139,http://api.elsevier.com/content/abstract/scopus_id/84863542697,,84863542697,145752,p,Content-based layouts for exploratory metadata search in scientific research data
"The HUBzero cyberinfrastructure provides a virtual research environment that includes a set of tools for web-based, scientific collaboration and a platform for publishing and using resources such as executable software, source code, images, learning modules, videos, documents, and datasets. Released as open source in 2010, HUBzero has been implemented on a typical LAMP stack (Linux, Apache, MySQL, and PHP) and utilizes the Joomla! content management system. This paper describes the subsequent refactoring of HUBzero to produce and expose Linked Data from its backend, relational database, altering the external expression of the data without changing its internal structure. The Open Archives Initiative Object Reuse and Exchange (OAI-ORE) specification is applied to model the basic structural semantics of HUBzero resources as Nested Aggregations, and data and metadata are mapped to vocabularies such as Dublin Core and published within the web representations of the resources using RDFa. Resource Maps can be harvested using an RDF crawler or an OAI-PMH data provider that were bundled for demonstration purposes. A visualization was produced to browse and navigate the relations among data and metadata from an example hub. © 2012 ACM.",3,,2-s2.0-84863558330,Conference Proceeding,2012-07-11,10.1145/2232817.2232845,152,9781450311540,15525996,149-152,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,149,http://api.elsevier.com/content/abstract/scopus_id/84863558330,,84863558330,145752,p,Refactoring HUBzero for linked data
"In this short paper, we describe the production data approach to data curation. We argue that by treating data in a similar fashion to how we build production software, that data will be more readily accessible and available for broad re-use. We should be treating data as an ongoing process. This includes considering third-party contributions; planning for cyclical releases; bug fixes, tracking, and versioning; and issuing licensing and citation information with each release. © 2012 ACM.",5,,2-s2.0-84863552499,Conference Proceeding,2012-07-11,10.1145/2232817.2232846,156,9781450311540,15525996,153-156,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,153,http://api.elsevier.com/content/abstract/scopus_id/84863552499,,84863552499,145752,p,Treating data like software: A case for production quality data
"While most digital collections have limited forms of change - primarily creation and deletion of additional resources - there exists a class of digital collections that undergoes additional kinds of change. These collections are made up of resources that are distributed across the Internet and brought together into a collection via hyperlinking. Resources in these collections can be expected to change as time goes on. Part of the difficulty in maintaining these collections is determining if a changed page is still a valid member of the collection. Others have tried to address this problem by measuring change and defining a maximum allowed threshold of change, however, these methods treat all change as a potential problem and treat web content as a static document despite its intrinsically dynamic nature. Instead, we approach the significance of change on the web as a normal part of a web document's life-cycle and determine the difference between what a maintainer expects a page to do and what it actually does. In this work we evaluate the different options for extractors and analyzers in order to determine the best options from a suite of techniques. The evaluation used a human-generated ground-truth set of blog changes. The results of this work showed a statistically significant improvement over a range of traditional threshold techniques when applied to our collection of tagged blog changes. © 2012 ACM.",2,,2-s2.0-84863541696,Conference Proceeding,2012-07-11,10.1145/2232817.2232847,166,9781450311540,15525996,157-166,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,157,http://api.elsevier.com/content/abstract/scopus_id/84863541696,,84863541696,145752,p,A quantitative evaluation of techniques for detection of abnormal change events in blogs.
"Entity search is an emerging IR and NLP task that involves the retrieval of entities of a specific type in response to a query. We address the similar researcher search"" or the ""researcher recommendation"" problem, an instance of similar entity search"" for the academic domain. In response to a researcher name' query, the goal of a researcher recommender system is to output the list of researchers that have similar expertise as that of the queried researcher. We propose models for computing similarity between researchers based on expertise profiles extracted from their publications and academic homepages. We provide results of our models for the recommendation task on two publicly-available datasets. To the best of our knowledge, we are the first to address content-based researcher recommendation in an academic setting and demonstrate it for Computer Science via our system, ScholarSearch. © 2012 ACM.",14,,2-s2.0-84863541947,Conference Proceeding,2012-07-11,10.1145/2232817.2232849,170,9781450311540,15525996,167-170,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,167,http://api.elsevier.com/content/abstract/scopus_id/84863541947,,84863541947,145752,p,'Similar researcher search' in academic environments
"Information resources in digital libraries are usually described, along with their context, by structured data records, commonly referred as metadata. Those records often contain unstructured information in natural language text, since they typically follow a data model which defines generic semantics for its data elements, or includes data elements modeled to contain free text. The information contained in these data elements, although machine readable, resides in unstructured natural language texts that are difficult to process by computers. This paper addresses a particular task of information extraction, typically called named entity recognition, which deals with the references to entities made by names occurring in the texts. This paper presents the results of a study of how the named entity recognition problem manifests itself in digital library metadata. In particular, we present the main differences between performing named entity recognition in natural language and in the text within metadata. The paper finalizes with a novel approach for named entity recognition in metadata. © 2012 ACM.",0,,2-s2.0-84863543349,Conference Proceeding,2012-07-11,10.1145/2232817.2232850,174,9781450311540,15525996,171-174,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,171,http://api.elsevier.com/content/abstract/scopus_id/84863543349,,84863543349,145752,p,An analysis of the named entity recognition problem in digital library metadata
"One of the hardest problems faced by current scholarly digital libraries is author name ambiguity. This problem occurs when, in a set of citation records, there are records of a same author under distinct names, or citation records belonging to distinct authors with similar names. Among the several proposed methods, the most effective ones seem to be based on the direct assignment of the records to their respective authors by means of the application of supervised machine learning techniques. The effectiveness of such methods is usually directly correlated with the amount of supervised training data available. However, the acquisition of training examples requires skilled human annotators to manually label references. Aiming to reduce the set of examples needed to produce the training data, in this paper we propose a new active sampling strategy based on association rules for the author name disambiguation task. We compare our strategy with state-of-the-art supervised baselines that use the complete labeled training dataset and other active methods and show that very competitive results in terms of disambiguation effectiveness can be obtained with reductions in the training set of up to 71%. © 2012 ACM.",10,,2-s2.0-84863551817,Conference Proceeding,2012-07-11,10.1145/2232817.2232851,184,9781450311540,15525996,175-184,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,175,http://api.elsevier.com/content/abstract/scopus_id/84863551817,,84863551817,145752,p,Active associative sampling for author name disambiguation
"Acknowledgments are widely used in scientific articles to express gratitude and credit collaborators. Despite suggestions that indexing acknowledgments automatically will give interesting insights, there is currently, to the best of our knowledge, no such system to track acknowledgments and index them. In this paper we introduce AckSeer, a search engine and a repository for automatically extracted acknowledgments in digital libraries. AckSeer is a fully automated system that scans items in digital libraries including conference papers, journals, and books extracting acknowledgment sections and identifying acknowledged entities mentioned within. We describe the architecture of AckSeer and discuss the extraction algorithms that achieve a F1 measure above 83%. We use multiple Named Entity Recognition (NER) tools and propose a method for merging the outcome from different recognizers. The resulting entities are stored in a database then made searchable by adding them to the AckSeer index along with the metadata of the containing paper/book. We build AckSeer on top of the documents in CiteSeerx digital library yielding more than 500,000 acknowledgments and more than 4 million mentioned entities. © 2012 ACM.",13,,2-s2.0-84863541932,Conference Proceeding,2012-07-11,10.1145/2232817.2232852,194,9781450311540,15525996,185-194,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,185,http://api.elsevier.com/content/abstract/scopus_id/84863541932,,84863541932,145752,p,AckSeer: A repository and search engine for automatically extracted acknowledgments from digital libraries
"The number of books available online is increasing, but user interfaces may not be taking full advantage of advances in machine learning techniques that could help users navigate, explore, discover and understand interesting and useful content in books. Using a group of ten students and over one thousand crowdsourced judgments, we conducted multiple user studies to evaluate topics and related passages in books, all learned by topic modeling. Using ten books, selected from humanities (e.g. Plato's Republic), social sciences (e.g. Marx's Capital) and sciences (e.g. Einstein's Relativity), and four different evaluation experiments, we show that users agree that the learned topics are coherent and important to the book, and related to the automatically generated passages. We show how crowdsourced evaluations are useful, and can complement more focused evaluations using students who have studied the texts. This work provides a framework for (1) learning topics and related passages in books, and (2) evaluating those learned topics and passages, and moves one step toward automatic annotation to support topic navigation of books. © 2012 ACM.",0,,2-s2.0-84863544403,Conference Proceeding,2012-07-11,10.1145/2232817.2232854,198,9781450311540,15525996,195-198,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,195,http://api.elsevier.com/content/abstract/scopus_id/84863544403,,84863544403,145752,p,Learning topics and related passages in books
"We studied how an enriched public library catalogue is used to access novels. 58 users searched for interesting novels to read in a simulated situation where they had only a vague idea of what they would like to read. Data consist of search logs, pre and post search questionnaires and observations. Results show, that investing effort on examining results improves search success, i.e. finding interesting novels, whereas effort in querying has no bearing on it. In designing systems for fiction retrieval, enriching result presentation with detailed book information would benefit users. © 2012 ACM.",7,,2-s2.0-84863541723,Conference Proceeding,2012-07-11,10.1145/2232817.2232855,202,9781450311540,15525996,199-202,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,199,http://api.elsevier.com/content/abstract/scopus_id/84863541723,,84863541723,145752,p,Emphasis on examining results in fiction searches contributes to finding good novels
"In 2008, Iowa City was designated as one of only five""Cities of Literature worldwide by UNESCO. To take advantage of our rich local literary history, an interdisciplinary research team from the University of Iowa collaborated to develop a digital library featuring Iowa City authors and locations. The UNESCO City of Literature digital library (referred to internally as ""City of Lit"") consists of a mobile application for the general public to access the database and a set of web-based interfaces for researcher and content creators to contribute to the database. Members of the research team have developed undergraduate literature courses to study the feasibility of using young scholars for digital content creation, and the pedagogical effect of including digital research in traditional literary courses. Students in the courses were trained to conduct scholarly research and generate a variety of digital resources to be included in the digital collection. This paper reports our experience building the City of Lit digital library and the results from evaluations and studies of the students in the courses. We also outline the implementation and development of the digital library, its framework, and the client-side mobile application. © 2012 ACM.",1,,2-s2.0-84863548652,Conference Proceeding,2012-07-11,10.1145/2232817.2232856,212,9781450311540,15525996,203-212,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,203,http://api.elsevier.com/content/abstract/scopus_id/84863548652,,84863548652,145752,p,"The ""City of Lit"" digital library: A case study of interdisciplinary research and collaboration"
"The surviving corpora of Greek and Latin are relatively compact but the shift from books and written objects to digitized texts has already challenged students of these languages to move away from books as organizing metaphors and to ask, instead, what do you do with a billion, or even a trillion, words? We need a new culture of intellectual production in which student researchers and citizen scholars play a central role. And we need as a consequence to reorganize the education that we provide in the humanities, stressing participatory learning, and supporting a virtuous cycle where students contribute data as they learn and learn in order to contribute knowledge. We report on five strategies that we have implemented to further this virtuous cycle: (1) reading environments by which learners can work with languages that they have not studied, (2) feedback for those who choose to internalize knowledge about a particular language, (3) methods whereby those with knowledge of different languages can collaborate to develop interpretations and to produce new annotations, (4) dynamic reading lists that allow learners to assess and to document what they have mastered, and (5) general e-portfolios in which learners can track what they have accomplished and document what they have contributed and learned to the public or to particular groups. © 2012 ACM.",2,,2-s2.0-84863544284,Conference Proceeding,2012-07-11,10.1145/2232817.2232857,222,9781450311540,15525996,213-222,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,213,http://api.elsevier.com/content/abstract/scopus_id/84863544284,,84863544284,145752,p,"Student researchers, citizen scholars and the trillion word library"
"Textual data ranging from corpora of digitized historic documents to large collections of news feeds provide a rich source for temporal and geographic information. Such types of information have recently gained a lot of interest in support of different search and exploration tasks, e.g., by organizing news along a timeline or placing the origin of documents on a map. However, for this, temporal and geographic information embedded in documents is often considered in isolation. We claim that through combining such information into (chronologically ordered) event-like features interesting and meaningful search and exploration tasks are possible. In this paper, we present a framework for the extraction, exploration, and visualization of event information in document collections. For this, one has to identify and combine temporal and geographic expressions from documents, thus enriching a document collection by a set of normalized events. Traditional search queries then can be enriched by conditions on the events relevant to the search subject. Most important for our event-centric approach is that a search result consists of a sequence of events relevant to the search terms and not just a document hit-list. Such events can originate from different documents and can be further explored, in particular events relevant to a search query can be ordered chronologically. We demonstrate the utility of our framework by different (multilingual) search and exploration scenarios using a Wikipedia corpus. © 2012 ACM.",9,,2-s2.0-84863556678,Conference Proceeding,2012-07-11,10.1145/2232817.2232859,232,9781450311540,15525996,223-232,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,223,http://api.elsevier.com/content/abstract/scopus_id/84863556678,,84863556678,145752,p,Event-centric search and exploration in document collections
"For a collection of digitized monographs in a subject domain, a domain meta-index provides a summary of domain concepts, and a structured vocabulary to support a scholar's navigation and search. We present a prototype of a Meta-index User Interface (MUI) that provides views of a domain at three levels: summarizing and comparing domains, exposing the regularities of a domain's vocabulary, and displaying book information and page content related both to objectively-representative books, and to specific user searches. © 2012 ACM.",2,,2-s2.0-84863539296,Conference Proceeding,2012-07-11,10.1145/2232817.2232860,236,9781450311540,15525996,233-236,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,233,http://api.elsevier.com/content/abstract/scopus_id/84863539296,,84863539296,145752,p,Dynamic online views of meta-indexes
"Concept taxonomies such as MeSH, the ACM Computing Classification System, and the NY Times Subject Headings are frequently used to help organize data. They typically consist of a set of concept names organized in a hierarchy. However, these names and structure are often not sufficient to fully capture the intended meaning of a taxonomy node, and particularly non-experts may have difficulty navigating and placing data into the taxonomy. This paper introduces two semi-supervised topic models that automatically augment a given taxonomy with many additional keywords by leveraging a corpus of multi-labeled documents. Our experiments show that users find the topics beneficial for taxonomy interpretation, substantially increasing their cataloging accuracy. Furthermore, the models provide a better information rate compared to Labeled LDA. © 2012 ACM.",11,,2-s2.0-84863546329,Conference Proceeding,2012-07-11,10.1145/2232817.2232861,240,9781450311540,15525996,237-240,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,237,http://api.elsevier.com/content/abstract/scopus_id/84863546329,,84863546329,145752,p,Topic models for taxonomies
"For most, the web is the first source to answer a question formulated by curiosity, need, or research reasons. This phenomenon is due to the internet's ubiquitous access, ease of use, and the extensive and ever expanding content. The problem is no longer the need to acquire content to encourage use, but to provide organizational tools to support content categorization that will facilitate improved access methods. This paper presents the results of a new text characterization algorithm that combines semantic and linguistic techniques utilizing domain-based ontology background knowledge. It explores the combination of meronym, synonym, and hypernym linguistic relationships to create a set of concept chains used to represent concepts found in a document. The experiments show improved accuracy over bag-of-words based term weighting methods and reveal characteristics of the meronym contribution to document representation. © 2012 ACM.",0,,2-s2.0-84863549997,Conference Proceeding,2012-07-11,10.1145/2232817.2232862,248,9781450311540,15525996,241-248,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,241,http://api.elsevier.com/content/abstract/scopus_id/84863549997,,84863549997,145752,p,Concept chaining utilizing meronyms in text characterization
"Multi-faceted book search engine presents diverse category-style options to allow users to refine search results without re-entering a query. In this paper, we propose a novel multi-faceted book search engine that utilizes users' query-related latent intents mined from click-through logs as multiple facets for books. The latent query intents can be effectively and efficiently discovered by applying the Sparse Latent Semantic Analysis (LSA) model to users' query and clicking behaviors in the click-through logs. This paper presents the details to improve the multi-faceted book search by incorporating the compact representation of query-intent-book relationships generated by Sparse LSA into the off-line and online processing procedures. The specificity of latent query intents can be flexibly changed by adjusting the sparsity level of projection matrix in the Sparse LSA model. We evaluated our approach on CADAL click-through logs containing 45,892 queries and 164,822 books. The experimental results show the Sparse LSA model with more sparse projection matrix tends to discover the more specific latent query intents. The latent query intents suggested by our approach usually gain the high user satisfaction ratio. © 2012 ACM.",2,,2-s2.0-84863546874,Conference Proceeding,2012-07-11,10.1145/2232817.2232864,257,9781450311540,15525996,249-257,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,249,http://api.elsevier.com/content/abstract/scopus_id/84863546874,,84863546874,145752,p,Improving multi-faceted book search by incorporating sparse latent semantic analysis of click-through logs
"Query In Context (QIC) is a personalized search system that enhances individual search by incorporating user preferences in query expansion, capturing meanings embedded in documents, and ranking search results with context-enriched features. In this paper, we propose a new technique for QIC's Query Expansion module, which reformulates user queries by using novel statistical-based and knowledge-based query expansion techniques to improve the returned results. The promising preliminary results analyzed through precision and recall metrics show better alignment between the user's interests and the results retrieved. © 2012 ACM.",1,,2-s2.0-84863556655,Conference Proceeding,2012-07-11,10.1145/2232817.2232865,262,9781450311540,15525996,259-262,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,259,http://api.elsevier.com/content/abstract/scopus_id/84863556655,,84863556655,145752,p,Personalized query expansion in the QIC system
"In this paper, we report on indexing performance by a state-of-the-art keyphrase indexer, Maui, when paired with a text extraction procedure called text denoising. Text denoising is a method that extracts the denoised text, comprising the content-rich sentences, from full texts. The performance of the keyphrase indexer is demonstrated on three standard corpora collected from three domains, namely food and agriculture, high energy physics, and biomedical science. Maui is trained using the full texts and denoised texts. The indexer, using its trained models, then extracts keyphrases from test sets comprising full texts, and their denoised and noise parts (i.e., the part of texts that remains after denoising). Experimental findings show that against a gold standard, the denoised-text-trained indexer indexing full texts, performs either better than or as good as its benchmark performance produced by a full-text-trained indexer indexing full texts. © 2012 ACM.",5,,2-s2.0-84863550132,Conference Proceeding,2012-07-11,10.1145/2232817.2232866,266,9781450311540,15525996,263-266,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,263,http://api.elsevier.com/content/abstract/scopus_id/84863550132,,84863550132,145752,p,Investigating keyphrase indexing with text denoising
"Information seeking behavior in microblogging environments such as Twitter differs from traditional web search. The best performing microblog retrieval techniques attempt to utilize both semantic and temporal aspects of documents. In this paper, we present an effective approach, including the query modeling, the document modeling and the temporal re-ranking, to discover the most recent but relevant information to the query. For the query modeling, we introduce a two-stage pseudo-relevance feedback query expansion to overcome the severe vocabulary-mismatch problem of short message retrieval in microblog. For the document modeling, we propose two ways to expand document with the help of the shortened URL. For the temporal re-ranking, we suggest several methods to evaluate the temporal aspects of documents. Experimental results demonstrate that our approach obtains significant improvements compared with baseline systems. Specifically, the proposed system gives 26.37% and 9.94% further increases in P@30 and MAP over the best performing result on highrel in the TREC'11 Real-Time Search Task. © 2012 ACM.",18,,2-s2.0-84863543085,Conference Proceeding,2012-07-11,10.1145/2232817.2232867,276,9781450311540,15525996,267-276,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,267,http://api.elsevier.com/content/abstract/scopus_id/84863543085,,84863543085,145752,p,Exploiting real-time information retrieval in the microblogosphere
"Algorithms are an essential part of computational science. An algorithm search engine, which extracts pseudo-codes and their metadata from documents, and makes it searchable, has recently been developed as part of the CiteseerX suite. However, this algorithm search engine only retrieves and ranks relevant algorithms solely on textual similarity. Here, we propose a method for using the algorithm co-citation network to infer the similarity between algorithms. We apply a graph clustering algorithm on the network for algorithm recommendation and make suggestions on how to improve the current CiteseerX algorithm search engine. © 2012 ACM.",9,,2-s2.0-84863539696,Conference Proceeding,2012-07-11,10.1145/2232817.2232869,280,9781450311540,15525996,277-280,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,277,http://api.elsevier.com/content/abstract/scopus_id/84863539696,,84863539696,145752,p,Improving algorithm search using the algorithm co-citation network
"Citation counts have been widely used in a digital library for purposes such as ranking scientific publications and evaluating patents. This paper demonstrates that distinguishing different types of citations could rank better for these purposes. We differentiate patent citations along two dimensions (assignees and technologies) into four types, and propose a weighted citation approach for assessing and ranking patents. We investigate five weight learning methods and compare their performance. Our weighted citation method performs consistently better than simple citation counts, in terms of rank correlations with patent renewal status. The estimated weights on different citations are consistent with economic insights on patent citations. Our study points to an interesting and promising research line on patent citation and network analysis that has not been explored. © 2012 ACM.",1,,2-s2.0-84863541648,Conference Proceeding,2012-07-11,10.1145/2232817.2232870,284,9781450311540,15525996,281-284,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,281,http://api.elsevier.com/content/abstract/scopus_id/84863541648,,84863541648,145752,p,Evaluating and ranking patents using weighted citations
"In education and research, references play a key role. However, extracting and parsing references are difficult problems. One concern is that there are many styles of references; hence, given a surface form, identifying what style was employed is problematic, especially in heterogeneous collections of theses and dissertations, which cover many fields and disciplines, and where different styles may be used even in the same publication. We address these problems by drawing upon suitable knowledge found in the WWW. In particular, we research a two-stage classifier approach, involving multi-class classification with respect to reference styles, and partially solve the problem of parsing surface representations of references. We describe empirical evidence for the effectiveness of our approach and plans for improvement of our methods. © 2012 ACM.",5,,2-s2.0-84863543532,Conference Proceeding,2012-07-11,10.1145/2232817.2232871,294,9781450311540,15525996,285-294,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,285,http://api.elsevier.com/content/abstract/scopus_id/84863543532,,84863543532,145752,p,A hybrid two-stage approach for discipline-independent canonical representation extraction from references
"Considering the tremendous value of citation metadata, many methods have been proposed to automate Citation Metadata Extraction (CME). The existing methods primarily rely on the content analysis of citation text. However, the results from such content-based methods are often unreliable. Moreover, the extracted citation metadata is only a small part of the relevant metadata that spreads across the Internet. As opposed to the content-based CME methods, this paper proposes a Web-based CME approach and a citation enriching system, called as BibAll, which is capable of correcting the parsing results of content-based CME methods and augmenting citation metadata by leveraging relevant bibliographic data from digital repositories and cited-by publications on the Web. BibAll consists of four main components: citation parsing, Web-based bibliographic data retrieval, irrelevant bibliographic data filtering, and relevant bibliographic data integration. The system has been tested on the publicly available FLUX-CIM dataset. Experimental results show that BibAll significantly improves the citation parsing accuracy and augments the metadata of the original citation. © 2012 ACM.",6,,2-s2.0-84863540909,Conference Proceeding,2012-07-11,10.1145/2232817.2232872,304,9781450311540,15525996,295-304,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,295,http://api.elsevier.com/content/abstract/scopus_id/84863540909,,84863540909,145752,p,"Web-based citation parsing, correction and augmentation"
"Little is known about how readers select books, whether they be print books or ebooks. In this paper we present a study of how people select physical books from academic library shelves. We use the insights gained into book selection behavior to make suggestions for the design of ebook-based digital libraries in order to better facilitate book selection behavior. © 2012 ACM.",26,,2-s2.0-84863552278,Conference Proceeding,2012-07-11,10.1145/2232817.2232874,314,9781450311540,15525996,305-314,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,305,http://api.elsevier.com/content/abstract/scopus_id/84863552278,,84863552278,145752,p,Book selection behavior in the physical library: Implications for ebook collections
"This paper explores photo organization within an event photo stream, i.e. the chronological sequence of photos from a single event. The problem is important: with the advent of inexpensive, easy-to-use photo capture devices, people can take a large number of photos per event. A family trip, for example, may include hundreds of photos. In this work, we have developed a photo browser that uses automatically segmented groups of photos - -referred to as chapters - -to organize such photos. The photo browser also affords users with a drag-and-drop interface to refine the chapter groupings. We conducted an exploratory study of 23 college students with their 8096 personal photos from 92 events, to understand the role of different spatial organization strategies in our chapter-based photo browser, in performing storytelling, photo search and photo set interpretation tasks. We also report novel insights on how the subjects organized their photos into chapters. We tested three layout strategies: bi-level, grid-stacking and space-filling, against a baseline plain grid layout. We found that subjects value the chronological order of the chapters more than maximizing screen space usage and that they value chapter consistency more than the chronological order of the photos. For automatic chapter groupings, having low chapter boundary misses is more important than having low chapter boundary false alarms; the choice of chapter criteria and granularity for chapter groupings are very subjective; and subjects found that chapter-based photo organization helps in all three tasks of the user study. Users preferred the chapter-based layout strategies to the baseline at a statistically significant level, with the grid-stacking strategy preferred the most. © 2012 ACM.",2,,2-s2.0-84863544274,Conference Proceeding,2012-07-11,10.1145/2232817.2232875,324,9781450311540,15525996,315-324,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,315,http://api.elsevier.com/content/abstract/scopus_id/84863544274,,84863544274,145752,p,"How do people organize their photos in each event and how does it affect storytelling, searching and interpretation tasks?"
"Collaborative reading, or co-reading as we call it, is ubiquitous; it occurs, for instance, in classrooms, book-clubs, and in less coordinated ways through mass media. While individual digital reading has been the subject of much investigation, research into co-reading is scarce. We report a two-phase field study of group reading to identify an initial set of user requirements. A co-reading interface is then designed that facilitates the coordination of group reading by providing temporary 'Point-out' markers to indicate specific locations within documents. A user study compared this new system with collaborative reading on paper, with a positive outcome; the differences in user behavior between paper and the new interface reveal intriguing insights into user needs and the potential benefits of digital media for co-reading. © 2012 ACM.",12,,2-s2.0-84863538121,Conference Proceeding,2012-07-11,10.1145/2232817.2232876,334,9781450311540,15525996,325-334,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,325,http://api.elsevier.com/content/abstract/scopus_id/84863538121,,84863538121,145752,p,Co-reading: Investigating collaborative group reading
"This paper describes a prototype of a digital library for water main break identification and visualization. Many utilities rely on an emergency call to detect water main breaks, because breaks are difficult to predict. Collecting the information by call requires time consuming human efforts. Furthermore, it is not archived and not shared with others. Collecting and archiving the information by tweets, news, and web resources helps users to identify relevant water main breaks efficiently. In developing this prototype, we extracted location information from text instead of using GPS data. We also describe the importance of tweet visualization by location, and how we visualize tweets on a map. © 2012 Authors.",1,,2-s2.0-84863552838,Conference Proceeding,2012-07-11,10.1145/2232817.2232878,336,9781450311540,15525996,335-336,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,335,http://api.elsevier.com/content/abstract/scopus_id/84863552838,,84863552838,145752,p,A digital library for water main break identification and visualization
"The Functional Requirements for Bibliographic Records (hereafter FRBR) has been adopted to address the relationships for bibliographic records and the related aggregate works. However, an approach to transform FRBR-based bibliographic relationships and their patterns into path-based rules for retrieval, navigation, display and data mining in the bibliographic space is still lacking. This study used the FRBR as a basis to analyze bibliographic relationships and their path-based rules. The novel ""Harry Potter and the Philosopher's Stone"" was used as a case study. Up until now, 87 unique records were retrieved from OCLC's Open WorldCat for analysis. Two specialists in library and information science familiar with FRBR conducted in-depth analysis to achieve inter-reliability agreement. This study generalizes several patterns of path-based rules for associating bibliographic records and outlines related issues for future study. © 2012 Authors.",1,,2-s2.0-84863544866,Conference Proceeding,2012-07-11,10.1145/2232817.2232879,338,9781450311540,15525996,337-338,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,337,http://api.elsevier.com/content/abstract/scopus_id/84863544866,,84863544866,145752,p,A preliminary analysis of FRBR's bibliographic relationships for path based associative rules
"This study examines the use of Twitter in a digital library, the Internet Public Library (ipl2), to understand the content and dissemination patterns of Twitter messages posted by the ipl2. We conducted a content analysis on ipl2's messages on Twitter to develop a categorization of the type of tweets, and examined retweets and the active users who retweeted ipl2 tweets. We present our analysis of four areas related to the tweets: motivation, content, audience, and sources. Active users are categorized into eight groups. The research findings contribute to a further understanding of the actual use of Twitter in a digital library. © 2012 Authors.",3,,2-s2.0-84863544780,Conference Proceeding,2012-07-11,10.1145/2232817.2232880,340,9781450311540,15525996,339-340,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,339,http://api.elsevier.com/content/abstract/scopus_id/84863544780,,84863544780,145752,p,A qualitative analysis of information dissemination through twitter in a digital library
"In the event of emergencies and disasters, massive amounts of web resources are generated and shared. Due to the rapidly changing nature of those resources, it is important to start archiving them as soon as a disaster occurs. This led us to develop a prototype system for constructing archives with minimum human intervention using the seed URLs extracted from tweet collections. We present the details of our prototype system. We applied it to five tweet collections that had been developed in advance, for evaluation. We also identify five categories of non- relevant files and conclude with a discussion of findings from the evaluation. © 2012 Authors.",3,,2-s2.0-84863548065,Conference Proceeding,2012-07-11,10.1145/2232817.2232881,342,9781450311540,15525996,341-342,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,341,http://api.elsevier.com/content/abstract/scopus_id/84863548065,,84863548065,145752,p,A study of automation from seed URL generation to focused web archive development: The CTRnet context
"Indexing objects such as documents, figures, tables and algorithms in a single system presents challenges in schema mapping, detecting overlapping objects in documents, presenting results from such an system to users. We propose a federated approach to indexing and retrieving such objects in academic papers © 2012 Authors.",1,,2-s2.0-84863554402,Conference Proceeding,2012-07-11,10.1145/2232817.2232882,344,9781450311540,15525996,343-344,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,343,http://api.elsevier.com/content/abstract/scopus_id/84863554402,,84863554402,145752,p,"A system for indexing tables, algorithms and figures"
"With more than 3.7 million articles, Wikipedia has become an important social medium for sharing knowledge. However, with this enormous repository of information, it can often be difficult to locate fundamental topics that support lower-level articles. By exploiting the information stored in the links between articles, we propose that related companion articles can be automatically generated to help further the reader's understanding of a given topic. This approach to a recommendation system uses tested link analysis techniques to present users with a clear path to related high-level articles, furthering the understanding of low-level topics. © 2012 Authors.",0,,2-s2.0-84863538698,Conference Proceeding,2012-07-11,10.1145/2232817.2232883,346,9781450311540,15525996,345-346,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,345,http://api.elsevier.com/content/abstract/scopus_id/84863538698,,84863538698,145752,p,A technique for suggesting related Wikipedia articles using link analysis
"Evaluation is a vital research area in the digital library domain, demonstrating a growing literature in conference and journal papers. In this poster we present the research trends that governed the field within the decade 2001 - 2010 in the JCDL and ECDL conferences. The DL evaluation literature was annotated using the domain ontology DiLEO, which defines explicitly the main concepts of the digital library evaluation field and their correlations. Several findings from this study underline the persistent character of quantitative research in evaluation initiatives. © 2012 Authors.",2,,2-s2.0-84863548658,Conference Proceeding,2012-07-11,10.1145/2232817.2232884,348,9781450311540,15525996,347-348,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,347,http://api.elsevier.com/content/abstract/scopus_id/84863548658,,84863548658,145752,p,An exploration of the research trends in the digital library evaluation domain
"This study addresses problems of reliability in the creation of tagged corpora by self-selected semi-anonymous raters. In order to account for both strong and weak raters, this paper contributes a recursive technique for scoring rater reliability. By assigning raters trust scores in the proposed method, candidate labels can be weighted by a confidence score and low-confidence ratings can be routed to an expert rater or additional amateur raters for further action. © 2012 Author.",0,,2-s2.0-84863545493,Conference Proceeding,2012-07-11,10.1145/2232817.2232885,350,9781450311540,15525996,349-350,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,349,http://api.elsevier.com/content/abstract/scopus_id/84863545493,,84863545493,145752,p,An iterative reliability measure for semi-anonymous annotators
"Search results of the existing general-purpose search engines usually do not satisfy domain-specific information retrieval tasks as there is a mis-match between the technical expertise of a user and the results returned by the search engine. In this paper, we investigate the problem of ranking domain-specific documents based on the technical difficulty. We propose an unsupervised conceptual terrain model using Latent Semantic Indexing (LSI) for re-ranking search results obtained from a similarity based search system. We connect the sequences of terms under the latent space by the semantic distance between the terms and compute the traversal cost for a document indicating the technical difficulty. Our experiments on a domain-specific corpus demonstrate the efficacy of our method. © 2012 Authors.",4,,2-s2.0-84863548599,Conference Proceeding,2012-07-11,10.1145/2232817.2232886,352,9781450311540,15525996,351-352,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,351,http://api.elsevier.com/content/abstract/scopus_id/84863548599,,84863548599,145752,p,An unsupervised technical difficulty ranking model based on conceptual terrain in the latent space
"Digital libraries often contain historical documents of varying age. The degree to which users can understand their content depends much on their reading difficulty. In this poster paper we report the results of our studies on the readability of historical documents from the viewpoint of present users. We investigate the correlation between the outcomes of different readability measurements and publication dates of prose texts on the basis of two datasets, the Victorian Women's Writers Project and the Corpus of Late Modern English Texts. © 2012 Authors.",2,,2-s2.0-84863543358,Conference Proceeding,2012-07-11,10.1145/2232817.2232887,354,9781450311540,15525996,353-354,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,353,http://api.elsevier.com/content/abstract/scopus_id/84863543358,,84863543358,145752,p,Longitudinal analysis of historical texts' readability
"In the domain of biology a huge amount of different data sources is available. Therefore, information gathering and searching are challenging tasks. To avoid a manual assessment of all relevant data sources, their knowledge has to be integrated. The presented system focuses on all aspects needed for suitable data integration and retrieval for domain experts from the field of biology. The knowledge from different data sources is combined and further used for, e.g. synonym enrichment of the query term. The resulting prototype was presented to a group of domain experts who confirmed that the system delivers suitable results supporting the scientists by their literature search. © 2012 Authors.",0,,2-s2.0-84863557346,Conference Proceeding,2012-07-11,10.1145/2232817.2232888,356,9781450311540,15525996,355-356,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,355,http://api.elsevier.com/content/abstract/scopus_id/84863557346,,84863557346,145752,p,Bi 2SoN: A digital library for supporting biomedical research
"CADAL(China Academic Digital Associate Library) plays a primary role in Universal Digital Library. By the end of 2011, CADAL has digitized 1.85 million books. Chinese calligraphy occupies an important place in Chinese culture, and the collection of digitized Chinese calligraphy is the large part of CADAL resources. So, the services of making full use of the collections are required for diverse users, such as art historians, students and the public. Here we propose a CADAL Digital Calligraphy System, in which over 1,100 works and 100,000 characters are included, the services of multi-level metadata-based search(metadata-based books search, works search and characters search) and multi-grain calligraphic character search(content-based search and radical-based search) are provided. In the end, some search-related applications of CADAL Digital Calligraphy System are discussed. © 2012 Authors.",3,,2-s2.0-84863548405,Conference Proceeding,2012-07-11,10.1145/2232817.2232889,358,9781450311540,15525996,357-358,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,357,http://api.elsevier.com/content/abstract/scopus_id/84863548405,,84863548405,145752,p,CADAL digital calligraphy system
"Domain knowledge map construction as an important method can describe the significant characters of a selected domain. In this research, we will address three problems for knowledge graph generation. Firstly, this paper will construct domain (core journals and conference proceedings) knowledge and domain context (domain citation) knowledge graphs, and propose a novel method to integrate those graphs. Secondly, two different methods will be investigated to associate keywords on the graph: Co-occur Domain Distance and Citation Probability Distribution Distance. Last but not least, the paper will propose an innovative method to evaluate the accuracy and coverage of knowledge graphs based on training keyword oriented Labeled-LDA model and validate different domain or domain context graphs. © 2012 Authors.",0,,2-s2.0-84863553736,Conference Proceeding,2012-07-11,10.1145/2232817.2232890,360,9781450311540,15525996,359-360,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,359,http://api.elsevier.com/content/abstract/scopus_id/84863553736,,84863553736,145752,p,Characterize scientific domain and domain context
"Through the application of multiple strategies and tools, the Biodiversity Heritage Library has created an effective and collaborative multi-institutional virtual organization. The purpose of this paper is to explore the communication and collaboration strategies used by the BHL to create, maintain, and provide open access to its corpus of biodiversity literature. BHL, in its seventh year, is a mature service and no longer a pilot project. Largely driven from the ground up, and without any institutional mandate, the BHL has successfully and organically fostered an organizational model that has encouraged innovation, user engagement, and global expansion. © 2012 Authors.",0,,2-s2.0-84863541533,Conference Proceeding,2012-07-11,10.1145/2232817.2232891,362,9781450311540,15525996,361-362,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,361,http://api.elsevier.com/content/abstract/scopus_id/84863541533,,84863541533,145752,p,Collaboration and communication tools used by the biodiversity heritage library: Refining strategies for success
"Entity and instance determination, disambiguation, and referencing, referred to as authority control in libraries, are essential for scientific research. This study examines the authority control practices and issues in molecular biology using literature and scenario analyses. The analyses imply that the concept of authority control in molecular biology is associated with three tasks: named entity recognition, disambiguation, and unification. The identified authority control issues were conceptualized as quality problems caused by four sources: inconsistent or incomplete mapping, context changes, entity changes, and changes in entity metadata. This study can inform librarians and repository curators of the needs and issues of authority control in molecular biology and other related disciplines. © 2012 Authors.",0,,2-s2.0-84863548912,Conference Proceeding,2012-07-11,10.1145/2232817.2232892,364,9781450311540,15525996,363-364,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,363,http://api.elsevier.com/content/abstract/scopus_id/84863548912,,84863548912,145752,p,"Data determination, disambiguation, and referencing in molecular biology"
"Computational journalism is driving the evolution of news media, devising new ways for collecting and analyzing large numbers of digital artifacts such as tweets and memes. This paper presents Breadcrumbs PDL, a specialized Personal Digital Library system that helps readers and journalists to access and use a collection of user-detected memes. PDL is part of Project Breadcrumbs, which aims to capitalize on public participation in the news media cycle. PDL supports browsing and exploration, and supports recommendations services that suggest alternative memes to read and ways to organize the users' personal workspace. Based on the users' clipping and organizational behaviors and textual similarities between clips, PDL can infer relationships between memes that computers alone cannot easily detect. © 2012 Author.",0,,2-s2.0-84863539231,Conference Proceeding,2012-07-11,10.1145/2232817.2232893,366,9781450311540,15525996,365-366,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,365,http://api.elsevier.com/content/abstract/scopus_id/84863539231,,84863539231,145752,p,Digital libraries for computational journalism
"Digital libraries often require very specialized interfaces in order to present various types of digital content. It is therefore critical to create interfaces that improve presentation of digital information and maximize user experience with digital collections. In this respect, this research aims to examine interfaces of three digital libraries that provide collections of digital text. The three digital libraries include Open Library, Google Books, and Hathi Trust. An evaluation matrix was developed to measure usability, aesthetics and interface components. The overall findings of the study showed that the majority of the participants preferred the Open Library interface followed by Google Books. The statistical analysis indicated that Open Library is significantly better than Google Books and Hathi Trust in terms of usability, aesthetics, and interface components. The preference for the Open Library stemmed largely from aesthetic choices. Participants also appreciated the use of elements that are analogous to their physical counterparts. © 2012 Authors.",3,,2-s2.0-84863541848,Conference Proceeding,2012-07-11,10.1145/2232817.2232894,368,9781450311540,15525996,367-368,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,367,http://api.elsevier.com/content/abstract/scopus_id/84863541848,,84863541848,145752,p,"Comparison of three digital library interfaces: Open library, Google books, and Hathi Trust"
"""Digital Preservation in a Box"" is a major activity of the National Digital Stewardship Alliance (NDSA) Outreach Working Group. This toolkit of digital stewardship outreach resources can be utilized by diverse communities as a gentle introduction to the concepts of preserving digital information. © 2012 Authors.",0,,2-s2.0-84863552284,Conference Proceeding,2012-07-11,10.1145/2232817.2232895,370,9781450311540,15525996,369-370,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,369,http://api.elsevier.com/content/abstract/scopus_id/84863552284,,84863552284,145752,p,Digital preservation in a box: Outreach resources for digital stewardship
"A principal goal for most research scientists is to publish. There are different kinds of publications covering different topics and requiring different writing formats. While authors tend to have unique personal writing styles, no work has been carried out to find out whether publication venues are distinguishable by their writing styles. Our work takes the first step into exploring this problem. Using the traditional classification approach and carrying out experiments on real data from the CiteSeer digital library, we demonstrate that venues are also distinguished by their writing styles. © 2012 Authors.",2,,2-s2.0-84863545430,Conference Proceeding,2012-07-11,10.1145/2232817.2232896,372,9781450311540,15525996,371-372,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,371,http://api.elsevier.com/content/abstract/scopus_id/84863545430,,84863545430,145752,p,Distinguishing venues by writing styles
"The issues of mobility and sight impairment with respect to virtual accessibility are as important as physical accessibility when it comes to using public library services. However, few studies have discussed public library website accessibility from the perspective of underrepresented user groups. The purpose of this study is to evaluate the accessibility of websites of public libraries and further identify the association between accessibility and public libraries' budgets. The study selected 20 public library systems that have the highest percentages of the disabled or senior citizen patrons. The study employed the Pearson correlation test in order to investigate the correlation between the accessibility and the budgets of public libraries. Preliminary findings show that most current public library websites do not comply with the Section 508. The findings indicate that public libraries did not consider their users or potential users with physical disabilities when designing their websites. Therefore, the findings suggest that public library websites are not suited to deliver effective information services for underrepresented user populations who need special assistance. Furthermore, this study finds that there is no significant association between the public library websites' accessibility and the budgets. © 2012 Authors.",0,,2-s2.0-84863558272,Conference Proceeding,2012-07-11,10.1145/2232817.2232897,374,9781450311540,15525996,373-374,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,373,http://api.elsevier.com/content/abstract/scopus_id/84863558272,,84863558272,145752,p,Do public library websites consider the disabled or senior citizens?
"In August 2011, five project partners (the State Library of North Carolina, the North Carolina State Archives, North Carolina Libraries for Virtual Education, Elon University, and the University of North Carolina at Charlotte) began a collaboration to develop a computer application that collects, ingests, and authenticates the electronic records that libraries and archives are often mandated to maintain. The application, called ""CINCH,"" incorporates existing digital curation technologies, but adds to their functionality by creating a pull-down (or capture) utility to gather content available from the Internet. The final product will be a lightweight, open-source software tool that institutions required to collect and authenticate records on ingest can employ to retrieve and process their digital content. © 2012 Authors.",0,,2-s2.0-84863550115,Conference Proceeding,2012-07-11,10.1145/2232817.2232898,376,9781450311540,15525996,375-376,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,375,http://api.elsevier.com/content/abstract/scopus_id/84863550115,,84863550115,145752,p,Electronic records processing: It's a CINCH!
"In this poster, we describe the approach taken to designing and implementing a tera-scale multi-repository index of archived web resources using massively parallel processing. © 2012 Author.",3,,2-s2.0-84863547597,Conference Proceeding,2012-07-11,10.1145/2232817.2232900,380,9781450311540,15525996,379-380,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,379,http://api.elsevier.com/content/abstract/scopus_id/84863547597,,84863547597,145752,p,Global web archive integration with memento
"The field of digital document content analysis includes many important tasks, for example page segmentation or zone classification. It is impossible to build effective solutions for such problems and evaluate their performance without a reliable test set, that contains both input documents and expected results of segmentation and classification. In this paper we present GROTOAP - - a test set useful for training and performance evaluation of page segmentation and zone classification tasks. The test set contains input articles in a digital form and corresponding ground truth files. All input documents included in the test set have been selected from DOAJ database, which indexes articles published under CC-BY license. The whole test set is available under the same license. © 2012 Authors.",8,,2-s2.0-84863549099,Conference Proceeding,2012-07-11,10.1145/2232817.2232901,382,9781450311540,15525996,381-382,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,381,http://api.elsevier.com/content/abstract/scopus_id/84863549099,,84863549099,145752,p,GROTOAP: Ground truth for open access publications
The Digitization Registry of the Czech Republic is a research project the aim of which is to create a national registry of digitized documents to avoid unwanted duplications in the digitization as well as to share digitization results throughout the Czech Republic. This could make the digitization more effective and also economize financial resources of participating institutions. © 2012 Authors.,0,,2-s2.0-84863539187,Conference Proceeding,2012-07-11,10.1145/2232817.2232902,384,9781450311540,15525996,383-384,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,383,http://api.elsevier.com/content/abstract/scopus_id/84863539187,,84863539187,145752,p,Has it been already digitized? How to find information about digitized documents
"Most studies on social influence have focused on direct influence, while another interesting question can be raised as whether indirect influence exists between two users who're not directly connected in the network and what affects such influence. In addition, the theory of complex contagion tells us that more spreaders will enhance the indirect influence between two users. Our observation of intensity of indirect influence, propagated by n parallel spreaders and quantified by retweeting probability on Twitter , shows that complex contagion is validated globally but is violated locally. In other words, the retweeting probability increases non-monotonically with some local drops. © 2012 Authors.",0,,2-s2.0-84863539157,Conference Proceeding,2012-07-11,10.1145/2232817.2232903,386,9781450311540,15525996,385-386,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,385,http://api.elsevier.com/content/abstract/scopus_id/84863539157,,84863539157,145752,p,How can spreaders affect the indirect infuence on twitter?
"Literary reading is an important activity for individuals and can be a long term commitment, making book choice an important task for book lovers and public library users. In this paper, we present a hybrid recommendation system to help readers decide which book to read next. We study book and author recommendations in a hybrid recommendation setting and test our algorithm on the LitRec data set. Our hybrid method combines two item-based collaborative filtering algorithms to predict books and authors that the user will like. Author predictions are expanded into a booklist that is subsequently aggregated with the former book predictions. Finally, the resulting booklist is used to yield the top-n book recommendations. By means of various experiments, we demonstrate that author recommendation can improve overall book recommendation. © 2012 Authors.",11,,2-s2.0-84863550188,Conference Proceeding,2012-07-11,10.1145/2232817.2232904,388,9781450311540,15525996,387-388,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,387,http://api.elsevier.com/content/abstract/scopus_id/84863550188,,84863550188,145752,p,Improving a hybrid literary book recommendation system through author ranking
"As larger collections need to be processed for digital library projects, libraries have to adopt technologies of scale. We present a case that involved creating image derivatives using High Performance Computing (HPC) resources. This experience opens up possibilities to conduct various processing tasks effectively and in reasonable time frames. Most importantly, it enables library IT staff access to cyberinfrastructure that can address the computing challenges of large-scale digital library projects. © 2012 Authors.",1,,2-s2.0-84863545496,Conference Proceeding,2012-07-11,10.1145/2232817.2232905,390,9781450311540,15525996,389-390,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,389,http://api.elsevier.com/content/abstract/scopus_id/84863545496,,84863545496,145752,p,Introducing high performance computing in digital library processing workflows
We investigate user perceptions of engagement and information quality of a mobile human computation game (HCG) by comparing it against a non-game-based application. Results suggest that the mobile HCG enabled participants to occupy their leisure time but the information contributed was perceived to be not as relevant. Implications of this study are discussed. © 2012 Authors.,5,,2-s2.0-84863549076,Conference Proceeding,2012-07-11,10.1145/2232817.2232906,392,9781450311540,15525996,391-392,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,391,http://api.elsevier.com/content/abstract/scopus_id/84863549076,,84863549076,145752,p,Investigating user perceptions of engagement and information quality in mobile human computation games
"Educating the engineering education community in today's digital world requires straightforward yet flexible access to high-quality educational resources. The Teach Engineering and NEEDS (National Engineering Education Delivery System) digital libraries collaborated in 2005 to create and steward the K-Gray Engineering Pathway (EP), a premier portal to comprehensive engineering and computing education resources within the greater National Science Digital Library (NSDL). We collaborated to design navigation, implement features, and find imagery that could effectively address both K-12 and higher education audiences. A system was designed to serve both target audiences, including an expanded simple search on every page to include grade/audience level search fields. This search, on all main pages, also includes a choice of learning resource type and a link to the Advanced Search with expanded search fields. EP tailored many features such as community pages and cataloging to be distinguishable by K-12 versus higher education users. Evaluation studies show that our current strength is a consistent interface with strong usability features. In this paper, we a provide retrospective and summarize our lessons learned and evaluation results, along with our directions for future research and development. © 2012 Authors.",3,,2-s2.0-84863555857,Conference Proceeding,2012-07-11,10.1145/2232817.2232907,394,9781450311540,15525996,393-394,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,393,http://api.elsevier.com/content/abstract/scopus_id/84863555857,,84863555857,145752,p,Lessons learned from developing and evaluating a comprehensive digital library for engineering education
"Controlled content quality also in terms of indexing is one of the major advantages of using digital libraries in contrast to general Web sources or Web search engines. However, considering today's information flood the mostly manual effort in acquiring new sources and creating suitable (semantic) metadata for content indexing and retrieval is already prohibitive. A recent solution is given by automatic generation of metadata, where various methods currently become more widespread. But in this case neglecting quality assurance is even more problematic, because heuristic generation often fails and the resulting low-quality metadata will directly diminish the quality of service that a digital library provides. To address this problem, we propose a metadata quality model to determine the overall quality of a metadata set and validate individual requirements imposed on that metadata set. Furthermore, lineage information is provided to trace the quality evolution of a metadata set. © 2012 Authors.",0,,2-s2.0-84863549068,Conference Proceeding,2012-07-11,10.1145/2232817.2232908,396,9781450311540,15525996,395-396,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,395,http://api.elsevier.com/content/abstract/scopus_id/84863549068,,84863549068,145752,p,Meta-line: Lineage information for improved metadata quality
"The ACM Computing Classification System (CCS) is a hierarchical classification system used to index and classify all the published literature of ACM. They reflect major areas and topics of the computing field and they often serve as an overview and navigational guide to the field. However, similar to all the traditional classification systems and subject domain thesauri, such an overview and navigational guide is static and sketchy, representing only a top-down representation of a domain. In this paper, we look into a 10-year period of ACM literature and examine how the CCS terms are actually used in the ACM digital library and how the patterns of term usages show different term relationships than those defined in the CCS. By comparing the dynamic statistical patterns of term usage with the static hierarchical structures of the terms, we show that much can be gained by integrating both of them into an interactive interface to provide better overview maps and navigational guides to the domain of computing. © 2012 Authors.",1,,2-s2.0-84863547580,Conference Proceeding,2012-07-11,10.1145/2232817.2232909,398,9781450311540,15525996,397-398,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,397,http://api.elsevier.com/content/abstract/scopus_id/84863547580,,84863547580,145752,p,Multi-view of the ACM classification system
"This poster presents a case study describing how the National Digital Newspaper Program's (NDNP) metadata specification and public website, Chronicling America, have been designed to promote a wide range of data sharing. Through use of the website's extensive application programming interface (API) and open-source software counterpart, several institutions are benefiting from the publicly-funded program's data. © 2012 Authors.",0,,2-s2.0-84863539223,Conference Proceeding,2012-07-11,10.1145/2232817.2232910,400,9781450311540,15525996,399-400,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,399,http://api.elsevier.com/content/abstract/scopus_id/84863539223,,84863539223,145752,p,"National digital newspaper program: A case study in sharing, linking, and using data"
"In the framework of a project aiming to realize a strategy of open research data access in Slovenia in accordance with OECD principles, we conducted a series of interviews with different target audiences in order to assess the initial conditions in the area of data handling. The data creators and data services expressed a high level of awareness about data quality issues, especially in relation to good publication potential. Barriers to ensuring the greater accessibility of data in the future include the little recognition and reputation for doing the related extra work involved in preparing data and documentation, the need for financial rewards for such additional work, and the undeveloped culture of data exchange in general. The motivation to provide open access to such data will involve a combination of requirements prescribed for data delivery, and the provision of support services and financial rewards, in particular changing the views held by the professional scientific community about the benefits of open data for research activities. © 2012 Author.",0,,2-s2.0-84863558340,Conference Proceeding,2012-07-11,10.1145/2232817.2232911,402,9781450311540,15525996,401-402,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,401,http://api.elsevier.com/content/abstract/scopus_id/84863558340,,84863558340,145752,p,Responsibility for research data quality in open access: A Slovenian case
"The goal of this research is to describe an innovative method of creating scientific referential metadata for a cyberinfrastructure-enabled learning environment to enhance student and scholar learning experiences. By using information retrieval and meta-search approaches, different types of referential metadata, such as related Wikipedia Pages, Datasets, Source Code, Video Lectures, Presentation Slides, and (online) Tutorials, for an assortment of publications and scientific topics will be automatically retrieved, associated, and ranked. © 2012 Authors.",1,,2-s2.0-84863546256,Conference Proceeding,2012-07-11,10.1145/2232817.2232912,404,9781450311540,15525996,403-404,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,403,http://api.elsevier.com/content/abstract/scopus_id/84863546256,,84863546256,145752,p,Scientific cyberlearning resources referential metadata creation via information retrieval
"Digital content can benefit K-12 science, technology, engineering, and mathematics (STEM) teaching and learning, but it is not widely integrated. Many school librarians are not sure how to build upon their expertise to share and link digital learning resources in their roles as resource providers and instructional collaborators. This poster will present Web2MARC, a web-based application for integration of digital resources into school library collections. Further work on the state of school library STEM collections, survey analysis, and Web2MARC is slated to be complete in 2013. © 2012 Authors.",0,,2-s2.0-84863558348,Conference Proceeding,2012-07-11,10.1145/2232817.2232914,408,9781450311540,15525996,407-408,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,407,http://api.elsevier.com/content/abstract/scopus_id/84863558348,,84863558348,145752,p,Web2MARC: Sharing and using STEM digital content in school libraries
"Traditional recommender system research often explores customer, product, and transaction information in providing recommendations. Social relationships in social networks are related to individuals' preferences. This study investigates the product recommendation problem based solely on people's social network information. Taking a kernel-based approach, we capture consumer social influence similarities into a graph random walk kernel and build SVR models to predict consumer opinions. In experiments on a dataset from a movie review website, our proposed model outperforms trust-based models and state-of-the-art graph kernels. © 2012 Authors.",6,,2-s2.0-84863546958,Conference Proceeding,2012-07-11,10.1145/2232817.2232915,410,9781450311540,15525996,409-410,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,409,http://api.elsevier.com/content/abstract/scopus_id/84863546958,,84863546958,145752,p,Social network-based recommendation: A graph random walk kernel approach
"The David Livingstone Spectral Imaging Project is a collaborative, international effort to use spectral imaging technology and digital publishing to make available a series of faded, illegible texts produced by the famous Victorian explorer when he was stranded without ink or writing paper in Central Africa. The poster describes existing achievements of the project, plans for an innovative portal providing access to images and data, and preservation challenges. © 2012 Authors.",0,,2-s2.0-84863554450,Conference Proceeding,2012-07-11,10.1145/2232817.2232916,412,9781450311540,15525996,411-412,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,411,http://api.elsevier.com/content/abstract/scopus_id/84863554450,,84863554450,145752,p,The David Livingstone spectral imaging project
"Metadata records are a ubiquitous and foundational feature of contemporary information systems. However, while their simple surface structure may lead us to think that the semantics of a metadata record is unproblematic and easily discerned, our analysis of an example record suggests otherwise. We show three possibilities for the logical form of the proposition expressed by a metadata record. All three are substantially different in the first order constructs utilized, and no two can be recognized as equivalent for the purposes of information organization. The semantics of the common metadata record is elusive. The main source of this problem appears to be the identifier attribute. Although identifier attributes have the syntactic appearance of any other attribute in the metadata vocabulary, this uniformity conceals their potential for assuming a distinctive semantic role, and one which appears to cross the traditional object language / metalanguage boundary, suggesting that translation of colloquial metadata records into logic-based knowledge representations does not take place entirely at a first-order level. © 2012 Authors.",1,,2-s2.0-84863541720,Conference Proceeding,2012-07-11,10.1145/2232817.2232917,414,9781450311540,15525996,413-414,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,413,http://api.elsevier.com/content/abstract/scopus_id/84863541720,,84863541720,145752,p,The logical form of the proposition expressed by a metadata record
"Geospatial metadata enable rich and varied interfaces to digital collections, and present unique challenges and affordances for automated extraction. We describe our findings developing and utilizing a geoparser for the Texas A&M University Libraries' Institutional Repository. © 2012 Authors.",0,,2-s2.0-84863552312,Conference Proceeding,2012-07-11,10.1145/2232817.2232918,416,9781450311540,15525996,415-416,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,415,http://api.elsevier.com/content/abstract/scopus_id/84863552312,,84863552312,145752,p,Toponym extraction and resolution in a digital library
"YADDA2 is an open software platform which facilitates creation of digital library applications. It consists of versatile building blocks providing, among others: storage, relational and full-text indexing, process management, and asynchronous communication. Its loosely-coupled service-oriented architecture enables deployment of highly-scalable, distributed systems. © 2012 Authors.",3,,2-s2.0-84863541915,Conference Proceeding,2012-07-11,10.1145/2232817.2232920,420,9781450311540,15525996,419-420,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,419,http://api.elsevier.com/content/abstract/scopus_id/84863541915,,84863541915,145752,p,YADDA2: Assemble your own digital library application from LEGO bricks
"We describe the functions of HeMT, a multilingual participatory platform for Human Evaluation of Machine Translation. HeMT is used by three types of users including translators, evaluators, and reviewers. It consists of six major modules: User Management, Manual Translation, User Training, Evaluation, Result Visualization, and Multilingual Lexicon Management. HeMT can be used by Digital Libraries and Machine Translation communities for conducting manual translation, machine translation evaluation, and computer-assisted translation tasks. © 2012 Authors.",2,,2-s2.0-84863542888,Conference Proceeding,2012-07-11,10.1145/2232817.2232922,422,9781450311540,15525996,421-422,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,421,http://api.elsevier.com/content/abstract/scopus_id/84863542888,,84863542888,145752,p,An integrated participatory platform for human evaluation of machine translation
"Digital library interoperability is supported by good quality metadata. The design of metadata creation and management tools is therefore an important component of overall digital library design. A number of factors affect metadata tool usability, including task complexity, interface usability, and organizational context of use. These issues are being addressed in the user-centered design of a metadata tool for the Internet Public Library. © 2012 Authors.",1,,2-s2.0-84863551525,Conference Proceeding,2012-07-11,10.1145/2232817.2232923,424,9781450311540,15525996,423-424,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,423,http://api.elsevier.com/content/abstract/scopus_id/84863551525,,84863551525,145752,p,'Erasmus': An organization- and user-centered dublin core metadata tool
"The idea of faceted search has received growing attentions in the digital library field for its potential of improving user satisfaction by combing the query and browse strategies interactively. Furthermore, with the trend of using digital repositories as the central infrastructure for curation and preservation, there is a demand for a single search interface providing public access to all the diversified content stored in the repositories. In this demo, we present Digital Collections Search, a system that is designed to assist users who are unfamiliar with the subject of their information needs locating relevant items as well exploring related but unknown collections in the repository. © 2012 Authors.",1,,2-s2.0-84863542836,Conference Proceeding,2012-07-11,10.1145/2232817.2232924,426,9781450311540,15525996,425-426,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,425,http://api.elsevier.com/content/abstract/scopus_id/84863542836,,84863542836,145752,p,Faceted search for heterogeneous digital collections
"In this demo, we will demonstrate usage of NLM Video Search, open-source software which facilitates the dissemination of video content by combining traditional web video playback controls with on-demand seeking using text selected from a corresponding transcript (see Figure 1). NLM Video Search has been implemented in NLM's Fedora-based digital repository, which provides preservation and access to a growing number of rare, historical films and digitized texts. © 2012 Authors.",0,,2-s2.0-84863543704,Conference Proceeding,2012-07-11,10.1145/2232817.2232925,428,9781450311540,15525996,427-428,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,427,http://api.elsevier.com/content/abstract/scopus_id/84863543704,,84863543704,145752,p,NLM video search
"VIVO is an open source semantic web platform that contains information about scholars and their interests and activities. This demonstration will highlight the platform and ontology, data sources, features of the software and the ways that VIVO data can be leveraged for a variety of purposes within and beyond an institution to facilitate collaboration and research discovery. © 2012 Authors.",0,,2-s2.0-84863541713,Conference Proceeding,2012-07-11,10.1145/2232817.2232926,430,9781450311540,15525996,429-430,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,429,http://api.elsevier.com/content/abstract/scopus_id/84863541713,,84863541713,145752,p,Research discovery through linked open data
"This work illustrates how audio content analysis of music and manually assigned structural temporal metadata can be used to form a digital library designed for musicological exploration. In addition to text-based searching and browsing, the document view is enriched with an interactive structured audio time-line that shows ground-truth data representing the logical segments to the song, and a version that was automatically generated for comparison. A self-similarity ""heat"" map is also displayed, and is interactive. Clicking within the map at a co-ordinate (x,y) results in the audio being played simultaneous at time offset x and y, panned left and right, respectively, to make it easier for the listener to separate out the differences. The musicologist can also initiate an audio content based query starting at any point in the song. This produces a ranked result set which can be further studied through their respective document views. Alternatively they can perform a musical structure search (for example, for songs that contain the structure b, b, c, b, c). © 2012 Authors.",1,,2-s2.0-84863554310,Conference Proceeding,2012-07-11,10.1145/2232817.2232927,432,9781450311540,15525996,431-432,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,431,http://api.elsevier.com/content/abstract/scopus_id/84863554310,,84863554310,145752,p,Structured audio content analysis and metadata in a digital library
"This demonstration shows the Profiles in Science® digital library. Profiles in Science contains digitized selections from the personal manuscript collections of prominent biomedical researchers, medical practitioners, and those fostering science and health. The Profiles in Science Web site is the delivery mechanism for content derived from the digital library system. The system is designed according to our basic principles for digital library development [1]. The digital library includes the rules and software used for digitizing items, creating and editing database records and performing quality control as well as serving the digital content to the public. Among the types of data managed by the digital library are detailed item-level, collection-level and cross-collection metadata, digitized photographs, papers, audio clips, movies, born-digital electronic files, optical character recognized (OCR) text, and annotations (see Figure 1). The digital library also tracks the status of each item, including digitization quality, sensitivity of content, and copyright. Only items satisfying all required criteria are released to the public through the World Wide Web. External factors have influenced all aspects of the digital library's infrastructure.",0,,2-s2.0-84863544668,Conference Proceeding,2012-07-11,10.1145/2232817.2232928,434,9781450311540,15525996,433-434,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,433,http://api.elsevier.com/content/abstract/scopus_id/84863544668,,84863544668,145752,p,The Profiles in Science digital library: Behind the scenes
"The ResultsSpace Collaborative Search Environment is a tool to support asynchronous collaborative information retrieval among a small group of collaborators. It is designed to promote awareness of collaborators' searches and the documents they have rated. Awareness is supported through several mechanisms: an area that shows a history of queries, a summary display of collaborators' ratings next to each search result, and changes in the visual salience of search results based on their aggregate rating from all collaborators. Faceted controls allow users to filter results based on specific ratings (relevant, not relevant, and maybe) and on specific collaborator(s) who have rated an item. We describe features of the system, how they are implemented, and give insights into the design rationale. © 2012 Authors.",4,,2-s2.0-84863552322,Conference Proceeding,2012-07-11,10.1145/2232817.2232929,436,9781450311540,15525996,435-436,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,435,http://api.elsevier.com/content/abstract/scopus_id/84863552322,,84863552322,145752,p,The ResultsSpace collaborative search environment
"The Internet Archive's Wayback Machine is the most common way that typical users interact with web archives. The Internet Archive uses the Heritrix web crawler to transform pages on the publicly available web into Web ARChive (WARC) files, which can then be accessed using the Wayback Machine. Because Heritrix can only access the publicly available web, many personal pages (e.g. password-protected pages, social media pages) cannot be easily archived into the standard WARC format. We have created a Google Chrome extension, WARCreate, that allows a user to create a WARC file from any webpage. Using this tool, content that might have been otherwise lost in time can be archived in a standard format by any user. This tool provides a way for casual users to easily create archives of personal online content. This is one of the first steps in resolving issues of ""long term storage, maintenance, and access of personal digital assets that have emotional, intellectual, and historical value to individuals"". © 2012 Authors.",6,,2-s2.0-84863555383,Conference Proceeding,2012-07-11,10.1145/2232817.2232930,438,9781450311540,15525996,437-438,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,437,http://api.elsevier.com/content/abstract/scopus_id/84863555383,,84863555383,145752,p,WARCreate: Create wayback-consumable WARC files from any webpage
"Cultural institutions are increasingly opening up their repositories and contribute digital objects to social media platforms such as Flickr. In return they often receive user comments containing information that could be incorporated in their catalog records. Since judging the usefulness of a large number of user comments is a labor-intensive task, our aim is to provide automated support for filtering potentially useful social media comments on digital objects. In this paper, we discuss the notion of usefulness in the context of social media comments and compare it from end-users as well as expertusers perspectives. Then we present a machine-learning approach to automatically classify comments according to their usefulness. Our approach makes use of syntactic and semantic comment features and also considers user context. We present the results of an experiment we did on user comments received in six different Flickr Commons collections. They show that a few relatively straightforward features can be used to infer useful comments with up to 89% accuracy. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",15,,2-s2.0-84882237390,Conference Proceeding,2013-08-23,10.1145/2467696.2467711,10,9781450320764,15525996,1-10,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,1,http://api.elsevier.com/content/abstract/scopus_id/84882237390,,84882237390,145752,p,Identification of useful user comments in social media: A case study on flickr commons
"Mathematical formulae in structural formats such as MathML and LATEX are becoming increasingly available. Moreover, repositories and websites, including ArXiv and Wikipedia, and growing numbers of digital libraries use these structural formats to present mathematical formulae. This presents an important new and challenging area of research, namely Mathematical Information Retrieval (MIR). In this paper, we propose WikiMirs, a tool to facilitate mathematical formula retrieval in Wikipedia. WikiMirs is aimed at searching for similar mathematical formulae based upon both textual and spatial similarities, using a new indexing and matching model developed for layout structures. A hierarchical generalization technique is proposed to generate sub-trees from presentation trees of mathematical formulae, and similarity is calculated based upon matching at different levels of these trees. Experimental results show that WikiMirs can efficiently support sub-structure matching and similarity matching of mathematical formulae. Moreover, WikiMirs obtains both higher accuracy and better ranked results over Wikipedia in comparison to Wikipedia Search and Egomath. We conclude that WikiMirs provides a new, alternative, and hopefully better service for users to search mathematical expressions within Wikipedia. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",7,,2-s2.0-84882266971,Conference Proceeding,2013-08-23,10.1145/2467696.2467699,20,9781450320764,15525996,11-20,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,11,http://api.elsevier.com/content/abstract/scopus_id/84882266971,,84882266971,145752,p,WikiMirs: A mathematical information retrieval system for wikipedia
"There is growing interest by digital collection providers to engage collection users in interacting with the collection (e.g. by tagging or annotating collection contents) and with the collection organizers and other users (e.g. to form loose 'communities' associated with the collection). At present, little has been documented as to the uptake of these mechanisms in specific collections, or the range of behaviors that emerge as users bend existing facilities to their own needs. This paper is one step in that direction: it describes the social information behaviors exhibited in a cultural heritage photography collection in The Commons on Flickr, and suggests implications for digital library design in response to these behaviors. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",2,,2-s2.0-84882273493,Conference Proceeding,2013-08-23,10.1145/2467696.2467745,24,9781450320764,15525996,21-24,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,21,http://api.elsevier.com/content/abstract/scopus_id/84882273493,,84882273493,145752,p,Interacting with and through a digital library collection: Commenting Behavior in flickr's the commons
"In addition to its broad popularity Wikipedia is also widely used for scholarly purposes. Many Wikipedia pages pertain to academic papers, scholars and topics providing a rich ecology for scholarly uses. Scholarly references and mentions on Wikipedia may thus shape the \societal impact"" of a certain scholarly communication item, but it is not clear whether they shape actual \academic impact"". In this paper we compare the impact of papers, scholars, and topics according to two different measures, namely scholarly citations and Wikipedia mentions. Our results show that academic and Wikipedia impact are positively correlated. Papers, authors, and topics that are mentioned on Wikipedia have higher academic impact than those are not mentioned. Our findings validate the hypothesis that Wikipedia can help assess the impact of scholarly publications and underpin relevance indicators for scholarly retrieval or recommendation systems. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",8,,2-s2.0-84882257404,Conference Proceeding,2013-08-23,10.1145/2467696.2467746,28,9781450320764,15525996,25-28,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,25,http://api.elsevier.com/content/abstract/scopus_id/84882257404,,84882257404,145752,p,A comparative study of academic and wikipedia ranking
"The reliable and consistent long-term preservation of digital content and metadata is becoming increasingly important - even though the storage media used are potentially subject to failures, or the data formats may become obsolete over time. A common approach is to replicate data across several sites to increase their availability. Nevertheless, network, software, or hardware failures as well as the evolution of data formats have to be coped with in a timely and, ideally, an autonomous way, without intervention of an administrator. In this paper we present DISTARNET, a distributed, autonomous long-term digital preservation system. Essentially, DISTARNET exploits dedicated processes to ensure the integrity and consistency of data with a given replication degree. At the data level, DISTARNET supports complex data objects, the management of collections, annotations, and arbitrary links between digital objects. At process level, dynamic replication management, consistency checking, and automated recovery of the archived digital objects is pro- vided utilizing autonomic behavior governed by preservation policies without any centralized component. We present the concepts and implementation of the distributed DISTAR- NET preservation approach. Most importantly, we provide details of the qualitative and quantitative evaluation of the DISTARNET system. The former addresses the effectiveness of the internal preservation processes while the latter evaluates DISTARNET's performance regarding the overall archiving storage capacity and scalability. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",4,,2-s2.0-84882278129,Conference Proceeding,2013-08-23,10.1145/2467696.2467710,38,9781450320764,15525996,29-38,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,29,http://api.elsevier.com/content/abstract/scopus_id/84882278129,,84882278129,145752,p,A distributed archival network for process-oriented autonomic long-term digital preservation
"When a user views an archived page using the archive's user interface (UI), the user selects a datetime to view from a list. The archived web page, if available, is then displayed. From this display, the web archive UI attempts to simulate the web browsing experience by smoothly transitioning between archived pages. During this process, the target date- time changes with each link followed; drifting away from the datetime originally selected. When browsing sparsely- Archived pages, this nearly-silent drift can be many years in just a few clicks. We conducted 200,000 acyclic walks of archived pages, following up to 50 links per walk, comparing the results of two target datetime policies. The Sliding Tar- get policy allows the target datetime to change as it does in archive UIs such as the Internet Archive'sWaybackMachine. The Sticky Target policy, represented by the Memento API, keeps the target datetime the same throughout the walk. We found that the Sliding Target policy drift increases with the number of walk steps, number of domains visited, and choice (number of links available). However, the Sticky Tar- get policy controls temporal drift, holding it to less than 30 days on average regardless of walk length or number of do- mains visited. The Sticky Target policy shows some increase as choice increases, but this may be caused by other factors. We conclude that based on walk length, the Sticky Target policy generally produces at least 30 days less drift than the Sliding Target policy. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",2,,2-s2.0-84882281071,Conference Proceeding,2013-08-23,10.1145/2467696.2467718,48,9781450320764,15525996,39-48,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,39,http://api.elsevier.com/content/abstract/scopus_id/84882281071,,84882281071,145752,p,Evaluating sliding and sticky target policies by measuring temporal drift in acyclic walks through a web archive
"The Medusa digital preservation service at the University of Illinois at Urbana-Champaign provides a storage environment for digital content selected for long-term retention by content managers and producers affiliated with the Library in order to ensure its enduring access and use. This paper reports on Medusa development, with emphasis on the research processes that informed key decisions related to its design, the central role of PREMIS metadata in its architecture, and future directions of integrating PREMIS management into a Fedora repository architecture. In so doing, it describes a strategy of digital preservation content management that draws strength from the creation and management of comprehensive PREMIS preservation metadata records. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882254444,Conference Proceeding,2013-08-23,10.1145/2467696.2467725,52,9781450320764,15525996,49-52,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,49,http://api.elsevier.com/content/abstract/scopus_id/84882254444,,84882254444,145752,p,Medusa at the university of Illinois at Urbana-Champaign: A digital preservation service based on PREMIS
"Smartphones and tablets are increasingly used to access the Web, and many websites now provide alternative sites tailored specifically for these mobile devices. Web archivists are in need of tools to aid in archiving this equally ephemeral Mobile Web. We present Findmobile, a tool for automating the discovery of mobile websites. We tested our tool in an experiment examining 10K popular websites and found that the most frequently used technique used by popular websites to direct mobile users to mobile sites was by automated client and server-side redirection. We found that nearly half of mobile web pages differ dramatically from their stationary web counterparts and that the most popular websites are those most likely to have mobile-specific pages. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",3,,2-s2.0-84882258922,Conference Proceeding,2013-08-23,10.1145/2467696.2467735,56,9781450320764,15525996,53-56,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,53,http://api.elsevier.com/content/abstract/scopus_id/84882258922,,84882258922,145752,p,First steps in archiving the mobile web: Automated discovery of mobile websites
"In this paper we explore the vertical selection methods in aggregated search in the specific domain of topics for children between 7 and 12 years old. A test collection consisting of 25 verticals, 3.8K queries and relevant assessments for a large sample of these queries mapping relevant verticals to queries was built. We gather relevant assessment by envisaging two aggregated search systems: one in which the Web vertical is always displayed and in which each vertical is assessed independently from the web vertical. We show that both approaches lead to a di?erent set of relevant verticals and that the former is prone to bias of visually oriented verticals. In the second part of this paper we estimate the size of the verticals for the target domain. We show that employing the global size and domain specific size estimation of the verticals lead to significant improvements when using state-of-the art methods of vertical selection. We also introduce a novel vertical and query representation based on tags from social media and we show that its use lead to significant performance gains. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",3,,2-s2.0-84882265290,Conference Proceeding,2013-08-23,10.1145/2467696.2467714,66,9781450320764,15525996,57-66,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,57,http://api.elsevier.com/content/abstract/scopus_id/84882265290,,84882265290,145752,p,Vertical selection in the information domain of children
"A key challenge facing educational technology researchers is how to provide structure and guidance when learners use unstructured and open tools such as digital libraries for their own learning. This work attempts to use computational methods to identify that structure in a domain independent way and support learners as they navigate and interpret the information they find. This article highlights a computational methodology for generating a pedagogical sequence through core learning goals extracted from a collection of resources which in this case, are resources from the Digital Library for Earth System Education (DLESE). This article describes how we use the technique of multi-document summarization to extract the core learning goals from the digital library resources and how we create a supervised classifier that performs a pair-wise classification of the core learning goals; the judgments from these classifications are used to automatically generate pedagogical sequences. Results show that we can extract good core learning goals and make pair-wise classifications that are up to 76% similar to the pair-wise classifications generated from pedagogical sequences created by two science education experts. Thus we can dynamically generate pedagogically meaningful learning paths through digital library resources. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",2,,2-s2.0-84882253487,Conference Proceeding,2013-08-23,10.1145/2467696.2467708,76,9781450320764,15525996,67-76,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,67,http://api.elsevier.com/content/abstract/scopus_id/84882253487,,84882253487,145752,p,Automatic extraction of core learning goals and generation of pedagogical sequences through a collection of digital library resources
"Syllabi are rich educational resources. However, finding Computer Science syllabi on a generic search engine does not work well. Towards our goal of building a syllabus collection we have trained various Machine Learning classifiers to recognize Computer Science syllabi from other web pages and the discipline that they represent (AI or SE for instance) among other things. We have crawled 50 Computer Science departments in the US and gathered 100,000 candidate pages. Our best classifiers are more than 90% accurate at identifying syllabi from real-world data. The syllabus repository we created is live for public use [1] and contains more than 3000 syllabi that our classifiers filtered out from the crawl data. We present an analysis of the various feature selection methods and classifiers used. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882273506,Conference Proceeding,2013-08-23,10.1145/2467696.2467723,86,9781450320764,15525996,77-86,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,77,http://api.elsevier.com/content/abstract/scopus_id/84882273506,,84882273506,145752,p,Building a search engine for computer science course syllabi
"Expert search or recommendation involves the retrieval of people (experts) in response to a query and on occasion, a given set of constraints. In this paper, we address expert recommendation in academic domains that are different from web and intranet environments studied in TREC. We propose and study graph-based models for expertise retrieval with the objective of enabling search using either a topic (e.g. ""Information Extraction"") or a name (e.g. ""Bruce Croft""). We show that graph-based ranking schemes despite being ""generic"" perform on par with expert ranking models specific to topic-based and name-based querying. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",12,,2-s2.0-84882255582,Conference Proceeding,2013-08-23,10.1145/2467696.2467707,96,9781450320764,15525996,87-96,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,87,http://api.elsevier.com/content/abstract/scopus_id/84882255582,,84882255582,145752,p,Ranking experts using author-document-topic graphs
"The impact of scientific research has traditionally been quantified using productivity indices such as the well-known hindex. On the other hand, different research fields-in fact, even different research areas within a single field-may have very different publishing patterns, which may not be well described by a single, global index. In this paper, we argue that productivity indices should account for the singularities of the publication patterns of different research areas, in order to produce an unbiased assessment of the impact of scientific research. Inspired by ranking aggregation approaches in distributed information retrieval, we propose a novel approach for ranking researchers across multiple research areas. Our approach is generic and produces crossarea versions of any global productivity index, such as the volume of publications, citation count and even the h-index. Our thorough evaluation considering multiple areas within the broad field of Computer Science shows that our crossarea indices outperform their global counterparts when assessed against the official ranking produced by CNPq, the Brazilian National Research Council for Scientific and Technological Development. As a result, this paper contributes a valuable mechanism to support the decisions of funding bodies and research agencies, for example, in any research assessment effort. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",9,,2-s2.0-84882275983,Conference Proceeding,2013-08-23,10.1145/2467696.2467715,106,9781450320764,15525996,97-106,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,97,http://api.elsevier.com/content/abstract/scopus_id/84882275983,,84882275983,145752,p,"Aggregating productivity indices for ranking researchers across multiple areas,Research performance; Bibliometric indicators; Ranking aggregation; Cross-disciplinarity"
"With the amount of digitalized documents increasing exponentially, it is more difficult for users to keep up to date with the knowledge in their domain. In this paper, we present a framework named IFME (Information Filtering by Multiple Examples) in a digital library environment to help users identify the literature related to their interests by leveraging the Positive Unlabeled learning (PU learning). Using a few relevant documents provided by a user and considering the documents in an online database as unlabeled data (called U), it ranks the documents in U using a PU learning algorithm. From the experimental results, we found that while the approach performed well when a large set of relevant feedback documents were available, it performed relatively poor when the relevant feedback documents were few. We improved IFME by combining PU learning with under-sampling to tune the performance. Using Mean Average Precision (MAP), our experimental results indicated that with under-sampling, the performance improved significantly even when the size of P was small. We believe the PU learning based IFME framework brings insights to develop more effective digital library systems. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",4,,2-s2.0-84882257258,Conference Proceeding,2013-08-23,10.1145/2467696.2467736,110,9781450320764,15525996,107-110,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,107,http://api.elsevier.com/content/abstract/scopus_id/84882257258,,84882257258,145752,p,IFME: Information filtering by multiple examples with under-sampling in a digital library environment
"Scientists continue to find challenges in the ever increasing amount of information that has been produced on a world wide scale, during the last decades. When writing a paper, an author searches for the most relevant citations that started or were the foundation of a particular topic, which would very likely explain the thinking or algorithms that are employed. The search is usually done using specific keywords submitted to literature search engines such as Google Scholar and CiteSeer. However, finding relevant citations is distinctive from producing articles that are only topically similar to an author's proposal. In this paper, we address the problem of citation recommendation using a singular value decomposition approach. The models are trained and evaluated on the Citeseer digital library. The results of our experiments show that the proposed approach achieves significant success when compared with collaborative filtering methods on the citation recommendation task. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",12,,2-s2.0-84882266614,Conference Proceeding,2013-08-23,10.1145/2467696.2467743,114,9781450320764,15525996,111-114,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,111,http://api.elsevier.com/content/abstract/scopus_id/84882266614,,84882266614,145752,p,Can't see the forest for the trees? A citation recommendation system
"Clifford Lynch describes the value of digital libraries as adding interpretive layers to collections of cultural heritage materials. However, standard forms of evaluation, which focus on the degree to which a system solves problems, are insufficient assessments of the expressive qualities that distinguish such interpretive content. This paper describes a form of comparative, structured appraisal that supplements the existing repertoire of assessment techniques. Comparative appraisal uses a situationally defined set of procedures to be followed by multiple assessors in examining a group of artifacts. While this approach aims for a goal of systematic comparison based on selected dimensions, it is grounded in the recognition that expressive qualities are not conventionally measurable and that absolute agreement between assessors is neither possible nor desirable. The conceptual basis for this comparative method is drawn from the literature of writing assessment. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",1,,2-s2.0-84882285070,Conference Proceeding,2013-08-23,10.1145/2467696.2467700,123,9781450320764,15525996,115-123,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,115,http://api.elsevier.com/content/abstract/scopus_id/84882285070,,84882285070,145752,p,Comparative appraisal: Systematic assessment of expressive qualities
"The digital library evaluation field has an evolving nature and it is characterized by a noteworthy proclivity to enfold various methodological orientations. Given the fact that the scientific literature in the specific domain is vast, researchers require tools that will exhibit either commonly acceptable practices, or areas for further investigation. In this paper, a data mining methodology is proposed to identify prominent patterns in the evaluation of digital libraries. Using Machine Learning techniques, all papers presented in the ECDL and JCDL conferences between the years 2001 and 2011 were categorized as relevant or non-relevant to the DL evaluation domain. Then, the relevant papers were semantically annotated according to the Digital Library Evaluation Ontology (DiLEO) vocabulary. The produced set of annotations was clustered to evaluation patterns for the most frequently used tools, methods and goals of the domain. Our findings highlight the expressive nature of DiLEO, place emphasis on semantic annotation as a necessary step in handling domaincentric corpora and underline the potential of the proposed methodology in the profiling of evaluation activities. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",5,,2-s2.0-84882283650,Conference Proceeding,2013-08-23,10.1145/2467696.2467713,134,9781450320764,15525996,125-134,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,125,http://api.elsevier.com/content/abstract/scopus_id/84882283650,,84882283650,145752,p,Charting the digital library evaluation domain with a semantically enhanced mining methodology
"In this paper, we studied interdisciplinary structures by looking into how online academic groups of different disciplines share members and followers. Results based on Mendeley online groups show clear interdisciplinary structures, indicating Mendeley online groups as a promising data source and a new perspective of disciplinarity and interdisciplinarity studies. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",6,,2-s2.0-84882259848,Conference Proceeding,2013-08-23,10.1145/2467696.2467738,138,9781450320764,15525996,135-138,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,135,http://api.elsevier.com/content/abstract/scopus_id/84882259848,,84882259848,145752,p,Mendeley group as a new source of interdisciplinarity study: How do disciplines interact on mendeley?
"Using bibliometric methods, this exploratory work shows evidence of transitions in the field of computer science since the emergence of HCI as a distinct sub-discipline. We mined the ACM Digital Library in order to expose relationships between sub-disciplines in computer science, focusing in particular on the transformational nature of the SIG Computer-Human Interaction (CHI) in relation to other SIGs. Our results suggest shifts in the field due to broader social, economic and political changes in computing research and are intended as a prolegomena to further investigations. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",2,,2-s2.0-84882264697,Conference Proceeding,2013-08-23,10.1145/2467696.2467732,142,9781450320764,15525996,139-142,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,139,http://api.elsevier.com/content/abstract/scopus_id/84882264697,,84882264697,145752,p,Following bibliometric footprints: The ACM digital library and the evolution of computer science
"We propose a new theory to quantify information in probability distributions and derive a new document representation model for text clustering. By extending Shannon entropy to accommodate a non-linear relation between information and uncertainty, the proposed Least Information theory (LIT) provides insight into how terms can be weighted based on their probability distributions in documents vs. in the collection. We derive two basic quantities in the document clustering context: 1) LI Binary (LIB) which quantifies information due to the observation of a term's (binary) occurrence in a document; and 2) LI Frequency (LIF) which measures information for the observation of a randomly picked term from the document. Both quantities are computed given term distributions in the document collection as prior knowledge and can be used separately or combined to represent documents for text clustering. Experiments on four benchmark text collections demonstrate strong performances of the proposed methods compared to classic TF*IDF. Particularly, the LIB*LIF weighting scheme, which combines LIB and LIF, consistently outperforms TF*IDF in terms of multiple evaluation metrics. The least information measure has a potentially broad range of applications beyond text clustering. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",4,,2-s2.0-84882274574,Conference Proceeding,2013-08-23,10.1145/2467696.2467698,152,9781450320764,15525996,143-152,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,143,http://api.elsevier.com/content/abstract/scopus_id/84882274574,,84882274574,145752,p,Information-theoretic term weighting schemes for document clustering
"To help generate relevant suggestions for researchers, recommendation systems have started to leverage the latent interests in the publication profiles of the researchers themselves. While using such a publication citation network has been shown to enhance performance, the network is often sparse, making recommendation difficult. To alleviate this sparsity, we identify ""potential citation papers"" through the use of collaborative filtering. Also, as different logical sections of a paper have different significance, as a secondary contribution, we investigate which sections of papers can be leveraged to represent papers effectively. On a scholarly paper recommendation dataset, we show that recommendation accuracy significantly outperforms state-of-the-art recommendation baselines as measured by nDCG and MRR, when we discover potential citation papers using imputed similarities via collaborative filtering and represent candidate papers using both the full text and assigning more weight to the conclusion sections. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",29,,2-s2.0-84882251598,Conference Proceeding,2013-08-23,10.1145/2467696.2467701,162,9781450320764,15525996,153-162,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,153,http://api.elsevier.com/content/abstract/scopus_id/84882251598,,84882251598,145752,p,Exploiting potential citation papers in scholarly paper recommendation
"Highly heterogeneous collections present difficulties to term weighting models that are informed by corpus-level frequencies. Collections which span multiple languages or large time periods do not provide realistic statistics on which words are interesting to a system. This paper presents a case where diverse corpora can frustrate term weighting and proposes a modification that weighs documents according to their class or cluster within the collection. In cases of diverse corpora, the proposed modification better represents the intuitions behind corpus-level document frequencies. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882241498,Conference Proceeding,2013-08-23,10.1145/2467696.2467740,166,9781450320764,15525996,163-166,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,163,http://api.elsevier.com/content/abstract/scopus_id/84882241498,,84882241498,145752,p,Addressing diverse corpora with cluster-based term weighting
"Scatter/Gather is a document browsing and information retrieval method based on document clustering. It is de- signed to facilitate user articulation of information needs through iterative clustering and interactive browsing. This paper reports on a study that investigated the effectiveness of Scatter/Gather browsing for information retrieval. We conducted a within-subject user study of 24 college students to investigate the utility of a Scatter/Gather system, to ex- Amine its strengths and weaknesses, and to receive feedback from users on the system. Results show that the clustering- based Scatter/Gather method was more difficult to use than the classic information retrieval systems in terms of user perception. However, clustering helped the subjects accomplish the tasks more efficiently. Scatter/Gather clustering was particularly useful in helping users finish tasks that they were less familiar with and allowed them to search with fewer words. Scatter/Gather tended to be more useful when it was more difficult for the user to do query specification for an in- formation need. Topic familiarity and specificity had significant influences on user perceived retrieval effectiveness. The influences appeared to be greater with the Scatter/Gather system compared to a classic search system. Topic familiarity also had significant influences on query formulation. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",1,,2-s2.0-84882255125,Conference Proceeding,2013-08-23,10.1145/2467696.2467726,170,9781450320764,15525996,167-170,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,167,http://api.elsevier.com/content/abstract/scopus_id/84882255125,,84882255125,145752,p,Interactive search result clustering: A study of user behavior and retrieval effectiveness
"This paper explores the role of audio as a means to access books in a digital library while being at the location referred to in the books. The books are sourced from the digital library and can either be accompanied by pre-recorded audio or synthesized using text-to-speech. The paper details the functional requirements, design and implementation of Tipple. The concept was extensively tested in three field studies. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",4,,2-s2.0-84882275041,Conference Proceeding,2013-08-23,10.1145/2467696.2467724,179,9781450320764,15525996,171-179,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,171,http://api.elsevier.com/content/abstract/scopus_id/84882275041,,84882275041,145752,p,Tipple: Location-triggered mobile access to a digital library for audio books
"Forensic document analysis has become an important aspect of investigation of many different kinds of crimes from money laundering to fraud and from cybercrime to smuggling. The current workflow for analysts includes powerful tools, such as Palantir and Analyst's Notebook, for moving from evidence to actionable intelligence and tools for finding documents among the millions of files on a hard disk, such as Forensic Toolkit (FTK). Analysts often leave the process of sorting through collections of seized documents to filter out noise from actual evidence to highly labor-intensive manual efforts. This paper presents the Redeye Analysis Workbench, a tool to help analysts move from manual sorting of a collection of documents to performing intelligent document triage over a digital library. We will discuss the tools and techniques we build upon in addition to an in-depth discussion of our tool and how it addresses two major use cases we observed analysts performing. Finally, we also include a new layout algorithm for radial graphs that is used to visualize clusters of documents in our system. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",2,,2-s2.0-84882245080,Conference Proceeding,2013-08-23,10.1145/2467696.2467716,190,9781450320764,15525996,181-190,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,181,http://api.elsevier.com/content/abstract/scopus_id/84882245080,,84882245080,145752,p,Redeye: A digital library for forensic document triage
"Digital collections of primary source materials have potential to change how citizen historians and scholars research and engage with local history. The problem at the heart of this study is how to evaluate local history coverage, particularly among large-scale, distributed collections and aggregations. As part of an effort to holistically evaluate one such national aggregation, the Institute of Museum and Library Services (IMLS) Digital Collections and Content (DCC), we conducted a national survey of reference service providers at academic and public libraries throughout the United States. In this paper, we report the results of this survey that appear relevant to local history and collection evaluation, and consider the implications for scalable evaluation of local history coverage in massive, aggregative digital libraries. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",2,,2-s2.0-84882248212,Conference Proceeding,2013-08-23,10.1145/2467696.2467742,194,9781450320764,15525996,191-194,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,191,http://api.elsevier.com/content/abstract/scopus_id/84882248212,,84882248212,145752,p,Local histories in global digital libraries: Identifying demand and evaluating coverage
"Because of the unique characteristics of music scores, searching bibliographical music collections using traditional library systems can be a challenge. In this paper, we present two specific search functionalities added to the Swiss RISM data- base and describe how they improve the user experience. The first is a search functionality for instrument and vocal part distribution that leverages coded information available in the MarcXML records of the database. It enables scores for precise ensemble distribution to be retrieved. The second is a search functionality of music notation excerpts transcribed from the beginning of the pieces, known as music incipits. The incipit search is achieved using a well-known mu- sic information retrieval (MIR) tool, Theme finder. A novelty of our implementation is that it can operate at three different levels (pitch, duration and metric), singularly or combined, and that it is performed through a specifically- developed intuitive graphical interface for note input and parameter selection. The two additions illustrate why it is important to take into consideration the particularities of music scores when designing a search system and how MIR tools can be beneficially integrated into existing heterogneous bibliographic score collections. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882270106,Conference Proceeding,2013-08-23,10.1145/2467696.2467728,198,9781450320764,15525996,195-198,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,195,http://api.elsevier.com/content/abstract/scopus_id/84882270106,,84882270106,145752,p,Instrument distribution and music notation search for enhancing bibliographic music score retrieval
"This paper presents an approach for predicting the gender orientation of any given first name over time based on a set of search engine queries with the name prefixed by masculine and feminine markers (e.g., ""Uncle Taylor""). We hypothesize that these markers can capture the great majority of variability in gender orientation, including temporal changes. To test this hypothesis, we train a logistic regression model, with timevarying marker weights, using marker counts from Bing.com to predict male/female counts for 85,406 names in US Social Security Administration (SSA) data during 1880-2008. The model misclassifies 2.25% of the people in the SSA dataset (slightly worse than the 1.74% pure error rate) and provides accurate predictions for names beyond the SSA. The misclassification rate is higher in recent years (due to increasing name diversity), for general English words (e.g., Will), for names from certain countries (e.g., China), and for rare names. However, the model tends to err on the side of caution by predicting neutral/unknown rather than false positive. As hypothesized, the markers also capture temporal patterns of androgyny. For example, Daughter is a stronger female predictor for recent years while Grandfather is a stronger male predictor around the turn of the 20 th century. The model has been implemented as a web-tool called Genni (available via http://abel.lis.illinois.edu/) that displays the predicted proportion of females vs. males over time for any given name. This should be a valuable resource for those who utilize names in order to discern gender on a large scale, e.g., to study the roles of gender and diversity in scholarly work based on digital libraries and bibliographic databases where the authors' names are listed. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",2,,2-s2.0-84882261244,Conference Proceeding,2013-08-23,10.1145/2467696.2467720,208,9781450320764,15525996,199-208,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,199,http://api.elsevier.com/content/abstract/scopus_id/84882261244,,84882261244,145752,p,A search engine approach to estimating temporal changes in gender orientation of first names
"This paper presents a new name disambiguation method that exploits user feedback on ambiguous references across iterations. An unsupervised step is used to define pure training samples, and a hybrid supervised step is employed to learn a classification model for assigning references to authors. Our classification scheme combines the Optimum- Path Forest (OPF) classifier with complex reference similarity functions generated by a Genetic Programming framework. Experiments demonstrate that the proposed method yields better results than state-of-the-art disambiguation methods on two traditional datasets. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",2,,2-s2.0-84882252992,Conference Proceeding,2013-08-23,10.1145/2467696.2467709,218,9781450320764,15525996,209-218,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,209,http://api.elsevier.com/content/abstract/scopus_id/84882252992,,84882252992,145752,p,A relevance feedback approach for the author name disambiguation problem
"We introduce Enlil, an information extraction system that discovers the institutional affiliations of authors in scholarly papers. Enlil consists of two steps: one that first identifies authors and affiliations using a conditional random field; and a second support vector machine that connects authors to their affiliations. We benchmark Enlil in three separate experiments drawn from three different sources: The ACL Anthology, the ACM Digital Library, and a set of cross-disciplinary scientific journal articles acquired by querying Google Scholar. Against a state-of-the-art production baseline, Enlil reports a statistically significant improvement in F1 of nearly 10% (p « 0.01). In the case of multidisciplinary articles from Google Scholar, Enlil is benchmarked over both clean input (F1 > 90%) and automatically-acquired input (F1 > 80%). We have deployed Enlil in a case study involving Asian genomics research publication patterns to understand how government sponsored collaborative links evolve. Enlil has enabled our team to construct and validate new metrics to quantify the facilitation of research as opposed to direct publication. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",10,,2-s2.0-84882239139,Conference Proceeding,2013-08-23,10.1145/2467696.2467703,228,9781450320764,15525996,219-228,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,219,http://api.elsevier.com/content/abstract/scopus_id/84882239139,,84882239139,145752,p,Extracting and matching authors and affiliations in scholarly documents
"Video games and interactive media are increasingly becoming important part of our culture and everyday life, and subsequently, of archival and digital library collections. However, existing organizational systems often use vague or inconsistent terms to describe video games or attempt to use schemas designed for textual bibliographic resources. Our research aims to create a standardized metadata schema and encoding scheme that provides an intelligent and comprehensive way to represent video games. We conducted interviews with 24 gamers, focusing on their video game-related information needs and seeking behaviors. We also performed a domain analysis of current organizational systems used in catalog records and popular game websites, evaluating metadata elements used to describe games. With these results in mind, we created a list of elements which form a metadata schema for describing video games, with both a core set of 16 elements and an extended set of 46 elements providing more flexibility in expressing the nature of a game. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",10,,2-s2.0-84882252147,Conference Proceeding,2013-08-23,10.1145/2467696.2467702,238,9781450320764,15525996,229-238,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,229,http://api.elsevier.com/content/abstract/scopus_id/84882252147,,84882252147,145752,p,User-centered approach in creating a metadata schema for video games and interactive media
"The increase of the complexity and advancement in ecological and environmental sciences encourages scientists across the world to collect data from multiple places, times, and thematic scales to verify their hypotheses. Accumulated over time, such data not only increases in amount, but also in the diversity of the data sources spread around the world. This poses a huge challenge for scientists who have to manually search for information. To alleviate such problems, ONEMercury has recently been implemented as part of the DataONE project to serve as a portal for accessing environmental and observational data across the globe. ONEMercury harvests metadata from the data hosted by multiple repositories and makes it searchable. However, harvested metadata records sometimes are poorly annotated or lacking meaningful keywords, which could affect effective retrieval. Here, we develop algorithms for automatic annotation of metadata. We transform the problem into a tag recommendation problem with a controlled tag library, and propose two variants of an algorithm for recommending tags. Our experiments on four datasets of environmental science metadata records not only show great promises on the performance of our method, but also shed light on the different natures of the datasets. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",26,,2-s2.0-84882251627,Conference Proceeding,2013-08-23,10.1145/2467696.2467706,248,9781450320764,15525996,239-248,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,239,http://api.elsevier.com/content/abstract/scopus_id/84882251627,,84882251627,145752,p,Automatic tag recommendation for metadata annotation using probabilistic topic modeling
"Digital libraries are supported by good quality metadata, and thus by the use of good quality metadata tools. The design of metadata tools can be supported by following user-centered design processes. In this paper we discuss the application and evaluation of several cognitively-based rules, derived from the work of Donald Norman, to the design of a metadata tool for administering Dublin Core metadata. One overall finding was that while the use of the rules supported users in their immediate interactions with the tool interface, they provided less support for the more cognitively intensive tasks associated with developing a wider conceptual understanding of the purpose of metadata. The findings have implications for the wider development of tools to support metadata work in digital libraries and allied contexts. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882244038,Conference Proceeding,2013-08-23,10.1145/2467696.2467739,252,9781450320764,15525996,249-252,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,249,http://api.elsevier.com/content/abstract/scopus_id/84882244038,,84882244038,145752,p,The user-centered development and testing of a Dublin core metadata tool
"Manga - A Japanese term meaning graphic novel or comic - has been globally accepted. In Japan, there are a huge number of monographs and magazines of manga published. The work entity defined in Functional Requirements of Bibliographic Records (FRBR) is useful to identify and find manga. This paper examines how to identify manga works in a set of bibliographic records maintained by Kyoto International Manga Museum. It is known that authority data is useful to identify works from the bibliographic records. However, the authority data of manga is not rich, because manga has been recognized as a sub-culture resource and is generally not included in library collections. In this study, we used DBpedia, which is a large Linked Open Data (LOD) resource created from Wikipedia, to identify FRBR manga entities in bibliographic records. The results of this study show that using LOD resources is a reasonable way to identify works from bibliographic records. It also shows the accuracy and efficiency of work identification depending on the quality of the LOD resources used. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",3,,2-s2.0-84882281857,Conference Proceeding,2013-08-23,10.1145/2467696.2467731,256,9781450320764,15525996,253-256,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,253,http://api.elsevier.com/content/abstract/scopus_id/84882281857,,84882281857,145752,p,Identification of works of manga using LOD resources - An experimental FRBRization of bibliographic data of comic books
"The web is trapped in the \perpetual now"", and when users traverse from page to page, they are seeing the state of the web resource (i.e., the page) as it exists at the time of the click and not necessarily at the time when the link was made. Thus, a temporal discrepancy can arise between the resource at the time the page author created a link to it and the time when a reader follows the link. This is especially important in the context of social media: The ease of sharing links in a tweet or Facebook post allows many people to author web content, but the space constraints combined with poor awareness by authors often prevents sufficient context from being generated to determine the intent of the post. If the links are clicked as soon as they are shared, the temporal distance between sharing and clicking is so small that there is little to no difference in content. However, not all clicks occur immediately, and a delay of days or even hours can result in reading something other than what the author intended. We introduce the concept of a user's temporal intention upon publishing a link in social media. We investigate the features that could be extracted from the post, the linked resource, and the patterns of social dissemination to model this user intention. Finally, we analyze the historical integrity of the shared resources in social media across time. In other words, how much is the knowledge of the author's intent beneficial in maintaining the consistency of the story being told through social posts and in enriching the archived content coverage and depth of vulnerable resources?. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",3,,2-s2.0-84882262200,Conference Proceeding,2013-08-23,10.1145/2467696.2467721,266,9781450320764,15525996,257-266,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,257,http://api.elsevier.com/content/abstract/scopus_id/84882262200,,84882262200,145752,p,Reading the correct history? Modeling temporal intention in resource sharing
"As defined by the Memento Framework, TimeMaps are machine- readable lists of time-specific copies - called ""mementos"" - of an archived original resource. In theory, as an archive acquires additional mementos over time, a TimeMap should be monotonically increasing. However, there are reasons why the number of mementos in a TimeMap would decrease, for example: Archival redaction of some or all of the mementos, archival restructuring, and transient errors on the part of one or more archives. We study TimeMaps for 4,000 original resources over a three month period, note their change patterns, and develop a caching algorithm for TimeMaps suitable for a reverse proxy in front of a Memento aggregator. We show that TimeMap cardinality is constant or monotonically increasing for 80.2% of all TimeMap downloads observed in the observation period. The goal of the caching algorithm is to exploit the ideally monotonically increasing nature of TimeMaps and not cache responses with fewer mementos than the already cached TimeMap. This new caching algorithm uses conditional cache replacement and a Time To Live (TTL) value to ensure the user has access to the most complete TimeMap available. Based on our empirical data, a TTL of 15 days will minimize the number of mementos missed by users, and minimize the load on archives contributing to TimeMaps. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",4,,2-s2.0-84882249068,Conference Proceeding,2013-08-23,10.1145/2467696.2467717,276,9781450320764,15525996,267-276,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,267,http://api.elsevier.com/content/abstract/scopus_id/84882249068,,84882249068,145752,p,An evaluation of caching policies for memento timemaps
"The documents used in the ResourceSync synchronization framework are based on the widely adopted document for- mat defined by the Sitemap protocol. In order to address requirements of the framework, extensions to the Sitemap format were necessary. This short paper describes the concerns we had about introducing such extensions, the tests we did to evaluate their validity, and aspects of the framework to address them. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",1,,2-s2.0-84882249549,Conference Proceeding,2013-08-23,10.1145/2467696.2467733,280,9781450320764,15525996,277-280,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,277,http://api.elsevier.com/content/abstract/scopus_id/84882249549,,84882249549,145752,p,Extending sitemaps for resourcesync
"We present a multimodal system for aligning scholarly docu- ments to corresponding presentations in a fine-grained manner (i.e., per presentation slide and per paper section). Our method improves upon a state-of-the-art baseline that employs only textual similarity. Based on an analysis of base- line errors, we propose a three-pronged alignment system that combines textual, image, and ordering information to establish alignment. Our results show a statistically significant improvement of 25%, confirming the importance of visual content in improving alignment accuracy. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",3,,2-s2.0-84882255838,Conference Proceeding,2013-08-23,10.1145/2467696.2467741,284,9781450320764,15525996,281-284,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,281,http://api.elsevier.com/content/abstract/scopus_id/84882255838,,84882255838,145752,p,Multimodal alignment of scholarly documents and their presentations
"Large amounts of multivariate data are collected in different areas of scientific research and industrial production. These data are collected, archived and made publicly available by research data repositories. In addition to meta-data based access, content-based approaches are highly desirable to effectively retrieve, discover and analyze data sets of interest. Several such methods, that allow users to search for particular curve progressions, have been proposed. However, a major challenge when providing content-based access interactive feedback during query formulation has not received much attention yet. This is important because it can substantially improve the user's search effectiveness. In this paper, we present a novel interactive feedback approach for content-based access to multivariate research data. Thereby, we enable query modalities that were not available for multivariate data before. We provide instant search results and highlight query patterns in the result set- Real-time search suggestions give a.11 overview of important patterns to look for in the data repository. For this purpose, we develop a bag-of-words index for multivariate data as the back-end of our approach. We apply our method to a large repository of multivariate data from the climate research domain. We describe a use-case for the discovery of interesting patterns in maritime climate research using our new visual-interactive query tools. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",2,,2-s2.0-84882241202,Conference Proceeding,2013-08-23,10.1145/2467696.2467705,294,9781450320764,15525996,285-294,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,285,http://api.elsevier.com/content/abstract/scopus_id/84882241202,,84882241202,145752,p,Visual-interactive querying for multivariate research data repositories using bag-of-words
"Field archaeology only recently developed centralized systems for data curation, management, and reuse. Data documentation guidelines, standards, and ontologies have yet to see wide adoption in this discipline. Moreover, repository practices have focused on supporting data collection, deposit, discovery, and access more than data reuse. In this paper we examine the needs of archaeological data reusers, particularly the context they need to understand, verify, and trust data others collect during field studies. We then apply our findings to the existing work on standards development. We find that archaeologists place the most importance on data collection procedures, but the reputation and scholarly affiliation of the archaeologists who conducted the original field studies, the wording and structure of the documentation created during field work, and the repository where the data are housed also inform reuse. While guidelines, standards, and ontologies address some aspects of the context data reusers need, they provide less guidance on others, especially those related to research design. We argue repositories need to address these missing dimensions of context to better support data reuse in archaeology. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",19,,2-s2.0-84882251539,Conference Proceeding,2013-08-23,10.1145/2467696.2467712,304,9781450320764,15525996,295-304,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,295,http://api.elsevier.com/content/abstract/scopus_id/84882251539,,84882251539,145752,p,The challenges of digging data: A study of context in archaeological data reuse
"Personal digital photo libraries embody a large amount of information useful for research into photo organization, photo layout, and development of novel photo browser features. Even when anonymity can be ensured, amassing a sizable dataset from these libraries is still difficult due to the visibility and cost that would be required from such a study. We explore using the Mac App Store to reach more users to collect data from such personal digital photo libraries. More specifically, we compare and discuss how it differs from common data collection methods, e.g. Amazon Mechanical Turk, in terms of time, cost, quantity, and design of the data collection application. We have collected a large, openly available photo feature dataset using this manner. We illustrate the types of data that can be collected. In 60 days, we collected data from 20,778 photo sets (473,772 photos). Our study with the Mac App Store suggests that popular application distribution channels is a viable means to acquire massive data collections for researchers. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882254199,Conference Proceeding,2013-08-23,10.1145/2467696.2467730,308,9781450320764,15525996,305-308,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,305,http://api.elsevier.com/content/abstract/scopus_id/84882254199,,84882254199,145752,p,Constructing an anonymous dataset from the personal digital photo libraries of Mac app store users
"Digital repositories are grappling with an influx of scientific data brought about by the well publicized ""data deluge"" in science, business, and society. One particularly perplexing problem is the long-term archival and reuse of complex data sets. This paper presents an integrated approach to data discovery over heterogeneous data resources in social-ecological systems research. Social-ecological systems data is complex because the research draws from both social and natural sciences. Using a sample set of data resources from the domain, we explore an approach to discovery and representation of this data. Specifically, we develop an ontology-based process of organization and visualization from a data-centric perspective. We define data resources broadly and identify six key categories of resources that include data collected from site visits to shared ecological resources, the structure of research instruments, domain concepts, research designs, publications, theories and models. We identify the underlying relationships and construct an ontology that captures these relationships using semantic web languages. The ontology and a NoSQL data store at the back end store the data resource instances. These are integrated into a portal architecture we refer to as the Integrated Visualization of Social-Ecological Resources (IViSER) that allows users to both browse the relationships captured in the ontology and easily visualize the granular details of data resources. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",1,,2-s2.0-84882245538,Conference Proceeding,2013-08-23,10.1145/2467696.2467737,312,9781450320764,15525996,309-312,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,309,http://api.elsevier.com/content/abstract/scopus_id/84882245538,,84882245538,145752,p,Modeling heterogeneous data resources for social-ecological research: A data-centric perspective
"Mainstream approaches in the design of virtual libraries basically exploit the same ambient space as their physical twins. Our paper is an attempt to rather capture automatically the actual space on which the books live, and learn the virtual library as a non-linear book manifold. This tackles tantalizing questions, chief among which whether modeling should be static and book focused (e.g. using bag of words encoding) or dynamic and user focused (e.g. relying on what we define as a bag of readers encoding). Experiments on a real-world digital library display that the latter encoding is a serious challenger to the former. Our results also show that the geometric layers of the manifold learned bring sizeable advantages for retrieval and visualization purposes. For example, the topological layer of the manifold allows to craft Manifold association rules; experiments display that they bring dramatic improvements over conventional association rules built from the discrete topology of book sets. Improvements embrace each of the following major standpoints on association rule mining: computational, support, confidence, lift, and leverage standpoint. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",3,,2-s2.0-84882263164,Conference Proceeding,2013-08-23,10.1145/2467696.2467697,322,9781450320764,15525996,313-322,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,313,http://api.elsevier.com/content/abstract/scopus_id/84882263164,,84882263164,145752,p,Non-linear book manifolds: Learning from associations the dynamic geometry of digital libraries
"Chinese calligraphy is the art of handwriting and is an important part of Chinese traditional culture. But due to the complexity of shape and styles of calligraphic characters, it is difficult for common people to recognize them. So it would be great if a tool is provided to help users to recognize the unknown calligraphic characters. But the well-known OCR (Optical Character Recognition) technology can hardly help people to recognize the unknown characters because of their deformation and complexity. Numerous collections of historical Chinese calligraphic works are digitized and stored in CADAL (China Academic Digital Associate Library) calligraphic system [1], and a huge database CCD (Calli-graphic Character Dictionary) is built, which contains character images labeled with semantic meaning. In this paper, a LSH-based large scale Chinese calligraphic character recognition method is proposed basing on CCD. In our method, GIST descriptor is used to represent the global features of the calligraphic character images, LSH (Locality-sensitive hashing) is used to search CCD to find the similar character images to the recognized calligraphic character image. The recognition is based on the se-mantic probability which is computed according to the ranks of retrieved images and their distances to the recognized image in the Gist feature space. Our experiments show that our method is effective and efficient for recognizing Chinese calligraphic character image. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",5,,2-s2.0-84882244788,Conference Proceeding,2013-08-23,10.1145/2467696.2467704,329,9781450320764,15525996,323-329,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,323,http://api.elsevier.com/content/abstract/scopus_id/84882244788,,84882244788,145752,p,LSH-based large scale Chinese calligraphic character recognition
"Geometric distortions are among the major challenging issues in the analysis of historical document images. Such distortions appear as arbitrary warping, folds and page curl, and have detrimental effects upon recognition (OCR) and readability. While there are many dewarping techniques discussed in the literature, there exists no standard method by which their performance can be evaluated against each other. In particular, there is not any satisfactory method capable of comparing the results of existing dewarping techniques on arbitrary wrapped documents. The existing methods either rely on the visual comparison of the output and input images or depend on the recognition rate of an OCR system. In the case of historical documents, OCR either is not available or does not generate an acceptable result. In this paper, an objective and automatic evaluation methodology for document image dewarping technique is presented. In the first step, all the baselines in the original distorted image as well as dewarped image are modelled precisely and automatically. Then based on the mathematical function of each line, a comprehensive metric which calculates the performance of a dewarping technique is introduced. The presented method does not require user interference in any stage of evaluation and therefore is quite objective. Experimental results, applied to two state-of-the art dewarping methods and an industry-standard commercial system, demonstrate the effectiveness of the proposed dewarping evaluation method. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882256834,Conference Proceeding,2013-08-23,10.1145/2467696.2467744,334,9781450320764,15525996,331-334,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,331,http://api.elsevier.com/content/abstract/scopus_id/84882256834,,84882256834,145752,p,Automatic performance evaluation of dewarping methods in large scale digitization of historical documents
"Early maps are a valuable resource for historical research, this is why digital libraries for early maps become a necessary tool for research support in the age of information. In this article we introduce the Referencing and Annotation Tool (RAT), designed to extract information about all places displayed in a map and link them to a place on a modern map. RAT automatically recognizes place markers in an early map according to a template specified by the user and estimates the position of the annotated place in the modern map, thus making georeferencing easier. After a brief summary on related projects, we describe the functionality of the system. We discuss the most important implementation details and factors influencing recognition accuracy and performance. The advantages of our semiautomatic approach are high accuracy and a significant decrease of the user's cognitive load. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",3,,2-s2.0-84882284378,Conference Proceeding,2013-08-23,10.1145/2467696.2467734,338,9781450320764,15525996,335-338,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,335,http://api.elsevier.com/content/abstract/scopus_id/84882284378,,84882284378,145752,p,Semiautomatic recognition and georeferencing of places in early maps
"Although user access patterns on the live web are wellunderstood, there has been no corresponding study of how users, both humans and robots, access web archives. Based on samples from the Internet Archive's public Wayback Machine, we propose a set of basic usage patterns: Dip (a single access), Slide (the same page at different archive times), Dive (different pages at approximately the same archive time), and Skim (lists of what pages are archived, i.e., Time- Maps). Robots are limited almost exclusively to Dips and Skims, but human accesses are more varied between all four types. Robots outnumber humans 10:1 in terms of sessions, 5:4 in terms of raw HTTP accesses, and 4:1 in terms of megabytes transferred. Robots almost always access Time- Maps (95% of accesses), but humans predominately access the archived web pages themselves (82% of accesses). In terms of unique archived web pages, there is no overall preference for a particular time, but the recent past (within the last year) shows significant repeat accesses. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",10,,2-s2.0-84882262925,Conference Proceeding,2013-08-23,10.1145/2467696.2467722,348,9781450320764,15525996,339-348,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,339,http://api.elsevier.com/content/abstract/scopus_id/84882262925,,84882262925,145752,p,Access patterns for robots and humans in web archives
"Digital preservation is an active area of research, and recent years have brought forward an increasing number of characterisation tools for the object-level analysis of digital content. However, there is a profound lack of objective, standardised and comparable metrics and benchmark collections to enable experimentation and validation of these tools. While fields such as Information Retrieval have for decades been able to rely on benchmark collections annotated with ground truth to enable systematic improvement of algorithms and systems along objective metrics, the digital preservation field is yet unable to provide the necessary ground truth for such benchmarks. Objective indicators, however, are the key enabler for quantitative experimentation and innovation. This paper presents a systematic model-driven benchmark generation framework that aims to provide realistic approximations of real-world digital information collections with fully known ground truth that enables systematic quantitative experimentation, measurement and improvement against objective indicators. We describe the key motivation and idea behind the framework, outline the technological building blocks, and discuss results of the generation of pagebased and hierarchical documents from a ground truth model. Based on a discussion of the benefits and challenges of the approach, we outline future work. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",6,,2-s2.0-84882248849,Conference Proceeding,2013-08-23,10.1145/2467696.2467719,358,9781450320764,15525996,349-358,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,349,http://api.elsevier.com/content/abstract/scopus_id/84882248849,,84882248849,145752,p,Free benchmark corpora for preservation experiments: Using model-driven engineering to generate data sets
"The use of map-based browser services is of great relevance in numerous digital libraries. The implementation of such services, however, demands the use of geocoded data collections. This paper investigates the use of image content local representations in geocoding tasks. Performed experiments demonstrate that some of the evaluated descriptors yield effective results in the task of geocoding VT building photos. This study is the first step to geocode multimedia material. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882268215,Conference Proceeding,2013-08-23,10.1145/2467696.2467727,366,9781450320764,15525996,363-366,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,363,http://api.elsevier.com/content/abstract/scopus_id/84882268215,,84882268215,145752,p,Domain-specific image geocoding: A case study on virginia tech building photos
"Algorithms are ubiquitous in the computer science literature. A search engine for algorithms has been tested as part of the CiteseerX suite; however, it only retrieves algorithms whose metadata is textually matched with the search query. Such a limitation occurs because a traditional search engine does not have the ability to understand what algorithms are and how they work. Here, we present an initial effort in understanding the semantics of algorithms. Specifically, we identify how an existing algorithm can be used in scholarly works and propose a classification scheme for algorithm function. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",5,,2-s2.0-84882283563,Conference Proceeding,2013-08-23,10.1145/2467696.2467754,368,9781450320764,15525996,367-368,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,367,http://api.elsevier.com/content/abstract/scopus_id/84882283563,,84882283563,145752,p,A classification scheme for algorithm citation function in scholarly works
"Academic papers contain multiple figures representing important findings and experimental results; we present a search engine specifically focused on figures in academic documents. This search engine allows users to search on figures in approximately 150,000 chemistry journal articles though the method is easily extendable to other domains. Our system indexes figure caption and mentions extracted from the PDF in documents using a custom built extractor. Recall and precision performance of extracted figures is in the 80 to 90 % range. We give the frame work for the extraction algorithm, architecture and ranking function. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",12,,2-s2.0-84882283062,Conference Proceeding,2013-08-23,10.1145/2467696.2467757,370,9781450320764,15525996,369-370,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,369,http://api.elsevier.com/content/abstract/scopus_id/84882283062,,84882283062,145752,p,A figure search engine architecture for a chemistry digital library
"The Memento framework allows web browsers to request and view archived web pages in a transparent fashion. However, Memento is still in the early stages of adoption, and browserplugins are often required to enable Memento support. We report on a new iOS app called the Memento Browser, a web browser that supports Memento and gives iPhone and iPad users transparent access to the world's largest web archives. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",2,,2-s2.0-84882252657,Conference Proceeding,2013-08-23,10.1145/2467696.2467764,372,9781450320764,15525996,371-372,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,371,http://api.elsevier.com/content/abstract/scopus_id/84882252657,,84882252657,145752,p,A memento web browser for iOS
"Since 2000, the National Science Foundation's NSDL program has made many direct contributions to digital library research and STEM education. Originally called the National STEM Digital Library (and now National STEM Distributed Learning), the program catalyzed significant technology developments and served to advance state-of-the-art teaching and learning practices during a period of dramatic technological change. This poster describes the results of a three-day writing workshop, convened in April 2012, which generated a retrospective report and a series of interviews on the NSDL library-building process. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882286141,Conference Proceeding,2013-08-23,10.1145/2467696.2467759,374,9781450320764,15525996,373-374,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,373,http://api.elsevier.com/content/abstract/scopus_id/84882286141,,84882286141,145752,p,A retrospective review on a decade of building a national science digital library to transform STEM education
"This poster describes our experiences as four CLIR/DLF postdoctoral fellows in developing data services at our respective universities. We report on our particular activities and achievements, which we synthesize into a common framework that can guide the development of data services at other academic institutions. The analysis of our experiences suggests the necessity of stronger cooperation of units within universities as well as increased and more diverse collaborations among universities. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882287778,Conference Proceeding,2013-08-23,10.1145/2467696.2467763,376,9781450320764,15525996,375-376,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,375,http://api.elsevier.com/content/abstract/scopus_id/84882287778,,84882287778,145752,p,A roadmap for data services
"We present ArcLink, a proof-of-concept system that complements open source Wayback Machine installations by optimizing the construction, storage, and access to the temporal web graph. We divide the web graph construction into four stages (filtering, extraction, storage, and access) and explore optimization for each stage. ArcLink extends the current web archive interfaces to return content and structural metadata for each URI. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",1,,2-s2.0-84882265595,Conference Proceeding,2013-08-23,10.1145/2467696.2467751,378,9781450320764,15525996,377-378,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,377,http://api.elsevier.com/content/abstract/scopus_id/84882265595,,84882265595,145752,p,ArcLink: Optimization techniques to build and retrieve the temporal web graph
"As the idea of a digital library resource evolves from the notion of a single resource potentially ""consisting of multiple datastreams"" [6] to complex resources composed of possibly many other distinct resources, our traditional notions of digital library usage and ""check-out"" should also evolve. Consider for example, a school curriculum composed of instructional materials and assessments. The individual resources in the complex resource may exist on their own, outside of the context of the compound resource, as first-class objects. Each resource may also be used in multiple compound resources-for example, an instructional material may appear in any number of curricula. If an end user would like to check out a curriculum. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882252818,Conference Proceeding,2013-08-23,10.1145/2467696.2467775,380,9781450320764,15525996,379-380,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,379,http://api.elsevier.com/content/abstract/scopus_id/84882252818,,84882252818,145752,p,Checking out: Customizing and downloading complex and compound digital library resources
"We propose CSSeer1, a free and publicly available keyphrase based recommendation system for expert discovery based on the CiteSeerX digital library and Wikipedia as an auxiliary resource. CSSeer generates keyphrases from the title and the abstract of each document in CiteSeerX. These keyphrases are then utilized to infer the authors' expertise. We compared CSSeer with the other two state-of-the-art expert recommenders and found that the three systems have moderately divergent recommendations on 20 benchmark queries. Thus, we recommend users to browse through several different recommenders to obtain a more complete expert list. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",8,,2-s2.0-84882271960,Conference Proceeding,2013-08-23,10.1145/2467696.2467750,382,9781450320764,15525996,381-382,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,381,http://api.elsevier.com/content/abstract/scopus_id/84882271960,,84882271960,145752,p,CSSeer: An expert recommendation system based on CiteseerX
"This research explores the attitudes of Environmental Studies faculty towards sharing research data. The findings are drawn from a broader unpublished study in progress on information behavior of Environmental Studies faculty in e-science and scholarly communications. The author conducted fourteen semistructured interviews with tenure-track and tenured faculty in various environmental studies and earth science disciplines at two large state universities. Early findings and areas for further analysis are described. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",2,,2-s2.0-84882248319,Conference Proceeding,2013-08-23,10.1145/2467696.2467773,384,9781450320764,15525996,383-384,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,383,http://api.elsevier.com/content/abstract/scopus_id/84882248319,,84882248319,145752,p,Environmental studies faculty attitudes towards sharing of research data
"This paper evaluates the performance of tools for the extraction of metadata from scientific articles. Accurate metadata extraction is an important task for automating the management of digital libraries. This comparative study is a guide for developers looking to integrate the most suitable and effective metadata extraction tool into their software. We shed light on the strengths and weaknesses of seven tools in common use. In our evaluation using papers from the arXiv collection, GROBID delivered the best results, followed by Mendeley Desktop. SciPlore Xtract, PDFMeat, and SVMHeaderParse also delivered good results depending on the metadata type to be extracted. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",21,,2-s2.0-84882270532,Conference Proceeding,2013-08-23,10.1145/2467696.2467753,386,9781450320764,15525996,385-386,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,385,http://api.elsevier.com/content/abstract/scopus_id/84882270532,,84882270532,145752,p,Evaluation of header metadata extraction approaches and tools for scientific PDF documents
"This paper presents a usability evaluation of the Indianapolis Museum of Art website - As a typical ait museum website supporting both tag-based search and user tagging of artwork - in an effort to explore how users access artwork while interacting with the museum online search and retrieval system. The usability study examined the extent of usage of Steve Tagger capabilities (annotation and use of tags in the process of searching/accessing artwork resources) deployed on the website. The usability test results showed that 55% of the users were able to successfully locate information 011 the website using both traditional searching techniques and folksonomies. However, only 34% of the users were able to successfully locate artwork using tags only. On the other hand, 95% of the participants were able to annotate an object by adding a term or tag to describe the artwork. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882273456,Conference Proceeding,2013-08-23,10.1145/2467696.2467760,388,9781450320764,15525996,387-388,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,387,http://api.elsevier.com/content/abstract/scopus_id/84882273456,,84882273456,145752,p,Exploring the usability of folksonomies in the online art museum community
"It has been well documented that cultural heritage institutions can enhance their metadata by sharing content through popular web services such as Flickr. Through the Flickr Feasibility Study, the IMLS Digital Collections and Content project examined how an aggregation service can facilitate participation of cultural heritage institutions in popular web services. This poster presents a proposed feedback framework through which an aggregation service can facilitate and increase the impact of Web user interactions with shared cultural heritage collections through direct metadata enhancement and user analysis. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882246990,Conference Proceeding,2013-08-23,10.1145/2467696.2467766,390,9781450320764,15525996,389-390,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,389,http://api.elsevier.com/content/abstract/scopus_id/84882246990,,84882246990,145752,p,Flickr feedback framework: A service model for leveraging user interactions
"Many digital library design, development, and deployment processes are not based on systematic generation activities. The utilization of generation processes enables the precise definition of digital libraries, identification of existing soft- ware components, co-generation of multiple digital libraries, and evaluation of a digital library's coverage and completeness. The foundation of a digital library generation process is in the formal framework in which it is described. Two no- table formal frameworks have previously been proposed for describing digital libraries and their content, architecture, functionality, and related societies. These two frameworks are merged in this effort to provide the foundation for a generation framework in support of an emerging class of scientific digital libraries. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882252076,Conference Proceeding,2013-08-23,10.1145/2467696.2467774,392,9781450320764,15525996,391-392,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,391,http://api.elsevier.com/content/abstract/scopus_id/84882252076,,84882252076,145752,p,Formal foundations for systematic digital library generation
"The idea behind AuthorRank is that a content created by more popular authors should rank higher than the content created by less popular authors. This paper brings this idea into scientific publications analysis to test whether the optimized topical AuthorRank can replace or enhance topical PageRank for publication ranking. First, the PageRank with Priors (PRP) algorithm was employed to rank topic-based publications and authors. Second, the first author's reputation was used for generating an AuthorRank score. Additionally, linear combination method of topical AuthorRank and PageRank were compared with several baselines. Finally, as shown in our evaluation results, the performance of topical AuthorRank combined with topic-based PageRank is better than other baselines for publication ranking. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",1,,2-s2.0-84882280948,Conference Proceeding,2013-08-23,10.1145/2467696.2467748,394,9781450320764,15525996,393-394,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,393,http://api.elsevier.com/content/abstract/scopus_id/84882280948,,84882280948,145752,p,Full-text and topic based authorrank and enhanced publication ranking
"Academic libraries are increasingly looking to provide services that allow their users to work with digital collections in innovative ways, for example, to analyze large volumes of digitized collections. The HathiTrust Research Center (HTRC) is a large collaborative that provides an innovative research infrastructure for dealing with massive amounts of digital texts. In this poster, we report on the technical progress of the HTRC as well as on the efforts to build a user community around our cyberinfrastructure. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",3,,2-s2.0-84882244012,Conference Proceeding,2013-08-23,10.1145/2467696.2467767,396,9781450320764,15525996,395-396,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,395,http://api.elsevier.com/content/abstract/scopus_id/84882244012,,84882244012,145752,p,HathiTrust research center: Computational access for digital humanities and beyond
"This study investigates the relationships between users' search tactic selections and search outputs while conducting exploratory searches in digital libraries. Frequencies of different types of search tactics applied in an exploratory search task were counted. Based on correlation analysis and multiple regression analysis, we identified types of search tactics that are associated with aspectual recall. Preliminary results indicate that browsing and evaluating item tactics affect aspectual recall in exploratory search tasks. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",1,,2-s2.0-84882240166,Conference Proceeding,2013-08-23,10.1145/2467696.2467761,398,9781450320764,15525996,397-398,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,397,http://api.elsevier.com/content/abstract/scopus_id/84882240166,,84882240166,145752,p,How do users' search tactic selections influence search outputs in exploratory search tasks?
"This poster presents multiple information visualization techniques for scientific visualization of the nuclear isotope de- cay process, including (but not limited to) circle packing and directed graphs. The practical goal of this visualization process is to support nuclear forensics, the identification of the origin of intercepted smuggled nuclear materials. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882248828,Conference Proceeding,2013-08-23,10.1145/2467696.2467772,400,9781450320764,15525996,399-400,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,399,http://api.elsevier.com/content/abstract/scopus_id/84882248828,,84882248828,145752,p,Information visualization of nuclear decay chain libraries
"Institutions can be conceptualized as ""regulative, normative and cultural-cognitive elements that, together with associated activities and resources, provide stability and meaning to social life"" [14]. These regulative, normative, and cultural-cognitive elements provide the institutional structures in which organizations or individuals are embedded. By providing particular courses of action, institutions serve as patterns that constrain and empower individuals. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882267476,Conference Proceeding,2013-08-23,10.1145/2467696.2467755,402,9781450320764,15525996,401-402,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,401,http://api.elsevier.com/content/abstract/scopus_id/84882267476,,84882267476,145752,p,Institutional structures for research data and metadata curation
"This study aims to investigate the factors influencing news sharing in social media. Drawing from the diffusion of innovations theory (DOI), the influential factors identified are opinion leadership, homophily, tie strength, and news attributes. By incorporating social network analysis with multiple regression analysis, our results indicate that opinion leadership was the strongest factor predicting users' news sharing, followed by news attribute and tie strength. Unexpectedly, we also found that homophily hampered news sharing in social media. Implications are discussed. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",2,,2-s2.0-84882252731,Conference Proceeding,2013-08-23,10.1145/2467696.2467749,404,9781450320764,15525996,403-404,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,403,http://api.elsevier.com/content/abstract/scopus_id/84882252731,,84882252731,145752,p,Investigating influential factors influencing users to share news in social media: A diffusion of innovations perspective
"This poster presents what we believe to be the first attempt to empirically measure and visualize the cross-pollination of science and philosophy through citation patterns. Using the Stanford Encyclopedia of Philosophy as a proxy for the philosophical literature, we plot SEP citations onto the UCSD Map of Science to highlight areas of science which overlap with philosophical discussion. An outline of further studies is also discussed. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",1,,2-s2.0-84882264164,Conference Proceeding,2013-08-23,10.1145/2467696.2467777,406,9781450320764,15525996,405-406,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,405,http://api.elsevier.com/content/abstract/scopus_id/84882264164,,84882264164,145752,p,Mapping the intersection of science & philosophy
"The University of Illinois Library has been conducting transaction log analyses to model user search behaviors within our Library gateway. These analyses have informed the development and implementation of various search assistance mechanisms designed to facilitate search strategy modification and enhance user search navigation methods. This paper discusses the efforts to effectively overlay search assistance mechanisms into the web-scale discovery system environment. These search assistance mechanisms seek to meet user search needs and to address known issues with web-scale systems. This paper describes an evolving search assistance model being deployed in a web-scale environment and reports our findings from transaction log studies and user surveys. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882253107,Conference Proceeding,2013-08-23,10.1145/2467696.2467784,408,9781450320764,15525996,407-408,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,407,http://api.elsevier.com/content/abstract/scopus_id/84882253107,,84882253107,145752,p,Modeling search assistance mechanisms within web-scale discovery systems
"In this poster, we present findings from the user experience and metadata perspectives of using Blacklight and Solr to combine large and distinct resource sets. We also share results of a survey of academic and educational institutions on their approaches to Solr indexing and end-user options and identify next steps toward articulating best practices for user experience around discovery in the context of metadata. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882272594,Conference Proceeding,2013-08-23,10.1145/2467696.2467771,,9781450320764,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,409,http://api.elsevier.com/content/abstract/scopus_id/84882272594,,84882272594,145752,p,MOOD-lighting: Massive open online discovery using solr and blacklight
"A common complaint of providers of institutional repository services is that they have low utilization by their intended user base. The reasons are varied, but two are germane to our project: lack of individual incentives among potentially participating faculty; and a perceived high barrier to entry. The OmniMea project adopts a user-centric focus by advocating for personal repositories as a more appealing concept and by directing relevant intellectual output placed in these personal repositories to the institutional repository for long-term curation. While our approach was explicitly aimed and capturing long-tail data, it has turned out to be more generally applicable. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882244946,Conference Proceeding,2013-08-23,10.1145/2467696.2467776,412,9781450320764,15525996,411-412,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,411,http://api.elsevier.com/content/abstract/scopus_id/84882244946,,84882244946,145752,p,OmniMea: An approach to improved content recruitment for institutional repositories
"Despite the increase in interest in video games across commercial and academic areas, organizational systems for classifying them remain inadequate, particularly in describing the visual styles of video games. Because video games are by and large a visual medium, the ability to describe their visual ""look"" coherently and consistently greatly contributes to their discovery through classification. A set of controlled terms would be instrumental in complementing game recommendation engines and search applications in digital libraries to meet users' content-related information needs. In our study we examine the academic and usergenerated content about video games' visual styles in order to extract potentially useful controlled vocabulary terms. These terms are then organized into facets and arranged into a classified schedule. In this poster, we discuss the challenges in our controlled vocabulary term definitions and their application. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",5,,2-s2.0-84882270302,Conference Proceeding,2013-08-23,10.1145/2467696.2467747,414,9781450320764,15525996,413-414,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,413,http://api.elsevier.com/content/abstract/scopus_id/84882270302,,84882270302,145752,p,Pretty as a pixel: Issues and challenges in developing a controlled vocabulary for video game visual styles
"In 2004, the Federal Reserve Bank of St. Louis created FRASER (Federal Reserve Archival System for Economic Research, http://fraser.stlouisfed.org), a digital library of economic, financial, and banking data and policy documents. The history of American economic policy is documented in these publications, records, and archival materials. It has become evident that FRASER's growing user base needs additional context to improve users' ability to navigate, select, and understand the continually growing content. We have taken three approaches to improve the accessibility of our content: changes to the database, integration with other web databases, and addition of material to support teaching activities. We hope that these changes will broaden our audience and increase site traffic. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882260738,Conference Proceeding,2013-08-23,10.1145/2467696.2467768,416,9781450320764,15525996,415-416,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,415,http://api.elsevier.com/content/abstract/scopus_id/84882260738,,84882260738,145752,p,Providing context for digital library content
"Earthquake engineering brings together researchers from seismology, structural, mechanical, and geotechnical engineering whose research results in saving lives and protecting property during earthquakes and tsunamis. Such diversity poses unique challenges for data management, data archiving, preservation, and data publication. The poster demonstrates new innovative approaches to curation, visualization, and publishing of earthquake engineering research data in the NEEShub, a collaborative platform that provides a combined virtual research environment and data repository to researchers participating in the Network for Earthquake Engineering Simulations (NEES) and to the earthquake engineering community in general. The poster provides graphical depictions demonstrating the curation workflows established in NEES, the progression of data from unprocessed sensor measurements to datasets that can be analyzed by a variety of analytical and visualization tools, and finally their transformation into a citable published product. It documents ways in which NEEShub exposes research data and facilitates collaboration and sharing, as well as re-use and repurposing of the datasets. Furthermore, the poster illustrates some of the successes of the NEEShub in its four years of existence including continuous growth in uploaded files, users, number of downloaded files, curated projects, and published datasets. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882238271,Conference Proceeding,2013-08-23,10.1145/2467696.2467758,418,9781450320764,15525996,417-418,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,417,http://api.elsevier.com/content/abstract/scopus_id/84882238271,,84882238271,145752,p,Publishing earthquake engineering research data
"Citation relationships between publications are important for assessing the importance of scholarly components (e.g., authors, publications, and venues) within a network. Missing citation metadata in scholarly databases, however, creates problems for classical citation-based ranking algorithms. In the ACM database, for example, 18.5% of publications don't have citation metadata. In this research we propose an innovative, 2-step method of citation analysis, to investigate the importance of publications for which citation data is missing. Preliminary evaluation results show that this method can effectively uncover the importance of publications without using citation metadata. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882270410,Conference Proceeding,2013-08-23,10.1145/2467696.2467782,420,9781450320764,15525996,419-420,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,419,http://api.elsevier.com/content/abstract/scopus_id/84882270410,,84882270410,145752,p,Recovering missing citations in a scholarly network: A 2-step citation analysis to estimate publication importance
"Users frequently post popular material to YouTube, and in response, others lmk to these videos from social media, blogs, forums, and email. However, this content may be removed for numerous reasons, only to resurface again at another URL. This continuous movement and breaking of the web graph makes it difficult for users to relocate content that has moved in YouTube. We present Volitrax, an add-on for FireFox which redirects users to YouTube music videos that have moved to a different URL within YouTube. Volitrax acts as an intermediary that corrects the web graph transparently so YouTube links continue to work even after the content has changed locations. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882288747,Conference Proceeding,2013-08-23,10.1145/2467696.2467765,422,9781450320764,15525996,421-422,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,421,http://api.elsevier.com/content/abstract/scopus_id/84882288747,,84882288747,145752,p,Semi-automated rediscovery of lost youtube music videos
"This paper presents an approach for helping users more quickly discover relevant information resources in a tag based system, where each resource is associated with a number of descriptive meta-data tags. Our approach builds an adaptive conversational decision-tree structure to minimize the number of interactive cues required to help a user navigate to resources of interest. Initial experiments demonstrate the potential of the approach, with shallower decision trees supporting better overall interaction performance. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882272092,Conference Proceeding,2013-08-23,10.1145/2467696.2467769,424,9781450320764,15525996,423-424,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,423,http://api.elsevier.com/content/abstract/scopus_id/84882272092,,84882272092,145752,p,Streamlining user interaction in tag-based conversational navigation of knowledge resource libraries
"To be effective and at the same time sustainable, a community data curation model has to be aligned with the community's current work organization: practices and activities; divisions of labor; data and collaborative relationships; and the community's value structure, norms, and conventions for data, quality assessment, and data sharing. This poster discusses a framework for developing a community data curation model, using a case of the scientific community gathered around the National High Magnetic Field Laboratory, a large national lab. The poster also reports findings of preliminary research based on semi-structured interviews with a sample of the main stakeholder groups of the community. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",3,,2-s2.0-84882253247,Conference Proceeding,2013-08-23,10.1145/2467696.2467781,426,9781450320764,15525996,425-426,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,425,http://api.elsevier.com/content/abstract/scopus_id/84882253247,,84882253247,145752,p,Studying the data practices of a scientific community
"This poster presents an overview of the new ACM Computing Classification system and compares it with work done in creating an ontology of all computing-related topics. There are similarities and differences and the differences lead to conclusions about both approaches. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",1,,2-s2.0-84882286402,Conference Proceeding,2013-08-23,10.1145/2467696.2467780,428,9781450320764,15525996,427-428,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,427,http://api.elsevier.com/content/abstract/scopus_id/84882286402,,84882286402,145752,p,The new ACM CCS and a computing ontology
"This poster describes the progress of a research project exploring how public digital publishing affects undergraduate research and learning. Participants are students in ""Latina/o Immigration"", an undergraduate-level history course at the University of Iowa. Students use a custom web interface to create a digital exhibit about the history of Latino/as in Iowa, using multimedia primarysource materials from the Iowa Women's Archives (IWA). Students also use the tool to learn the concepts related to metadata and digital libraries. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882266558,Conference Proceeding,2013-08-23,10.1145/2467696.2467778,430,9781450320764,15525996,429-430,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,429,http://api.elsevier.com/content/abstract/scopus_id/84882266558,,84882266558,145752,p,The nuestra iowa project - creating a digital collection as a tool for history education
"The goal of the Open Parks Network (OPN) is to create a portal that connects park managers, researchers, policy makers, and citizens to each other and to valuable cultural resources related. Led by Clemson University in collaboration with the National Parks Service and Purdue University, OPN is designed to provide a virtual community of professionals in parks and protected areas with the tools, resources, and knowledge base they need to conduct intensive research, perform their jobs duties effectively, and share information with colleagues and users on an international scale. To date, 80,000 of 200,000 archival images and 500,000 out of 2 million bound pages have been digitized from various parks, and a beta version of the platform will be available for demonstration in March 2013. The project includes the integration of a Fedora repository with the Joomla! content management system with extensions to enable GIS functionality, expose metadata as Linked Data and for harvest using OAI-PMH, and enable users to create their own custom collections. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882277366,Conference Proceeding,2013-08-23,10.1145/2467696.2467779,432,9781450320764,15525996,431-432,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,431,http://api.elsevier.com/content/abstract/scopus_id/84882277366,,84882277366,145752,p,The open parks network
"The academic community has published millions of research papers to date, and the number of new papers has been increasing with time. To discover new research, researchers typically rely on manual methods such as keyword-based search, reading proceedings of conferences, browsing publication lists of known experts, or checking the references of the papers they are interested. Existing tools for the literature search are suitable for a first-level bibliographic search. However, they do not allow complex second-level searches. In this paper, we present a web service called theadvisor (http://theadvisor.osu.edu) which helps the users to build a strong bibliography by extending the document set obtained after a first-level search. The service makes use of the citation graph for recommendation. It also features diversification, relevance feedback, graphical visualization, venue and reviewer recommendation. In this work, we explain the design criteria and rationale we employed to make the theadvisor a useful and scalable web service along with a thorough experimental evaluation. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",10,,2-s2.0-84882289030,Conference Proceeding,2013-08-23,10.1145/2467696.2467752,434,9781450320764,15525996,433-434,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,433,http://api.elsevier.com/content/abstract/scopus_id/84882289030,,84882289030,145752,p,TheAdvisor: A webservice for ac ademic recommendation
"In the Indexer's Legacy Project, we have created meta-indexes for domain-oriented collections of digital books in order to promote searching, navigation and browsing in digital collections. Because the meta-index is a new knowledge structure, we have used focus groups and sample tasks to collect information on user's perception and use of meta-indexes. User's responses were positive and their suggestions led to improvements in our online Meta-Dex User Interface (MUI) tool, which will be tested in subsequent user studies. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882240825,Conference Proceeding,2013-08-23,10.1145/2467696.2467783,436,9781450320764,15525996,435-436,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,435,http://api.elsevier.com/content/abstract/scopus_id/84882240825,,84882240825,145752,p,User interface evaluation of meta-indexes for search
"This poster presents preliminary Google Analytics usage data for a collection of electronic theses and dissertations (ETDs). Correlation of page views with page type, user location, and source (referring link) shows that, during the study period, most in-state users found the collection via internal sources (University links) and viewed mostly home and navigation pages, while most out-of-state users found the collection via external sources (search engines, databases) and viewed mostly bibliographic information pages. Nearly all of those who viewed actual ETDs were out-ofstate ""direct"" users who may have bookmarked the collection during a previous visit. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",4,,2-s2.0-84882287884,Conference Proceeding,2013-08-23,10.1145/2467696.2467770,438,9781450320764,15525996,437-438,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,437,http://api.elsevier.com/content/abstract/scopus_id/84882287884,,84882287884,145752,p,Using google analytics to explore ETDs use
"In this poster we will present the SEAD project [1] and its prototype software and describe how SEAD approaches long-term data preservation and access through multiple partnerships and how it supports sustainability science researchers in their data management, analysis and archival needs. SEAD's initial prototype system currently is being tested by ingesting datasets from the National Center for Earth Surface Dynamics (1.6 terabyte of data containing over 450,000 files) [2] and packaging them for transmission to long-term archival storage. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",1,,2-s2.0-84882290036,Conference Proceeding,2013-08-23,10.1145/2467696.2467762,440,9781450320764,15525996,439-440,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,439,http://api.elsevier.com/content/abstract/scopus_id/84882290036,,84882290036,145752,p,The SEAD datanet prototype: Data preservation services for sustainability science
"The push for free online availability of research outputs promoted by the Open Access (OA) movement is undoubtedly transforming the publishing industry. However, the mere availability of research outputs is insufficient. To exploit the full potential of OA, it must be possible to search, discover, mine, analyse, etc. this content. To achieve this, it is essential to improve the existing OA technical infrastructure to effectively support these functionalities. Many of the vital benefits of OA are expected to come with the ability to reuse OA content in unanticipated ways. Access to the OA content must therefore be flexible, yet practical, content-based and not just metadata based. In this demonstration, we present the CORE system, which aggregates millions of OA resources from hundreds of OA repositories and journals. We discuss the use cases aggregations should support and demonstrate how the CORE system addresses them, including searching, discovering, mining and analyzing content. We also show how aggregated OA content can be reused to build new applications on top of CORE's functionality. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882244509,Conference Proceeding,2013-08-23,10.1145/2467696.2467787,442,9781450320764,15525996,441-442,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,441,http://api.elsevier.com/content/abstract/scopus_id/84882244509,,84882244509,145752,p,CORE: Aggregation use cases for open access
"In this demo-paper we present Docear's PDF Inspector (DPI). DPI extracts titles from academic PDF files by applying a simple heuristic: The largest text on the first page of a PDF is assumed to be the title. This simple heuristic achieves accuracies around 70% and outperforms the tools ParsCit and SciPlore Xtract in both run-time and accuracy. In addition, DPI is released under the free open source license GPL 2+ at http://www.docear.org, written in JAVA, and runs on any major operating system. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",10,,2-s2.0-84882284946,Conference Proceeding,2013-08-23,10.1145/2467696.2467789,444,9781450320764,15525996,443-444,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,443,http://api.elsevier.com/content/abstract/scopus_id/84882284946,,84882284946,145752,p,Docear's PDF inspector: Title extraction from PDF files
"In this demo-paper we introduce Docear4Word which enables researchers to insert and format their references and bibliographies in Microsoft Word. Docear4Word is based on BibTeX and the Citation Style Language (CSL), features over 1,700 citation styles (Harvard, IEEE, ACM, etc.), is published as open source tool on http://docear.org, and runs with Microsoft Word 2002 (and later) on Windows XP (and later). Docear4Word is similar to the MS-Word add-ons that reference managers like Endnote, Zotero, or Citavi offer with the difference that it is being developed to work with the de-facto standard BibTeX and hence to work with almost any reference manager. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882281190,Conference Proceeding,2013-08-23,10.1145/2467696.2467785,446,9781450320764,15525996,445-446,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,445,http://api.elsevier.com/content/abstract/scopus_id/84882281190,,84882281190,145752,p,Docear4Word: Reference management for microsoft word based on BibTeX and the citation style language (CSL)
"In this paper we describe the new development of FishTraits. Originating from an ecological database that documents and consolidates more than 100 traits for 809 fish species, the new version focuses on the integration of these traits data with the bibliographic and biogeographic information. We explain the overall design as well as the implementation details. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",1,,2-s2.0-84882247498,Conference Proceeding,2013-08-23,10.1145/2467696.2467791,448,9781450320764,15525996,447-448,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,447,http://api.elsevier.com/content/abstract/scopus_id/84882247498,,84882247498,145752,p,"FishTraits version 2: Integrating ecological, biogeographic and bibliographic information"
"In this paper we present Greenbug: A hybrid web inspector, debugger and design editor developed for use with the open source digital library software Greenstone 3. Inspired by the web development tool Firebug, Greenbug is more tightly coupled with the underlying (digital library) server than that provided by Firebug; for example, Greenbug has a fine-grained knowledge of the connection between the underlying file system and the rendered web content, and also provides the ability to commit any changes made through the web interface back to the underlying file system. More- over, because web page production in Greenstone 3 is the result of an XSLT processing pipeline, the necessarily well- formed hierarchical XML content can be manipulated into a graphical representation, which can then be manipulated directly through a visual interface supplied by Greenbug. We showcase the interface in use, provide a brief overview of implementation details, and conclude with a discussion on how the approach can be adapted to other XSLT transformation- based content management systems, such as DSpace. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882288750,Conference Proceeding,2013-08-23,10.1145/2467696.2467788,450,9781450320764,15525996,449-450,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,449,http://api.elsevier.com/content/abstract/scopus_id/84882288750,,84882288750,145752,p,"Greenbug: A hybrid web-inspector, debugger and design editor for greenstone"
"In this paper, we describe IssueLab, a digital library and distribution network for social sector publications and resources. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882275341,Conference Proceeding,2013-08-23,10.1145/2467696.2467793,452,9781450320764,15525996,451-452,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,451,http://api.elsevier.com/content/abstract/scopus_id/84882275341,,84882275341,145752,p,IssueLab: The social sector's digital library
"A system for exploring the rich recorded legacy of the Apollo missions to the Moon, using the event structure of each mission as an organizing principle, will be demonstrated. A scalable implementation is achieved by automating temporal, spatial, and topical content alignment across diverse media. Multiple access points are supported, including event-based access through the flight plan, time-based access using event timelines, and contentbased access using information retrieval techniques. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",6,,2-s2.0-84882285476,Conference Proceeding,2013-08-23,10.1145/2467696.2467794,454,9781450320764,15525996,453-454,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,453,http://api.elsevier.com/content/abstract/scopus_id/84882285476,,84882285476,145752,p,The apollo archive explorer
"This demonstration will show version 1.0 of the Avalon Media System, an open source system being developed by Indiana University and Northwestern University to allow libraries and archives to provide online access to audio and video collections. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882280542,Conference Proceeding,2013-08-23,10.1145/2467696.2467790,,9781450320764,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,455,http://api.elsevier.com/content/abstract/scopus_id/84882280542,,84882280542,145752,p,The avalon media system: A platform for access-controlled delivery of time-based media
"In this demonstration-paper we introduce DAAR, the Digital Atlas of American Religion (www.religionatlas.org). The DAAR is a web-based research platform with innovative data exploration and visualization tools to support research in the humanities. Using a user-centered design approach, we incorporated historic religion data on adherence, membership, and congregations with historic census data and new religion typologies as the test-bed for the tools that we developed to establish the technology infrastructure and framework that can be used for other humanities data. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",0,,2-s2.0-84882267985,Conference Proceeding,2013-08-23,10.1145/2467696.2467792,458,9781450320764,15525996,457-458,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,457,http://api.elsevier.com/content/abstract/scopus_id/84882267985,,84882267985,145752,p,The digital atlas of American religion
"In this demo paper we present Docear's research paper recommender system. Docear is an academic literature suite to search, organize, and create research articles. The users' data (papers, references, annotations, etc.) is managed in mind maps and these mind maps are utilized for the recommendations. Using content-based filtering methods, Docear's recommender achieves click-through rates around 6%, in some scenarios even over 10%. Copyright © 2013 by the Association for Computing Machinery, Inc. (ACM).",25,,2-s2.0-84882281565,Conference Proceeding,2013-08-23,10.1145/2467696.2467786,460,9781450320764,15525996,459-460,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,459,http://api.elsevier.com/content/abstract/scopus_id/84882281565,,84882281565,145752,p,Introducing docear's research paper recommender system
© 2015 ACM. It is studied how users browse search results to find interesting novels for four search scenarios. It is evaluated in particular whether there are differences in search result page (SERP) browsing patterns and effectiveness between an enriched catalog for finding fiction compared to a traditional public library catalog. The data was collected from 30 participants by eye-tracking and questionnaires. The results indicate that the enriched catalog supported users to identify sooner and more effectively potentially clickable items on the results list compared to a traditional public library catalog. This is likely due to the more informative metadata in the enriched catalog like snippets of content description on the result list items. The discussion includes a theoretical and empirical comparison of findings in studies on fiction and non-fiction searching.,3,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952006649,Conference Proceeding,2015-06-21,10.1145/2756406.2756911,16,9781450335942,15525996,7-16,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,7,http://api.elsevier.com/content/abstract/scopus_id/84952006649,2015-June,84952006649,145752,p,Result List Actions in Fiction Search
"© 2015 ACM.Digital reading is a topic of rising interest in digital libraries, particularly in terms of optimizing the reading experience. However, there is relatively little data on the patterns of digital reading, including issues of where and what users read, and how they organize, plan and conduct their reading sessions. This paper reports the first data on mobile reading, combining insights from three different studies of users, including diary studies, interviews and ethnomethodological work. The data reveals that reading often depends on highly developed and rehearsed practices, especially when the reading is related to study or research. From this, we are able to identify a number of opportunities for further digital library research to better support the needs of users.",5,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951965923,Conference Proceeding,2015-06-21,10.1145/2756406.2756917,26,9781450335942,15525996,17-26,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,17,http://api.elsevier.com/content/abstract/scopus_id/84951965923,2015-June,84951965923,145752,p,Where My Books Go: Choice and Place in Digital Reading
"© 2015 ACM.We compared fiction readers' search actions during various query reformulation intervals. We aimed to understand how readers' search actions differed between successful and unsuccessful QRIs and which search actions predicted the selecting of very interesting novels compared to less interesting ones. We conducted a controlled user study with 80 participants searching for interesting novels. Three types of browsing tasks and two types of catalogs were used. Our results demonstrated that browsing task type was associated to readers' document viewing behavior in terms of observed search result pages, opened book pages and dwell time on book pages. When browsing for topical novels, most effort was required to select somewhat interesting novels. When browsing for good novels, most effort was required to select very interesting ones. Logistic regression analysis yielded that the most significant predictors of higher document value were the number of observed search result pages and opened book pages.",2,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952017878,Conference Proceeding,2015-06-21,10.1145/2756406.2756922,36,9781450335942,15525996,27-36,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,27,http://api.elsevier.com/content/abstract/scopus_id/84952017878,2015-June,84952017878,145752,p,Books' Interest Grading and Fiction Readers' Search Actions during Query Reformulation Intervals
"© 2015 ACM. While many clustering techniques have been successfully applied to the person name disambiguation problem, most do not address two main practical issues: allowing constraints to be added to the clustering process, and allowing the data to be added incrementally without clustering the entire database. Constraints can be particularly useful especially in a system such as a digital library, where users are allowed to make corrections to the disambiguated result. For example, a user correction on a disambiguation result specifying that a record does not belong to an author could be kept as a cannot-link constraint to be used in any future disambiguation (such as when new documents are added). Besides such user corrections, constraints also allow background heuristics to be encoded into the disambiguation process. We propose a constraint-based clustering algorithm for person name disambiguation, based on DBSCAN combined with a pairwise distance based on random forests. We further propose an extension to the density-based clustering algorithm (DBSCAN) to handle online clustering so that the disambiguation process can be done iteratively as new data points are added. Our algorithm utilizes similarity features based on both metadata information and citation similarity. We implement two types of clustering constraints to demonstrate the concept. Experiments on the CiteSeer data show that our model can achieve 0.95 pairwise F1 and 0.79 cluster F1. The presence of constraints also consistently improves the disambiguation result across different combinations of features.",3,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952018463,Conference Proceeding,2015-06-21,10.1145/2756406.2756915,46,9781450335942,15525996,37-46,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,37,http://api.elsevier.com/content/abstract/scopus_id/84952018463,2015-June,84952018463,145752,p,Online Person Name Disambiguation with Constraints
"© 2015 ACM.We propose an approach to index raster images of dictionary pages which in turn would require very little manual effort to enable direct access to the appropriate pages of the dictionary for lookup. Accessibility is further improved by feedback and crowdsourcing that enables highlighting of the specific location on the page where the lookup word is found, annotation, digitization, and fielded searching. This approach is equally applicable on simple scripts as well as complex writing systems. Using our proposed approach, we have built a Web application called ""Dictionary Explorer"" which supports word indexes in various languages and every language can have multiple dictionaries associated with it. Word lookup gives direct access to appropriate pages of all the dictionaries of that language simultaneously. The application has exploration features like searching, pagination, and navigating the word index through a tree-like interface. The application also supports feedback, annotation, and digitization features. Apart from the scanned images, ""Dictionary Explorer"" aggregates results from various sources and user contributions in Unicode. We have evaluated the time required for indexing dictionaries of different sizes and complexities in the Urdu language and examined various trade-offs in our implementation. Using our approach, a single person can make a dictionary of 1,000 pages searchable in less than an hour.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951976680,Conference Proceeding,2015-06-21,10.1145/2756406.2756926,56,9781450335942,15525996,47-56,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,47,http://api.elsevier.com/content/abstract/scopus_id/84951976680,2015-June,84951976680,145752,p,Improving Accessibility of Archived Raster Dictionaries of Complex Script Languages
"© 2015 ACM.In this paper, we identify sentences in Wikipedia articles that are either identical or highly similar by applying techniques for near-duplicate detection of web pages. This is accomplished with a MapReduce implementation of minhash to identify sentences with high Jaccard similarity, followed by a pass to generate sentence clusters. Based on manual examination, we discovered that these clusters can be categorized into six different types: templates, identical sentences, copyediting, factual drift, references, and other. Two of these categories are particularly interesting: identical sentences quantify the extent to which content in Wikipedia is copied and pasted, and near-duplicate sentences that state contradictory facts point to quality issues in Wikipedia.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951929844,Conference Proceeding,2015-06-21,10.1145/2756406.2756947,60,9781450335942,15525996,57-60,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,57,http://api.elsevier.com/content/abstract/scopus_id/84951929844,2015-June,84951929844,145752,p,Identifying Duplicate and Contradictory Information in Wikipedia
"© 2015 ACM. We address the tasks of recovering bibliographic and document structure metadata from scholarly documents. We leverage higher order semi-Markov conditional random fields to model long-distance label sequences, improving upon the performance of the linear-chain conditional random field model. We introduce the notion of extensible features, which allows the expensive inference process to be simplified through memoization, resulting in lower computational complexity. Our method significantly betters the state-of-the-art on three related scholarly document extraction tasks.",3,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951966497,Conference Proceeding,2015-06-21,10.1145/2756406.2756946,64,9781450335942,15525996,61-64,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,61,http://api.elsevier.com/content/abstract/scopus_id/84951966497,2015-June,84951966497,145752,p,Scholarly Document Information Extraction using Extensible Features for Efficient Higher Order Semi-CRFs
"© 2015 ACM.We propose a use and reuse driven big data management approach that fuses the data repository and data processing capabilities in a co-located, public cloud. It answers to the urgent data management needs from the growing number of researchers who don't fit in the big science/small science dichotomy. This approach will allow researchers to more easily use, manage, and collaborate around big data sets, as well as give librarians the opportunity to work alongside the researchers to preserve and curate data while it is still fresh and being actively used. This also provides the technological foundation to foster a sharing culture more aligned with the open source software development paradigm than the lone-wolf, gift-exchanging small science sharing or the top-down, highly structured big science sharing. To materialize this vision, we provide a system architecture consisting of a scalable digital repository system coupled with the co-located cloud storage and cloud computing, as well as a job scheduler and a deployment management system. Motivated by Virginia Tech's Goodwin Hall instrumentation project, we implemented and evaluated a prototype. The results show not only sufficient capacities for this particular case, but also near perfect linear storage and data processing scalabilities under moderately high workload.",4,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951982557,Conference Proceeding,2015-06-21,10.1145/2756406.2756924,74,9781450335942,15525996,65-74,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,65,http://api.elsevier.com/content/abstract/scopus_id/84951982557,2015-June,84951982557,145752,p,Towards Use and Reuse Driven Big Data Management
"© 2015 ACM.Researchers in the Digital Humanities and journalists need to monitor, collect and analyze fresh online content regarding current events such as the Ebola outbreak or the Ukraine crisis on demand. However, existing focused crawling approaches only consider topical aspects while ignoring temporal aspects and therefore cannot achieve thematically coherent and fresh Web collections. Especially Social Media provide a rich source of fresh content, which is not used by state-of-the-art focused crawlers. In this paper we address the issues of enabling the collection of fresh and relevant Web and Social Web content for a topic of interest through seamless integration of Web and Social Media in a novel integrated focused crawler. The crawler collects Web and Social Media content in a single system and exploits the stream of fresh Social Media content for guiding the crawler.",2,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951995904,Conference Proceeding,2015-06-21,10.1145/2756406.2756925,84,9781450335942,15525996,75-84,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,75,http://api.elsevier.com/content/abstract/scopus_id/84951995904,2015-June,84951995904,145752,p,ICrawl: Improving the Freshness of Web Collections by Integrating Social Web and Focused Web Crawling
"© 2015 ACM. We demonstrate a prototype that takes advantage of open-source software to put a full-text searchable copy of Wikipedia on a Raspberry Pi, providing nearby devices access to content via wifi or bluetooth without requiring internet connectivity. This short paper articulates the advantages of such a form factor and provides an evaluation of browsing and search capabilities. We believe that personal digital libraries on lightweight mobile computing devices represent an interesting research direction to pursue.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952030828,Conference Proceeding,2015-06-21,10.1145/2756406.2756938,86,9781450335942,15525996,85-86,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,85,http://api.elsevier.com/content/abstract/scopus_id/84952030828,2015-June,84952030828,145752,p,The Sum of All Human Knowledge in Your Pocket: Full-Text Searchable Wikipedia on a Raspberry Pi
"© 2015 ACM.Problem/project Based Learning (PBL) is a highly effective student-centered teaching method, where student teams learn by solving problems. This paper describes an instance of PBL applied to digital library education. We show the design, implementation, results, and partial evaluation of a Computational Linguistics course that provides students an opportunity to engage in active learning about adding value to digital libraries with large collections of text, i.e., one aspect of ""big data."" Students are engaging in PBL with the semester long challenge of generating good English summaries of an event, given a large collection from our webpage archives. Six teams, each working with a different type of event, and applying three different summarization methods, learned how to generate good summaries; these have fair precision relative to the Wikipedia page that describes their event.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952038828,Conference Proceeding,2015-06-21,10.1145/2756406.2756943,90,9781450335942,15525996,87-90,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,87,http://api.elsevier.com/content/abstract/scopus_id/84952038828,2015-June,84952038828,145752,p,Big Data Text Summarization for Events: A Problem Based Learning Course
"© 2015 ACM.Emotion annotations are important metadata for narrative texts in digital libraries. Such annotations are necessary for automatic text-to-speech conversion of narratives and affective education support and can be used as training data for machine learning algorithms to train automatic emotion detectors. However, obtaining high-quality emotion annotations is a challenging problem because it is usually expensive and time-consuming due to the subjectivity of emotion. Moreover, due to the multiplicity of ""emotion"", emotion annotations more naturally fit the paradigm of multi-label classification than that of multi-class classification since one instance (such as a sentence) may evoke a combination of multiple emotion categories. We thus investigated ways to obtain a set of high-quality emotion annotations ({instance, multi-emotion} paired data) from variable-quality crowdsourced annotations. A common quality control strategy for crowdsourced labeling tasks is to aggregate the responses provided by multiple annotators to produce a reliable annotation. Given that the categories of ""emotion"" have characteristics different from those of other kinds of labels, we propose incorporating domain-specific information of emotional consistencies across instances and contextual cues among emotion categories into the aggregation process. Experimental results demonstrate that, from a limited number of crowdsourced annotations, the proposed models enable gold standards to be more effectively estimated than the majority vote and the original domain-independent model.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951978032,Conference Proceeding,2015-06-21,10.1145/2756406.2756910,100,9781450335942,15525996,91-100,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,91,http://api.elsevier.com/content/abstract/scopus_id/84951978032,2015-June,84951978032,145752,p,Multi-Emotion Estimation in Narratives from Crowdsourced Annotations
"© 2015 ACM.In this paper, we describe the process we used to debug a crowdsourced labeling task with low inter-rater agreement. In the labeling task, the workers' subjective judgment was used to detect high-quality social media content-interesting tweets-with the ultimate aim of building a classifier that would automatically curate Twitter content. We describe the effects of varying the genre and recency of the dataset, of testing the reliability of the workers, and of recruiting workers from different crowdsourcing platforms. We also examined the effect of redesigning the work itself, both to make it easier and to potentially improve inter-rater agreement. As a result of the debugging process, we have developed a framework for diagnosing similar efforts and a technique to evaluate worker reliability. The technique for evaluating worker reliability, Human Intelligence Data-Driven Enquiries (HIDDENs), differs from other such schemes, in that it has the potential to produce useful secondary results and enhance performance on the main task. HIDDEN subtasks pivot around the same data as the main task, but ask workers questions with greater expected inter-rater agreement. Both the framework and the HIDDENs are currently in use in a production environment.",3,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951918369,Conference Proceeding,2015-06-21,10.1145/2756406.2757741,110,9781450335942,15525996,101-110,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,101,http://api.elsevier.com/content/abstract/scopus_id/84951918369,2015-June,84951918369,145752,p,Debugging a Crowdsourced Task with Low Inter-Rater Agreement
"© 2015 ACM. Widespread misinformation on social media is a cause of concern. Currently, it is unclear what factors prompt regular social media users with no malicious intent to forward misinformation to their online networks. Using a questionnaire informed by the Uses and Gratifications theory and the literature on rumor research, this study asked university students in Singapore why they shared misinformation on social media. Gender differences were also tested. The study found that perceived information characteristics such as its ability to spark conversations and its catchiness were top factors. Self-expression and socializing motivations were also among the top reasons. Women reported a higher prevalence of misinformation sharing. The implications for the design of social media applications and information literacy training were discussed.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951923910,Conference Proceeding,2015-06-21,10.1145/2756406.2756941,114,9781450335942,15525996,111-114,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,111,http://api.elsevier.com/content/abstract/scopus_id/84951923910,2015-June,84951923910,145752,p,Why Do Social Media Users Share Misinformation?
"© 2015 ACM.Building evaluation datasets for information retrieval is a time-consuming and exhausting activity. To evaluate research over novel corpora, researchers are increasingly turning to crowdsourcing to efficiently distribute the evaluation dataset creation among many workers. However, there has been little investigation into the effect of instrument design on data quality in crowdsourced evaluation datasets. We pursue this question through a case study, music similarity judgments in a music digital library evaluation, where we find that even with trusted graders song pairs are not consistently rated the same. We find that much of this low intra-coder consistency can be attributed to the task design and judge effects, concluding with recommendations for achieving reliable evaluation judgments for music similarity and other normative judgment tasks.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951922284,Conference Proceeding,2015-06-21,10.1145/2756406.2756942,118,9781450335942,15525996,115-118,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,115,http://api.elsevier.com/content/abstract/scopus_id/84951922284,2015-June,84951922284,145752,p,Improving Consistency of Crowdsourced Multimedia Similarity for Evaluation
"© 2015 ACM.The most important goal for digital libraries is to ensure high quality search experience for all kinds of users. To attain this goal, it is necessary to have as much relevant metadata as possible at hand to assess the quality of publications. Recently, a new group of metrics appeared, that has the potential to raise the quality of publication metadata to the next level - the altmetrics. These metrics try to reflect the impact of publications within the social web. However, currently it is still unclear if and how altmetrics should be used to assess the quality of a publication and how altmetrics are related to classical bibliographical metrics (like e.g. citations). To gain more insights about what kind of concepts are reflected by altmetrics, we conducted an in-depth analysis on a real world dataset crawled from the Public Library of Science (PLOS). Especially, we analyzed if the common approach to regard the users in the social web as one homogeneous group is sensible or if users need to be divided into diverse groups in order to receive meaningful results.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952027070,Conference Proceeding,2015-06-21,10.1145/2756406.2756913,128,9781450335942,15525996,119-128,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,119,http://api.elsevier.com/content/abstract/scopus_id/84952027070,2015-June,84952027070,145752,p,What does Twitter Measure?: Influence of Diverse User Groups in Altmetrics
"© 2015 ACM.A user often interacts with multiple applications while working on a task. User models can be developed individually at each of the individual applications, but there is no easy way to come up with a more complete user model based on the distributed activity of the user. To address this issue, this research studies the importance of combining various implicit and explicit relevance feedback indicators in a multi-application environment. It allows different applications used for different purposes by the user to contribute user activity and its context to mutually support users with unified relevance feedback. Using the data collected by the web browser, Microsoft Word and Microsoft PowerPoint, combinations of implicit relevance feedback with semi-explicit relevance feedback were analyzed and compared with explicit user ratings. Our results are two-fold: first we demonstrate the aggregation of implicit and semi-explicit user interest data across multiple everyday applications using our Interest Profile Manager (IPM) framework. Second, our experimental results show that incorporating implicit feedback with semi-explicit feedback for page-level user interest estimation resulted in a significant improvement over the content-based models.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952011634,Conference Proceeding,2015-06-21,10.1145/2756406.2756914,138,9781450335942,15525996,129-138,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,129,http://api.elsevier.com/content/abstract/scopus_id/84952011634,2015-June,84952011634,145752,p,Unified Relevance Feedback for Multi-Application User Interest Modeling
"© 2015 ACM.As public libraries become increasingly digitalized they become producers of Big Data. Furthermore, public libraries are often obliged to make their data openly available as part of national open data policies, which have gained momentum in many countries including USA, UK, and Denmark. However, in order to utilize such data and make it intelligible for citizens, decision makers, or other stakeholders, raw data APIs are insufficient. Therefore, we have developed PivotViz that is a comprehensible visualization technique, which combines parallel coordinates and pivot tables. It provides, a multidimensional visual interactive pivot table for analysis of library transactions - loans, renewals, and returns of books and other materials across location and time. The paper presents the PivotViz technique and discusses its prospects based on implementations in two publicly available versions using open data from the two largest municipalities in Denmark. Examples of analysis results from these data illustrate the power of PivotViz.",2,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951994826,Conference Proceeding,2015-06-21,10.1145/2756406.2756937,142,9781450335942,15525996,139-142,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,139,http://api.elsevier.com/content/abstract/scopus_id/84951994826,2015-June,84951994826,145752,p,PivotViz: Interactive Visual Analysis of Multidimensional Library Transaction Data
"© 2015 ACM. A survey measured users' perceived self-efficacy about interactively retrieving digital video, both overall and according to different factors potentially related to user confidence preceding an actual video search session. A total of 270 surveys, with quantifiable responses, were collected and analyzed. T-tests and correlation tests produced significant findings about users' levels of perceived self-efficacy, including associations with topic familiarly, type or nature of the information need, and system context. Findings give researchers a better understanding of users' confidence and preconceptions prior to interactive information retrieval (IIR) sessions for video, providing valuable insight about users' attitudes which can be used to promote initial and continued use of interactive tools like digital libraries.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951967606,Conference Proceeding,2015-06-21,10.1145/2756406.2756950,146,9781450335942,15525996,143-146,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,143,http://api.elsevier.com/content/abstract/scopus_id/84951967606,2015-June,84951967606,145752,p,User and Topical Factors in Perceived Self-Efficacy of Video Digital Libraries
"© 2015 ACM. With 13,000,000 volumes comprising 4.5 billion pages of text, it is currently very difficult for scholars to locate relevant sets of documents that are useful in their research from the HathiTrust Digital Libary (HTDL) using traditional lexically-based retrieval techniques. Existing document search tools and document clustering approaches use purely lexical analysis, which cannot address the inherent ambiguity of natural language. A semantic search approach offers the potential to overcome the shortcoming of lexical search, but even if an appropriate network of ontologies could be decided upon it would require a full semantic markup of each document. In this paper, we present a conceptual design and report on the initial implementation of a new framework that affords the benefits of semantic search while minimizing the problems associated with applying existing semantic analysis at scale. Our approach avoids the need for complete semantic document markup using pre-existing ontologies by developing an automatically generated Concept-in-Context (CiC) network seeded by a priori analysis of Wikipedia texts and identification of semantic metadata. Our Capisco system analyzes documents by the semantics and context of their content. The disambiguation of search queries is done interactively, to fully utilize the domain knowledge of the scholar. Our method achieves a form of semantic-enhanced search that simultaneously exploits the proven scale benefits provided by lexical indexing.",7,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952046322,Conference Proceeding,2015-06-21,10.1145/2756406.2756920,156,9781450335942,15525996,147-156,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,147,http://api.elsevier.com/content/abstract/scopus_id/84952046322,2015-June,84952046322,145752,p,Improving Access to Large-scale Digital Libraries ThroughSemantic-enhanced Search and Disambiguation
"© 2015 ACM. Efforts to make highly specialized knowledge accessible through scientific digital libraries need to go beyond mere bibliographic metadata, since here information search is mostly entity-centric. Previous work has realized this trend and developed different methods to recognize and (to some degree even automatically) annotate several important types of entities: genes and proteins, chemical structures and molecules, or drug names to name but a few. Moreover, such entities are often crossreferenced with entries in curated databases. However, several questions still remain to be answered: Given a scientific discipline what are the important entities? How can they be automatically identified? Are really all of them relevant, i.e. do all of them carry deeper semantics for assessing a publication? How can they be represented, described, and subsequently annotated? How can they be used for search tasks? In this work we focus on answering some of these questions. We claim that to bring the use of scientific digital libraries to the next level we must find treat topic-specific entities as first class citizens and deeply integrate their semantics into the search process. To support this we propose a novel probabilistic approach that not only successfully provides a solution to the integration problem, but also demonstrates how to leverage the knowledge encoded in entities and provide insights to explore the use of our approach in different scenarios. Finally, we show how our results can benefit information providers.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952061470,Conference Proceeding,2015-06-21,10.1145/2756406.2756923,164,9781450335942,15525996,157-164,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,157,http://api.elsevier.com/content/abstract/scopus_id/84952061470,2015-June,84952061470,145752,p,Demystifying the Semantics of Relevant Objects in Scholarly Collections: A Probabilistic Approach
"© 2015 ACM. This paper describes an ontological framework for game description. Games are a multi-billion dollar industry and are cultural heritage objects studied by a growing number of scholars. The conceptual model described here supports the description of both individual games and relationships among games, their versions and variants for more effective discovery, more reliable provenance, and detailed scoping of copyright, patent, and trademark claims.",3,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951950575,Conference Proceeding,2015-06-21,10.1145/2756406.2756939,168,9781450335942,15525996,165-168,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,165,http://api.elsevier.com/content/abstract/scopus_id/84951950575,2015-June,84951950575,145752,p,An Ontological Framework for Describing Games
"© 2015 ACM.Bibliographic metadata standards are a longstanding mechanism for Digital Libraries to manage records and express relationships between them. As digital scholarship, particularly in the humanities, incorporates and manipulates these records in an increasingly direct manner, existing systems are proving insufficient for providing the underlying addressability and relational expressivity required to construct and interact with complex research collections. In this paper we describe motivations for these ""worksets"" and the technical requirements they raise. We survey the coverage of existing bibliographic ontologies in the context of meeting these scholarly needs, and finally provide an illustrated discussion of potential extensions that might fully realize a solution.",5,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84940469993,Conference Proceeding,2015-06-21,10.1145/2756406.2756944,172,9781450335942,15525996,169-172,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,169,http://api.elsevier.com/content/abstract/scopus_id/84940469993,2015-June,84940469993,145752,p,Building Complex Research Collections in Digital Libraries: A Survey of Ontology Implications
"© 2015 ACM.Nowadays, mathematical information is increasingly available in websites and repositories, such like ArXiv, Wikipedia and growing numbers of digital libraries. Mathematical formulae are highly structured and usually presented in layout presentations, such as PDF, LATEX and Presentation MathML. The differences of presentation between text and formulae challenge traditional text-based index and retrieval methods. To address the challenge, this paper proposes an upgraded Mathematical Information Retrieval (MIR) system, namely WikiMirs 3.0, based on the context, structure and importance of formulae in a document. In WikiMirs 3.0, users can easily ""cut"" formulae and contexts from PDF documents as well as type in queries. Furthermore, a novel hybrid indexing and matching model is proposed to support both exact and fuzzy matching. In the hybrid model, both context and structure information of formulae are taken into consideration. In addition, the concept of formula importance within a document is introduced into the model for more reasonable ranking. Experimental results, compared with two classical MIR systems, demonstrate that the proposed system along with the novel model provides higher accuracy and better ranking results over Wikipedia.",3,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951926484,Conference Proceeding,2015-06-21,10.1145/2756406.2756918,182,9781450335942,15525996,173-182,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,173,http://api.elsevier.com/content/abstract/scopus_id/84951926484,2015-June,84951926484,145752,p,"WikiMirs 3.0: A Hybrid MIR System Based on the Context, Structure and Importance of Formulae in a Document"
"© 2015 ACM.The assignment of subject metadata to music is useful for organizing and accessing digital music collections. Since manual subject annotation of large-scale music collections is labor-intensive, automatic methods are preferred. Topic modeling algorithms can be used to automatically identify latent topics from appropriate text sources. Candidate text sources such as song lyrics are often too poetic, resulting in lower-quality topics. Users' interpretations of song lyrics provide an alternative source. In this paper, we propose an automatic topic discovery system from web-mined user-generated interpretations of songs to provide subject access to a music digital library. We also propose and evaluate filtering techniques to identify high-quality topics. In our experiments, we use 24,436 popular songs that exist in both the Million Song Dataset and songmeanings.com. Topic models are generated using Latent Dirichlet Allocation (LDA). To evaluate the coherence of learned topics, we calculate the Normalized Pointwise Mutual Information (NPMI) of the top ten words in each topic based on occurrences in Wikipedia. Finally, we evaluate the resulting topics using a subset of 422 songs that have been manually assigned to six subjects. Using this system, 71% of the manually assigned subjects were correctly identified. These results demonstrate that topic modeling of song interpretations is a promising method for subject metadata enrichment in music digital libraries. It also has implications for affording similar access to collections of poetry and fiction.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952055147,Conference Proceeding,2015-06-21,10.1145/2756406.2756936,186,9781450335942,15525996,183-186,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,183,http://api.elsevier.com/content/abstract/scopus_id/84952055147,2015-June,84952055147,145752,p,Topic Modeling Users' Interpretations of Songs to Inform Subject Access in Music Digital Libraries
"© 2015 ACM.The Internet provides access to content in almost all languages through a combination of crawling, indexing, and ranking capabilities. The ability to locate content on almost any topic has become expected for most users. But it is not the case for those whose primary language is a sign language. Members of this community communicate via the Internet, but they pass around links to videos via email and social media. In this paper, we describe the need for, the architecture of, and initial software components of a distributed digital library of sign language content, called SLaDL. Our initial efforts have been to develop a model of collection development that enables community involvement without assuming it. This goal necessitated the development of video processing techniques that automatically detect sign language content in video.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951970148,Conference Proceeding,2015-06-21,10.1145/2756406.2756945,190,9781450335942,15525996,187-190,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,187,http://api.elsevier.com/content/abstract/scopus_id/84951970148,2015-June,84951970148,145752,p,Towards a Distributed Digital Library for Sign Language Content
"© 2015 ACM. Digital libraries are called upon to organize, aggregate, and steward born-digital news collections. Rather than continuously building silos of such non-traditional collections, digital libraries are seeking to manage these collections in conjunction with each other in order to provide the most value to scholars. We here present the results of a preliminary study analyzing characteristics of items in two collections of digital news media: television broadcasts and social media coverage. Our findings indicate a number of factors that similar efforts will need to take into consideration when linking digital ""news"" collections similar to ours.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951976458,Conference Proceeding,2015-06-21,10.1145/2756406.2756948,194,9781450335942,15525996,191-194,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,191,http://api.elsevier.com/content/abstract/scopus_id/84951976458,2015-June,84951976458,145752,p,Analyzing News Events in Non-Traditional Digital Library Collections
"© 2015 ACM.Readers of news articles are typically faced with the problem of getting a good understanding of a complex story covered in an article. However, as news articles mainly focus on current or recent events, they often do not provide sufficient information about the history of an event or topic, leaving the user alone in discovering and exploring other news articles that might be related to a given article. This is a time consuming and non-trivial task, and the only help provided by some news outlets is some list of related articles or a few links within an article itself. What further complicates this task is that many of today's news stories cover a wide range of topics and events even within a single article, thus leaving the realm of traditional approaches that track a single topic or event over time. In this paper, we present a framework to link news articles based on temporal expressions that occur in the articles, following the idea ""if an article refers to something in the past, then there should be an article about that something"". Our approach aims to recover the chronology of one or more events and topics covered in an article, leading to an information network of articles that can be explored in a thematic and particular chronological fashion. For this, we propose a measure for the relatedness of articles that is primarily based on temporal expressions in articles but also exploits other information such as persons mentioned and keywords. We provide a comprehensive evaluation that demonstrates the functionality of our framework using a multi-source corpus of recent German news articles.",2,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951951192,Conference Proceeding,2015-06-21,10.1145/2756406.2756919,204,9781450335942,15525996,195-204,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,195,http://api.elsevier.com/content/abstract/scopus_id/84951951192,2015-June,84951951192,145752,p,Time will Tell: Temporal Linking of News Stories
"© 2015 ACM. When users post links to web pages in Twitter there is a time delta between when the post was shared (t tweet ) and when it was read (t click ). Ideally, when this time delta is small there is often no change in the page's state. However upon reading shared content in the past and due to the dynamic nature of the web, the page's state could change and the intention of the author need to be inferred. In this work, we enhance a prior temporal intention model and tackle its shortcomings by incorporating extended linguistic feature analysis, replacing the prior textual similarity measure with semantic similarity one based on latent topic detection trained on Wikipedia English corpus, and finally by enriching and balancing the training dataset. We uncovered three different intention behaviors in respect to time: Stable Intention, Changing Intention from current to past, and Undefined intention. Using these classes and only the information available at posting time from the tweet and the current state of the resource, we correctly predict the temporal intention classification and strength with 77% accuracy.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952049267,Conference Proceeding,2015-06-21,10.1145/2756406.2756921,214,9781450335942,15525996,205-214,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,205,http://api.elsevier.com/content/abstract/scopus_id/84952049267,2015-June,84952049267,145752,p,Predicting Temporal Intention in Resource Sharing
"© 2015 ACM.This paper describes the results of a large survey designed to quantify the risks and threats to the preservation of the research data in the lab and to determine the mitigating actions of researchers. A total of 724 National Science Foundation awardees completed this survey. Identifying risks and threats to digital preservation has been a significant research stream. Much of this work has been within the context of a preservation technology infrastructure such as data archives for a digital repository. This study looks at the risks and threats to research data prior to its inclusion in a preservation technology infrastructure. The greatest threat to preservation is human error, followed by equipment malfunction, obsolete software, and data corruption. Lost and mislabeled media are not components in the threat taxonomies developed for repositories; however, they do represent an important threat to research data in the lab. Researchers have recognized the need to mitigate the risks inherent in maintaining digital data by implementing data management in their lab environments and have taken their responsibility as data managers seriously; however, they would still prefer to have professional data management support.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952014783,Conference Proceeding,2015-06-21,10.1145/2756406.2756909,222,9781450335942,15525996,215-222,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,215,http://api.elsevier.com/content/abstract/scopus_id/84952014783,2015-June,84952014783,145752,p,Before the Repository: Defining the Preservation Threats to Research Data in the Lab
"© 2015 ACM.It is has long been anecdotally known that web archives and search engines favor Western and English-language sites. In this paper we quantitatively explore how well indexed and archived are Arabic language web sites. We began by sampling 15,092 unique URIs from three different website directories: DMOZ (multi-lingual), Raddadi and Star28 (both primarily Arabic language). Using language identification tools we eliminated pages not in the Arabic language (e.g., English language versions of Al-Jazeera sites) and culled the collection to 7,976 definitely Arabic language web pages. We then used these 7,976 pages and crawled the live web and web archives to produce a collection of 300,646 Arabic language pages. We discovered: 1) 46% are not archived and 31% are not indexed by Google (www.google.com), 2) only 14.84% of the URIs had an Arabic country code top-level domain (e.g., .sa) and only 10.53% had a GeoIP in an Arabic country, 3) having either only an Arabic GeoIP or only an Arabic top-level domain appears to negatively impact archiving, 4) most of the archived pages are near the top level of the site and deeper links into the site are not well-archived, 5) the presence in a directory positively impacts indexing and presence in the DMOZ directory, specifically, positively impacts archiving.",3,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952053298,Conference Proceeding,2015-06-21,10.1145/2756406.2756912,232,9781450335942,15525996,223-232,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,223,http://api.elsevier.com/content/abstract/scopus_id/84952053298,2015-June,84952053298,145752,p,How Well Are Arabic Websites Archived?
"© 2015 ACM.The citation of resources is a fundamental part of scholarly discourse. Due to the popularity of the web, there is an increasing trend for scholarly articles to reference web resources (e.g. software, data). However, due to the dynamic nature of the web, the referenced links may become inaccessible ('rotten') sometime after publication, returning a ""404 Not Found"" HTTP error. In this paper we first present some preliminary findings of a study of the persistence and availability of web resources referenced from papers in a large-scale scholarly repository. We reaffirm previous research that link rot is a serious problem in the scholarly world and that current web archives do not always preserve all rotten links. Therefore, a more pro-active archival solution needs to be developed to further preserve web content referenced in scholarly articles. To this end, we propose to apply machine learning techniques to train a link rot predictor for use by an archival framework to prioritise pro-active archiving of links that are more likely to be rotten. We demonstrate that we can obtain a fairly high link rot prediction AUC (0.72) with only a small set of features. By simulation, we also show that our prediction framework is more effective than current web archives for preserving links that are likely to be rotten. This work has a potential impact for the scholarly world where publishers can utilise this framework to prioritise the archiving of links for digital preservation, especially when there is a large quantity of links to be archived.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951974381,Conference Proceeding,2015-06-21,10.1145/2756406.2756940,236,9781450335942,15525996,233-236,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,233,http://api.elsevier.com/content/abstract/scopus_id/84951974381,2015-June,84951974381,145752,p,No More 404s: Predicting Referenced Link Rot in Scholarly Articles for Pro-Active Archiving
"© 2015 ACM.Additional content for video games such as mods (modifications) or DLC (downloadable content) are increasingly prevalent in the current video game market. For cultural heritage institutions with video game collections, such content introduces various philosophical and practical challenges on multiple aspects including acquisition, description, access/use, and preservation. In this paper, we discuss these challenges and propose a solution that can alleviate the problem of managing a digital library collection including video games with additional content. While our discussion and proposed solution focus on video games, they also have broader implications for cultural heritage institutions that manage other types of digital and multimedia objects with additional content as well as serial publications.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951956404,Conference Proceeding,2015-06-21,10.1145/2756406.2756949,240,9781450335942,15525996,237-240,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,237,http://api.elsevier.com/content/abstract/scopus_id/84951956404,2015-June,84951956404,145752,p,"The Problem of ""additional Content"" in Video Games"
"© 2015 Authors.We describe a web archiving application that handles server errors using the most recently archived representation of the requested web resource. The application is developed as an Apache module. It leverages the transactional web archiving tool SiteStory, which archives all previously accessed representations of web resources originating from a website. This application helps to improve the website's quality of service by temporarily masking server errors from the end user and gaining precious time for the system administrator to debug and recover from server failures. By providing pertinent support to website operations, we aim to reduce the resistance to transactional web archiving, which in turn may lead to a better coverage of web history.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951960380,Conference Proceeding,2015-06-21,10.1145/2756406.2756955,242,9781450335942,15525996,241-242,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,241,http://api.elsevier.com/content/abstract/scopus_id/84951960380,2015-June,84951960380,145752,p,Using Transactional Web Archives to Handle Server Errors
"© 2015 Authors. We describe the mobile app \emph{Mobile Mink} which extends Mink, a browser extension that integrates the live and archived web. Mobile Mink discovers mobile and desktop URIs and provides the user an aggregated TimeMap of both mobile and desktop mementos. Mobile Mink also allows users to submit mobile and desktop URIs for archiving at the Internet Archive and Archive.today. Mobile Mink helps to increase the archival coverage of the growing mobile web.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951937099,Conference Proceeding,2015-06-21,10.1145/2756406.2756956,244,9781450335942,15525996,243-244,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,243,http://api.elsevier.com/content/abstract/scopus_id/84951937099,2015-June,84951937099,145752,p,Mobile Mink: Merging Mobile and Desktop Archived Webs
"© 2015 Author. In the field of academic document search, citations are often used for measuring implicit relationships between documents. Recently, some studies have attempted to extend co-citation searching. However, these studies mainly focus on comparisons of traditional co-citation and extended co-citation search methods; combination effects of word-based and extended co-citation search algorithms have not yet been sufficiently evaluated. This paper empirically evaluates the search performance of the combination search by using a test collection comprising about 152,000 documents and a metric 'precision at k.' The experimental results indicate that the combination search outperforms two baseline methods: a word-based search and a combination search of word-based and traditional co-citation search algorithms.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951950396,Conference Proceeding,2015-06-21,10.1145/2756406.2756957,246,9781450335942,15525996,245-246,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,245,http://api.elsevier.com/content/abstract/scopus_id/84951950396,2015-June,84951950396,145752,p,Combination Effects of Word-based and Extended Co-citation Search Algorithms
"© 2015 Authors.With the increasing number of multilingual webpages on the Internet, cross-language information retrieval has become an important research issue. Using Activity Theory as a theoretical framework, this study employs semi-structured interviews with key informants who are frequent users of Chinese-English mixed language queries in web searching. The findings present the context of and reasons for using Chinese-English mixed language queries, which can inform the design of cross-language controlled vocabularies and information retrieval systems.",2,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951965712,Conference Proceeding,2015-06-21,10.1145/2756406.2756958,248,9781450335942,15525996,247-248,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,247,http://api.elsevier.com/content/abstract/scopus_id/84951965712,2015-June,84951965712,145752,p,Studying Chinese-English Mixed Language Queries from the User Perspectives
"© 2015 Authors. This poster presents preliminary findings of user tag analysis in the domain of consumer health information. To obtain user terms, 36,205 tags from 38 consumer health information sites were collected from delicious.com. Content analysis was applied to identify the dimensions and types of the collected tags. The preliminary findings showed that user generated tags covers a variety of aspects of health information, ranging from general terms, subject terms, knowledge type, and to audience. General terms and subject terms were observed dominantly by showing 31.7% and 22.8% respectively.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951954702,Conference Proceeding,2015-06-21,10.1145/2756406.2756959,250,9781450335942,15525996,249-250,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,249,http://api.elsevier.com/content/abstract/scopus_id/84951954702,2015-June,84951954702,145752,p,Content Analysis of Social Tags Generated by Health Consumers
"© 2015 Authors.Exploring the accumulative nature of Internet documents has become a rising issue that requires systematic ways to construct what we need from what we have. Manual and semi-manual document classification techniques have facilitated retrieval and maintenance of document repositories for easy access; however, they are customarily painstaking and labor-intensive. Herein, we propose a document classification model using automatic access of natural language meaning. The model is made up of application, business, and storage layers. The business layer, as a core component, automatically extracts sentences containing keywords from research documents and classifies them using the geometrical similarity of their sentential entailments.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951950382,Conference Proceeding,2015-06-21,10.1145/2756406.2756960,252,9781450335942,15525996,251-252,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,251,http://api.elsevier.com/content/abstract/scopus_id/84951950382,2015-June,84951950382,145752,p,Automatic Classification of Research Documents using Textual Entailment
"© 2015 Authors. With the increasing popularity of e-books and audiobooks provided by public libraries in the U.S., the demand does not seem to be met with sufficient supply, as many popular titles require months of waiting time. In this study, we collected data from the Wisconsin Public Library Consortium's digital libraries service once a day for more than two months for selected popular titles. This data reflects the current supply and demand of popular titles in public libraries' digital library services. Based on our data analysis and observation, we suggest ways to achieve faster circulation, which ultimately allows for better services to library users.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951951574,Conference Proceeding,2015-06-21,10.1145/2756406.2756961,254,9781450335942,15525996,253-254,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,253,http://api.elsevier.com/content/abstract/scopus_id/84951951574,2015-June,84951951574,145752,p,Case Study of Waiting List on WPLC Digital Library
"© 2015 Author.Due to the large volume and complexity of data, exploring data using visual analytics has become more helpful to interpret and analyze it. The box plot is one of graphical ways and is the most common technique for presenting and summarizing statistics. In this paper, we focus on discussing the tagging patterns by integrating visualization assessment using the box plot with the Shapiro-Wilk test.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951996768,Conference Proceeding,2015-06-21,10.1145/2756406.2756962,256,9781450335942,15525996,255-256,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,255,http://api.elsevier.com/content/abstract/scopus_id/84951996768,2015-June,84951996768,145752,p,Analyzing Tagging Patterns by Integrating Visual Analytics with the Inferential Test
"© 2015 Authors.Classifying publication venues into top-tier or non top-tier is quite subjective and can be debatable at times. sIn this paper, we propose ConfAssist, a novel assisting framework for conference categorization that aims to address the limitations in the existing systems and portals for venue classification. We identify various features related to the stability of conferences that might help us separate a top-tier conference from the rest of the lot. While there are many clear cases where expert agreement can be almost immediately achieved as to whether a conference is a top-tier or not, there are equally many cases that can result in a conflict even among the experts. ConfAssist tries to serve as an aid in such cases by increasing the confidence of the experts in their decision. A human judgment survey was conducted with 28 domain experts. The results were quite impressive with 91.6% classification accuracy.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952050532,Conference Proceeding,2015-06-21,10.1145/2756406.2756963,258,9781450335942,15525996,257-258,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,257,http://api.elsevier.com/content/abstract/scopus_id/84952050532,2015-June,84952050532,145752,p,ConfAssist: A Conflict Resolution Framework for Assisting the Categorization of Computer Science Conferences
"© 2015 Authors.Historically, supervised methods have been the most effective ones for author name disambiguation tasks. In here, we propose a specific manner to combine supervised techniques along with user feedback. Although, we use supervised techniques, the only user effort is to provide feedback on results since initial training data is automatically generated. Our experiments show gains up to 20% in the disambiguation performance against representative baselines.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952016776,Conference Proceeding,2015-06-21,10.1145/2756406.2756964,260,9781450335942,15525996,259-260,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,259,http://api.elsevier.com/content/abstract/scopus_id/84952016776,2015-June,84952016776,145752,p,Combining Classifiers and User Feedback for Disambiguating Author Names
© 2015 Authors. This poster presents a pragmatic risk assessment method based on best practice from the ISO 31000 family of standards regarding risk management. The method proposed is supported by established risk management concepts that can be applied to help a data repository to gain awareness of the risks and costs of the controls for the identified risks. In simple terms the technique that supports this method is a pragmatic risk registry that can be used to identify risks from a Business Model Canvas of an organization. A Business Model Canvas is a model used in strategic management to document existing business models and develop new ones.,0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951971366,Conference Proceeding,2015-06-21,10.1145/2756406.2756965,262,9781450335942,15525996,261-262,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,261,http://api.elsevier.com/content/abstract/scopus_id/84951971366,2015-June,84951971366,145752,p,Using the Business Model Canvas to Support a Risk Assessment Method for Digital Curation
"© 2015 Authors.It is not unusual for digital collections to degrade and suffer from problems associated with unexpected change. In an analysis of the ACM conference list, we found that categorizing the degree of change affecting a digital collection over time is a difficult task. More specifically, we found that categorizing this degree of change is not a binary problem where documents are either unchanged or they have changed so dramatically that they do not fit within the scope of the collection. It is, in part, a characterization of the intent of the change. In this work, we examine and categorize the various degrees of change that digital documents endure within the boundaries of an institutionally managed repository.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951937240,Conference Proceeding,2015-06-21,10.1145/2756406.2756966,264,9781450335942,15525996,263-264,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,263,http://api.elsevier.com/content/abstract/scopus_id/84951937240,2015-June,84951937240,145752,p,Grading Degradation in an Institutionally Managed Repository
"© 2015 Authors. We propose a novel graph-based approach for constructing concept hierarchy from a large text corpus. Our algorithm incorporates both statistical co-occurrences and lexical similarity in optimizing the structure of the taxonomy. To automatically generate topic-dependent taxonomies from a large text corpus, we first extracts topical terms and their relationships from the corpus. The algorithm then constructs a weighted graph representing topics and their associations. A graph partitioning algorithm is then used to recursively partition the topic graph into a taxonomy. For evaluation, we apply our approach to articles, primarily computer science, in the CiteSeerX digital library and search engine.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951972499,Conference Proceeding,2015-06-21,10.1145/2756406.2756967,266,9781450335942,15525996,265-266,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,265,http://api.elsevier.com/content/abstract/scopus_id/84951972499,2015-June,84951972499,145752,p,Automatically Generating a Concept Hierarchy with Graphs
"© 2015 Authors.Taxonomy is a useful and ubiquitous way to organize knowledge. As online education attracting more and more attention, organizing lecture notes or exercises, from different online sources, in a more structured form has become an effective way to navigate users to better access course materials. However, it is expensive and time consuming to manually annotate large amounts of corpora to build a detailed taxonomy. In this paper, we propose a taxonomy induction framework with limited human involvement. We also show that the constructed taxonomy can be used to improve lecture notes/exercises recommendations.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951916625,Conference Proceeding,2015-06-21,10.1145/2756406.2756968,268,9781450335942,15525996,267-268,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,267,http://api.elsevier.com/content/abstract/scopus_id/84951916625,2015-June,84951916625,145752,p,Taxonomy Induction and Taxonomy-based Recommendations for Online Courses
"© 2015 Authors.Anime is increasingly becoming recognized as an important commercial product and cultural artifact. However, little is known regarding users' information needs and behavior related to anime. This study specifically attempts to improve our understanding of how people seek anime recommendations. We analyzed 546 user questions in natural language, collected from a Korean Q&A website Naver Knowledge-iN, where users are asking for anime recommendations. The findings suggest the importance of establishing robust metadata for the seven commonly used features for anime recommenders (i.e., title, genre, artistic style, story, character description, series title, and mood) in digital libraries, as well as allowing users to specify known anime and series titles as examples for seeking similar items, or examples of the kinds of items to be excluded.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952039170,Conference Proceeding,2015-06-21,10.1145/2756406.2756969,270,9781450335942,15525996,269-270,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,269,http://api.elsevier.com/content/abstract/scopus_id/84952039170,2015-June,84952039170,145752,p,Analyzing User Requests for Anime Recommendations
"© 2015 Authors.The Computational Collection Description project is developing mechanisms for generating field-specific collection-level descriptors from item values. Using the Digital Public Library of America (DPLA) as a sample data set, we describe a flexible, extensible architecture for processing field-level values, an augmented Collection class to record the generated metadata, and our early results of enhancements for a DPLA collection.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951969128,Conference Proceeding,2015-06-21,10.1145/2756406.2756970,272,9781450335942,15525996,271-272,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,271,http://api.elsevier.com/content/abstract/scopus_id/84951969128,2015-June,84951969128,145752,p,Computationally Supported Collection-level Descriptions in Large Heterogeneous Metadata Aggregations
"© 2015 Authors.This paper describes a Machine Learning (ML) approach for extracting named entities and disambiguating the location of tweets based on those named entities and related content. We conducted experiments with tweets (e.g., about potholes), and found significant improvement in disambiguating tweet locations using a ML algorithm along with the Stanford NER. Adding state information predicted by our classifiers increases the possibility to find the state-level geo-location unambiguously by up to 80%.",3,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951928952,Conference Proceeding,2015-06-21,10.1145/2756406.2756971,274,9781450335942,15525996,273-274,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,273,http://api.elsevier.com/content/abstract/scopus_id/84951928952,2015-June,84951928952,145752,p,Read between the lines: A Machine Learning Approach for Disambiguating the Geo-location of Tweets
"© 2015 Author. Faceted browsing has become ubiquitous with modern digital libraries and online search engines, yet the process is still difficult to abstractly model in a manner that supports the development of interoperable and reusable interfaces. Existing efforts in facet modeling are based upon set theory, formal concept analysis, and light-weight ontologies, but in many regards, they are implementations of faceted browsing rather than a specification of the basic, underlying structures and interactions. We propose category theory as a theoretical foundation for faceted browsing and demonstrate how the interactive process can be mathematically abstracted in a way that naturally supports interoperability and reuse.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951947206,Conference Proceeding,2015-06-21,10.1145/2756406.2756972,276,9781450335942,15525996,275-276,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,275,http://api.elsevier.com/content/abstract/scopus_id/84951947206,2015-June,84951947206,145752,p,Modeling Faceted Browsing with Category Theory to Support Interoperability and Reuse
© 2015 Authors.The process of merging two or more library catalogues is considered in this paper. It's necessary to solve the problem of duplicate detection and merging into one database instead of simple union of different resources. The toolbox Cflib for duplicate detection and merging has been developed by us. It's based on standard principles of record linkage and has quite simple architecture.,1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952014397,Conference Proceeding,2015-06-21,10.1145/2756406.2756973,278,9781450335942,15525996,277-278,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,277,http://api.elsevier.com/content/abstract/scopus_id/84952014397,2015-June,84952014397,145752,p,An Instrument for Merging of Bibliographic Databases
"© 2015 Authors.Video and audio recordings serve as a primary data source in many fields, especially in the social and behavioral sciences. Recordings present unique opportunities for reuse and reanalysis for novel scientific purposes, but also present challenges related to respecting the privacy of individuals depicted. Databrary is a web-based service for sharing and reusing the video data created by researchers in the developmental and learning sciences. By investigating how researchers organize, analyze, and mine their own recordings, we have implemented a system that empowers researchers to capture, store, and share recordings in a standardized way. This demo will provide a tour through the Databrary service, highlighting how it promotes storage, management, sharing, and reuse of research data, controls access privileges to restricted human subject data, and facilitates browsing and discoverability of datasets.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952062599,Conference Proceeding,2015-06-21,10.1145/2756406.2756951,280,9781450335942,15525996,279-280,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,279,http://api.elsevier.com/content/abstract/scopus_id/84952062599,2015-June,84952062599,145752,p,Databrary: Enabling Sharing and Reuse of Research Video
"© 2015 Authors. The goal of the RMap Project is to create a prototype service that can capture and preserve maps of relationships amongst the increasingly distributed components (article, data, software, workflow objects, multimedia, etc.) that comprise the new model for scholarly publication. The demonstration will provide a tour of some of the features of the initial web service prototype. This will include examples of Distributed Scholarly Complex Objects (DiSCOs) and associated provenance data in RMap, as well as some of the options that users might have for interacting with the framework.",4,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952038141,Conference Proceeding,2015-06-21,10.1145/2756406.2756952,282,9781450335942,15525996,281-282,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,281,http://api.elsevier.com/content/abstract/scopus_id/84952038141,2015-June,84952038141,145752,p,The RMap Project: Capturing and Preserving Associations amongst Multi-Part Distributed Publications
"© 2015 Authors. This paper presents 5ex+y, a system that is able to extract, index and query mathematical content expressed as mathematical expressions, complementing the CERN Document Server (CDS). We present the most important aspects of its design, our approach to model the relevant features of the mathematical content, and provide a demonstration of its searching capabilities.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951996872,Conference Proceeding,2015-06-21,10.1145/2756406.2756953,284,9781450335942,15525996,283-284,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,283,http://api.elsevier.com/content/abstract/scopus_id/84951996872,2015-June,84951996872,145752,p,5e{x+y}: Searching over Mathematical Content in Digital Libraries
"© 2015 Author. The Web idea started on 1989 with a proposal from Sir Tim Berners-Lee. The first US website has been developed at SLAC on 1991. This early version of the Web and the subsequent updates until 1998 have been preserved by SLAC archive and history office for many years. In this paper, we discuss the strategy and techniques to reconstruct this early website and make it available through Stanford Web Archive Portal.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951924396,Conference Proceeding,2015-06-21,10.1145/2756406.2756954,286,9781450335942,15525996,285-286,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,285,http://api.elsevier.com/content/abstract/scopus_id/84951924396,2015-June,84951924396,145752,p,Reconstruction of the US First Website
"© 2015 Authors. The organisation of personal data is receiving increasing research attention due to the challenges that are faced in gathering, enriching, searching and visualising this data. Given the increasing quantities of personal data being gathered by individuals, the concept of a lifelong digital library of rich multimedia and sensory content for every individual is becoming a reality. This panel brought together researchers from different parts of the information retrieval and digital libraries community to debate the opportunities and challenges for researchers in this new and challenging area.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952052673,Conference Proceeding,2015-06-21,10.1145/2756406.2756974,,9781450335942,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,287,http://api.elsevier.com/content/abstract/scopus_id/84952052673,2015-June,84952052673,145752,p,Lifelong Digital Libraries
"© 2015 Author. This tutorial is a thorough and deep introduction to the DL field, providing a firm foundation: covering key concepts and terminology, as well as services, systems, technologies, methods, standards, projects, issues, and practices. It introduces and builds upon a firm theoretical foundation (starting with the '5S' set of intuitive aspects: Streams, Structures, Spaces, Scenarios, Societies), giving careful definitions and explanations of all the key parts of a 'minimal digital library', and expanding from that basis to cover key DL issues. Illustrations come from a set of case studies. Attendees will be exposed to four Morgan & Claypool books that elaborate on 5S, 2012-2014. Complementing the coverage of '5S' will be an overview of key aspects of the DELOS Reference Model and DL.org activities. Further, use of a Hadoop cluster supporting DLs will be described.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951996339,Conference Proceeding,2015-06-21,10.1145/2756406.2756927,,9781450335942,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,291,http://api.elsevier.com/content/abstract/scopus_id/84951996339,2015-June,84951996339,145752,p,Introduction to Digital Libraries
© 2015 Authors. This paper describes a detailed description of a full-day data digital curation tutorial held at JCDL'15.,0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951923779,Conference Proceeding,2015-06-21,10.1145/2756406.2756928,294,9781450335942,15525996,293-294,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,293,http://api.elsevier.com/content/abstract/scopus_id/84951923779,2015-June,84951923779,145752,p,Digital Data Curation Essentials for Data Scientists and Data Curators and Librarians
"© 2015 Authors.In this half-day tutorial, we will show 1) how the HathiTrust Research Center (HTRC) Data Capsule can be used for non-consumptive research over collection of texts and 2) how integrated tools for LDA topic modeling and visualization can be used to drive formulation of new research questions. Participants will be given an account in the HTRC Data Capsule and taught how to use the workset manager to create a corpus, and then use the VM's secure mode to download texts and analyze their contents.",1,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951951245,Conference Proceeding,2015-06-21,10.1145/2756406.2756929,,9781450335942,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,295,http://api.elsevier.com/content/abstract/scopus_id/84951951245,2015-June,84951951245,145752,p,Topic Exploration with the HTRC Data Capsule for Non-Consumptive Research
"© 2015 Authors.Name ambiguity in the context of bibliographic citation records is a hard problem that affects the quality of services and content in digital libraries and similar systems. This problem occurs when an author publishes works under distinct names or distinct authors publish works under similar names. The challenges of dealing with author name ambiguity have led to a myriad of name disambiguation methods. In this tutorial, we characterize such methods by means of a proposed taxonomy, present an overview of some of the most representative ones and discuss open challenges.",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84952061779,Conference Proceeding,2015-06-21,10.1145/2756406.2756930,298,9781450335942,15525996,297-298,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,297,http://api.elsevier.com/content/abstract/scopus_id/84952061779,2015-June,84952061779,145752,p,Automatic Methods for Disambiguating Author Names in Bibliographic Data Repositories
"© 2015 Authors. This workshop will explore integration of Web archiving and digital libraries, so the complete life cycle involved is covered: creation/authoring, uploading/publishing in the Web (2.0), (focused) crawling, indexing, exploration (searching, browsing), ..., archiving (of events). It will include particular coverage of current topics of interest:, big data, mobile web archiving, and systems (e.g., Memento, SiteStory, Uninterruptible Web Service).",0,Institute of Electrical and Electronics Engineers Inc.,2-s2.0-84951916153,Conference Proceeding,2015-06-21,10.1145/2756406.2756934,,9781450335942,15525996,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries,303,http://api.elsevier.com/content/abstract/scopus_id/84951916153,2015-June,84951916153,145752,p,Web Archiving and Digital Libraries (WADL)
